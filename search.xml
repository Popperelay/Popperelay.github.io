<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[深入理解计算机系统第二章 信息的表示和处理]]></title>
    <url>%2F2018%2F06%2F20%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%BA%8C%E7%AB%A0%E4%BF%A1%E6%81%AF%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%92%8C%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[信息存储 字数据大小每台计算机都有一个字长（word size），指明指针数据的标称大小（normal size）。因为虚拟地址是以这样的一个字来编码的，所以字长决定的最重要的系统参数就是虚拟地址空间的最大大小。也就是说，对于一个字长为$\omega$位的机器而言，虚拟地址的范围为$0 \sim 2^\omega-1$，程序最多访问$2^\omega$个字节。 我们将程序称为“32位程序”或“64位程序”时，区别在于该程序是如何编译的，而不是其运行的机器类型。即用32位还是64位指令来编译的： linux> gcc -m32 prog.c linux> gcc -m64 prog.c C语言数据类型中，有两种数据类型大小与程序字长有关： long和unsigned long类型，在32位程序里是4个字节，在64位程序里是8个字节。 指针类型char*，在32位程序里是4个字节，在64位程序里是8个字节（指针使用的是程序的全字长）。 许多程序员假设一个声明为int类型的程序对象能被用来存储一个指针。这在多数32位的机器上能正常工作，但是在一台64位的机器上却会出问题。因为在64位程序里，指针时64位，不能用32位的int类型来存储。 寻址和字节顺序某些机器选择在内存中按照从最低有效字节到最高有效字节的顺序存储对象，而另一些机器则按照从最高有效字节到最低有效字节的顺序存储。前一种规则——最低有效字节在最前面的方式，称为小端法（little endian），后一种规则——最高有效字节在最前面的方式，称为大端法（big endian）。比如有一个变量x的类型为int，位于地址0x100处，它的十六进制值为0x01234567，下图分别是按照小端法和大端法来存储该变量值的方式：注意，在字0x01234567中，高位字节的十六进制值为0x01，而低位字节值为0x67（有个很好的记法：地址由小到大增加时，如果存储的值的顺序和对应变量的十六进制表示顺序相同，则是大端法，顺序相反则是小端法）。 大多数Intel兼容机都只用小端模式，但是IBM和Oracle的大多数机器则是按照大端模式操作。许多比较新的微处理器是双端法（bi-endian），也就是说可以把它们配置成大端或者小端的机器运行。然而，实际情况是：一旦选择了特定操作系统，那么字节顺序也就固定下来（因为一种操作系统可能只能运行于大端或者小端模式）。 大多数情况下，大端或者小端机器所编译的程序会得到同样的结果。但是有时候，大端还是小端的字节顺序会成为问题： 首先是在不同类型的机器之间通过网络传送二进制数据时，一个常见的问题是当小端法机器产生的数据被发送到大端法机器或者反过来时，接收程序会发现，字里的字节成了反序的。为了避免这类问题，网络应用程序的代码编写必须遵守已建立的关于字节顺序的规则，以确保发送方机器将它的内部表示转换成网络标准，而接收机器则将网络标准转换为它的内部表示。 第二种情况是，当阅读表示整数数据的字节序列时字节顺序也很重要。比如下面的机器级代码：4004d3: 01 05 43 0b 20 00 add %eax,0x200b43(%rip) 这一行是由反汇编器（disassembler）生成的，反汇编器是一种可确定可执行程序文件所表示的指令序列的工具。这行代码的意思是：把一个字长的数据加到一个值上，该值的存储地址由0x200b43加上当前程序计数器的值得到。如果取出这个序列的最后4个字节：43 0b 20 00，并且按照相反的顺序（小端法）写出，我们得到00 20 0b 43。去掉开头的0，得到值0x200b43，这就是右边要加的数值；但是如果是大端法，那么要加的值就是0x430b2000了。 第三种情况是当编写规避正常的类型系统的程序时（比如强制类型转换）。比如下面的代码使用强制类型转换来规避类型系统，来打印程序对象的字节表示： typedef unsigned char* byte_pointer; void showBytes(byte_pointer vStart, size_t vLen) { for (size_t i = 0; i &lt; vLen; ++i) printf("%.2x ", vStart[i]); std::cout &lt;&lt; std::endl; } void showInt(int vValue) { showBytes((byte_pointer)(&amp;vValue), sizeof(int)); } void showFloat(float vValue) { showBytes((byte_pointer)(&amp;vValue), sizeof(float)); } void showPointer(void *vPointer) { showBytes((byte_pointer)(&amp;vPointer), sizeof(void*)); } int main() { int IValue = 12345; float FValue = (float)IValue; int *pValue = &amp;IValue; showInt(IValue); showFloat(FValue); showPointer(pValue); return 0; } 上面程序使用(byte_pointer)将指针&amp;vValue强制类型转换为unsigned char *，它告诉编译器，程序应该把这个指针看成指向一个字节序列，而不是指向一个原始数据类型的对象。运行结果如下： 39 30 00 00 00 e4 40 46 14 fa cf 00 数字12345的十六进制表示为0x00003039，本机输出它的十六进制表示是0x3930000，说明笔者本机是小端法机器。虽然上面的整型和浮点型数据都是对数值12345的编码，但是它们有截然不同的字节模式，整型为0x00003039，浮点型为0x4640E400，将他俩分别展开为二进制形式，如下： 00000000000000000011000000111001 ************* 01000110010000001110010000000000 会发现它俩有一个13位相匹配的位序列（星号标出来那一串），这当然不是巧合，后文研究浮点数表示格式时会见分晓。 表示字符串在使用ASCII码作为字符码的任何系统上都将得到相同的结果，与字节顺序和字大小规则无关。因此，使用ASCII码表示的文本数据比二进制数据具有更强的平台独立性。二进制代码是不兼容的，很少有二进制代码能够在不同机器和操作系统组合之间移植。 C语言中的位级运算位级运算的一个常见用法就是实现掩码运算，这里掩码是一个位模式，表示从一个字中选出的位的集合。比如位级运算x&amp;0xFF将会生成一个由x的最低有效字节组成的值，而其他自己被置位0。 C语言中的移位运算 左移：C表达式x&lt;&lt;k会生成一个值：x向左移动k位，并在右端补k个0。 右移：右移x&gt;&gt;k有两种：逻辑右移和算术右移。逻辑右移是直接在左端补k个0；而算术右移是在左端补k个最高有效位的值（最高有效位是1就补1，是0就补0，它对有符号整数数据的运算非常有用）。 因为算术右移补的实际上是符号位（最高有效位），所以只有有符号数才存在算术右移，无符号数不存在算术右移，它只有逻辑右移。 C语言标准并没有明确定义对于有符号数应该使用哪种类型的右移：算术右移或者逻辑右移都可以。不幸的是，这就意味着任何假设一种或者另一种右移形式的代码都可能会遇到可移植性问题。然而实际上，几乎所有的编译器/机器组合都对有符号数使用算术右移，且许多程序员也都假设机器会使用这种右移。与C相比，Java对于如何进行右移有明确的定义：表达式x&gt;&gt;k会将x算术右移k个位置，而x&gt;&gt;&gt;k会对x做逻辑右移。 如果数据只有w位，但是要求移动k位而且k&gt;=w，C语言规定这种情况下实际上移动的是k%w位。 整数表示 整型数据类型对于有符号数据类型，它们的取值范围不是对称的：负数的范围比正数的范围大1。 C和C++都支持有符号（默认）和无符号数。Java只支持有符号数。 无符号数的编码无符号数编码定义如下(B2U是Binary to Unsigned的缩写)：对向量$\vec x=[x_{\omega-1}, x_{\omega-2}, …, x_0]$：$$B2U_{\omega}(\vec x) \doteq \sum_{i=0}^{\omega-1} x_i 2^i$$也就是说无符号数编码其实就是每个二进制位对应的二次幂的加和。 补码编码最常见的有符号数的计算机表示方式是补码形式。有符号数补码编码的定义如下（B2T是Binary to Two’s-complement的缩写）：对向量$\vec x=[x_{\omega-1}, x_{\omega-2}, …, x_0]$：$$B2T_{\omega}(\vec x) \doteq -x_{\omega-1}2^{\omega-1}+\sum_{i=0}^{\omega-2}x_i2^i $$也就是说补码编码实际上是最高位（符号位）的二次幂的负数，加上其余位的二次幂的和。如下：$$B2T_4([1011])=-1 \cdot 2^3+ 0 \cdot 2^2+1\cdot2^1+1\cdot2^0=-8+0+2+1=-5$$从无符号数编码和补码编码的定义上我们可以很容易得知，对于16位的编码，最小的无符号数$UMin_{\omega}$=0x0000=0，最大的无符号数$UMax_{\omega}$=0xFFFF=65535，最小的补码$TMin_{\omega}$=0x8000=-32768，最大的补码$TMax_{\omega}$=0x7FFF=32767。而且-1的补码编码是0xFFFF，0的补码编码是0x0000。 也可以看到补码编码下负数的表示范围总比正数的表示范围大1，之所以会有这样的不对称性，是因为一半的位模式（符号位设置为1的数）表示负数，一般的位模式（符号位设置为0的数）表示非负数，然后0恰好是非负数，当然就导致补码编码能表示的正数比负数少了一个。 有符号数还有其他两种表示方法：反码和原码。反码编码(Ones’ Complement)定义如下：$$B2O_{\omega}(\vec x) \doteq -x_{\omega-1}(2^{\omega-1}-1)+\sum_{i=0}^{\omega-2}x_i2^i$$可以看到除了符号位的权是$-(2^{\omega-1}-1)$而不是$-2^{\omega-1}$以外，反码和补码的定义几乎是一样的。 原码编码(Sign-Magnitude)定义如下：$$B2S_{\omega}(\vec x) \doteq (-1)^{x_{\omega-1}}\cdot(\sum_{i=0}^{\omega-2}x_i2^i)$$可以看到原码实际上是除了符号位以外的其余位的二次幂的加和，再乘上符号位（符号位是0就乘1，符号位是1就乘-1）。 这两种表示方法都一个奇怪的数学，那就是对于数字0有两种不同的编码方式，它们都把[00…0]都解释为+0；-0在原码中是[10…0]，在反码中是[11…1]。虽然过去生成过基于反码表示的机器，但是几乎所有的现代机器都使用补码。 C语言标准并没有要求要用补码形式来表示有符号整数，但是几乎所有的机器都是这么做的。不过Java标准明确要求用补码来表示有符号整数。 有符号数和无符号数之间的转换强制类型转换时，数的底层位模式是不会变的，变的只是解释这些位的方式。比如0xFF在被解释为有符号数，按照补码编码它的值就是-1，但是按照无符号数编码它的值就是255： char N1 = 0xFF; printf("%d ", N1); unsigned char N2 = 0xFF; printf("%d ", N2); unsigned char N3 = (unsigned char)N1; printf("%d\n", N3); 输出如下： -1 255 255 从上面无符号数编码和补码编码的定义中，我们可以很容易看出当符号位为-1时：$B2U_{\omega}(\vec x)-B2T_{\omega}(\vec x)=2*2^{\omega-1}=2^{\omega}$，当然符号位为0时，这个差值为0。所以补码到无符号数的转换可以定义为如下：对满足$TMin_{\omega}\le x \le TMax_{\omega}$的$x$有：$$T2U_{\omega}(x)=\begin{cases}x+2^{\omega}, &amp; x&lt;0 \\x, &amp; x \ge 0\end{cases}$$再通俗解释一下，如果是4位长度的编码，从补码变为无符号数，最高有效位的权重从-8变为+8。因此，补码表示的负数如果看出无符号数，值会增加16。所以，补码的-5被强制转换为无符号数以后变成11，-1被变成15。 从无符号数变成补码当然就是反过来了，比如对于8位长度的编码，当无符号数处在补码能够表示的非负数范围0~127时，转换后的补码值不变；但是当无符号数处在这个范围之外时，即128~255的范围，转换后的补码值就是将该数减去$2^8=256$。所以，无符号数到补码的转换可以定义为如下：$$U2T_{\omega}(u)=\begin{cases}u, &amp; u \le TMax_{\omega} \\u-2^{\omega}, &amp; u &gt; TMax_{\omega}\end{cases}$$ C语言中的有符号数与无符号数尽管C语言标准没有指定有符号数要采用某种表示，但是几乎所有的机器都使用补码。通常，大多数数字都默认为是有符号的。例如当声明一个像12345或者0x1A2B这样的常量时，这个值就被认为是有符号的。要创建一个无符号常量，必须加上后缀字符‘U’或者‘u’，例如12345U或者0x1A2Bu。 当执行一个运算时，如果它的一个运算数是有符号的而另一个是无符号的，那么C语言会隐式地将有符号参数强制类型转换为无符号数，并假设这两个数都是非负的，来执行这个运算。例如下面的代码： unsigned int x = 0; (-1 &lt; x) ? (std::cout &lt;&lt; "Little" &lt;&lt; std::endl) : (std::cout &lt;&lt; "Greater" &lt;&lt; std::endl); 输出的并不是我们通常想要的Little，二是Greater。这是因为在进行小于运算时，由于x是无符号数，所以有符号数-1会先被转换成无符号数4294967295U，所以实际上比较的是4294967295U&lt;0U，当然输出的就是Greater了。 扩展一个数字的位表示要将一个无符号数转换为一个更大的数据类型，我们只要简单地在二进制位表示的开头添加0，这种运算被称为零扩展（zero extension）。要讲一个补码数字转换为一个更大的数据类型，可以执行一个符号扩展（sign extension），在二进制位表示的开头添加符号位。比如把0101扩展为8位变成00000101，把1101扩展为8位变成11111101。可以很简单地证明符号扩展以后的值和原来的值相等（即1101和11111101表示的是同一个数值）：对向量$\vec x=[1,x_{\omega-2},x_{\omega-3},…,x_0]$，把它从$\omega$位扩展为$\omega+k$位，变成$ \vec {x^,}=[1,…,1,1,x_{\omega-2},x_{\omega-3,…,x_0}]$，$\vec{x^,}$是在$\vec{x}$前面扩展了$k$个1。证明如下：$$\begin{align}B2T_{\omega+k}(\vec{x^,})&amp;=(-2^{\omega+k}*1+2^{\omega+k-1}*1+…+2^{\omega}*1+2^{\omega-1}*1)+(2^{\omega-2}*x_{\omega-2}+…+2^0*x_0)\\&amp;=-2^{\omega-1}*1+2^{\omega-2}*x_{\omega-2}+…+2^0*x_0\\&amp;=B2T_{\omega}(\vec x)\end{align}$$其实道理很简单，就是[111]和[111111111]其实都表示的是-1的意思。 当把short转换成unsigned（unsigned就是unsigned int）时，我们先要改变大小（从2字节扩展到4字节），之后再完成从有符号到无符号的转换。如下程序： short sx = -12345; unsigned uy = sx; showBytes((byte_pointer)&amp;uy, sizeof(unsigned)); 程序在本机（小端法机器）输出如下： c7 cf ff ff 输出结果也证明了short到unsigned的转换是先扩展大小，再从有符号转变为无符号数。如果是先从有符号转变为无符号数，uy会先变成无符号数0xcfc7，然后把该无符号数扩展为4字节0x0000cfc7；如果是先把有符号数扩展4字节，uy会先变0xffffcfc7，然后把该有符号数转换从成无符号数0xffffcfc7。 截断数字截断无符号数：令$\vec x$等于位向量$\vec x=[x_{\omega-1}, x_{\omega-2}, …, x_0]$，而$\vec {x^,}$是将其截断为$k$位的结果：$\vec x=[x_{k-1}, x_{k-2}, …, x_0]$。令$x=B2U_{\omega}(\vec x)$，$x^,=B2U_{k}(\vec {x^,})$，则$x^,=x\;mod\;2^k$。该原理背后的直觉就是：截去的部分变为0，就好像是对其取模$2^k$，前面那些位在该取模下结果都为0。 截断补码数值：令$\vec x$等于位向量$\vec x=[x_{\omega-1}, x_{\omega-2}, …, x_0]$，而$\vec {x^,}$是将其截断为$k$位的结果：$\vec x=[x_{k-1}, x_{k-2}, …, x_0]$。令$x=B2U_{\omega}(\vec x)$，$x^,=B2T_{k}(\vec {x^,})$，则$x^,=U2T_k(x\;mod\;2^k)$。该原理背后的直觉就是：和无符号数一样，在位级操作上把前k位变为0（把有符号当作无符号数来截断），然后再把截断后的二进制数解释为有符号补码数（相当于把无符号数转换为有符号补码数）。 关于有符号数与无符号数的建议先看如下代码： float sumElements(float vArray[], unsigned vLength) { float Result; for (int i = 0; i &lt;= vLength - 1; ++i) Result += vArray[i]; return Result; } 当参数vLength等于0时，运行这段代码应该返回0.0。但是实际上，运行时会遇到一个内存错误（内存冲突，无法访问的地址）。这是因为0-1的结果是一个无符号数$UMax$，所以在i递增时，代码将会试图访问数组vArray以外的非法元素。解决方案是换成&lt;vLength，或者将参数vLength声明为有符号数。再看下面的代码： int strLonger(char *vStr1, char *vStr2) { return strlen(vStr1) - strlen(vStr2) > 0; } 由于strlen函数的返回值是无符号size_t类型，所以当字符串vStr1的长度小于字符串vStr2的长度时，由于是无符号数运算，所以函数最终返回的不是0，而是1，出现错误结果。解决方案是改成return strlen(vStr1) &gt; strlen(vStr2);。 避免这类错误的一种方法就是绝不使用无符号数。实际上，除了C以外很少有语言支持无符号整数。因为这些语言的设计者认为无符号数带来的麻烦比益处多得多。比如Java只支持有符号整数，并且要求以补码运算来实现，正常的右移运算符&gt;&gt;被定义为执行算术右移，特殊的运算符&gt;&gt;&gt;被定义为逻辑右移。 整数运算 有时我们会发现，两个整数相加会得出一个负数，而比较表达式x&lt;y和比较表达式x-y&lt;0会产生不同的结果。这些都是由于计算机运算的有限性造成的（即一定字长的编码表示的数的范围有限）。 无符号加法无符号数加法：对满足$0\le x,y&lt;2^{\omega}$的$x$和$y$有：$$x+^u_{\omega}y=\begin{cases}x+y, &amp;x+y&lt;2^{\omega} &amp;正常 \\x+y-2^{\omega}, &amp;2^{\omega}\le x+y&lt;2^{\omega+1} &amp;溢出\end{cases}$$公式很好理解，就是溢出时，把溢出的那一位1给截掉。 说一个算术运算溢出，是指完整的整数结果不能放到数据类型的字长限制中去。 我们检测无符号数加法中的溢出，可以判断加法结果是否小于任何一个加数：对在范围$0\le x,y\le UMax_{\omega}$中的$x$和$y$，令$s \doteq x+^u_{\omega}y$。则对计算$s$，当且仅当$s&lt;x$（或者等价地$s&lt;y$）时，发生了溢出。对应程序如下： int uAddOK(unsigned x, unsigned y) { unsigned sum = x + y; return sum > x &amp;&amp; sum > y; } 无符号数求反：对满足$0 \le x\&lt;2^{\omega}$的任意$x$，其$\omega$位的无符号逆元$-^u_{\omega}x$由下式给出： $$-^u_{\omega}x=\begin{cases}x, &amp; x = 0\\2^{\omega}-x, &amp; y>0\end{cases}$$ 公式的原理很简单就不细说了。 补码加法补码加法：对满足$-2^{\omega-1}\le x，y\le 2^{\omega-1}-1$的整数$x$和$y$有：]]></content>
      <categories>
        <category>计算机系统</category>
      </categories>
      <tags>
        <tag>深入理解计算机系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解计算机系统第一章 计算机系统漫游]]></title>
    <url>%2F2018%2F04%2F21%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%AC%AC%E4%B8%80%E7%AB%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%BC%AB%E6%B8%B8%2F</url>
    <content type="text"><![CDATA[信息就是位+上下文 源程序实际上是0和1组成的位序列，8个位组成一个字节。每个字节表示程序程序中的某些文本字符。 大部分的现代计算机系统都使用ASCII标准来表示文本字符，这种方式实际上就是用一个唯一的单字节大小的整数值来表示每个字符。 只有ASCII字符构成的文件成文文本文件，所有其他文件都称为二进制文件。 程序被其他程序翻译成不同的格式 如下hello.c程序： #include &lt;stdio.h> int main() { printf("hello, world\n"); return 0; } 把这个源文件hello.c转换成可执行目标程序的过程是由编译系统来完成的。编译过程分为4个阶段，这4个阶段的程序：预处理器、编译器、汇编器、链接器，一起构成了编译系统。如下图所示： 预处理阶段。预处理器（cpp）根据以字符#开头的命令，修改原始的C程序hello.c。它会把对应的头文件直接插入程序文本中，得到新的C程序hello.i。 编译阶段。编译器（ccl）将预处理之后的文本文件hello.i转换成汇编语言程序hello.s： main: subq $8, %rsp movl $.LOC, %edi call puts movl $0, %eax addq $8, %rsp ret 汇编语言是非常有用的，因为它为不同高级语言的不同编译器提供了通用的输出语言。例如C编译器和Fortran编译器产生的输出文件用的都是一样的汇编语言 汇编阶段。汇编器（as）将汇编语言程序hello.s转换成二进制的可重定位目标程序hello.o。 链接阶段。注意到在程序中调用了一个printf函数，它存在于一个名为printf.o的单独的预编译好了的目标文件中，而这个文件必须以某种方式合并到我们的hello.o程序中。链接器（ld）就负责处理这种合并。链接结果会得到一个二进制的可执行目标文件hello。这个可执行目标文件后续可以被加载到内存中，由系统来执行。 GCC是GNU（GNU’s Not Unix）项目开发出来的一个编译器。 了解编译系统如何工作是大有益处的 了解编译系统如何工作会有以下几点好处： 优化程序性能。比如，一个switch语句是否总是比一些列的if-else语句高效得多？一个函数调用的开销有多大？while循环比for循环更有效吗？指针引用比数组索引更有效吗？为什么将循环求和的结果放到一个本地变量中，会比将其放到一个通过引用传递过来的参数中，运行起来快很多呢？为什么我们只是简单地重新排列一下算术表达式中的括号就能让函数运行得更快？ 理解链接时出现的错误。比如，链接器报告说它无法解析一个引用，这是什么意思？静态变量和全局变量的区别是什么？如果你在不同的C文件中定义了名字相同的两个全局变量会发生什么？静态库和动态库的区别是什么？我们在命令行上排列库的顺序有什么影响？最严重的是，为什么有些链接错误直到运行时才会出现？ 避免安全漏洞。学习安全编程的第一步就是理解数据和控制信息存储在程序栈上的方式会引起的后果。 处理器读并解释存储在内存中的指令 系统的硬件组成为了理解运行hello程序时发生了什么，我们需要了解一个典型系统的硬件组织。如下图所示： 总线总线是贯穿整个系统的一组电子管道，它携带信息字节并负责在各个部件间传递信息。通常总线被设计成传送定长的字节块，也就是字（word）。字中的字节数（即字长）是一个基本的系统参数，各个系统中都不尽相同。现在大多数机器字长要么是4个字节（32位机），要么是8个字节（64位机）。 I/O设备I/O（输入/输出）设备是系统与外部世界的联系通道。每个I/O设备都通过一个控制器或适配器与I/O总线相连。控制器和适配器之间的区别主要在于它们的封装方式。控制器是I/O设备本身或者系统的主板（主印制电路板）上的芯片组；而适配器则是一块插在主板插槽上的卡。无论如何，它们的功能都是在I/O总线和I/O设备之间传递信息。 主存主存是一个临时存储设备，在处理器执行程序时，用来存放程序和程序处理的数据。从物理上来说，主存是一组动态随机存取存储器（DRAM）芯片组成的。在运行Linux的x86-64机器上，short类型的数据需要2个字节，int和float类型需要4个字节，而long和double类型需要8个字节。 处理器中央处理单元（CPU），简称处理器，是解释（或执行）存储在主存中指令的引擎。处理器的核心是一个大小为一个字的存储设备（或寄存器），称为程序计数器（PC）。在任何时刻，PC都指向主存中的某条机器语言指令（即含有该条指令的地址）。执行一条指令包含执行一系列的步骤。处理器从程序计数器指向的内存处读取指令，解释指令中的位，执行该指令指示的简单操作，然后更新PC，使其指向下一条指令，而这条指令并不一定和在内存中刚刚执行的指令相邻。 寄存器文件是一个小的存储设备，由一些单个字长的寄存器组成，每个寄存器都有唯一的名字。ALU计算新的数据和地址值。 处理器看上去它的指令集架构的简单实现，但是实际上现代处理器使用了非常复杂的机制来加速程序的执行。 运行hello程序当我们通过键盘在终端输入“./hello”字符串以后，shell程序会将字符串逐一读入CPU的寄存器中，然后再把该字符串从寄存器放到内存中。这个过程如下图所示：当我们在键盘上输入回车键时，shell程序就知道我们已经结束了命令的输入。然后shell会执行一系列指令来加载可执行文件hello，它们会把hello文件中的代码和数据从磁盘复制到主存（数据主要是要程序中要输出的字符串“hello, world\n”，而且利用直接存储器存取（DMA）技术，代码和数据可以不通过处理器而直接从磁盘到达主存）。这个过程如下图所示：一旦可执行文件hello中的代码和数据被加载到内存，处理器就开始执行hello程序的main程序中的机器语言指令。这些指令将字符串“hello, world\n”中的字节从主存复制到CPU的寄存器文件中，然后再从寄存器文件复制到显示设备里，最终显示在屏幕上。这个过程如下图所示： 高速缓存至关重要 上面hello程序的执行过程揭示了一个重要的问题：系统花费了大量的时间把信息从一个地方挪到另一个地方。hello程序的机器指令最初是放在磁盘上，当程序加载时，它们被复制到主存；当处理器运行程序时，指令又从主存复制到处理器。相似地，数据串“hello, world\n”开始时在磁盘上，然后被复制到主存，最后从主存上复制到显式设备。从程序员的角度看，这些复制就是开销，减慢了程序“真正”的工作。但是这些复制操作又必不可少，系统设计者能做的就是让这些复制操作尽可能快地完成。 针对处理器与主存之间的差异（速度、容量、造价等等），系统设计者采用了更小更快的存储设备，称为高速缓存存储器（cache，高速缓存），作为暂时的集结区域，存放处理器近期可能会需要的信息。如下图所示：高速缓存有可能分为多级：L1、L2、L3，即多个访问速度、容量不同的高速缓存存储器（L1最快容量最小）。高速缓存是用一种叫做静态随机访问存储器（SRAM）的硬件技术实现的。 通过多级高速缓存，系统可以获得一个很大的存储器，同时访问速度也很快，其实根本原因不只是在硬件上，更在于利用了高速缓存的局部性原理，即程序具有访问局部区域的数据和代码的趋势，通过让高速缓存里存放可能经常访问的数据，大部分的内存操作都能在快速的高速缓存中完成。 意识到高速缓存存在的应用程序员，能够利用高速缓存将程序性能提高一个数量级。 存储设备形成层次结构 在处理器和一个较大较慢的设备（例如主存）之间插入一个更小更快的存储设备（例如高速缓存）的想法已经成为一个普遍的观念。所以，实际上每个计算机系统中的存储设备都被组织成了一个存储器层次结构：从上至下，设备的访问速度越来越慢、容量越来越大，并且每字节的造价也越来越便宜。 存储器层次结构的主要思想是上一层的存储器作为低一层存储器的高速缓存。 正如可以运用不同的高速缓存的知识来提高程序性能一样，程序员同样可以利用对整个存储器层次结构的理解来提高程序性能。 操作系统管理硬件 所有应用程序对硬件的操作尝试都必须通过操作系统。 操作系统有两个基本功能：1. 防止硬件被失控的应用程序滥用； 2. 向应用程序提供简单一致的机制来控制复杂而又通常大不相同的低级硬件设备。操作系统通过几个基本的抽象概念来实现这两个功能：文件（对I/O设备的抽象表示）、虚拟内存（对主存和磁盘I/O设备的抽象表示）、进程（对处理器、主存和I/O设备的抽象表示）。 进程进程是操作系统对一个正在运行的程序的一种抽象。在一个系统上每个进程都好像在独立地适用硬件。而并发运行，则是说一个进程的指令和另一个进程的指令是交错执行的。 下图展示了hello程序运行时的进程切换概念：hello程序运行时有两个并发的进程：shell进程（A）和hello进程（B）。最开始，只有shell进程在运行，即等待命令行上的输入。当我们让它运行hello程序时，shell通过调用一个专门的函数，即系统调用，来执行我们的请求，系统调用会将控制权传递给操作系统。操作系统保存shell进程的上下文，创建一个新的hello进程及其上下文，然后将控制权传给新的hello进程。hello进程终止后，操作系统恢复shell进程的上下文，并将控制权传回给它，shell进程会继续等待下一个命令行输入。 如上图中所示，从一个进程到另一个进程的转换是由操作系统内核（kernel）管理的。内核是操作系统代码常驻主存的部分。注意，内核不是一个独立的进程。相反，它是系统管理全部进程所用代码和数据结构的集合。 线程在现代系统中，一个进程实际上可以由多个称为线程的执行单元组成，每个线程都运行在进程的上下文中，并共享同样的代码和全局数据。 虚拟内存虚拟内存是一个抽象概念，它为每个进程提供了一个假象，即每个进程都在独占地适用主存。每个进程看到的内存都是一致的，称为虚拟地址空间。下图是Linux进程的虚拟地址空间（图中的地址是从下往上增大的）：每个进程看到的虚拟地址空间由大量准确定义的区构成，每个区都有专门的功能。我们从下往上介绍： 程序代码和数据。对所有的进程来说，代码是从同一固定地址开始，紧接着的是和C全局变量相对应的数据位置。 堆。代码和数据区后紧随着的是运行时堆。代码和数据区在进程一开始运行时就被指定了固定大小，而堆可以在运行时动态地扩展和收缩（动态分配内存new、delete）。 共享库。大约在地址空间的中间部分是一块用来存放像C标准库和数学库这样的共享库的代码和数据的区域。 栈。位于用户虚拟地址空间顶部的是用户栈，编译器用它来实现函数调用。和堆一样，用户栈在程序执行期间可以动态地扩展和收缩（函数调用和返回时）。 内核虚拟内存。地址空间顶部的区域是为内核保留的。不允许应用程序读写这个区域的内容或者直接调用内核代码定义的函数。 文件文件就是字节序列，仅此而已。每个I/O设备，包括磁盘、键盘、显示器，甚至网络，都可以看成是文件。系统中的所有输入输出都是通过使用一小组称为Unix I/O的系统函数调用读写文件来实现的。 系统之间利用网络通信 我们可以使用telnet应用在一个远程主机上运行hello程序。过程如下图所示： 重要主题 Amdahl定律Amdahl定律的主要思想是：当我们对系统的某个部分加速时，其对系统整体性能的影响取决于该部分的重要性和加速程度。要想显著加速整个系统，必须提升全系统中相当大的部分的速度（即优化系统的大部分组间才能获得较高的加速比）。 加速比的相关公式可以参考《深入理解计算机系统第三版》P16页。 并发和并行并发是指一个同时具有多个活动的系统，而并行是指用并发来使一个系统运行得更快。计算机系统中主要是三个层级的并发/并行： 线程级并发： 传统意义上，这种并发执行只是模拟出来的，是通过使一台计算机在它正在执行的进程间快速切换来实现的。 多核处理器是将多个CPU（称为“核”）集成到一个集成电路芯片上。下图就是一个典型多核处理器的组织结构： 超线程，有时称为同时多线程（simultaneous multi-threading），是一项允许一个CPU执行多个控制流的技术。常规的处理器需要大约20000个时钟周期做不同线程间的转换，而超线程的处理器可以在单个周期的基础上决定要执行哪一个线程。举例来说，Intel Core i7处理器可以让每个核执行两个线程，所以一个4核的系统实际上可以并行执行8个线程。 指令级并行在较低的抽象层次上，现代处理器可以同时执行多条指令的属性称为指令级并行。如果处理器可以达到比一个周期一条指令更快的执行速率，就称之为超标量处理器。大多数现代处理器都支持超标量操作。 单指令、多数据并行在最低层次上，许多现代处理器拥有特殊的硬件，允许一条指令产生多个可以并行执行的操作，这种方式称为单指令、多数据，即SIMD并行。例如，较新几代的Intel和AMD处理器都具有并行地对8对单精度浮点数（C数据类型float）做加法的指令。&nbsp; 参考文献：《深入理解计算机系统第三版》]]></content>
      <categories>
        <category>计算机系统</category>
      </categories>
      <tags>
        <tag>深入理解计算机系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++Primer第十九章 特殊工具与技术]]></title>
    <url>%2F2018%2F04%2F18%2FC%2B%2BPrimer%E7%AC%AC%E5%8D%81%E4%B9%9D%E7%AB%A0%E7%89%B9%E6%AE%8A%E5%B7%A5%E5%85%B7%E4%B8%8E%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[控制内存分配 有时候会需要自定义分配内存的细节，比如使用关键字new将对象放置在特定的内存空间中。为了实现这一目的，应用程序需要重载new运算符和delete运算符以控制内存分配的过程 在调用new或delete时，实际上是在调用一个名为operator new（或者operator new[]）或operator delete(或者operator delete[])的标准库函数。如果应用程序希望控制内存分配的过程，则它们需要定义自己的operator new函数和operator delete函数。即使在标准库中已经存在这两个函数的定义，我们仍旧可以定义自己的版本。编译器不会对这种重复的定义提出异议，相反，编译器将使用我们自定义的版本替换标准库定义的版本。 应用程序可以在全局作用域中定义operator new函数和operator delete函数，也可以将它们定义为成员函数。 标准库定义了operator new函数和operator delete函数的如下8个重载版本： //这些版本可能抛出异常 void *operator new (size_t); //分配一个对象 void *operator new[](size_t); //分配一个数组 void operator delete(void*) noexcept; //释放一个对象 void operator delete[](void*) noexcept; //释放一个数组 //这些版本承诺不会抛出异常 void *operator new (size_t, std::nothrow_t&amp;) noexcept; void *operator new[](size_t, std::nothrow_t&amp;) noexcept; void operator delete(void*, std::nothrow_t&amp;) noexcept; void operator delete[](void*, std::nothrow_t&amp;) noexcept; 应用程序可以定义上面函数版本中的任意一个。如下所示： void *operator new(size_t vSize) { if (void *pMem = std::malloc(vSize)) { std::cout &lt;&lt; "Custom new!" &lt;&lt; std::endl; return pMem; } else throw std::bad_alloc(); } void operator delete(void *vMem) noexcept { std::cout &lt;&lt; "Custom delete!" &lt;&lt; std::endl; std::free(vMem); } int *a = new int(41); std::cout &lt;&lt; *a &lt;&lt; std::endl; delete a; 程序输出如下： Custom new! 41 Custom delete! 通常情况下，new申请空间时都是在系统的“堆”上分配内存空间，而定位new可以让我们自己指定在哪个内存地址上创建对象，甚至在栈内存上创建对象都可以（注意这时是new并不分配内存空间，内存空间已经事先分配好，然后把内存地址作为参数传递给定位new）： class CData { public: CData() { std::cout &lt;&lt; "A Constructor!" &lt;&lt; std::endl; } ~CData() { std::cout &lt;&lt; "A Destructor!" &lt;&lt; std::endl; } void show() { std::cout &lt;&lt; "Data: " &lt;&lt; m_Data &lt;&lt; std::endl; } private: int m_Data; }; char Memory[100] = { 'A' }; std::cout &lt;&lt; "Memory Address: " &lt;&lt; (void*)Memory &lt;&lt; std::endl; CData *pDataObj = new (Memory) CData(); //定位new，用参数Memory指明想要在哪个内存地址上创建对象 std::cout &lt;&lt; "pDataObj Address: " &lt;&lt; pDataObj &lt;&lt; std::endl; pDataObj->show(); pDataObj->~CData(); //显式调用所创建对象的析构函数 std::cout &lt;&lt; "Memory Address: " &lt;&lt; (void*)Memory &lt;&lt; std::endl; 程序运行结果如下： Memory Address: 006FF8E8 A Constructor! pDataObj Address: 006FF8E8 Data: 65 A Destructor! Memory Address: 006FF8E8 可以看到创建出来pDataObj对象的内存地址和Memory的地址相同，说明确实是在我们指定的内存地址上创建了该对象。 有以下几点需要注意的： 使用定位new，既可以把对象放在堆上，也可以放在栈上，比如上面程序就是放在栈内存Memory上的。 使用定位new时，并没有分配内存空间，而是使用已经存在的内存空间去创建一个对象。这点很像allocator类的construct函数，也就是说除了使用allocator类，我们也可以使用定位new来达到内存分配和对象创建分离的效果。 和allocator类的destory函数类似，我们使用定位new创建一个对象后，还需要显式调用对象的析构函数，来释放该对象。 和和allocator类的destory函数类似，调用对象的析构函数并不会释放内存空间Memory，由于Memory是栈内存，所以函数退出后系统会自动释放它；如果Memory是事先分配的堆内存，那么这里我们就需要显式调用delete来释放该堆内存空间（类似allocator类的deallocate函数）。 运行时类型识别 运行时类型识别（run-time type identification，RTTI）的功能由两个运算符实现： typeid运算符，用于返回表达式的类型 dynamic_cast运算符，用于将基类的指针或引用安全地转换成派生类的指针或引用。 如果一条dynamic_cast语句的转换目标是指针类型并且失败了，则结果为0。如果转换目标是引用类型并且失败了，则dynamic_cast运算符将抛出一个bad_cast异常，该异常定义在typeinfo头文件中： CBase BaseObj; try { const CDerived &amp;DerivedObj = std::dynamic_cast&lt;const CDerived&amp;>(BaseObj); } catch (std::bad_cast e) { //处理异常类转换失败的情况 } 我们可以对一个空指针执行dynamic_cast，结果是所需类型的空指针。 typeid运算符可以得知一个对象是什么类型，形式是typeid(e)，结果是一个常量对象的引用，该对象的类型是标准库类型type_info或者它的公有派生类型。type_info类定义在头文件typeinfo中。通常情况下，我们使用typeid来比较变量的类型是否相同： int i,j; char c; std::cout &lt;&lt; std::boolalpha &lt;&lt; (typeid(i) == typeid(j)) &lt;&lt; std::endl; //输出true std::cout &lt;&lt; (typeid(i) == typeid(c)) &lt;&lt; std::noboolalpha &lt;&lt; std::endl; //输出false 当typeid运算符作用于数组或函数时，并不会执行向指针的标准类型转换。也就是说，如果我们对数组a执行typeid(a)，则所得的结果是数组类型而非指针类型。 当运算对象是定义了至少一个虚函数的类的左值时，typeid的结果直到运行时才会求得： class CBase { public: virtual void print() {} //注意基类一定要有虚函数，才会存在动态类型这一说法 }; class CDerived :public CBase { public: virtual void print() override {} }; CDerived *pDerivedObj = new CDerived(); CBase *pBaseObj = pDerivedObj; //运行时比较两个对象的类型，注意使用的是对象*pBaseObj，而非指针 std::cout &lt;&lt; std::boolalpha &lt;&lt; (typeid(*pBaseObj) == typeid(*pDerivedObj)) &lt;&lt; std::endl; //输出true //检查运行时类型是否是某种指定的类型 std::cout &lt;&lt; (typeid(*pBaseObj) == typeid(CDerived)) &lt;&lt; std::endl; //输出true //typeid作用于指针时，返回的是指针的静态编译时类型 std::cout &lt;&lt; (typeid(pBaseObj) == typeid(pDerivedObj)) &lt;&lt; std::noboolalpha &lt;&lt; std::endl; //输出false typeid通常都是作用于对象而非指针，如果作用于指针时，返回的结果是该指针的静态编译时类型。 typeid返回的是一个type_info类对象，type_info类定义了自己的相等运算符，以及一个名为name的成员函数，可以返回一个C风格字符串，表示类型名字的可打印形式： CDerived *pDerivedObj = new CDerived(); CBase *pBaseObj = pDerivedObj; int a; std::cout &lt;&lt; typeid(a).name() &lt;&lt; std::endl; std::cout &lt;&lt; typeid(pBaseObj).name() &lt;&lt; std::endl; std::cout &lt;&lt; typeid(pDerivedObj).name() &lt;&lt; std::endl; 输出如下： int class CBase * class CDerived * 值得注意的是，name的返回值因编译器而异，并且不一定与在程序中使用的名字一致。 type_info类没有默认构造函数，而且它的拷贝和移动构造函数以及赋值运算符都被定义成删除的。因此，我们无法定义或拷贝type_info类型的对象，也不能为type_info类型的对象赋值。创建type_info对象的唯一途径是使用typeid运算符。 枚举类型 枚举类型使我们可以将一组整型常量组织在一起。枚举属于字面值常量类型。 C++包含两种枚举：限定作用域的和不限定作用域的。 C++11引入了限定作用域的枚举类型，其一般形式是： enum class EDirectionType { Forward, Back, Left, Right }; enum struct EAction { Jump, Fire }; enum class和enum struct是等价的。 定义不限定作用域的枚举类型就是省略掉关键字class或struct： enum EColor { Red, Green, Blue }; 对于不限定作用域的枚举类型，其枚举成员的作用域与枚举类型本身相同，但是限定作用域的枚举类型是不同的，它必须通过：枚举类型名::枚举成员，这样的方式才能访问到内部的枚举类型： EColor C = Red; //正确，不限定作用域的枚举类型可以直接访问其枚举成员 EAction A = Jump; //错误，限定作用域的枚举类型，不可以直接访问其枚举成员 EAction A2 = EAction::Jump; //正确，限定作用域的枚举类型，可以通过作用域运算符访问到其枚举成员 枚举类型中枚举成员的值不一定唯一： enum EIntTypes { CharType = 8, IntType = 16, FloatType = 16 }; 枚举成员是const，因此在初始化枚举成员时提供的初始值必须是常量表达式。 要想初始化enum对象或者为enum对象赋值，必须使用该类型的一个枚举成员或者该类型的另一个对象。 一个不限定作用域的枚举类型的对象或枚举成员自动（隐式）地转换成整型。因此，我们可以在任何需要整型值的地方使用它们，但是限定作用域的不行： int i = EColor::Red; //正确，不限定作用域的枚举成员可以隐式转换为int int J = EAction::Jump; //错误，限定作用域的枚举成员不能隐式转换为int int J1 = static_cast&lt;int>(EAction::Jump); //正确，可以强制转换 实际上enum是由某种整数类型表示的。在C++11新标准中，我们可以在enum的名字后面加上冒号以及我们一个类型，来显式指出enum使用的具体整数类型，也就相当于指定了该enum的大小： enum EIntValues : unsigned long long { CharType = 255, IntType = 65535, LLType = 18446744073709551615ULL }; 如果我们没有指定enum的类型，则默认情况下限定作用域的enum类型是int，不限定作用的enum类型不确定，编译器会保证类型足够大，以容纳枚举值。在限定作用域的enum中，如果枚举值超过了enum类型的所能表示的大小，程序将有可能会出错。 这种指定enum类型的能力使得我们可以控制不同实现环境中使用的类型，我们将可以确保在一种实现环境中编译通过的程序锁生成的代码与其他实现环境中生成的代码一致。 类成员指针 成员指针是指可以指向类的非静态成员的指针。成员指针类型包括了类的类型以及成员的类型。初始化时，我们令其指向类的某个成员，但是不指定该成员所属的对象；直到使用该成员指针时，才提供所属的对象： class CData { public: CData(int vData) :m_Data(vData) {} public: int m_Data = 0; }; int CData::*pData = &amp;CData::m_Data; //int i = *pData; //错误，成员指针必须通过对象来访问 CData DataObj(41); std::cout &lt;&lt; DataObj.*pData &lt;&lt; std::endl; //先解引用成员指针得到对应成员，然后通过对象（这里是.，如果对象是指针，则是->）来调用该成员 成员指针必须通过对象来调用，不能像普通指针那样单独使用，因为它到底指向哪个对象的成员，是在对象调用它的时候才确定的（才确定是指向调用它的对象的对应成员）。在对象调用成员指针时，需要先解引用成员指针得到对应的成员，然后再使用调用运算符（.或者-&gt;）来访问该成员。 当然使用auto来定义和初始化成员指针最方便： auto pData = &amp;CData::m_Data; 我们也可以定义指向类的成员函数的指针： class CData { public: CData(int vData) :m_Data(vData) {} void print(const std::string &amp;vDataInfo) const { std::cout &lt;&lt; vDataInfo &lt;&lt; std::endl; } public: int m_Data = 0; }; void (CData::*pPrintFunc)(const std::string &amp;vDataInfo) const = &amp;CData::print; CData DataObj(41); (DataObj.*pPrintFunc)("Boy"); //调用成员函数指针，输出Boy 在调用时第一个括号比不可少，因为调用运算符的优先级高于指针指向成员运算符的优先级。 和普通函数指针不同的是，在成员函数和指向该成员的指针之间无法自动转换： void (CData::*pPrintFunc1)(const std::string &amp;vDataInfo) const = CData::print; //错误，成员函数名不能自动隐式转换为成员函数指针 auto pPrintFunc2 = &amp;CData::print; //正确 auto pPrintFunc3 = CData::print; //错误，理由同上 现在有一个保存有一堆string的vector，我们想要用算法find_if找到哪个个string是空的怎么办？ std::vector&lt;std::string> SVec{ "Boy","","Girl" }; auto itr = std::find_if(SVec.begin(), SVec.end(), &amp;std::string::empty); //错误，成员函数指针不是一个可调用对象 我们可以使用function函数来把成员函数指针包装成一个可调用对象： std::vector&lt;std::string> SVec{ "Boy","","Girl" }; std::function&lt;bool(const std::string&amp;)> fcn = &amp;std::string::empty; auto itr = std::find_if(SVec.begin(), SVec.end(), fcn); //正确，成员指针被包装成了可调用对象fcn 在定义function时，其中的返回值bool与成员函数empty的返回值相同，同时还要指明接受一个string类型的参数，find_if算法在调用fcn时会把具体的string对象传给它，然后它会去调用fcn中中包装的成员函数指针。也就是说，在用function包装成员函数指针时，需要声明一个可以调用该成员函数指针的类型参数。 上面使用function把成员函数指针包装成可调用对象的方式还是有点复杂，我们可以直接使用标准库函数mem_fn来生成一个可调用对象（该对象接受string，返回bool），它也定义在functional头文件中： std::vector&lt;std::string> SVec{ "Boy","","Girl" }; auto itr = std::find_if(SVec.begin(), SVec.end(), std::mem_fn(&amp;std::string::empty)); //正确，成员指针被mem_fn函数包装成了可调用对象 注意不要忘了&amp;，因为mem_fn是把成员函数指针包装成可调用对象。 我们还可以使用bind把成员函数指针包装成一个可调用对象（因为bind本身的意义就是把一个函数包装成另一个函数）： std::vector&lt;std::string> SVec{ "Boy","","Girl" }; auto itr = std::find_if(SVec.begin(), SVec.end(), std::bind(&amp;std::string::empty, std::placeholders::_1)); //正确，成员指针被bind函数封装成了可调用对象 union：一种节省空间的类 联合（union）是一种特殊的类。一个union可以有多个数据成员，但是在任意时刻只有一个数据成员可以有值。当我们给union的某个成员赋值之后，该union得其他成员就变成未定义的状态了。分配给一个union对象的存储空间至少要能容纳它的最大的数据成员。 union不能含有引用类型的成员。 和struct类似，默认情况下，union的成员都是公有的。 union既不能继承自其他类，也不能作为基类使用，所以在union中不能含有虚函数。 和其他内置类型一样，默认情况下union是未初始化的。 为union的一个数据成员赋值会令其他数据成员变成未定义的状态。因此，当我们使用union时，必须清楚地知道当前存储在union中的值到底是什么类型。如果使用错误的数据成员或者为错误的数据成员赋值，则程序可能崩溃或出现异常行为。 一旦我们定义了一个匿名union，编译器就会自动地为该union创建一个未命名的对象。在匿名union的定义所在的作用域内该union的成员都是可以直接访问的。 匿名union不能包含受保护的成员或私有成员，也不能定义成员函数。因为是匿名的，没有途径可以访问到它们。 union中如果含有类成员变量，则该变量所属的类必须要有构造函数和析构函数（自定义或者编译器合成的都可以）。 局部类 类可以定义在某个函数的内部，我们称这样的类为局部类。 在局部类中不允许声明静态数据成员。 局部类不能访问到函数作用域中的变量。也就是说如果局部类定义在某个函数内部，则该函数的局部普通变量不能被该局部类访问到（静态局部变量还是可以的）： void func() { int i = 0; static int j = 0; class Test { public: void count() { ++i; //错误，局部类访问不到其所在函数里的普通局部变量 ++j; //正确，函数的局部静态变量还是可以被局部类访问到的 } }; } 固有的不可移植的特性 所谓的不可移植的特性是指因机器而异的特性，当我们将含有不可移植特性的程序从一台机器转移到另一台机器上时，通常需要重新编写该程序。 算术类型的大小在不同机器上不一样，这是我们使用过的不可移植特性的一个典型示例。 类可以将其（非静态）数据成员定义成位域，在一个位域中含有一定数量的二进制位。当一个程序需要向其他程序或硬件设备传递二进制数据时，通常会用到位域。 位域在内存中的布局是与机器相关的。 位域的类型必须是整型或枚举类型，通常使用无符号类型来保存位域。 位域的声明形式是在成员之后紧跟一个冒号以及一个常量表达式，该表达式用于指定成员所占的二进制位数： using Bit = unsigned int; class CData { public: CData(int vData) :m_Data(vData) {} private: Bit m_Data : 2; //m_Data占2位 Bit m_Group : 3; //m_Group占3位 Bit m_Owner : 3; //m_Owner占3位 }; 如果可能的话，在类的内部连续定义的位域压缩在同一整数的相邻位，从而提供存储压缩。例如上面代码中的三个位域可能会存储在同一个unsined int中。这些二进制位是否能压缩到一个整数中以及如何压缩是与机器相关的。 取地址运算符（&amp;）不能作用于位域，因此任何指针都无法指向类的位域。 通常情况下最好将位域设为无符号类型，存储在带符号类型中的位域的行为将因具体实现而定。 直接处理硬件的程序常常包含这样的数据元素：它们的值由程序直接控制之外的过程控制。例如，程序可能包含一个由系统时钟定时更新的变量。当对象的值可能在程序的控制或检测之外被改变时，应该将该对象声明为volatile。关键字volatile告诉编译器不应对这样的对象进行优化。volatile限定符的用法和const很相似：volatile int DisplayRegister; //该int值可能发生改变 只有volatile的成员函数才能被volatile的对象调用。 const和volatile的一个重要区别是我们不能使用合成的拷贝/移动构造函数及赋值运算符初始化volatile对象或从volatile对象赋值。合成的成员接受的形参类型是（非volatile）常量引用，显然我们不能把一个非volatile引用绑定到一个volatile对象上。如果一个类希望拷贝、移动或赋值它的volatile对象，则该类必须自定义拷贝或移动操作。例如，可以将形参类型指定为const volatile引用。 C++使用链接指示指出任意非C++函数所用的语言。要想把C++代码和其他语言（包括C语言）编写的代码放在一起使用，要求我们必须有权访问该语言的编译器，并且这个编译器与当前的C++编译器是兼容的。 链接指示不能出现在类定义或函数定义的内部。同样的链接指示必须在函数的每个声明中都出现。 下面的代码显示了cstring头文件的某些C函数是如何声明的：//单语句链接指示 extern "C" size_t strlen(const char *); //复合语句链接指示 extern "C" { int strcmp(const char*, const char*); char *strcat(char*, const char*); } 复合语句链接声明的形式可以应用于整个头文件。例如，cstring头文件可能形如：extern "C" { #include &lt;string.h> } 当一个#include指示被放置在复合链接指示的花括号中时，头文件中的所有普通函数声明都被认为是由链接指示的语言编写的。 当我们使用链接指示时，它不仅对函数有效，而且对作为返回类型或形参类型的函数指针也有效：//f1是一个C函数，它的形参是一个指向C函数的指针 extern "C" void f1(void(*)(int)); 也就是说链接指示对整个声明都有效。、 因为链接指示同时作用于声明语句中的所有函数，所以我们希望给C++函数传入一个指向C函数的指针，则必须使用类型别名：//FC是一个指向C函数的指针 extern "C" typedef void FC(int); //f2是一个C++函数，该函数的形参是指向C函数的指针 void f2(FC *); 通过使用链接指示对函数进行定义，我们可以令一个C++函数在其他语言编写的程序中可用：//calc函数可以被C程序调用 extern "C" double calc(double dparm){} 编译器将为该函数生成适合于指定语言的代码。 C语言不支持函数重载，因此也就不难理解为什么一个C链接指示只能用于说明一组重载函数中的某一个了：//错误，两个extern "C"函数名字相同 extern "C" void print(const char*); extern "C" void print(int); &nbsp; 参考文献：《C++Primer第五版》]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++Primer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++Primer第十八章 用于大型程序的工具]]></title>
    <url>%2F2018%2F04%2F17%2FC%2B%2BPrimer%E7%AC%AC%E5%8D%81%E5%85%AB%E7%AB%A0%E7%94%A8%E4%BA%8E%E5%A4%A7%E5%9E%8B%E7%A8%8B%E5%BA%8F%E7%9A%84%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[异常处理 因为跟在throw后面的语句将不再被执行，所以throw语句的用法有点类似于return语句。 异常处理寻找匹配catch块的过程是一个栈展开过程。栈展开就是沿着函数调用链寻找catch块的过程。 异常处理时，如果找不到匹配的catch块，程序将调用标准库函数terminate，它会终止程序的执行。 如果在栈展开过程中退出了某个块，编译器将负责确保在这个块中创建的对象能被正确地销毁。 析构函数总是会被执行的，但是函数中负责释放资源的代码却可能被跳过。如果一个块分配了资源，并且在负责释放这些资源的代码前发生了异常，则释放资源的代码将不会被执行。 由于栈展开可能使用析构函数的考虑，析构函数不应该抛出不能被它自身处理的异常。换句话说，如果析构函数需要执行某个可能抛出异常的操作，则该操作应该被放置在一个try语句块当中，并且在析构函数内部得到处理。 在实际的编程过程中，因为析构函数仅仅是释放资源，所以它不太可能抛出异常。所有标准库类型都能确保它们的析构函数不会发生异常。 当我们抛出一条表达式时，该表达式的静态编译时类型决定了异常对象的类型。如果一条throw表达式解引用一个基类指针，而该指针实际指向的是派生类对象，则抛出的对象将被切掉一部分，只有基类部分被抛出。 抛出指针要求在任何对应的处理代码存在的地方，指针所指的对象都必须存在。 通常情况下，如果catch接受的异常与某个继承体系有关，则最好将该catch的参数定义成引用类型。 在搜寻catch语句的过程中，我们最终找到的catch未必是异常的最佳匹配。相反，挑选出来的应该是第一个与异常匹配的catch语句。因此，越是专门的catch越应该置于整个catch列表的前端。 在匹配catch块的过程中，允许的隐式类型转换是有限的： 允许从非常量向常量的类型转换，也就是说，一条非常量对象的throw语句可以匹配一个接受常量引用的catch语句。 允许从派生类向基类的类型转换。 数组被转换成指向数组（元素）类型的指针，函数被转换成指向该函数类型的指针。 除此之外，包括标准算术类型转换和类类型转换在内，其他所有转换规则都不能在匹配catch的过程中使用。 如果在多个catch语句的类型之间存在着继承关系，则我们应该把继承链最底端的类放在前面，而将继承链最顶端的类（基类）放在后面。 有时，一个单独的catch语句不能完整地处理某个异常。在执行了某些校正操作之后，当前的catch可能会决定由调用链更上一层的函数接着处理异常。一条catch语句通过重新抛出的操作将异常传递给另外一个catch语句。这里的重新抛出仍然是一条throw语句，只不过不包含任何表达式：throw 空的throw语句只能出现在catch语句或catch语句直接或间接调用的函数之内。如果在处理代码之外的区域遇到了空throw语句，编译器将调用terminate。一个重新抛出语句并不指定新的表达式，而是将当前的异常对象沿着调用链向上传递。 为了一次性捕获所有异常，我们在catch中使用省略号作为异常声明，这样的处理代码称为捕获所有异常的处理代码，形如catch(…)。一条捕获所有异常的语句可以与任意类型的异常匹配。catch(…)通常与重新抛出语句一起使用，其中catch执行当前局部能完成的工作，随后重新抛出异常：void manip() { try { //这里的操作将引发并抛出一个异常 } catch (...) { //处理异常的某些特殊类型 throw; } } 如果catch(…)与其他几个catch语句一起出现，则catch(…)必须在最后的位置。出现在捕获所有异常语句后面的catch语句将永远不会被匹配（最先匹配原则）。 要想处理构造函数初始值抛出的异常，我们必须将构造函数写成函数try语句块的形式，即把初始值列表和构造函数体写到try语句块中：template&lt;typename T> CData&lt;T>::CData(T vData) try : m_Data(vData) { //构造函数体... } catch (const std::bad_alloc &amp;e) { //异常处理... } 关键字try出现在表示构造函数初始值列表的冒号以及表示构造函数体的花括号之前。 处理构造函数初始值异常的唯一方法是将构造函数写成函数try语句块。 如果编译器确认函数不会抛出异常，它就能执行某些特殊的优化操作，而这些优化操作并不适用于可能出错的代码。 在C++11新标准宏，我们可以通过noexcept关键字来指定某个函数不会抛出异常： void recoup(int) noexcept; //不会抛出异常 void alloc(int); //可能抛出异常 对于一个函数来说，noexcept说明要么出现在该函数的所有声明语句和定义语句中，要么一次也不出现。该说明应该在函数的尾置返回类型之前。我们也可以在函数指针的声明和定义中指定noexcept。在typedef或类型别名中则不能出现noexcept。在成员函数中，noexcept说明符需要跟在const及引用限定符之后，而在final、override或虚函数的=0之前。 编译器并不会在编译时检查noexcept说明。实际上，如果一个函数在说明了noexcept的同时又含有throw语句或者调用了可能抛出异常的其他函数，编译器将顺利编译通过。但是一旦一个noexcept函数抛出了异常，程序就会调用terminate以确保遵守不在运行时抛出异常的承诺。noexcept可以用在两种情况下：一是我们确认函数不会抛出异常，二是我们根本不知道该如何处理异常。 noexcept说明符可以接受一个可选的实参，该实参必须能转换为bool类型：如果实参是true，则函数不会抛出异常；如果实参是false，则函数可能抛出异常：void recoup(int) noexcept(true); //不会抛出异常 void alloc(int) noexcept(false); //可能抛出异常 noexcept说明符的实参常常与noexcept一元运算符混合使用： noexcept(e) 当e调用的所有函数都做了不抛出说明且e本身不含有throw语句时，noexcept运算符的返回结果为true，否则返回false。 noexcept说明符和noexcept运算符混合使用的例子如下： void f() noexcept(noexcept(g())); //f和g的异常说明一致 如果函数g承诺了不会抛出异常，则f也不会抛出异常；如果g没有异常说明符noexcept，或者g虽然有异常说明符但是允许抛出异常（带false参数的noexcept），则f也可能抛出异常。 noexcept有两层含义：当跟在函数参数列表后面时它是异常说明符；而当作为noexcept异常说明的bool实参出现时，它是一个运算符。 如果一个虚函数承诺了它不会抛出异常，则后续派生出来的虚函数也必须作出同样的承诺；与之相反，如果基类的虚函数允许抛出异常，则派生类的对应函数既可以允许抛出异常，也可以不允许抛出异常。 标准库异常类的继承体系如下图所示：继承体系的第二层将exception划分为两个大的类别：运行时错误和逻辑错误。运行时错误表示的是只有在程序运行时才能检测到的错误；而逻辑错误一般指的是我们可以在程序代码中发现的错误。 我们通过继承上图中的类来自定义我们自己的异常类： class CMismatchDataNameE :public std::logic_error //继承自标准库异常类logic_error的自定义异常类 { public: CMismatchDataNameE(const std::string &amp;vStr) :logic_error(vStr) {} ~CMismatchDataNameE() = default; virtual char const* what() const override //重写what虚函数 { std::string *pTempStr = new std::string(logic_error::what()); *pTempStr += "\nDataName is not matched!"; return pTempStr->c_str(); } }; class CData { public: CData() = default; CData(int vData, const std::string &amp;vDataName) :m_Data(vData), m_DataName(vDataName) {} CData&amp; operator+(const CData &amp;vData) { if (m_DataName != vData.m_DataName) throw CMismatchDataNameE("ERROR"); //抛出异常 m_Data += vData.m_Data; return *this; } private: int m_Data = 0; std::string m_DataName; }; int main() { CData Data1(41, "Boy"), Data2(42, "Girl"); try { CData Data3 = Data1 + Data2; //对可能发生异常的代码使用try进行异常检测 } catch (CMismatchDataNameE e) //捕获异常 { std::cerr &lt;&lt; e.what() &lt;&lt; std::endl; } return 0; } 命名空间 命名空间为防止名字冲突提供了更加可控的机制。 命名空间可以是不连续的，它可以定义在几个不同的部分。如下代码： namespace nsp { //相关声明 } 可能是定义了一个名为nsp的新命名空间，也可能是为已经存在的命名空间添加一些新成员。 在通常情况下，我们不把#include放在命名空间内部。如果我们这么做了，隐含的意思是把头文件中所有的名字定义成该命名空间的成员。 C++11引入了一种新的嵌套命名空间，称为内联命名空间。和普通的嵌套命名空间不同，内联命名空间中的名字可以被外层命名空间直接使用。定义内联命名空间的方式是在关键字namespace前面加inline： namespace nsp { inline namespace inlineNsp { const int N = 10; } } std::cout &lt;&lt; nsp::N &lt;&lt; std::endl; 未命名的命名空间是指关键字namespace后紧跟花括号括起来的一系列声明语句。未命名的命名空间中定义的变量拥有静态生命周期：它们在使用前创建，并且直到程序结束才销毁。 一个未命名的命名空间可以在某个给定的文件内不连续，但是不能跨越多个文件。因为名字都没有~。也就是说未命名的命名空间仅在特定的文件内部有效，其作用范围不会横跨多个不同的文件。 定义在未命名空间中的名字可以直接使用，毕竟我们找不到什么命名空间的名字来限定它们；同样的，我们也不能对未命名的命名空间的成员使用作用域运算符。未命名的命名空间中定义的名字的作用域与该命名空间所在的作用域相同。 在文件中进行静态声明的做法已经被C++标准取消了，现在的做法是使用未命名的命名空间。因为未命名空间中的变量拥有静态生命周期，相当于静态变量。 应该尽量避免using指示。using指示一次性注入某个命名空间的所有名字，这种用法看似简单实则充满了风险：只使用一条语句就突然将命名空间中所有成员的名字变得可见了。如果应用程序使用了多个不同的库，而这些库中的名字通过using指示变得可见，则全局命名空间污染的问题将重新出现。 另一个风险是由using指示引发的二义性错误只有在使用了冲突名字的地方才能被发现。这种延后的检测意味着可能在特定库引入很久之后才爆发冲突。显然不符合软件开发原则。 多重继承与虚继承 在多重继承中，基类的构造顺序用户派生列表中基类的出现顺序保持一致，而与派生类构造函数初始值列表中基类的顺序无关。 当一个类有多个基类时，有可能出现派生类从两个或更多基类中继承了同名成员的情况。此时，不加前缀限定符直接使用该名字将引发二义性。 不论虚基类在继承体系中出现了多少次，在派生类中都只包含唯一一个共享的虚基类子对象。比如，如果ZooAnimal派生出Bear、Raccon两个类，然后Panda又多重继承自这两个类，那么如果ZooAnimal不是虚基类的话，在Panda中就会有两份ZooAnimal的成员。显然不合理。所以，这时就需要把ZooAnimal声明成虚基类，保证在子类中只有一个虚基类子对象。 指定虚基类的方式是在派生列表中添加关键字virtual： //关键字virtua和public的顺序随意 class Raccoon : public virtual public ZooAnimal { }; class Bear : virtual pubic ZooAnimal { }; virtual说明符表明了一种愿望：在后续的派生类当中共享虚基类的同一份实例。 class Panda : public Bear, public Raccoon { }; 因为Raccoon和Bear继承ZooAnimal的方式都是虚继承，所以在Panda中只有一个ZooAnimal基类部分。 虚基类总是先于非虚基类构造，与它们在继承体系中的次序和位置无关。&nbsp; 参考文献：《C++Primer第五版》]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++Primer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++Primer第十七章 标准库特殊设施]]></title>
    <url>%2F2018%2F04%2F17%2FC%2B%2BPrimer%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0%E6%A0%87%E5%87%86%E5%BA%93%E7%89%B9%E6%AE%8A%E8%AE%BE%E6%96%BD%2F</url>
    <content type="text"><![CDATA[tuple类型 tuple是类似pair的模板，一个tuple可以有任意数量的成员。当我们希望将一些数据组合成单一对象，但又不想麻烦地定义一个新数据结构来表示这些数据时，tuple是非常有用的。下表列出了一些重要的tuple操作，它们都定义在tuple头文件中：tuple操作 | 描述:-: | : -:tuple t; | 定义一个tuple，有n个成员，第i个成员的类型是Ti，所有成员都进行值初始化tuple t(v1,v2,…,vn)| 定义一个tuple，每个成员用对应的vi进行初始化。此构造函数是explicit的，即参数无法进行隐式转换make_tuple | 返回一个用给定值初始化的tuple。tuple的类型从初始值的类型推断。get(t) | 返回t的第i个数据成员的引用。如果t是一个左值，则返回的结果是一个左值引用；如果t是一个右值，则返回的结果是一个右值引用。tuple的所有成员都是public的。tuple_size::value | 返回给定tuple类型tupleType中包含的成员的数量。注意tupleType是一个类型而非变量，所以通常要配合decltype使用。tuple_element::type | 返回给定tuple类型中第i个成员的类型。 和上表tuple操作对应的程序如下： std::tuple&lt;size_t, size_t, size_t> t0; //正确，3个成员都值初始化 std::tuple&lt;size_t, size_t, size_t> t1{ 1,2,3 }; //正确 std::tuple&lt;size_t, size_t, size_t> t2 = { 1,2,3 }; //VS下实验正确 auto t3 = std::make_tuple(1, 2, 3); //正确 auto a1 = std::get&lt;1>(t1); //正确，通过get来访问t1中第1个成员的引用，a1 = 2 size_t sz = std::tuple_size&lt;decltype(t3)>::value; //正确，返回t3中的成员数量，sz = 3 if (1 &lt; sz) { std::tuple_element&lt;1, decltype(t3)>::type a3 = std::get&lt;1>(t3); //正确，用type返回t3中第1个成员的类型，a3的类型是size_t，a3 = 2 } 只有两个tuple具有相同数量的成员，而且成员之间可以隐式转换时，我们才可以比较它们： std::tuple&lt;size_t, size_t> t1{ 1,2 }; std::tuple&lt;size_t, size_t, size_t> t2{ 1,2,3 }; std::tuple&lt;size_t, std::string> t3{ 1,"girl" }; std::tuple&lt;size_t, std::string> t4{ 1,"boy" }; bool b1 = (t1 == t2); //错误，t1和t2成员数量不同，不能比较 bool b2 = (t1 == t3); //错误，t1的size_t类型成员和t3的string类型成员无法进行比较 bool b3 = (t3 == t4); //正确，t3和t4成员类型和数量都完全相同 由于tuple定义了&lt;和==运算符，所以我们可以将tuple序列传递给算法，并且可以在无序容器中将tuple作为关键字类型。 tuple的一个常见用途是从一个函数返回多个值。 bitset类型 除了第四章中说到的位运算符以外，标准库还定义了bitset类，使得位运算的使用更为容易，并且能够处理超过最长整型类型大小的位集合。bitset类定义在头文件bitset中。 bitset类是一个模板类，它类似array类，具有固定的大小。当我们定义一个bitset时，需要声明它包含多少个二进制位： std::bitset&lt;32> Bitvec(1U); //32位，最低位为1，其他位为0 指定的固定大小必须是一个常量表达式。 当我们使用一个整型值来初始化bitset时，此值将被转换为unsigned long long类型并被当做位模式来处理。如果常量整型值位数比定义的bitset位数少，则赋值之后不足的高位被置0；如果常量整型值位数比定义的bitset位数多，则多余的高位被丢弃。 我们也可以直接使用string或者字符数组来初始化bitset： std::bitset&lt;4> Bitvec2("1011"); //Bitvec2[0]到Bitvec2[3]分别是1、1、0、1（注意并不是顺序赋值） std::string str = "1101001110011"; std::bitset&lt;32> Bitvec3(str, 6, 4); //从str[6]开始的4个二进制位：1110（0被赋值给Bitvec3[0]）其余高位被置0 std::bitset&lt;32> Bitvec4(str, str.size() - 5); //使用最后5个字符 值得注意的是在字符串中的二进制字符也被认为是有高低位的，最右边的字符是最低位，初始化时被赋给bitset[0]。 bitset还有一系列成员函数用于设置或查询某些位是0或者1，具体可参考《C++Primer第五版》P643页，其中的置位是变成1的意思，复位是变成0的意思。 我们也可以使用IO运算符来直接读写bitset： std::bitset&lt;16> Bits; std::cin >> Bits; std::cout &lt;&lt; Bits &lt;&lt; std::endl; 当输入的01个数达到16，或者遇到输入的不是1或者0时，读取过程会停止。比如输入下面第一行的01字符，将得到第二行的输出： 111110000011 0000111110000011 其实在输入过程中，C++创建了一个临时的string对象来保存输入的字符，一旦输入结束，就立即用临时的string对象来初始化bitset。 通常使用bitset类来代替位运算符，会更简单直白。 正则表达式 C++正则表达式库（RE库）是新标准的一部分，它定义在头文件regex中，它包含如下表所示的多个组件： 组件 描述 regex 正则表达式类，会包含一个正则表达式字符串 regex_match 函数，确定一个字符序列与一个正则表达式是否匹配 regex_search 函数，寻找第一个与正则表达式匹配的子序列 sregex_iterator 迭代器适配器，调用regex_search来遍历一个string中所有匹配的子串 smatch 容器类，用于保存搜索结果（保存在内部的string中） ssub_match string中匹配的子表达式的结果 如果输入序列与regex匹配，则regex_match函数返回true；如果输入序列中一个子串与regex匹配，则regex_search函数返回true。如果匹配成功，成功匹配的信息会被保存在smatch对象中。 比如我们可以用正则表达式来判断一条众所周知的英文单词拼写规则：字符i和e连在一起时，i如果不在c之后，则必须在e之前（也就是说如果前面没有c，则只能是ie而不能是ei）。 std::string Pattern("[^c]ei"); //查找不在字符c之后的字符串ei Pattern = "[[:alpha:]]*" + Pattern + "[[:alpha:]]*"; //我们需要包含Pattern的整个单词 std::regex RegexObj(Pattern); //构建一个用正则表达式字符串Pattern来查找匹配的regex std::smatch Results; //定义一个对象保存搜索结果 std::string TestStr = "receipt freind theif receive"; if (regex_search(TestStr, Results, RegexObj)) //如果有匹配子串 std::cout &lt;&lt; Results.str() &lt;&lt; std::endl; //打印第一个匹配的单词 程序输出如下： freind 我们首先定义了一个string来保存希望查找的正则表达式。正则表达式[^c]表明我们希望匹配任意不是’c’的字符，而[^c]ei指出我们想要匹配这种字符后接ei的字符串。模式[[:alpha:]]匹配任意字母，符号+和*分别表示我们希望“一个或多个”或“零个或多个”匹配。因此[[:alpha:]]*将匹配零个或多个任意字母。 默认情况下，regex使用的正则表达式语言是ECMAScript。 在定义regex时，我们还可以提供一些选项，比如regex::icase就表示在匹配过程中忽略大小写。具体有哪些选项可参看《C++Primer第五版》P647页。 我们可以将一个C++程序保存在.cc结尾的文件中，也可以保存在.Cc、.cC或是.CC结尾的文件中，效果是一样的。我们可以编写一个正则表达式来识别上述任何一种扩展名： //一个或多个字母或数字字符后接一个'.'再接"cpp"或"cxx"或"cc" std::regex RegexObj("[[:alnum:]]+\\.(cpp|cxx|cc)$", std::regex::icase); std::smatch Results; std::string FileName; while (std::cin >> FileName) { if (regex_search(FileName, Results, RegexObj)) std::cout &lt;&lt; Results.str() &lt;&lt; std::endl; } 为了表示与句点字符‘.’匹配的正则表达式，必须写成\.（第一个反斜线去掉C++语言中反斜线的特殊含义，即，正则表达式字符串为.，第二个反斜线则表示在正则表达式中去掉.的特殊含义）。 正则表达式不是由C++编译器解释的，它是在运行时，当一个regex对象被初始化或被赋予一个新模式时，才被“编译”的。如果我们编写的正则表达式存在错误，则在运行时标准库会抛出一个类型为regex_error的异常。类似标准异常类型，regex_error也有一个what成员函数来描述发生了什么错误；它还有一个code成员函数，用来返回某个错误类型对应的数值编码（code返回的值是由具体实现定义的）。 try { //错误，alnum漏掉了右括号，构造函数会抛出异常 std::regex RegexObj("[[:alnum:]+\\.(cpp|cxx|cc)$", std::regex::icase); } catch (std::regex_error e) { std::cout &lt;&lt; e.what() &lt;&lt; "\ncode: " &lt;&lt; e.code() &lt;&lt; std::endl; } 程序输出如下： regex_error(error_brack): The expression contained mismatched [ and ]. code: 4 正则表达式的编译是一个非常慢的操作，特别是在使用了扩展的正则表达式语法或复杂的正则表达式时。因此，构造一个regex对象以及向一个已存在的regex赋予一个新的正则表达式可能是非常耗时的。为了最小化这种开销，应该努力避免创建很多不必要的regex。特别是，如果在一个循环中使用正则表达式，应该在循环外创建它，而不是在每步迭代时都编译它。 我们可以用smatch来把正则表达式匹配的结果存到string里，也可以用cmatch把结果存到数组序列里。 std::regex RegexObj("[[:alnum:]]+\\.(cpp|cxx|cc)$", std::regex::icase); std::smatch Results; if (std::regex_search("myfile.cc", Results, RegexObj)) //错误，输入的字符串是char*类型的，不能用smatch来保存 std::cout &lt;&lt; Results.str() &lt;&lt; std::endl; 因为输入的待搜索字符串是char*类型的，所以不能用smatch来存储匹配结果，应该使用cmatch，或者把输入字符串变为string类型： std::regex RegexObj("[[:alnum:]]+\\.(cpp|cxx|cc)$", std::regex::icase); std::cmatch Results; if (std::regex_search("myfile.cc", Results, RegexObj)) //正确，可以用cmatch来保存char*类型的匹配结果 std::cout &lt;&lt; Results.str() &lt;&lt; std::endl; std::regex RegexObj("[[:alnum:]]+\\.(cpp|cxx|cc)$", std::regex::icase); std::smatch Results; std::string Str = "myfile.cc"; if (std::regex_search(Str, Results, RegexObj)) //正确，可以用smatch来保存string类型的匹配结果 std::cout &lt;&lt; Results.str() &lt;&lt; std::endl; 之前查找违反“如果前面没有c，则只能是ie而不能是ei”规则（后面简称ie规则）的单词的程序，只能找到输入序列里第一个匹配的单词。我们可以使用sregex_iterator来获得所有匹配。regex迭代器是一种迭代器适配器，被绑定到一个输入序列和一个regex对象上。sregex_iterator对应的操作如下表： 操作 描述 sregex_iterator it(b, e, r); 定义一个迭代器it，它绑定到迭代器b和e表示的字符串上以及regex对象r上，定义时会自动调用regex_search，定位到给定string中的第一个匹配位置 sregex_iterator end; 定义一个尾后迭代器 *it或者it-&gt; 根据最后一次调用regex_search的结果，返回一个smatch对象的引用或一个指向smatch对象的指针 ++it或者it++ | 从输入序列当前匹配位置开始调用regex_search。前置版本返回递增后迭代器，后置版本返回旧值。it1==it2 | 如果两个sregex_iterator都是一样尾后迭代器，则它们相当；否则，如果它们是从相同的输入序列和regex对象构造，则它们相当 当我们将一个sregex_iterator绑定到一个string和一个regex对象时，迭代器自动定位到给定string中第一个匹配位置。即，sregex_iterator的构造函数会对给定的string和regex调用regex_search。当我们解引用迭代器时，会得到一个对应最近一次搜索结果的smatch对象。当我们递增迭代器时，它调用regex_search在输入string中查找下一个匹配。 用sregex_iterator来查找输入序列中所有不符合ie规则的单词：std::string Pattern("[^c]ei"); //查找不在字符c之后的字符串ei Pattern = "[[:alpha:]]*" + Pattern + "[[:alpha:]]*"; //我们需要包含Pattern的整个单词 std::regex RegexObj(Pattern,std::regex::icase); //构建一个用正则表达式字符串Pattern来查找匹配的regex，并且匹配时忽略大小写 std::string TestStr = "receipt freind theif receive"; for (std::sregex_iterator It(TestStr.begin(), TestStr.end(), RegexObj), EndIt; It != EndIt; ++It) //++时会调用regex_search来查找下一个匹配 { std::cout &lt;&lt; It->str() &lt;&lt; std::endl; } 程序输出如下：freind theif 在for语句中定义了迭代器It和EndIt，EndIt是一个空sregex_iterator，起到尾后迭代器的作用。我们可以将此循环想象为不断从一个匹配位置跳到下一个匹配位置。 正则表达式中通常包含一个或多个子表达式。通常用括号表示一个子表达式。如下： //RegexObj有两个子表达式：第一个是点之前表示文件名的部分，第二个表示文件扩展名 std::regex RegexObj("([[:alnum:]]+)\\.(cpp|cxx|cc)$", std::regex::icase); 匹配对象除了提供匹配整体的相关信息外，还提供访问正则表达式（模式）中每个子表达式的能力。子匹配是按照位置来访问的。第一个子匹配位置为0，表示与整个正则表达式对应的匹配，随后是每个子表达式对应的匹配。所以我们可以向下面的程序一样，输出每个子匹配的结果： //RegexObj有两个子表达式：第一个是点之前表示文件名的部分，第二个表示文件扩展名 std::regex RegexObj("([[:alnum:]]+)\\.(cpp|cxx|cc)$", std::regex::icase); std::string FileName = "TxtFile.txt CFile.cc"; std::smatch Results; if (std::regex_search(FileName, Results, RegexObj)) { std::cout &lt;&lt; Results.str(0) &lt;&lt; std::endl; //输出CFile.cc std::cout &lt;&lt; Results.str(1) &lt;&lt; std::endl; //输出CFile std::cout &lt;&lt; Results.str(2) &lt;&lt; std::endl; //输出cc } Results.str(0)是在访问整个正则表达式匹配的结果，而Results.str(1)是在访问Results.str(0)中与第一个子表达式匹配的结果，Results.str(2)是在访问Results.str(0)中与第二个子表达式匹配的结果。 可以看到子表达式最大的作用在于，可以把完整正则表达式匹配的结果分开成好几部分。 当我们希望在输入序列中查找并替换一个正则表达式时，可以调用regex_replace函数。它类似regex_search函数，不同的是，它还接受一个用于描述我们想要的输出形式的字符串，而且没有smatch Results参数：//RegexObj有两个子表达式：第一个是点之前表示文件名的部分，第二个表示文件扩展名 std::regex RegexObj("([[:alnum:]]+)\\.(cpp|cxx|cc)$", std::regex::icase); std::string FileName = "TxtFile.txt CFile.cc"; std::string Format = "$1-$2"; //把匹配的文件名改为类似a-cpp这种格式 std::cout &lt;&lt; std::regex_replace(FileName, RegexObj, Format) &lt;&lt; std::endl; //输出TxtFile.txt CFile-cc 其中我们用一个符号$后跟子表达式的索引号来表示一种特定的格式。 随机数 在新标准出现之前，C和C++都依赖于一个简单的C库函数rand来生成随机数。此函数生成均匀分布的伪随机整数，每个随机数的范围在0和一个系统相关的最大值（至少为32767）之间。rand函数有一些问题：即使不是大多数，也有很多程序需要不同范围的随机数。一些应用需要随机浮点数。一些程序需要非均匀分布的数。而程序员为了解决这些问题而试图转换rand生成的随机数的范围、类型或分布时，常常会引入非随机性。 定义在头文件random中的随机数库通过一组协作的类来解决这些问题：随机数引擎类和随机数分布类。一个引擎类可以生成unsigned随机数序列，一个分布类使用一个引擎类生成指定类型的、在给定范围内的、服从特定概率分布的随机数。 C++程序不应该使用库函数rand，而应使用default_random_engine类和恰当的分布类对象。 随机数引擎是函数对象类，它们定义了一个调用运算符，该运算符不接受参数并返回一个随机unsigned整数。我们可以通过调用一个随机数引擎对象来生成原始随机数： std::default_random_engine e; for (size_t i = 0; i &lt; 10; ++i) std::cout &lt;&lt; e() &lt;&lt; " "; //e()调用对象e来生成下一个随机数 在我的机子上，生成的结果如下： 3499211612 581869302 3890346734 3586334585 545404204 4161255391 3922919429 949333985 2715962298 1323567403 我们首先定义了一个名为e的default_random_engine对象。在for循环内，我们调用对象e来获得下一个随机数。 随机数引擎具有下表的这些操作： 操作 描述 Engine e; 默认构造函数；使用该引擎类型默认的种子 Engine e(s); 使用整型值s作为种子 e.seed(s) 使用种子s重置引擎的状态 e.min()，e.max() 此引擎可生成的最小值和最大值 Engine::result_type 此引擎生成的unsigned整型类型 e.discard(u) 将引擎推进u步；u的类型为unsigned unsigned long 对于大多数场合，随机数引擎的输出是要不能直接使用的，因为它生成的随机数的值返回和分布通常与我们需要的不符，正确转换随机数的范围和分布又极其困难。这也是我们之前将其叫为原始随机数的原因。这种时候，我们可以再结合分布类型对象来得到我们想要的随机数。比如下面的程序： std::uniform_int_distribution&lt;unsigned> u(0, 9); //定义0到9之间（包含）的均匀分布 std::default_random_engine e; //定义随机数引擎 for (size_t i = 0; i &lt; 10; ++i) std::cout &lt;&lt; u(e) &lt;&lt; " "; //将随机数引擎e作为分布对象的参数，每个调用会返回在指定范围内并服从均匀分布的值 本机运行的结果如下： 2 2 4 5 4 1 9 5 8 3 上面的uniform_int_distribution就是一个分布类型。类似引擎类型，分布类型也是函数对象类。分布类型定义了一个调用运算符，它接受一个随机数引擎作为参数。分布对象使用它的引擎参数生成随机数，并将其映射到指定的分布。值得注意的是，我们传递给分布对象的是引擎对象本身，即u(e)，而不是u(e())。我们传递的是引擎本身，而不是它生成的下一个值，原因是某些分布可能需要调用引擎多次才能得到一个值。 当我们说随机数发生器时，是指分布对象和引擎对象的组合。 先看如下程序： std::vector&lt;unsigned> badRandVec() { std::default_random_engine e; std::uniform_int_distribution&lt;unsigned> u(0, 9); std::vector&lt;unsigned> Set; for (size_t i = 0; i &lt; 100; ++i) Set.push_back(u(e)); return Set; } std::vector&lt;unsigned> v1 = std::move(badRandVec()); std::vector&lt;unsigned> v2 = std::move(badRandVec()); std::cout &lt;&lt; ((v1 == v2) ? "equal" : "not euqal") &lt;&lt; std::endl; 程序总会输出equal，也就是说两次调用badRandVec函数生成的随机数序列都总是一样的。想要每次调用生成的随机数都不一样，需要将引擎对象和分布对象都定义为static的： std::vector&lt;unsigned> badRandVec() { static std::default_random_engine e; static std::uniform_int_distribution&lt;unsigned> u(0, 9); std::vector&lt;unsigned> Set; for (size_t i = 0; i &lt; 100; ++i) Set.push_back(u(e)); return Set; } 由于e和u是static的，因此它们在函数调用之间会保持住状态。第一次调用会使用u(e)生成的序列中的前100个随机数，第二次调用会获得接下来100个，以此类推。 总结一下，一个给定的随机数发生器一直会生成相同的随机数序列。一个函数如果定义了局部的随机数发生器，应该将其（包括引擎和分布对象）定义为static的。否则，每次调用函数都会生成相同的序列。 当然，除了上面的方法，也可以通过给随机数引擎一个不同的种子，来让它生成不同的随机数序列。方法就是前面表中的第二行和第三行，可以在定义时或者使用seed成员函数来设置随机数种子。选择一个好的种子，与生成好的随机数所涉及的其他大多数事情相同，是极其困难的。可能最常用的方法是调用系统函数time（定义在头文件ctime中），它返回从一个特定时刻到当前经过了多少秒。函数time接受单个指针参数，它指向用于写入时间的数据结构。如果此指针为空，则函数简单地返回时间： static std::default_random_engine e(time(0)); //稍微随机些的种子 由于time返回以秒计的时间，因此这种方式只适用于生成种子的间隔为秒级或更长的应用。 值得注意的是，如果程序作为一个自动过程的一部分反复适用，将time的返回值作为种子的方式就无效了，因为它可能多次使用的都是相同的种子。 程序有时候需要生成随机浮点数。新标准以前最常用的是用rand()的结果除以RAND_MAX。但这种方法不正确，因为随机整数的精度通常低于随机浮点数，这样，有一些浮点值就永远不会被生成了。使用新标准，我们可以定义一个uniform_real_distribution类型的分布对象，用这个分布对象来将随机整数映射到随机浮点数（说白了就是使用它来生成随机浮点数）：static std::default_random_engine e; static std::uniform_real_distribution&lt;double> u(0, 1); for (size_t i = 0; i &lt; 10; ++i) std::cout &lt;&lt; u(e) &lt;&lt; " "; 本机运行结果如下：0.135477 0.835009 0.968868 0.221034 0.308167 0.547221 0.188382 0.992881 0.996461 0.967695 分布类型都是模板，具有单一的模板类型参数，表示分布生成的随机数的类型。这些分布类型要么生成浮点数类型，要么生成整数类型。每个分布模板都有都有一个默认实参，生成浮点值的分布类型默认生成double值，而生成整型值的分布默认生成int值：static std::uniform_real_distribution&lt;> u(0, 1); //默认生成double值 还有一些非均匀分布（新标准定义了20中分布类型，可以参考《C++Primer第五版》P781页），比如正态分布、伯努利分布等等。下面我们用正态分布来生成一些随机数：std::default_random_engine e; std::normal_distribution&lt;> n(4, 1.5); //均值为4，标准差为1.5 std::vector&lt;unsigned> Values(9); for (size_t i = 0; i != 200; ++i) //生成200次随机数 { unsigned v = lround(n(e)); //舍入到最接近的整数 if (v &lt; Values.size()) //如果结果在范围内 ++Values[v]; //统计每个数出现了多少次 } for (size_t i = 0; i &lt; Values.size(); ++i) { std::cout &lt;&lt; i &lt;&lt; ": " &lt;&lt; std::string(Values[i], '*') &lt;&lt; std::endl; } 程序运行结果如下：0: *** 1: *********** 2: ****************** 3: ******************************************** 4: ******************************************************* 5: ******************************** 6: ****************************** 7: ***** 8: * 可以看到生成的200次随机数，确实是符合正态分布的（3,4,5的个数最多）。 有一个分布不接受模板参数，即bernoulli_distribution，因为它是一个普通类，而非模板。此分布总是返回一个bool值。它返回true的概率是一个常数，此概率的默认值是0.5。比如现在围棋中需要决定白棋先行还是黑棋先行，我们可以用一个值范围是0到1的uniform_int_distribution来选择先行的棋子，也可以直接用伯努利分布来完成这个选择： std::default_random_engine e; std::bernoulli_distribution b; //默认是50/50的机会 for(int i=0;i&lt;20;++i) { //std::default_random_engine e; //std::bernoulli_distribution b; //默认是50/50的机会 bool IsWhiteFirst = b(e); std::cout &lt;&lt; (IsWhiteFirst ? "白棋先行" : "黑棋先行") &lt;&lt; " "; } 本机输出如下： 白棋先行 黑棋先行 黑棋先行 白棋先行 白棋先行 黑棋先行 白棋先行 黑棋先行 黑棋先行 黑棋先行 黑棋先行 黑棋先行 白棋先行 黑 棋先行 白棋先行 白棋先行 白棋先行 黑棋先行 黑棋先行 黑棋先行 值得注意的是，引擎和分布对象都应该定义在循环外面，否则每次迭代都是重新生成对象，产生的随机数每次都会是一样的： for(int i=0;i&lt;20;++i) { std::default_random_engine e; std::bernoulli_distribution b; //默认是50/50的机会 bool IsWhiteFirst = b(e); std::cout &lt;&lt; (IsWhiteFirst ? "白棋先行" : "黑棋先行") &lt;&lt; " "; } 程序输出会如下： 白棋先行 白棋先行 白棋先行 白棋先行 白棋先行 白棋先行 白棋先行 白棋先行 白棋先行 白棋先行 白棋先行 白棋先行 白棋先行 白 棋先行 白棋先行 白棋先行 白棋先行 白棋先行 白棋先行 白棋先行 可以看到引擎和分布对象在循环里时，每次迭代都是生成相同的随机值。 我们还可以调整先行一方的概率： std::bernoulli_distribution b(0.55); //给白棋一个微小的优势 IO库再探 当操纵符改变流的格式状态时，通常改变后的状态对所有后续IO都生效。 通常最好在不需要特殊格式时尽快将流恢复到默认状态。 默认情况下，bool值打印1或0。我们可以通过对流使用boolalpha操纵符来覆盖这种格式： std::cout &lt;&lt; "default bool values: " &lt;&lt; true &lt;&lt; " "&lt;&lt;false &lt;&lt; std::endl; std::cout &lt;&lt; "alpha bool values: " &lt;&lt; std::boolalpha &lt;&lt; true &lt;&lt; " " &lt;&lt; false &lt;&lt; std::endl; 程序输出如下： default bool values: 1 0 alpha bool values: true false 一旦向cout写入了boolalpha，我们就改变了cout打印bool值的方式。后续打印bool值的操作都会打印true或false而非1或0。 为了取消cout格式状态的改变，我们使用noboolalpha： bool b = true; std::cout &lt;&lt; std::boolalpha &lt;&lt; b &lt;&lt; std::noboolalpha &lt;&lt; std::endl; 我们只对b应用了boolalpha，改变了它的输出方式，b输出完成后就用noboolalpha将其恢复到初始状态。 我们可以使用hex、oct和dec将默认的十进制输入输出改为十六进制、八进制或是改回十进制： std::cout &lt;&lt; "default\t" &lt;&lt; 20 &lt;&lt; " " &lt;&lt; 1024 &lt;&lt; std::endl; //默认十进制 std::cout &lt;&lt; "octal\t" &lt;&lt; std::oct &lt;&lt; 20 &lt;&lt; " " &lt;&lt; 1024 &lt;&lt; std::endl; //八进制 std::cout &lt;&lt; "hex\t" &lt;&lt; std::hex &lt;&lt; 20 &lt;&lt; " " &lt;&lt; 1024 &lt;&lt; std::endl; //十六进制 std::cout &lt;&lt; "decimal\t" &lt;&lt; std::dec &lt;&lt; 20 &lt;&lt; " " &lt;&lt; 1024 &lt;&lt; std::endl; //改回十进制 类似boolalpha，这些操纵符也会改变格式状态。它们会影响下一个和随后所有的整型输出，直至另一个操纵符又改变了格式为止。 值得注意的是，操纵符hex、oct和dec只影响整型运算对象，浮点值的表示形式不受影响。 当对流应用showbase操纵符时，会在输出结果中显示进制，它遵循与整型常量中指定进制相同的规范： 前导0x表示十六进制 前导0表示八进制 无前导字符串表示十进制 std::cout &lt;&lt; std::showbase; //打印整型值时显示进制 std::cout &lt;&lt; "default\t" &lt;&lt; 20 &lt;&lt; " " &lt;&lt; 1024 &lt;&lt; std::endl; //默认十进制 std::cout &lt;&lt; "octal\t" &lt;&lt; std::oct &lt;&lt; 20 &lt;&lt; " " &lt;&lt; 1024 &lt;&lt; std::endl; //八进制 std::cout &lt;&lt; "hex\t" &lt;&lt; std::hex &lt;&lt; 20 &lt;&lt; " " &lt;&lt; 1024 &lt;&lt; std::endl; //十六进制 std::cout &lt;&lt; "decimal\t" &lt;&lt; std::dec &lt;&lt; 20 &lt;&lt; " " &lt;&lt; 1024 &lt;&lt; std::endl; //改回十进制 std::cout &lt;&lt; std::noshowbase; //恢复流状态 程序输出如下： default 20 1024 octal 024 02000 hex 0x14 0x400 decimal 20 1024 默认情况下，十六进制会以小写打印，前导字符也是小写的x。我们可以使用uppercase操纵符来输出大写的X并将十六进制数字a到f以大写输出： std::cout &lt;&lt; std::uppercase &lt;&lt; std::showbase &lt;&lt; std::hex &lt;&lt; 20 &lt;&lt; " " &lt;&lt; 1999&lt;&lt; std::nouppercase &lt;&lt; std::noshowbase &lt;&lt; std::dec &lt;&lt; std::endl; 输出如下： 0X14 0X7CF 我们可以控制浮点数输出三种格式： 以多高精度（多少个数字）打印浮点值 数值是打印为十六进制、定点十进制还是科学记数法形式 对于没有小数部分的浮点值是否打印小数点 默认情况下，浮点值按六位数字精度打印；如果浮点值没有小数部分，则不打印小数点；根据浮点数的值选择打印成定点十进制或科学记数法形式。 默认情况下，精度会控制打印的数字的总数。当打印时，浮点值按当前精度舎入而非截断。我们可以通过调用IO对象的precision成员或使用setprecision操纵符来改变精度（接受参数的操纵符都定义在头文件iomanip中，如setprecision）： std::cout &lt;&lt; "Precision: " &lt;&lt; std::cout.precision() &lt;&lt; ", value: " &lt;&lt; std::sqrt(2.0) &lt;&lt; std::endl; //输出当前精度以及当前精度下根号2的值 std::cout.precision(12); //设置打印精度为12位数字 std::cout &lt;&lt; "Precision: " &lt;&lt; std::cout.precision() &lt;&lt; ", value: " &lt;&lt; std::sqrt(2.0) &lt;&lt; std::endl; //输出当前精度以及当前精度下根号2的值 std::cout &lt;&lt; std::setprecision(3); //另一种设置打印精度的方式是使用setprecision操纵符 std::cout &lt;&lt; "Precision: " &lt;&lt; std::cout.precision() &lt;&lt; ", value: " &lt;&lt; std::sqrt(2.0) &lt;&lt; std::endl; //输出当前精度以及当前精度下根号2的值 输出如下： Precision: 6, value: 1.41421 Precision: 12, value: 1.41421356237 Precision: 3, value: 1.41 在iostream中定义了很多操纵符，比如对浮点数总是显示小数点的showpoint、左对齐的left、右对齐的right、浮点值显示为定点十进制的fixed、浮点值显示为科学记数法的scientific、浮点值显示为十六进制的hexfloat、重置浮点数格式为十进制的defaultfloat、输入运算符不跳过空白符的noskipws等等，详情可参考《C++Primer第五版》P670页。 通常情况下，由标准库来选择记数法是最好的方式。 scientific、fixed、hexfloat等操纵符会改变流的精度的默认含义。默认情况下精度指定的是数字的总位数，既包括小数点之后的数字也包含小数点之前的数字，而使用它们三以后精度控制的是小数点后面的数字位数。 默认情况下，输入运算符会忽略空白符。如下程序：char ch; while (std::cin >> ch) std::cout &lt;&lt; ch; 给定下面输入序列时：a b c 输出是：abc 可以看到空白符没有被输入运算符读进来，我们可以使用操纵符noskipws让输入运算符读取空白符，而不是跳过它们：char ch; std::cin >> std::noskipws; while (std::cin >> ch) std::cout &lt;&lt; ch; std::cin >> std::skipws; 还是如上输入序列时，输出将是下面这样：a b c 可以看到使用操纵符noskipws后，输入运算符可以不跳过空白符，可以把空白符也读进来。 标准库还提供了一组低层操作，支持未格式化IO。这些操作允许我们将一个流当作一个无解释的字节序列来处理。 我们可以使用未格式化IO操作get和put来读取和写入一个字符（不会忽略空白符）：char ch; while (std::cin.get(ch)) std::cout.put(ch); 此程序保留输入中的空白符，其输出与输入完全相同。 类似get、put这种单字节低层IO操作如下表： 操作 描述 is.get(ch) 从istream is读取下一个字符存入字符ch中。返回is os.put(ch) 将字符ch输出到ostream os。返回os is.get() 将is的下一个字节作为int返回 is.putback(ch) 将字符ch放回is。返回is is.unget() 将is向后移动一个字节。返回is is.peek() 将下一个字节作为int返回，但不从流中删除它 有时我们需要读取一个字符才能知道还未准备好处理它。在这种情况下，我们希望将字符放回流中。标准库提供了三种方法退回字符，它们有着细微的差别： peek 返回输入流中下一个字符的副本，但不会将它从流中删除，peek返回的值仍然留在流中。 unget 使得输入流向后移动，从而最后读取的值又回到流中。即使我们不知道最后从流中读取什么值，仍然可以调用unget。 putback是更特殊版本的unget：它退回从流中读取的最后一个值，但它接受一个参数，此参数必须与最后读取的值相同。 一般情况下，在读取下一个值之前，标准库保证我们可以退回最多一个值。即，标准库不保证在中间不进行读取操作的情况下能连续调用putback或unget。 函数peek和无参的get版本都以int类型从输入流返回一个字符，为什么不返回char呢？返回int的原因是可以返回文件尾标记。char范围中的每个值都表示一个真实字符（可参考ASCII码表），它的取值范围内吗，没有额外的值可以用来表示文件尾。 头文件cstdio定义了一个名为EOF的const，我们可以用它来检测从get返回的值是否是文件尾，而不必记忆表示文件尾的实际数值：int ch; //使用int而不是char来保存get()的返回值 while ((ch = std::cin.get()) != EOF) //循环读取并输出输入中的所有数据 std::cout.put(ch); 这个与之前的那段代码很相似，唯一不同的是这里的get版本是无参的，而前面的版本是有参数的。 前面说的是单字节低层IO操作，当然也还有多字节低层IO操作，如下表： 操作 描述 is.get(sink, size, delim) 从istream is中读取最多size个字节，并保存在sink表示的字符数组中。读取过程直至遇到字符delim或读取了size个字节或遇到文件尾时停止。如果遇到了delim，则将其留在输入流中，而不存入sink里。 is.getline(sink, size, delim) 与接受三个参数的get版本类似，但会读取并丢弃delim is.read(sink, size) 读取最多size个字节，存入字符数组sink中。返回is is.gcount() 返回上一个未格式化读取操作从is读取的字节数 os.write(source, size) 将字符数组source中的size个字节写入os。返回os is.ignore(size, delim) 读取并忽略最多size个字符，包括delim。与其他未格式化函数不同，ignore有默认参数：size的默认值为1，delim的默认值为文件尾 上表中get和getline函数很相似，差别在于处理分隔符的方式：get将分隔符留作istream中的下一个字符，而getline则读取并丢弃分隔符。不过无论哪个函数都不会将分隔符保存在sink中。 一般情况下，我们主张使用标准库提供的高层抽象。一个常见的编程错误是将get或peek的返回值赋予一个chat而不是一个int。这样做是错误的，但是编译器却不能发现这个错误。有可能会出现什么问题难以预料，甚至可能陷入无限循环。char ch; while ((ch = std::cin.get()) != EOF) std::cout.put(ch); 在大多数系统中，绑定到cin、cout、cerr和clog的流不支持随机访问：毕竟，当我们向cout直接输出数据时，类似向回跳10个位置这种操作时没有意义的。也就是说istream和ostream类型通常不支持随机访问，seek和tell函数对它们不一定有效，所以后续所述的tell和seek函数用法只适用于fstream和sstream类型。 seek和tell函数如下表所示： 操作 描述 tellg()、tellp 返回一个输入流中（tellg）或输出流中（tellp）标记的当前位置 seekg(pos)、seekp(pos) 在一个输入流或输出流中将标记重定位到给定的绝对地址。pos通常是前一个tellg或tellp返回的值。 seekp(off, from)、seekg(off, from) 在一个输入流或输出流中将标记重定位到from之前或之后off个位置（off可正可负），from可能是：beg（流开始位置）、cur（标记当前在流里的位置）、end（流结尾位置）。 上表中g版本表示我么正在获得（读取）数据，而p版本表示我们正在放置（写入）数据。虽然标准库对读和写的随机访问有不同版本的函数来完成，但是实际上在一个流中只有一个标记：并不存在独立的读标记和写标记，读和写用的同一个标记。标准库将g和p版本的读写位置都映射到这个单一的标记。 比如现在有如下文件Offset.txt： abcd efg hi j 现在我们想要新增一行，该行记录了文件里每一行的起始偏移位置（这样做有可能会对以后我们快速访问到某一行很有帮助哦！），我们想要得到的结果如下： abcd efg hi j 5 9 12 14 《C++Primer第五版》P678页的程序太复杂，它每统计一个偏移量就会写一次文件，这样做在实际开发中是不好的，效率太低。可以考虑使用下面的程序（简单很多而且只有一次文件写操作）： std::fstream FInOut("Offset.txt"); if (!FInOut) std::cout &lt;&lt; "open file failed!" &lt;&lt; std::endl; std::string Line, LastLine; size_t Count = 0; while (std::getline(FInOut, Line)) //到达文件尾之后seekp等等函数就都失效了，需要先用clear函数复位才能继续使用 { Count += Line.size() + 1; //1是指行末的换行符 LastLine += std::to_string(Count) + " "; } FInOut.clear(); //clear函数一定要有，重置所有状态标识位 FInOut.seekp(0, std::fstream::end); FInOut &lt;&lt; LastLine &lt;&lt; std::endl; FInOut.close(); 上面程序值得注意的有以下几点： 统计偏移量时，必须包含每行末尾不可见的换行符（因为getline函数读入字符串到string对象时不会读入换行符）。 while循环结束后，已经到达了文件末尾，此时seekp等等函数都会失效，无法再把读写指针重定位到某个位置，必须先使用clear函数将所有状态标识位复位。 fstream::end并不表示到达文件末尾，到达文件末尾是指流的eofbit位被置位。&nbsp; 参考文献：《C++Primer第五版》]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++Primer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MPI]]></title>
    <url>%2F2018%2F04%2F13%2FMPI%2F</url>
    <content type="text"><![CDATA[概述 MPI（Message Passing Interface，消息传递接口）实现的是进程级别的并行，通过通信在进程之间进行消息传递。它并不是一种新的程序语言，而是一个可以被C、C++、Fortran调用的函数库。 环境配置 可以在这里下载最新的微软MPI，然后直接运行安装下载的两个文件：msmpisdk.msi和msmpisetup.exe。这两个文件运行安装之后，会在安装目录下出现Include和Lib文件夹，把它们分别添加到VS项目属性里就可以了（不太懂的话可以参考这里的配置方法，是一个套路~）。 使用MPI的第一个Hello World程序 先了解一下MPI常用的六个函数： int MPI_Init (int *argc,char ***argv) 该函数用于对MPI这个并行环境进行初始化。其中参数argc、argv的实参通常都来自main函数的形参（main函数形参具体可参考这里）。当然，也可以直接给argc和argv这两个参数传递nullptr。从MPI_Init函数后面开始一直到MPI_Finalize()函数（包括该函数）为止的代码，在每个进程中都会被执行一次。 int MPI_Comm_size (MPI_Comm comm ,int* size ) 该函数用于获取通信子comm中的进程数size。通信子是一组可以互相发送消息的进程集合。MPI_COMM_WORLD是包含程序中所有进程的一个通信子。 int MPI_Comm_rank (MPI_Comm comm,int *rank) 该函数用于获取MPI并行程序中 ，当前进程在通信子comm中的进程编号rank。 int MPI_Send( void *buff, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm) 该函数用于进程间发送消息。将当前进程里count个datatype类型的数据（保存在buff里），发送到comm通信子里编号为dest的进程里，消息标签是tag（这个消息标签有点像对暗号或者是邮戳，接收方必须要有可以兼容的标签才可以接收该消息）。前三个参数构成了消息数据，后三个参数构成了消息信封。datatype必须是MPI自己定义的数据类型，比如MPI_INT。 int MPI_Recv( void *buff, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm comm, MPI_Status *status) 该函数用于进程间接收消息。从comm通信子里编号为source的进程里接收最多count个datatype类型的数据，接收后存放到buff里。tag是消息标签，只有进程号和标签号都对的上的消息才会被接收。status是一个结构体，保存了实际接收消息的状态消息，比如源进程号、消息标签、包含的数据项个数等等。 int MPI_Finalize() 该函数用于进程退出MPI系统，所有进程正常退出都必须调用它。它表明并行代码的结束，结束除主进程(rank=0)外的其他进程。串行代码仍可在主进程上继续执行，但不能再有MPI函数，包括MPI_Init()函数。 我们可以来看一下这个MPI并行的Hello World程序了： //MPI实例中最简单的HelloWorld #include &lt;iostream> #include &lt;mpi.h> int main(int argc, char *argv[]) { int MyId = 0, NumProcs = 0, NameLen = 0; char ProcessorName[MPI_MAX_PROCESSOR_NAME]; MPI_Init(&amp;argc, &amp;argv); //环境初始化，后面直到MPI_Finalize（包括它）的代码段，在每个进程中都会被执行一次 MPI_Comm_rank(MPI_COMM_WORLD, &amp;MyId); //获取本进程在通信空间中的rank值（类似进程ID号） MPI_Comm_size(MPI_COMM_WORLD, &amp;NumProcs); //获得进程个数 MPI_Get_processor_name(ProcessorName, &amp;NameLen); std::cout &lt;&lt; "Hello World form process " &lt;&lt; MyId &lt;&lt; "th of " &lt;&lt; NumProcs &lt;&lt; " processes, named " &lt;&lt; ProcessorName &lt;&lt; std::endl; MPI_Finalize(); //退出MPI系统，所有进程正常退出都必须调用它。表明并行代码的结束，结束除主进程外的其他进程，串行代码仍可在主进程(rank=0)上运行 return 0; } 想要使用mpi当然需要包含头文件mpi.h了。编译程序后会生成exe文件，通过cmd进入exe所在的文件目录下，输入：mpiexec -n 4 MPI(HelloWorld).exe，开始并行执行上面的代码。其中4表示使用4个进程进行并行计算。运行结果如下： >mpiexec -n 4 MPI(HelloWorld).exe Hello World form process 2th of 4 processes, named elay Hello World form process 1th of 4 processes, named elay Hello World form process 3th of 4 processes, named elay Hello World form process 0th of 4 processes, named elay 如果觉得从cmd输入文件目录比较麻烦，可以将下面的内容保存为.reg注册表文件，双击运行以后就会在鼠标右键里看到“Open cmd here as Admin”。 Windows Registry Editor Version 5.00 [HKEY_CLASSES_ROOT\Directory\shell\runas] @="Open cmd here as Admin" "HasLUAShield"="" [HKEY_CLASSES_ROOT\Directory\shell\runas\command] @="cmd.exe /s /k pushd \"%V\"" [-HKEY_CLASSES_ROOT\Directory\Background\shell\runas] [HKEY_CLASSES_ROOT\Directory\Background\shell\runas] @="Open cmd here as Admin" "HasLUAShield"="" [HKEY_CLASSES_ROOT\Directory\Background\shell\runas\command] @="cmd.exe /s /k pushd \"%V\"" [-HKEY_CLASSES_ROOT\Drive\shell\runas] [HKEY_CLASSES_ROOT\Drive\shell\runas] @="Open cmd here as Admin" "HasLUAShield"="" [HKEY_CLASSES_ROOT\Drive\shell\runas\command] MPI还提供一个同时发送和接收的函数： int MPI_Sendrecv(void *sendbuf, int sendcount,MPI_Datatype sendtype, int dest, int sendtag, void *recvbuf, int recvcount, MPI_Datatype recvtype, int source, int recvtag, MPI_Comm comm, MPI_Status *status) 它可以在一条语句中同时实现向其他进程发送数据和从其他进程接收数据的操作。可以有效地避免不合理的通信次序，最大限度避免死锁的产生。其参数和发送、接收函数的参数含义相同，就不再赘述了。 并行计算复化梯形积分 复化梯形积分法的基本思想是：将x轴上的区间划分为n个等长的子区间，然后计算子区间的和。具体可参考这里。其串行版本如下： int n = 102400000; double a = 0.0, b = 4.0; double h = (b - a) / n; double ApproximateArea = (f(a) + f(b)) / 2.0; for (int i = 1; i &lt; n - 1; i++) { double x_i = a + i * h; ApproximateArea += f(x_i); } ApproximateArea *= h; 比如我们现在要求f(x)=x^2，在区间0到4上的积分。我们可以把0到4这个区间分成n=1024个等长的子区间。如果采用串行版本，就需要依次计算1024个子区间的面积。很容易看到每个子区间面积的计算都是相互独立的，所以我们是可以用并行的方式来计算这些子区间面积的。当然，我们可能并没有1024个进程来分别计算每一个子区间的面积，可能只有8个或16个进程。我们可以让每个进程都执行上面的串行代码，来同时负责计算不同的多个子区间的面积和（8个进程的话就是每个进程负责计算128个子区间的面积和），然后再把它们加起来得到最终的积分面积。所以并行代码如下： //点对点通信，计算复化梯形积分 #include &lt;iostream> #include &lt;string> #include &lt;mpi.h> double f(double x); double trapArea(double vTrapsL, double vTrapsR, double vTrapCount, double h); int main() { int ProcessNum= 0, CurrentRank = 0, n = 102400000; double a = 0.0, b = 4.0, TotalArea = 0.0; double h = (b - a) / n; MPI_Init(nullptr, nullptr); double ElapsedTime = MPI_Wtime(); MPI_Comm_size(MPI_COMM_WORLD, &amp;ProcessNum); MPI_Comm_rank(MPI_COMM_WORLD, &amp;CurrentRank); int Local_n = n / ProcessNum; //每个进程要处理的梯形数目 double Local_a = a + CurrentRank * Local_n * h; double Local_b = Local_a + Local_n * h; double LocalArea = trapArea(Local_a, Local_b, Local_n, h); //每个进程调用trapArea这个串行代码来计算自己负责的多个子区间的面积和 if (CurrentRank != 0) { MPI_Send(&amp;LocalArea, 1, MPI_DOUBLE, 0, 99, MPI_COMM_WORLD); //其他进程把自己计算的面积和发送给0号进程 } else { TotalArea = LocalArea; for (int i = 1; i &lt; ProcessNum; ++i) { MPI_Recv(&amp;LocalArea, 1, MPI_DOUBLE, i, 99, MPI_COMM_WORLD, MPI_STATUS_IGNORE); //0号进程接收其他进程计算的面积和 TotalArea += LocalArea; //把这些面积和加起来，得到最终的积分面积 } ElapsedTime = MPI_Wtime() - ElapsedTime; std::cout &lt;&lt; "With " + std::to_string(n) + " trapezoids, our estimate:" &lt;&lt; std::endl; std::cout &lt;&lt; "The integral from " &lt;&lt; std::to_string(a) &lt;&lt; " to " &lt;&lt; std::to_string(b) &lt;&lt; " is: " + std::to_string(TotalArea) &lt;&lt; std::endl; std::cout &lt;&lt; "The elapsed time is: " &lt;&lt; ElapsedTime &lt;&lt; " seconds" &lt;&lt; std::endl; } MPI_Finalize(); return 0; } double f(double x) { return x*x; } double trapArea(double vTrapsL, double vTrapsR, double vTrapCount, double h) { double ApproximateArea = (f(vTrapsL) + f(vTrapsR)) / 2.0; double x = 0.0; for (int i = 1; i &lt; vTrapCount; ++i) { x = vTrapsL + i * h; ApproximateArea += f(x); } ApproximateArea *= h; return ApproximateArea; } 程序运行结果如下： >mpiexec -n 64 MPI2(TrapezoidalIntegration).exe With 102400000 trapezoids, our estimate: The integral from 0.000000 to 4.000000 is: 21.333333 The elapsed time is: 0.0084099 seconds 我们将102400000个子区间平均分配到64个进程中进程子任务求解，求解完成后，1-99号进程计算的结果将通过MPI_Send函数发送出去，而0号进程使用MPI_Recv函数接收汇总，将每个进程的结果求和，得到总区间[a, b]上的积分值。而同样地用串行程序计算积分的结果如下： Integration result is: 21.3333 The elapsed time is: 0.092 seconds 可以看到并行程序的时间开销确实少了很多（在子区间个数n比较大的时候差距才比较明显）。 我们把梯形面积计算均摊到100个进程里了，但最后的面积求和操作都是0号进程在做，0号进程在求和时，其他进程几乎都处于空闲，这无疑会浪费资源？有没有什么办法可以让其他进程也一起加入求和过程呢？这就需要使用集合通信了。 使用集合通信来并行计算复化梯形积分 上一节并行计算复化梯形积分的方法，其实是点对点通信，即单个进程对单个进程的通信。所有的求和过程都让进程0来做了。求和过程图示如下：1到7号进程将自己计算的结果（5,2,6,2,1,9,10,4）发送给0号进程，0号进程收到后把它们加起来。可以看到0号进程做了7次接收和7次加法操作。如果进程之间可以按照下图这样两两归并相加呢？那么0号进程只做了3次接收和3次加法操作。而整个并行系统中必然是0号进程花费的时间最多（因为它既要计算面积，又要进行面积加和操作），所以0号进程所花费的时间就是整个并行系统计算的时间。如果是1024个进程，按照原来的做法0号进程需要1023次接收和加法操作；但是如果按照这种归并方式，0号进程只需要做10次接收和加法操作(上面那幅图很像二叉树嘛，所以是log2(n）)，这样一来并行计算的效率就提高了100倍！ 这涉及到了进程集合之间的通信，即集合通信。幸运的是，MPI已经给我们封装好了这种类似的归约操作，使用MPI_Reduce函数就可以实现： //集合通信，计算梯形积分，使用归约的方式（Reduce，多到一） #include &lt;iostream> #include &lt;string> #include &lt;mpi.h> double f(double x); double trapArea(double vTrapsL, double vTrapsR, double vTrapCount, double h); int main() { int ProcessNum= 0, CurrentRank = 0, n = 102400000; double a = 0.0, b = 4.0, TotalArea = 0.0; double h = (b - a) / n; MPI_Init(nullptr, nullptr); double ElapsedTime = MPI_Wtime(); MPI_Comm_size(MPI_COMM_WORLD, &amp;ProcessNum); MPI_Comm_rank(MPI_COMM_WORLD, &amp;CurrentRank); int Local_n = n / ProcessNum; //每个进程要处理的梯形数目 double Local_a = a + CurrentRank * Local_n * h; double Local_b = Local_a + Local_n * h; double LocalArea = trapArea(Local_a, Local_b, Local_n, h); //每个进程调用trapArea这个串行代码来计算自己负责的多个子区间的面积和 MPI_Reduce(&amp;LocalArea, &amp;TotalArea, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD); //MPI_SUM是归约操作符 if (CurrentRank == 0) { ElapsedTime = MPI_Wtime() - ElapsedTime; std::cout &lt;&lt; "With " + std::to_string(n) + " trapezoids, our estimate:" &lt;&lt; std::endl; std::cout &lt;&lt; "The integral from " &lt;&lt; std::to_string(a) &lt;&lt; " to " &lt;&lt; std::to_string(b) &lt;&lt; " is: " + std::to_string(TotalArea) &lt;&lt; std::endl; std::cout &lt;&lt; "The elapsed time is: " &lt;&lt; ElapsedTime &lt;&lt; " seconds" &lt;&lt; std::endl; } MPI_Finalize(); return 0; } double f(double x) { return x*x; } double trapArea(double vTrapsL, double vTrapsR, double vTrapCount, double h) { double ApproximateArea = (f(vTrapsL) + f(vTrapsR)) / 2.0; double x = 0.0; for (int i = 1; i &lt; vTrapCount; ++i) { x = vTrapsL + i * h; ApproximateArea += f(x); } ApproximateArea *= h; return ApproximateArea; } 唯一不同的是，这段代码中，我们不再使用MPI_Send和MPI_Recv这样点对点的通信函数，而是使用了一个MPI_Reduce函数（函数什么意思后续再讲）。程序运行结果如下： mpiexec -n 1024 MPI3(Reduce).exe With 102400000 trapezoids, our estimate: The integral from 0.000000 to 4.000000 is: 21.333333 The elapsed time is: 0.105715 seconds 而同样在1024个进程下，之前点对点版本的程序运行结果如下： mpiexec -n 1024 MPI2(TrapezoidalIntegration).exe With 102400000 trapezoids, our estimate: The integral from 0.000000 to 4.000000 is: 21.333333 The elapsed time is: 0.509458 seconds 可以看到使用MPI_Reduce的集合通信的计算速度确实是点对点通信的5倍左右（并没有理论上的10倍那么高~），而且进程数增加时似乎并行计算的时间也增多了（比之前64个进程点对点通信的时间长），个人猜想可能是系统自身分不出这么多进程造成的原因~。 下面我们先来详细看一下集合通信。 集合通信 在MPI中，涉及所有的进程的通信函数我们称之为集合通信。而单个进程对单个进程的通信，类似于MPI_Send和MPI_Recv这样的通信函数，我们称之为点对点通信。集合通信具有一下特点： 在通信子中的所有进程都必须调用相同的集合通信函数 每个进程传递给MPI集合通信函数的参数必须是“相容的” 点对点通信函数是通过标签和通信子来匹配的，而集合通信函数不使用标签，只是通过通信子和调用的顺序来进行匹配。 下表汇总了MPI中的集合通信函数： 类型 函数 功能 数据移动 MPI_Bcast 一到多，数据广播 MPI_Gather 到一，数据汇合 MPI_Gatherv MPI_Gather的变种，数据块长度可以不同 MPI_Allgather MPI_Gather的变种，把结果值分发给每一个进程 MPI_Allgatherv MPI_Allgather的变种，数据块长度可以不同 MPI_Scatter 一到多，数据分散 MPI_Scatterv MPI_Scatter的变种，数据块长度可以不同 MPI_Alltoall 多到多，数据置换（全交换） MPI_Alltoallv MPI_Alltoall的变种，数据块长度可以不同 数据聚集 MPI_Reduce 多到一，数据归约 MPI_Allreduce MPI_Reduce的变种，把结果值分发给每一个进程 MPI_Reduce_Scatter MPI_Reduce的变种，把结果值散射到每一个进程 MPI_Scan 扫描归约，各进程以此得到部分归约的结果 同步 MPI_Barrier 同步操作 下面分别来具体看一下这些函数。 归约 数据归约的基本功能是从每个进程收集数据，把这些数据归约成单个值，把归约的值存储到根进程中。MPI_Reduce函数就是用来完成归约过程的，函数原型如下： int MPI_Reduce (void *sendbuf, void *recvbuf, int count,MPI_Datatype datatype, MPI_Op op, int root,MPI_Comm comm) 除了op以外，其他参数的含义都与MPI_Send和MPI_Recv函数相同。MPI_Op表示MPI归约中得操作符，我们上面的程序中所用的就是求累加和的归约操作符。MPI提供的所有归约操作符如下表： 归约操作符 描述 MPI_MAX 最大值 MPI_MIN 最小值 MPI_SUM 求和 MPI_PROD 求积 MPI_LAND 逻辑与 MPI_LOR 逻辑或 MPI_LXOR 逻辑异或 MPI_BAND 位与 MPI_BOR 位或 MPI_BXOR 位异或 MPI_MINLOC 计算一个全局最小值和附加到这个最小值上的进程索引 MPI_MAXLOC 计算一个全局最大值和附加到这个最大值上的进程索引 数据归约还有以下一些变种函数： int MPI_Allreduce (void *sendbuf, void *recvbuf, int count,MPI_Datatype datatype, MPI_Op op,MPI_Comm comm) 此函数在得到归约值以后，将结果值分发给每一个进程，这样的话，并行中的所有进程都能知道结果值了。图示如下： int MPI_Reduce_scatter (void *sendbuf, void *recvbuf,int *recvcnts,MPI_Datatype datatype, MPI_Op op,MPI_Comm comm) 该函数在得到归约值以后，再将结果进行一次散发操作（散发后续详述）。 int MPI_Scan (void *sendbuf, void *recvbuf, int count,MPI_Datatype datatype, MPI_Op op,MPI_Comm comm) 该函数完成扫描归约（又叫前缀归约），它会将部分归约结果依次发送给每个进程。 广播 在一个集合通信中，如果属于一个进程的数据被发送到通信子中的所有进程，这样的集合通信就叫做广播。图示如下： int MPI_Bcast (void *buffer, int count,MPI_Datatype datatype, int root,MPI_Comm comm) 通信子comm中进程号为root的根进程把自己buffer中的count个datatype类型的数据，发送给通信子中所有其他进程。实例程序如下： //集合通信，广播：将一个进程中的数据发送到通信子中的所有进程 #include &lt;iostream> #include &lt;string> #include &lt;mpi.h> class CBroadcast { public: CBroadcast() = default; ~CBroadcast() = default; void broadcastData(); }; void CBroadcast::broadcastData() { int CurrentRank = 0, ProcessNum = 0; MPI_Init(nullptr, nullptr); MPI_Barrier(MPI_COMM_WORLD); //阻塞，等所有进程都运行到这里之后再继续执行 double ElapsedTime = MPI_Wtime(); MPI_Comm_rank(MPI_COMM_WORLD, &amp;CurrentRank); MPI_Comm_size(MPI_COMM_WORLD, &amp;ProcessNum); int DataBuf[3]{ 0 }; if (CurrentRank == 0) { DataBuf[0] = 3; DataBuf[1] = 6; DataBuf[2] = 9; } MPI_Bcast(DataBuf, 3, MPI_INT, 0, MPI_COMM_WORLD); //将root进程（这里是0）的DataBuf中的内容发送给通信子中的所有进程 std::cout &lt;&lt; "Current rankID = " + std::to_string(CurrentRank) + ", Received Data are: " + std::to_string(DataBuf[0]) + "," + std::to_string(DataBuf[1]) + "," + std::to_string(DataBuf[2]) &lt;&lt; std::endl; ElapsedTime = MPI_Wtime() - ElapsedTime; if (CurrentRank == 0) std::cout &lt;&lt; "Elapsed time is: " &lt;&lt; ElapsedTime &lt;&lt; std::endl; MPI_Finalize(); } int main() { CBroadcast Broadcast; Broadcast.broadcastData(); return 0; } 程序运行结果如下： >mpiexec -n 8 MPI4(Broadcast).exe Current rankID = 0, Received Data are: 3,6,9 Current rankID = 4, Received Data are: 3,6,9 Current rankID = 2, Received Data are: 3,6,9 Current rankID = 5, Received Data are: 3,6,9 Current rankID = 6, Received Data are: 3,6,9 Current rankID = 3, Received Data are: 3,6,9 Current rankID = 7, Received Data are: 3,6,9 Current rankID = 1, Received Data are: 3,6,9 Elapsed time is: 3.58895e-05 散射 根进程将数据分块发送给各个进程的集合通信就叫散射。图示如下： int MPI_Scatter (void *sendbuf, int sendcnt,MPI_Datatype sendtype, void *recvbuf,int recvcnt, MPI_Datatype recvtype,int root, MPI_Comm comm) 根进程将自己sendbuf中的np（np是通信子comm中的进程总数）个连续存放的数据块按进程号的顺序依次发送给comm中的所有进程（包括根进程自己）的recvbuf中。值得注意的是，sendcnt和recvcnt是每个进程发送或接收的一个数据块的长度，而不是发送给所有进程得数据长度之和。 int MPI_Scatterv (void *sendbuf, int *sendcnts,int *displs, MPI_Datatype sendtype,void *recvbuf, int recvcnt,MPI_Datatype recvtype, int root,MPI_Comm comm) 散发不同长度的数据块。与MPI_Scatter类似，但允许sendbuf中每个数据块的长度不同并且可以按任意的顺序排放。数组sendcnts和displs的元素个数等于comm中的进程数，它们分别给出发送给每个进程的数据长度和位移，均以sendtype为单位。 示例程序如下： //集合通信，散射scatter：根进程将数据分块发送给所有进程进行并行计算 #include &lt;iostream> #include &lt;string> #include &lt;mpi.h> class CScatter { public: CScatter() = default; ~CScatter() = default; void scatterData(); }; void CScatter::scatterData() { float DataBuf[][4]= { {1.0,2.0,3.0,4.0}, {5.0,6.0,7.0,8.0}, {9.0,10.0,11.0,12.0}, {13.0,14.0,15.0,16.0} }; int CurrentRank = 0, ProcessNum = 0; MPI_Init(nullptr, nullptr); MPI_Comm_rank(MPI_COMM_WORLD, &amp;CurrentRank); MPI_Comm_size(MPI_COMM_WORLD, &amp;ProcessNum); if (ProcessNum == 4) { float ReceiveBuf[4]; MPI_Scatter(DataBuf, 4, MPI_FLOAT, ReceiveBuf, 4, MPI_FLOAT, 0, MPI_COMM_WORLD); //将0号进程DataBuf里的数据分块散射到通信子的所有进程里 std::cout &lt;&lt; "Current rankID = " + std::to_string(CurrentRank) + ", Received Data are: " + std::to_string(ReceiveBuf[0]) + "," + std::to_string(ReceiveBuf[1]) + "," + std::to_string(ReceiveBuf[2]) + "," + std::to_string(ReceiveBuf[3]) &lt;&lt; std::endl; } else std::cout &lt;&lt; "Please specify -n 4" &lt;&lt; std::endl; MPI_Finalize(); } int main() { CScatter Scatter; Scatter.scatterData(); return 0; } 程序运行结果如下： >mpiexec -n 4 MPI5(Scatter).exe Current rankID = 0, Received Data are: 1.000000,2.000000,3.000000,4.000000 Current rankID = 1, Received Data are: 5.000000,6.000000,7.000000,8.000000 Current rankID = 2, Received Data are: 9.000000,10.000000,11.000000,12.000000 Current rankID = 3, Received Data are: 13.000000,14.000000,15.000000,16.000000 聚集 每个进程都将自己的一块数据发送给根进程的集合通信就叫聚集。图示如下： int MPI_Gather (void *sendbuf, int sendcnt,MPI_Datatype sendtype, void *recvbuf,int recvcnt, MPI_Datatype recvtype,int root, MPI_Comm comm) 收集相同长度的数据块。所有进程（包括根进程自己）将sendbuf中的数据块发送给根进程root，根进程将这些数据块按进程号的顺序依次放到recvbuf中。和散射一样，sendcnt和recvcnt是每个进程发送或接收的一个数据块的长度。示例程序如下： //集合通信，聚集gather：所有进程将数据块发送给根进程，根进程按进程号依次存储接收到的数据块 #include &lt;iostream> #include &lt;string> #include &lt;mpi.h> class CGather { public: CGather() = default; ~CGather() = default; void gatherData(); }; void CGather::gatherData() { int CurrentRank = 0, ProcessNum = 0; MPI_Init(nullptr, nullptr); MPI_Barrier(MPI_COMM_WORLD); double ElapsedTime = MPI_Wtime(); MPI_Comm_rank(MPI_COMM_WORLD, &amp;CurrentRank); MPI_Comm_size(MPI_COMM_WORLD, &amp;ProcessNum); int *pReceiveBuf = new int[ProcessNum]; _ASSERT(pReceiveBuf); int SendBuf = CurrentRank; MPI_Gather(&amp;SendBuf, 1, MPI_INT, pReceiveBuf, 1, MPI_INT, 0, MPI_COMM_WORLD); ElapsedTime = MPI_Wtime() - ElapsedTime; if (CurrentRank == 0) { for (int i = 0; i &lt; ProcessNum; ++i) { std::cout &lt;&lt; "pReceiveBuf[" &lt;&lt; i &lt;&lt; "] = " &lt;&lt; pReceiveBuf[i] &lt;&lt; ", "; } std::cout &lt;&lt; std::endl &lt;&lt; "Elapsed time is: " &lt;&lt; ElapsedTime &lt;&lt; std::endl; } MPI_Finalize(); } int main() { CGather Gather; Gather.gatherData(); return 0; } 该程序里，每个进程将自己的进程序号发送给根进程。程序运行结果如下： >mpiexec -n 4 MPI6(Gather).exe pReceiveBuf[0] = 0, pReceiveBuf[1] = 1, pReceiveBuf[2] = 2, pReceiveBuf[3] = 3, Elapsed time is: 0.000143558 该函数还有其他变种： int MPI_Allgather (void *sendbuf, int sendcnt,MPI_Datatype sendtype, void *recvbuf,int recvcnt, MPI_Datatype recvtype,MPI_Comm comm) MPI_Allgather与MPI_Gather类似，区别是所有进程同时将数据收集到recvbuf中，因此也称为数据全收集，它相当于以comm中的每个进程为根进程来调用一次MPI_Gather函数；也相当于任意一个进程调用MPI_Gather之后再把收集到的数据广播到所有进程里。 int MPI_Gatherv (void *sendbuf, int sendcnt,MPI_Datatype sendtype, void *recvbuf,int *recvcnts, int *displs,MPI_Datatype recvtype, int root,MPI_Comm comm) 该函数允许每个进程发送得数据块长度不同。其参数和MPI_Scatterv的参数含义相同。 int MPI_Allgatherv (void *sendbuf, int sendcnt,MPI_Datatype sendtype, void *recvbuf,int *recvcnts, int *displs,MPI_Datatype recvtype, MPI_Comm comm) 不同长度数据块的全收集。 转置 对通信子中的所有进程，将进程i的第j块数据发送到进程j的第i个位置的集合通信就叫转置。图示如下： int MPI_Alltoall (void *sendbuf, int sendcnt,MPI_Datatype sendtype, void *recvbuf,int recvcnt, MPI_Datatype recvtype,MPI_Comm comm) 相同长度数据块的全转置：将进程i将sendbuf中的第j块数据发送到进程j的recvbuf中的第i个位置。sendcnt和recvcnt都是指一个数据块的长度。如果对一个二维数组使用该函数，则接收到的结果就是该二维数组的转置。 int MPI_Alltoallv (void *sendbuf, int *sendcnts,int *sdispls, MPI_Datatype sendtype,void *recvbuf, int *recvcnts,int *rdispls, MPI_Datatype recvtype,MPI_Comm comm) 不同长度数据块的全转置。每个数据块的长度可以不等，并且不要求连续存放。 MPI并行程序的两种基本模式 MPI两种最基本的并行程序设计模式是：对等模式和主从模式。对等模式：各个部分地位相同，功能和代码基本一致，只不过是处理的数据或对象不同，也容易用相同的程序来实现。主从模式：分为主进程和从进程，程序通信进程之间的一种主从或依赖关系，主程序运行一套代码，从进程运行另一套代码。 之前点对点通信并行计算复化梯形积分的程序，就是一种简单的主从模式，因为0号进程和其他进程执行的代码不一样：它还需要收集其他进程（从进程）计算的面积来进行求和，得到最终的积分面积。我们再看一个主从模式的实例代码： #include &lt;iostream> #include &lt;mpi.h> #include &lt;stdio.h> #define MSG_TAG_EXIT 0 #define MSG_TAG_PRINT 1 void slaver(); void master(); int main() { int CurrentRank = 0; MPI_Init(nullptr, nullptr); MPI_Comm_rank(MPI_COMM_WORLD, &amp;CurrentRank); (0 == CurrentRank) ? master() : slaver(); MPI_Finalize(); return 0; } void slaver() //从进程代码段 { int CurrentRank = 0; MPI_Comm_rank(MPI_COMM_WORLD, &amp;CurrentRank); char Message[100]; sprintf_s(Message, "Hello World from process %d", CurrentRank); MPI_Send(Message, strlen(Message), MPI_CHAR, 0, MSG_TAG_PRINT, MPI_COMM_WORLD); sprintf_s(Message, "Hello World from process %d again", CurrentRank); MPI_Send(Message, strlen(Message), MPI_CHAR, 0, MSG_TAG_PRINT, MPI_COMM_WORLD); sprintf_s(Message, "Bye from process %d", CurrentRank); MPI_Send(Message, strlen(Message), MPI_CHAR, 0, MSG_TAG_EXIT, MPI_COMM_WORLD); } void master() //主进程代码段 { int ProcessSize = 0; MPI_Comm_size(MPI_COMM_WORLD, &amp;ProcessSize); int SlaverCount = ProcessSize - 1; char Message[100]; MPI_Status Status; while (SlaverCount > 0) //主要还有从进程，则执行接收和打印消息 { memset(Message, 0, 100); MPI_Recv(Message, 100, MPI_CHAR, MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, &amp;Status); //接收任何进程发出的任何消息 switch (Status.MPI_TAG) { case MSG_TAG_PRINT: std::cout &lt;&lt; Message &lt;&lt; std::endl; //主进程收到从进程发来的消息标签如果是MSG_TAG_PRINT，就打印消息 break; case MSG_TAG_EXIT: std::cout &lt;&lt; Message &lt;&lt; std::endl; //主进程收到从进程发来的消息标签如果是MSG_TAG_EXIT，就令从进程数减1 --SlaverCount; break; } } } 这段代码的主从关系就更明显了，主进程（0号）和从进程（其他进程）执行的明显是两套代码。从进程负责发送多个消息，每个消息可能有不同的消息标签，而主进程负责接收所有消息然后打印消息内容，直到所有的从进程都退出并行系统为止。 MPI的4种通信模式 这里所说的通信模式不是指点对点通信或集合通信，而是： 标准通信模式：MPI_SEND 缓存通信模式：MPI_BSEND 同步通信模式：MPI_SSEND 就绪通信模式：MPI_RSEND 这四种通信模式的区别都在消息发送端，消息接收端的操作都是MPI_RECV。 标准通信模式 标准通信模式下，是否对发送的数据进行缓存是由MPI决定的，而不是由并行程序员来控制。 如果MPI不缓存将要发送的数据：对于阻塞通信，只有当相应的接收调用被执行后，并且发送数据完全到达接收缓冲区后，发送操作才算完成；对于非阻塞通信，发送操作虽然没有完成，但是发送调用可以正确返回，程序可以接下来执行其他的操作。 如果MPI缓冲将要发送的数据：发送操作不管接收操作是否执行，都可以进行；而且缓冲结束后发送操作就可以完成并返回，不需要等待接收操作接收到数据。 图示如下： 缓存通信模式 缓存通信模式下，由用户直接对通信缓冲区进行申请、使用和释放。缓存通信模式和上图由MPI决定的缓冲方式一样，消息发送能否进行以及能否正确返回都不依赖于接收进程，完全依赖于是否有足够的通信缓冲区可用。 int MPI_Buffer_attach(void *buffer, int size) //用于申请缓存 int MPI_Buffer_detach(void **buffer, int *size) //用于释放缓存，这是一个阻塞调用，函数返回表示缓冲区已经被释放 释放缓冲是阻塞调用，它一直等到使用该缓存的消息发送完成后才返回，这一调用返回后用户可以重新使用该缓冲区。图示如下：示例程序如下： #include &lt;iostream> #include &lt;mpi.h> int main() { int CurrentRank = 0, ProcessNum = 0, Src = 0, Dest = 1; double Buffer[6], *pTempBuffer = nullptr, *pTempBuffer2 = nullptr; MPI_Status Status; MPI_Init(nullptr, nullptr); MPI_Comm_rank(MPI_COMM_WORLD, &amp;CurrentRank); MPI_Comm_size(MPI_COMM_WORLD, &amp;ProcessNum); if (ProcessNum != 2) { std::cerr &lt;&lt; "This program uses exactly 2 processes!" &lt;&lt; std::endl; MPI_Abort(MPI_COMM_WORLD, 1); } if (CurrentRank == Src) //当前为发送进程 { for (int i = 0; i &lt; ProcessNum; ++i) Buffer[i] = double(i) + 1; int TempSize = 0; MPI_Pack_size(ProcessNum, MPI_DOUBLE, MPI_COMM_WORLD, &amp;TempSize); //计算发送ProcessNum个MPI_DOUBLE类型的数据需要多大空间 pTempBuffer = new double[TempSize + 2 * MPI_BSEND_OVERHEAD]; //申请缓存发送所需要的空间 _ASSERT(pTempBuffer); MPI_Buffer_attach(pTempBuffer, TempSize + 2 * MPI_BSEND_OVERHEAD); //将申请的缓存空间递交给MPI，告诉MPI_Bsend需要发送数据时去该缓存里拿 MPI_Bsend(Buffer, ProcessNum, MPI_DOUBLE, Dest, 2000, MPI_COMM_WORLD); //执行缓存模式发送 } else if (CurrentRank == Dest) //当前为接收进程 { MPI_Recv(Buffer, ProcessNum, MPI_DOUBLE, Src, 2000, MPI_COMM_WORLD, &amp;Status); for (int i = 0; i &lt; ProcessNum; ++i) std::cout &lt;&lt; "Buffer[" &lt;&lt; i &lt;&lt; "] = " &lt;&lt; Buffer[i] &lt;&lt; std::endl; } MPI_Finalize(); return 0; } 程序运行结果如下： >mpiexec -n 2 MPI8(CacheCommunication).exe Buffer[0] = 1 Buffer[1] = 2 同步通信模式 同步通信模式的开始不依赖于接收进程相应的接收操作是否已经启动，但是同步发送却必须等到相应的接收进程开始后才可以正确返回。因此，同步发送返回后，意味着发送缓冲区中的数据已经全部被系统缓冲区缓存，并且已经开始发送。这样当同步发送返回后，发送缓冲区可以被释放或重新使用。而在标准通信模式或缓存通信模式中，在用使用缓存的模式下，发送操作返回仅仅意味着数据都已经到发送缓冲区了，数据是否到系统缓冲区不得而知（发送缓冲区表示MPI的缓冲区，系统缓冲区表示操作系统的写缓冲区）。图示如下：示例代码如下： #include &lt;iostream> #include &lt;mpi.h> #define SIZE 10 int main() { int CurrentRank = 0, ProcessNum = 0, Src = 0, Dest = 1, Buffer[SIZE]; MPI_Status Status1, Status2; MPI_Init(nullptr, nullptr); MPI_Comm_rank(MPI_COMM_WORLD, &amp;CurrentRank); MPI_Comm_size(MPI_COMM_WORLD, &amp;ProcessNum); if (ProcessNum != 2) { std::cerr &lt;&lt; "This program uses exactly 2 processes!" &lt;&lt; std::endl; MPI_Abort(MPI_COMM_WORLD, 1); } int ActualSize = 5; if (CurrentRank == Src) //当前为发送进程 { ActualSize = 1; MPI_Ssend(Buffer, ActualSize, MPI_INT, Dest, 1, MPI_COMM_WORLD); //同步消息发送1个整型数，消息标签tag为1 ActualSize = 4; MPI_Ssend(Buffer, ActualSize, MPI_INT, Dest, 2, MPI_COMM_WORLD); //同步消息发送4个整型数，消息标签tag为2 } else if (CurrentRank == Dest) //当前为接收进程 { MPI_Recv(Buffer, ActualSize, MPI_INT, Src, 1, MPI_COMM_WORLD, &amp;Status1); MPI_Recv(Buffer, ActualSize, MPI_INT, Src, 2, MPI_COMM_WORLD, &amp;Status2); int Count1 = 0, Count2 = 0; MPI_Get_count(&amp;Status1, MPI_INT, &amp;Count1); //获取消息1包含的数据个数 MPI_Get_count(&amp;Status2, MPI_INT, &amp;Count2); //获取消息2包含的数据个数 std::cout &lt;&lt; "Receive " &lt;&lt; Count1 &lt;&lt; " data, tag = " &lt;&lt; Status1.MPI_TAG &lt;&lt; std::endl; std::cout &lt;&lt; "Receive " &lt;&lt; Count2 &lt;&lt; " data, tag = " &lt;&lt; Status2.MPI_TAG &lt;&lt; std::endl; } MPI_Finalize(); return 0; } 程序运行结果如下： >mpiexec -n 2 MPI9(SyncCommunication).exe Receive 1 data, tag = 1 Receive 4 data, tag = 2 就绪通信模式 在就绪通信模式中，只有当接收进程的接收操作已经启动时，才可以在发送端启动发送操作。图示如下：一种可能的就绪通信模式的底层实现方式如下图：目标是保证1要先于4执行，方法是插入2和3：程序上1一定先于2执行，3一定等2成功后才执行（标准模式通信），3成功后4才能执行。所以这样一来就保证了1一定优先于4执行，从而保证就绪通信。 使用就绪通信的示例代码如下： #include &lt;iostream> #include &lt;mpi.h> #define SIZE 2000 int main() { int CurrentRank = 0, ProcessNum = 0, Src = 0, Dest = 1; float SendBuf[SIZE], RecvBuf[SIZE]; MPI_Status Status; MPI_Request Request; MPI_Init(nullptr, nullptr); MPI_Comm_rank(MPI_COMM_WORLD, &amp;CurrentRank); MPI_Comm_size(MPI_COMM_WORLD, &amp;ProcessNum); if (ProcessNum != 2) { std::cerr &lt;&lt; "This program uses exactly 2 processes!" &lt;&lt; std::endl; MPI_Abort(MPI_COMM_WORLD, 1); } int NextRank = CurrentRank + 1; if (NextRank >= ProcessNum) NextRank = 0; int PrevRank = CurrentRank - 1; if (PrevRank &lt; 0) PrevRank = ProcessNum - 1; int Tag = 2000; int Count = SIZE / 3; if (0 == CurrentRank) { MPI_Recv(MPI_BOTTOM, 0, MPI_INT, NextRank, Tag, MPI_COMM_WORLD, &amp;Status); //收到其接收进程通知，表示接收操作已经启动 std::cout &lt;&lt; "Process " &lt;&lt; CurrentRank &lt;&lt; " post Ready send" &lt;&lt; std::endl; MPI_Rsend(SendBuf, Count, MPI_FLOAT, NextRank, Tag, MPI_COMM_WORLD); } else { std::cout&lt;&lt; "Process " &lt;&lt; CurrentRank &lt;&lt; " post a receive call" &lt;&lt; std::endl; MPI_Irecv(RecvBuf, SIZE, MPI_FLOAT, MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, &amp;Request); //启动非阻塞接收 MPI_Send(MPI_BOTTOM, 0, MPI_INT, NextRank, Tag, MPI_COMM_WORLD); //通知发送进程接收进程的接收操作已经启动 MPI_Wait(&amp;Request, &amp;Status); //等待非阻塞接收完成 std::cout &lt;&lt; "Process " &lt;&lt; CurrentRank &lt;&lt; " Receive Rsend message from " &lt;&lt; Status.MPI_SOURCE &lt;&lt; std::endl; } MPI_Finalize(); return 0; } 程序运行结果如下： >mpiexec -n 2 MPI10(ReadyCommutation).exe Process 1 post a receive call Process 0 post Ready send Process 1 Receive Rsend message from 0 阻塞通信与非阻塞通信 阻塞通信调用时，整个程序只能执行通信相关的内容，而无法执行计算相关的内容。非阻塞调用的初衷是尽量让通信和计算重叠进行，提高程序整体执行效率。如下图所示：非阻塞通信调用意味着通信开始启动；而非阻塞通信完成则需要调用其他的接口来查询。理想的非阻塞通信设计应该如下：非阻塞通信对应的发送和接收函数如下图所示：重复非阻塞通信，表示可以一次完成多个非阻塞调用。 int MPI_Isend(void* buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm, MPI_Request *request) 非阻塞调用的函数比一般对应的阻塞调用函数多了一个参数：request，这个参数是一个用来描述非阻塞通信状况的对象，称为非阻塞通信对象，通过对这一对象的查询，就可以知道与之相应的非阻塞发送是否完成。 非阻塞通信调用的返回并不意味着通信的完成，那么如何才能明确得知该非阻塞通信已经完成了呢？MPI提供两个调用MPI_WAIT和MPI_TEST用于这一目的。 int MPI_Wait(MPI_Request *request, MPI_Status *status) MPI_Wait以非阻塞通信对象MPI_Request为参数，一直等到与该阻塞通信对象相应的非阻塞通信完成后才返回，同时释放该非阻塞通信对象，因此程序员就不需要再显式释放该对象。与该非阻塞通信完成有关的信息放在返回的状态参数status中。 int MPI_Test(MPI_Request*request, int *flag, MPI_Status *status) MPI_Test与MPI_Wait类似，但是它的返回不一定等到与非阻塞通信对象相联系的非阻塞通信的结束。若在调用MPI_Test时，该非阻塞通信已经结束，则它和MPI_Wait的效果完全相同，完成标志flag=true；若在调用MPI_Test时，该非阻塞通信还未完成，则它和MPI_Wait不同，它不必等待非阻塞通信的完成，可以直接返回，但是完成标志flag=false，同时也不释放相应的非阻塞通信对象。示例程序如下： #include &lt;iostream> #include &lt;mpi.h> int main() { int CurrentRank = 0, ProcessNum = 0, RecevieBuf = 0, SendBuf = 0; MPI_Status Status; MPI_Request Request; MPI_Init(nullptr, nullptr); MPI_Comm_size(MPI_COMM_WORLD, &amp;ProcessNum); MPI_Comm_rank(MPI_COMM_WORLD, &amp;CurrentRank); if (ProcessNum != 2) { std::cerr &lt;&lt; "This program uses exactly 2 processes!" &lt;&lt; std::endl; MPI_Abort(MPI_COMM_WORLD, 1); } if (0 == CurrentRank) { SendBuf = CurrentRank; MPI_Isend(&amp;SendBuf, 1, MPI_INT, 1, 41, MPI_COMM_WORLD, &amp;Request); //标准非阻塞发送 MPI_Wait(&amp;Request, &amp;Status); //等待该发送的完成 std::cout &lt;&lt; "Process 0 has sended the data." &lt;&lt; std::endl; } else if (1 == CurrentRank) { MPI_Irecv(&amp;RecevieBuf, 1, MPI_INT, 0, 41, MPI_COMM_WORLD, &amp;Request);//标准非阻塞接收 MPI_Wait(&amp;Request, &amp;Status); //等待该接收操作的完成 std::cout &lt;&lt; "Process 1 has received the data." &lt;&lt; std::endl; } MPI_Finalize(); return 0; } 程序运行结果如下： >mpiexec -n 2 MPI11(NonBlocking).exe Process 0 has sended the data. Process 1 has received the data. 因为可以在一个进程中调用MPI_Send_Init函数来多次发送非阻塞通信，所以也有对应的Wait和Test函数来检测这多次非阻塞通信的完成状态： int MPI_Waitany(int count, MPI_Request *array_of_requests, int *index, MPI_Status *status) 该函数用于等待非阻塞通信对象中任何一个非阻塞通信对象的完成，然后释放已完成的非阻塞通信对象，然后返回，返回后index= i，表示第i个非阻塞通信完成了。 int MPI_Waitall(int count, MPI_Request *array_of_requests, MPI_Status *array_of_statuses) 该函数必须等到所有非阻塞通信对象对应的非阻塞通信操作都完成后才返回。 int MPI_Waitsome(int incount,MPI_Request *array_of_request, int *outcount, int *array_of_indices, MPI_Status *array_of_statuses) 该函数只要有一个或多个非阻塞通信完成就会返回。已完成非阻塞通信的个数记录在outcount中，它们的下标和状态分别记录在后两个参数里。 当然也有对应的Test函数（含义类似不再赘述了）： int MPI_Testany(int count, MPI_Request *array_of_requests, int *index, int *flag, MPI_Status *status) int MPI_Testall(int count, MPI_Request *array_of_requests, int *flag, MPI_Status *array_of_statuses) int MPI_Testsome(int incount,MPI_Request *array_of_request, int *outcount, int *array_of_indices, MPI_Status *array_of_statuses) 还可以用MPI_Probe和MPI_IProbe函数，来允许程序员在不实际执行接收的情况下，检查给定的消息是否到达。程序员可以根据返回的信息决定如何接收该消息，甚至可以根据被检查消息的长度来分配缓冲区的大小： int MPI_Iprobe(int source,int tag,MPI_Comm comm,int *flag, MPI_Status *status) 该函数是一个非阻塞调用，用于检查来源于通信子comm里进程号为source、标签为tag的消息是否到达，如果到达了flag为true，否则为false。 int MPI_Probe(int source,int tag,MPI_Comm comm,MPI_Status *status) 该函数是一个阻塞调用，只有找到一个匹配的消息达到之后它才会返回。示例程序如下： #include &lt;iostream> #include &lt;mpi.h> int main() { int CurrentRank = 0, ProcessNum = 0, RecvI = 0; double RecvD = 41.41; MPI_Status Status; MPI_Init(nullptr, nullptr); MPI_Comm_size(MPI_COMM_WORLD, &amp;ProcessNum); MPI_Comm_rank(MPI_COMM_WORLD, &amp;CurrentRank); if (ProcessNum != 3) { std::cerr &lt;&lt; "This program uses exactly 3 processes!" &lt;&lt; std::endl; MPI_Abort(MPI_COMM_WORLD, 1); } if (0 == CurrentRank) { MPI_Send(&amp;RecvI, 1, MPI_INT, 2, 0, MPI_COMM_WORLD); } else if (1 == CurrentRank) { MPI_Send(&amp;RecvD, 1, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD); } else if (2 == CurrentRank) { for (int k = 0; k &lt; 2; ++k) { MPI_Probe(MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, &amp;Status); if (0 == Status.MPI_SOURCE) { MPI_Recv(&amp;RecvI, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, &amp;Status); std::cout &lt;&lt; "Data: " &lt;&lt; RecvI &lt;&lt; " from process 0" &lt;&lt; std::endl;; } else if (1 == Status.MPI_SOURCE) { MPI_Recv(&amp;RecvD, 1, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD, &amp;Status); std::cout &lt;&lt; "Data: " &lt;&lt; RecvD &lt;&lt; " from process 1" &lt;&lt; std::endl; } } } MPI_Finalize(); return 0; } 程序运行结果如下： >mpiexec -n 3 MPI12(Probe).exe Data: 0 from process 0 Data: 41.41 from process 1 MPI发送不连续数据 其实这节也可以叫做如何用MPI发送用户自定义的数据类型。因为用户自定义的结构体等数据类型，通常都具有内部数据类型不完全一致、数据不连续的特性。 MPI处理不连续数据有两种方法： 允许用户把不连续的多个数据类型封装成自定义的新的数据类型（又称派生数据类型），然后使用这种新的数据类型来发送不连续的数据。 数据的打包和解包。即在发送方将不连续的数据打包到连续的区域，然后发送出去；在接收方将打包后的连续数据再解包到不连续的存储空间。 用户自定义新的数据类型 比如现在有一个结构体是这样的： struct SData { double d; char c; } Data; MPI不能直接把这个结构体发送出去，因为在类似MPI_Send这类函数里，指定数据内容的同时，需要指定数据的类型，但是这个数据的类型又必须是像MPI_INT这种专属于MPI的类型。当然这个结构体类型肯定没有对应的MPI类型，所以我们需要为MPI自定义一个类似这个结构体的类型，然后用这个新的类型来发送结构体数据： MPI使用类型图来表示一个自定义数据类型的结构： 类型图={&lt;类型0,偏移0>, &lt;类型1,偏移1>, &lt;类型2,偏移2>,...,&lt;类型n-1,偏移n-1>} 那么上面的结构体的类型图就是（要注意结构体等数据类型的对齐问题）： {&lt;double,0>, &lt;char, 8>} 了解数据的类型图在于我们要清楚地认识到，在MPI中定义一个复杂的数据类型需要明确告知其成员类型和内存偏移。 我们可以用MPI_Type_create_struct函数来创建结构体SData对应的自定义MPI类型： int MPI_Type_struct(int count,int *array_of_blocklengths, MPI_Aint *array_of_displacements, MPI_Datatype *array_of_types , MPI_Datatype *newtype) 需要提供块的数量count（块通常都是连续的相同类型组合在一起，比如我们通常认为{, , }是两个不同的块构成的类型图，前两个double型构成一个块，后一个char型构成一个块，所以对于SData就是两个块组成的）、各个块的长度\元素个数array_of_blocklengths（刚才的例子就是前一个块长度为2，后一个块长度为1）、各个块的起始地址的偏移字节数array_of_displacements、各个块中的元素类型array_of_types 、新数据类型newtype。 比如对于结构体SData，块数量为2、各个块长度为{1,1}、各个块偏移量为{0,8}、各个块类型为{double,char}，所以我们可以用如下代码来创建对应的MPI类型： int BlockLens[] = { 1,1 }; MPI_Aint BlockDisplacements[] = { 0,8 }; MPI_Datatype BlockDatatypes[] = { MPI_DOUBLE,MPI_CHAR }; MPI_Datatype NewStructType; MPI_Type_create_struct(2, BlockLens, BlockDisplacements, BlockDatatypes, &amp;NewStructType); //生成新的MPI结构体数据类型 NewStructType就是我们为SData生成的对应的MPI类型。这个新类型在使用之前，还必须先使用MPI_Type_commit函数将其递交给MPI系统。 MPI_Type_commit(&amp;NewStructType); 一个递交后的数据类型，就可以当作一个MPI基本类型了，甚至可以用它去生成别的数据类型。也就是说比如我们现在有了一个已经递交的MPI类型type1，它的类型图恰好是{, }，那么SData就可以直接由这一个块来组成，不用再分成两个块了。不过通常情况下，这样做会比较麻烦，因为需要先生成、递交中间数据类型type1，所以我们才通常把连续的基本类型数据作为一个块。 接下来我们就可以用NewStructType这个新的MPI类型，来直接发送、接收SData对象了： Data = { 41.41, 'a' }; MPI_Bcast(&amp;Data, 1, NewStructType, 0, MPI_COMM_WORLD); std::cout &lt;&lt; "Process " &lt;&lt; CurrentRank &lt;&lt; " received the struct data: " &lt;&lt; Data.d &lt;&lt; "," &lt;&lt; Data.c &lt;&lt; std::endl; 使用完新类型以后别忘了使用MPI_Type_free函数释放它： MPI_Type_free(&amp;NewStructType); 完整程序如下： #include &lt;iostream> #include &lt;mpi.h> struct SData { double d; char c; }Data; int main() { int CurrentRank = 0, ProcessNum = 0; MPI_Status Status; MPI_Init(nullptr, nullptr); MPI_Comm_rank(MPI_COMM_WORLD, &amp;CurrentRank); MPI_Comm_size(MPI_COMM_WORLD, &amp;ProcessNum); int BlockLens[] = { 1,1 }; MPI_Aint BlockDisplacements[2]; BlockDisplacements[0] = 0; BlockDisplacements[1] = 8; /*MPI_Get_address(&amp;Data.d, &amp;BlockDisplacements[0]); MPI_Get_address(&amp;Data.c, &amp;BlockDisplacements[1]); BlockDisplacements[1] -= BlockDisplacements[0]; BlockDisplacements[0] = 0;*/ MPI_Datatype BlockDatatypes[] = { MPI_DOUBLE,MPI_CHAR }; MPI_Datatype NewStructType; MPI_Type_create_struct(2, BlockLens, BlockDisplacements, BlockDatatypes, &amp;NewStructType); //生成新的MPI结构体数据类型 MPI_Type_commit(&amp;NewStructType); Data = { 41.41, 'a' }; MPI_Bcast(&amp;Data, 1, NewStructType, 0, MPI_COMM_WORLD); //直接使用新的MPI类型来发送结构体数据 std::cout &lt;&lt; "Process " &lt;&lt; CurrentRank &lt;&lt; " received the struct data: " &lt;&lt; Data.d &lt;&lt; "," &lt;&lt; Data.c &lt;&lt; std::endl; MPI_Type_free(&amp;NewStructType); MPI_Finalize(); return 0; } 上面的0和8是我们自己人为算出的偏移量，有时候可能会比较麻烦或者拿不准，我们可以直接使用MPI_Adress函数来获取到这些偏移量： int MPI_Get_address(void* location, MPI_Aint *address) 该函数用于返回一个变量在内存中相对于MPI预定义的地址MPI_BOTTOM的偏移地址。所以我们可以用如下代码来获取结构体对象Data中两个变量的偏移地址： MPI_Aint BlockDisplacements[2]; MPI_Get_address(&amp;Data.d, &amp;BlockDisplacements[0]); MPI_Get_address(&amp;Data.c, &amp;BlockDisplacements[1]); BlockDisplacements[1] -= BlockDisplacements[0]; BlockDisplacements[0] = 0; 使用MPI_Type_struct函数可以生成MPI结构体类型，还有一些其他函数可以生成一些别的MPI类型： int MPI_Type_contiguous(int count, MPI_Datatype oldtype, MPI_Datatype *newtype) 该函数用于生成连续的数据类型，相当于将一个已有的数据类型按顺序依次连续进行复制后的结果。例如如果原来的数据类型oldtype的类型图为{, }，对旧类型重复的次数count=3，则newtype返回的新类型的类型图为： {&lt;double,0>, &lt;char,8>, &lt;double,16>, &lt;char,24>, &lt;double,32>, &lt;char,40>} int MPI_Type_vector(int count, int blocklength, int stride, MPI_Datatype oldtype, MPI_Datatype *newtype) 该函数和MPI_Type_contiguous函数类似，只不过后者是把数据类型进行连续复制，而该函数是连续复制count个块，每个块有blocklength个元素，每个元素的类型是oldtype；而且块与块之间可以存在空隙，两个相邻块的各自第一个元素之间相隔stride个元素。例如oldtype的类型图是{, }，则调用MPI_Type_vector(2, 3, 4, oldtype, newtype)生成的新数据类型newtype的类型图为： {&lt;double,0>, &lt;char,8>, &lt;double,16>, &lt;char,24>, &lt;double,32>, &lt;char,40>, &lt;double,64>, &lt;char,72>, &lt;double,80>, &lt;char,88>, &lt;double,96>, &lt;char,104>} 如下图所示：图中黄色部分表示double，红色部分表示char。 int MPI_Type_hvector(int count,int blocklength,MPI_Aint stride,MPI_Datatype oldtype, MPI_Datatype *newtype) 该函数与上一个函数基本相同，只是stride不再是元素个数，而是字节数。 int MPI_Type_indexed(int count,int *array_of_blocklengths, int *array_of_displacements, MPI_Datatype oldtype, MPI_Datatype *newtype) 该函数也和MPI_Type_vector函数很相似，不同的是它可以单独指定每个块的偏移量，而不是像MPI_Type_vector里只是指定了相邻两个块的距离，而且每个块的长度可以不一样。count是块的数量，array_of_blocklengths是每个块的元素个数，array_of_displacements是每个块的偏移（整数数组，表示偏移量是元素大小的整数倍），oldtype是每个元素的类型，newtype是生成的新的数据类型。假设oldtype的类型图是{, }，令B={3,1}，D={4,0}，则调用MPI_Type_indexed(2,B,D,oldtype,newtype)生成的新数据类型的类型图是： {&lt;double,64>,&lt;char,72>,&lt;double,80>,&lt;char,88>,&lt;double,96>,&lt;char,104>, &lt;double,0>,&lt;char,8>} int MPI_Type_hindexed(int count,int *array_of_blocklengths, MPI_Aint* array_of_displacements, MPI_Datatype oldtype, MPI_Datatype *newtype) 该函数和上一个函数基本相同，只是array_of_displacements中的块偏移不再是旧数据类型大小的整数倍，而是字节数。 打包与解包 打包和解包是除了自定义数据类型以外，另一个用来发送不连续数据的方式，在发送前显式地把数据包装到一个连续的缓冲区，在接收之后从连续缓冲区中解包。 int MPI_Pack(void* inbuf, int incount, MPI_datatype, void *outbuf, int outcount, int *position, MPI_Comm comm) 该函数把发送缓冲区inbuf里的incount个datatype类型的数据放到输出缓冲区outbuf里，该输出缓冲区共有outcount个字节。position指定了把发送缓冲区的数据放置于输出缓冲区的第几个元素上（position是一个表示元素个数的整型，结合datatype就能算出其在输出缓冲区里的地址），调用完该函数后，position的值会按照被打包数据的个数来增加。 由position值的变化方式决定，通过连续几次对不同位置的消息调用该打包操作，就可以将不连续的数据放到一个连续的空间。 int MPI_Unpack(void* inbuf, int insize, int *position, void *outbuf, int outcount, MPI_Datatype datatype, MPI_Comm comm) 该函数与MPI_Pack函数对应，输入缓冲区inbuf是一个具有insize个元素位置的连续空间，position指定了将要被解包的数据在连续的输入缓冲区的第几个元素位置上（整型，结合datatype就可以算出其地址），解包后它的值根据解包数据的个数来增加，因此连续多次调用MPI_Unpack函数，就可以把连续的数据解包到不同（不连续）的输出缓存outbuf中。 打包后的数据可以用MPI_PACKED格式发送出去。接收方可以用MPI_PACKED格式来接收数据，然后调用MPI_Unpack来解包数据；也可以直接用MPI_INT这种类似的准确类型来接收，相当于自动解包了，只要和发送方发送的实际数据类型确实匹配就可以了。 下面我们用打包和解包的方式来发送一个结构体，示例程序如下： //通过打包和解包来发送结构体等等这些复杂的或者不连续的数据 #include &lt;iostream> #include "mpi.h" struct SData { double d; char c; }Data{ 41.41,'a' }; int main() { int CurrentRank = 0; MPI_Status Status; MPI_Init(nullptr, nullptr); MPI_Comm_rank(MPI_COMM_WORLD, &amp;CurrentRank); int Position4Pack = 0; int Position4Unpack = 0; char ContinusBuf[100]; if (0 == CurrentRank) { MPI_Pack(&amp;Data.d, 1, MPI_DOUBLE, ContinusBuf, 100, &amp;Position4Pack, MPI_COMM_WORLD); //将结构体对象Data的成员d打包到连续空间ContinusBuf里 MPI_Pack(&amp;Data.c, 1, MPI_CHAR, ContinusBuf, 100, &amp;Position4Pack, MPI_COMM_WORLD); //接着将结构体对象Data的成员c打包到连续空间ContinusBuf里 } MPI_Bcast(&amp;Position4Pack, 1, MPI_INT, 0, MPI_COMM_WORLD); MPI_Bcast(ContinusBuf, Position4Pack, MPI_PACKED, 0, MPI_COMM_WORLD); if (CurrentRank != 0) { SData Data2; Position4Unpack = 0; MPI_Unpack(ContinusBuf, Position4Pack, &amp;Position4Unpack, &amp;Data2.d, 1, MPI_DOUBLE, MPI_COMM_WORLD); //将连续空间里的第一个元素解包到Data2.d里 MPI_Unpack(ContinusBuf, Position4Pack, &amp;Position4Unpack, &amp;Data2.c, 1, MPI_DOUBLE, MPI_COMM_WORLD); //将连续空间里的第二个元素解包到Data2.c里 std::cout &lt;&lt; "Data2 = {" &lt;&lt; Data2.d &lt;&lt; ", " &lt;&lt; Data2.c &lt;&lt; "}" &lt;&lt; std::endl; } MPI_Finalize(); return 0; } 程序运行结果如下： >mpiexec -n 4 MPI14(Pack).exe Data2 = {41.41, a} Data2 = {41.41, a} Data2 = {41.41, a} MPI的进程组和通信域 通信域包括通信上下文、进程组、虚拟处理器拓扑、属性等内容，可分为组内通信域和组间通信域。组内通讯域用于描述属于同一组内进程间的通信，组间通讯域用于描述属于不同进程组的进程间的通信。 进程组是通讯域的一个重要组成部分，它定义了不同进程的有序集合，进程组内的每个进程都有一个序号rank，它们的序号是从0开始编号并且连续的。 进程组的管理 我们先来看一些与进程组有关的管理函数： int MPI_Group_size(MPI_Group group,int *size) 该函数用于返回进程中group中所包含的进程数size。 int MPI_Group_rank(MPI_Group group,int *rank) 该函数用于返回当前进程在进程组group中的编号，有点像MPI_Comm_rank。 int MPI_Group_translate_ranks(MPI_Group group1,int n,int *ranks1, MPI_Group group2,int *ranks2) 该函数用于返回进程组group1中的n个进程（由ranks指定）在进程组group2中对应的编号（把对应的编号放到ranks2里）。比如有的时候想要知道MPI_COMM_WORLD中的某些进程，在MPI_COMM_WORLD子通信域（子进程组）中对应的序号。 int MPI_Group_compare(MPI_Group group1,MPI_Group group2,int *result) 该函数对两个进程组group1和group2进行比较，如果两个进程组所包含的进程以及相同进程的编号都完全相同，则返回MPI_IDENT；如果所包含的进程完全相同但是相同进程的编号在两个组中并不相同，则返回MPI_SIMILAR；否则返回MPI_UNEQUAL。 int MPI_Comm_group(MPI_Comm comm, MPI_Group * group) 该函数用于返回通讯域comm中所包含的进程组group。 int MPI_Group_union(MPI_Group group1, MPI_Group group2, MPI_Group *newgroup) 该函数用于返回两个进程组的并集。该并集中的元素次序是第一组中的元素次序后跟第二组中出现的元素。 int MPI_Group_intersection(MPI_Group group1, MPI_Group group2, MPI_Group *newgroup) 该函数用于返回两个进程组的交集。该交集中的元素次序同第一组。 int MPI_Group_difference(MPI_Group group1,MPI_Group group2,MPI_Group *newgroup) 该函数用于返回第一个进程组group1对第二个进程组group2的差集。该差集中的元素次序同第一组。 int MPI_Group_incl(MPI_Group group,int n,int *ranks,MPI_Group *newgroup) 该函数将已有进程组group中的n个进程（由ranks指定）形成一个新的进程组newgroup。 int MPI_Group_excl(MPI_Group group, int n , int *ranks,MPI_Group *newgroup) 该函数是将已有进程组group中的n个进程（由ranks指定）删除后形成新的进程组newgroup。 int MPI_Group_free(MPI_Group *group) 该函数用于释放一个已有的进程组，然后把group置为MPI_GROUP_NULL，任何正在使用此组的操作将正常完成。 通讯域的管理 int MPI_Comm_size(MPI_Comm comm, int *size) 该函数用于返回通信域comm中的进程数。 int MPI_Comm_rank(MPI_Comm comm, int *rank) 该函数用于返回当前进程在通讯域comm中的编号rank。 int MPI_Comm_compare(MPI_Comm comm1,MPI_Comm comm2,int *result) 该函数用于比较两个通信域。如果comm1和comm2是同一对象的句柄（指针），返回MPI_IDENT；如果它俩包含的进程组的成员和序列编号都相同，则返回MPI_CONGRUENT；如果进程组的成员相同但编号不同，则返回MPI_SIMILAR；否则返回MPI_UNEQUAL。 int MPI_Comm_dup(MPI_Comm comm,MPI_Comm *newcomm) 该函数用于对一个已有的通信域comm进行复制，得到一个新的通信域newcomm。 int MPI_Comm_create(MPI_Comm comm,MPI_Group group,MPI_Comm *newcomm) 该函数根据通信域comm所包含的进程组的子集group，来创建一个新的通信域newcomm。如果当前进程不在group里，该函数调用会返回MPI_COMM_NULL（因为通常都是每个进程都会调用这个函数）。 int MPI_Comm_split(MPI_Comm comm,int color, int key,MPI_Comm *newcomm) 该函数太复杂了，没看懂。。。好像是把具有相同color的进程合在一起形成新的通信域，每个新的通信域中按照进程的key来排序。具体请参考《高性能计算之并行编程技术— MPI 并行程序设计》一书P189页把。 int MPI_Comm_free(MPI_Comm *comm) 该函数用于释放通信域comm，释放后该通信域被置为MPI_COMM_NULL。任何使用此通信域的挂起操作都会正常完成，仅当没有对此对象的活动引用时，它才会被实际撤销。 通信域和进程组管理的程序示例 比如现在有6个，在MPI_COMM_WORLD中的编号是{0,1,2,3,4,5}，现在需要用{1,3,5}形成新的通信域comm1，用{0,2,4}形成新的通信域comm2，然后在comm1中指向MAX归约操作，在comm2中执行MIN归约操作，在MPI_COMM_WORLD中执行SUM归约操作： #include &lt;iostream> #include "mpi.h" int main() { int ProcessNum = 0, CurrentRank4CommWorld; int SendBuf[4][4] = { { 1,2,3,4 },{ 4,3,2,1 }, { 3,4,2,1 },{ 2,1,4,3 } }; //4个进程会分别发送不同的数据 int RecevieBuf1[4], RecevieBuf2[4], RecevieBuf3[4]; MPI_Init(nullptr, nullptr); MPI_Comm_size(MPI_COMM_WORLD, &amp;ProcessNum); MPI_Comm_rank(MPI_COMM_WORLD, &amp;CurrentRank4CommWorld); if (4 != ProcessNum) { std::cerr &lt;&lt; "Please specify 6 processes!" &lt;&lt; std::endl; MPI_Abort(MPI_COMM_WORLD, 1); } MPI_Group WorldGroup; MPI_Comm_group(MPI_COMM_WORLD, &amp;WorldGroup); //获取通信域MPI_COMM_WORLD包含的进程组 int Ranks[] = { 1,3 }; MPI_Group NewGroup1, NewGroup2; MPI_Group_incl(WorldGroup, 2, Ranks, &amp;NewGroup1); //用WorldGroup中的1,3这两个进程组成新的进程组NewGroup1 MPI_Group_excl(WorldGroup, 2, Ranks, &amp;NewGroup2); //用WorldGroup中的0,2这两个进程组成新的进程组NewGroup2 MPI_Comm NewComm1, NewComm2; MPI_Comm_create(MPI_COMM_WORLD, NewGroup1, &amp;NewComm1); //用NewGroup1构造新的通信域NewComm1，当前进程不在NewGroup1里时会创建失败，返回MPI_COMM_NULL MPI_Comm_create(MPI_COMM_WORLD, NewGroup2, &amp;NewComm2); //用NewGroup2构造新的通信域NewComm2，当前进程不在NewGroup2里时会创建失败，返回MPI_COMM_NULL int OldRank1 = 1, OldRank2 = 0; int NewCommRoot1, NewCommRoot2; MPI_Group_translate_ranks(WorldGroup, 1, &amp;OldRank1, NewGroup1, &amp;NewCommRoot1); //获取WorldGroup中序号为1的进程在新进程组NewGroup1中的编号，后面发送数据时会将其作为新进程组的根进程 MPI_Group_translate_ranks(WorldGroup, 1, &amp;OldRank2, NewGroup2, &amp;NewCommRoot2); //获取WorldGroup中序号为0的进程在新进程组NewGroup2中的编号，后面发送数据时会将其作为新进程组的根进程 if (MPI_COMM_NULL != NewComm1) //这个if判断很重要，因为下面花括号里面的代码只在NewComm1非空时才有效 { MPI_Reduce(SendBuf[CurrentRank4CommWorld], RecevieBuf1, 4, MPI_INT, MPI_MAX, NewCommRoot1, NewComm1); int CurrentRank1 = 0; MPI_Comm_rank(NewComm1, &amp;CurrentRank1); if (NewCommRoot1 == CurrentRank1) { std::cout &lt;&lt; "Process " &lt;&lt; CurrentRank4CommWorld &lt;&lt; ":\t"; for (int i = 0; i &lt; 4; ++i) std::cout &lt;&lt; RecevieBuf1[i] &lt;&lt; "\t"; std::cout &lt;&lt; std::endl; } } else if (MPI_COMM_NULL != NewComm2) //这个if判断很重要，因为下面花括号里面的代码只在NewComm2非空时才有效 { MPI_Reduce(SendBuf[CurrentRank4CommWorld], RecevieBuf2, 4, MPI_INT, MPI_MIN, NewCommRoot2, NewComm2); int CurrentRank2 = 0; MPI_Comm_rank(NewComm2, &amp;CurrentRank2); if (NewCommRoot2 == CurrentRank2) { std::cout &lt;&lt; "Process " &lt;&lt; CurrentRank4CommWorld &lt;&lt; ":\t"; for (int i = 0; i &lt; 4; ++i) std::cout &lt;&lt; RecevieBuf2[i] &lt;&lt; "\t"; std::cout &lt;&lt; std::endl; } } MPI_Reduce(SendBuf[CurrentRank4CommWorld], RecevieBuf3, 4, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD); if (0 == CurrentRank4CommWorld) { std::cout &lt;&lt; "Process " &lt;&lt; CurrentRank4CommWorld &lt;&lt; ":\t"; for (int i = 0; i &lt; 4; ++i) std::cout &lt;&lt; RecevieBuf3[i] &lt;&lt; "\t"; std::cout &lt;&lt; std::endl; } MPI_Finalize(); return 0; } 程序运行结果如下： >mpiexec -n 4 MPI15(CommAndGroupManagement).exe Process 0: 1 2 2 1 Process 1: 4 3 4 3 Process 0: 10 10 11 9 上面的程序里指定只能运行4个进程，每个进程发送SendBuf里不同的内容，用{1,3}号进程创建新的通信域NewComm1，用{0,2}号进程创建新的通信域NewComm2。在通信域NewComm1里，原1号进程发送数据{4,3,2,1}，原3号进程发送数据{2,1,4,3}，所以做MPI_MAX归约操作以后，进程1会输出上面的：4,3,4,3。在通信域NewComm2里，原0号进程发送数据{1,2,3,4}，原2号进程发送数据{3,4,2,1}，所以做MPI_MIN归约操作以后，进程0会输出上面的1,2,2,1。在通信域MPI_COMM_WORLD里，进程0到进程3分别发送数据：{ 1,2,3,4 }、{ 4,3,2,1 }、{ 3,4,2,1 }、{ 2,1,4,3 }，所以做MIN_SUM归约操作以后，进程0会输出上面的10,10,11,9。 组间通信域 组间通信域是一种特殊的通信域，该通信域包括两个进程组，通过组间通信域实现两个不同进程组内进程之间的通信。一般把调用进程所在的进程组叫做本地组，而把另一个组叫做远程组。 int MPI_Comm_test_inter(MPI_Comm comm,int *flag) 该函数用于判断给定的通信域是组内通信域还是组间通信域，如果是组间通信域则返回true，否则返回false。 int MPI_COMM_Comm_remote_size(MPI_Comm comm,int *size) 该函数用于返回组间通信域内远程进程组的进程个数。 int MPI_Comm_remote_group(MPI_Comm comm,MPI_Group *group) 该函数用于返回组间通信域中的远程进程组。 int MPI_Intercomm_create(MPI_Comm local_comm,int local_leader,MPI_Comm peer_comm,int remote_leader,int tag,MPI_Comm *newintercomm) 该函数使用两个通信域local_comm和peer_comm创建了一个组间通信域。在同一个本地通信域local_comm中的所有进程，都提供相同的根进程编号local_leader，同时提供相同的远程通信域的根进程编号remote_leader。组成组间通信域的所有进程都必须提供相同的tag。通常远程通信域peer_comm都是使用MPI_COMM_WORLD来代替，也就是说如果comm1和MPI_COMM_WORLD组成组间通信域InterComm1，comm2和MPI_COMM_WORLD组成组间通信域InterComm2，而且创建两个组间通信域时都使用了相同的tag，那么comm1和comm2就能相互通信（MPI_COMM_WORLD就像起到了桥梁作用，这样做的原因是每个进程通常都只能获取到自己进程所在的通信域，得不到其他通信域，所以无法直接用comm1和comm2组成组间通信域，而需要分别在两个不同的进程中使用MPI_COMM_WORLD来作桥梁，可以参考下面的程序示例）。 int MPI_Intercomm_merge(MPI_Comm intercomm,int high,MPI_Comm *newintracomm) 该函数将一个组间通信域intercomm包含的两个通信域合并，形成一个组内通信域newintracomm。对于组间通信域中的两个进程组，如果一个组内的所有进程都提供high=true，另一个组内的所有进程都提供high=false，则提供true值的组的进程的编号在前，另一个组的编号在后。如果两个组的进程都提供相同的high值，则新通信域中进程的编号是任意的。 组间通信域程序示例 我们现在需要将通信域MPI_COMM_WORLD分裂成三个通信域，也就有三个进程组，然后让组0和组1通信，组1和组2通信，在构成组间通信域时需要借助MPI_COMM_WORLD： //创建组间通信域，实现不同组内通信域里的进程之间可以相互通信 #include &lt;iostream> #include "mpi.h" #define Tag_InterComm01 0 #define Tag_InterComm12 1 int main() { int CurrentRank = 0; MPI_Comm LocalComm; //标识当前进程属于分裂后的哪一个组内通信域 MPI_Comm InterComm1 = MPI_COMM_NULL, InterComm2 = MPI_COMM_NULL; //组间通信域 MPI_Init(nullptr, nullptr); MPI_Comm_rank(MPI_COMM_WORLD, &amp;CurrentRank); int Color = CurrentRank % 3; MPI_Comm_split(MPI_COMM_WORLD, Color, CurrentRank, &amp;LocalComm); //如果输入的进程数是9，则{0,3,6}、{1,4,7}、{2,5,8}构成分裂后的新的进程组(新的组内通信域) if (0 == Color) //进入if的进程都属于组0，因为color是0的所有进程都被分到组0里 { MPI_Intercomm_create(LocalComm, 0, MPI_COMM_WORLD, 1, Tag_InterComm01, &amp;InterComm1); //间接生成组0和组1之间的组间通信域InterComm1，使用标识Tag_InterComm01 //组0中的根进程在LocalComm中编号是0，而组1的根进程在原MPI_COMM_WORLD通信域里编号是1（{1,4,7}构成组1） } else if (1 == Color) //进入if的进程都属于组1，因为color是1的所有进程都被分到组1里 { MPI_Intercomm_create(LocalComm, 0, MPI_COMM_WORLD, 0, Tag_InterComm01, &amp;InterComm1); //间接生成组1和组0之间的组间通信域InterComm1，使用标识Tag_InterComm01 //组1中的根进程在LocalComm中编号是0，而组0的根进程在原MPI_COMM_WORLD通信域里编号是0（{0,3,6}构成组1） MPI_Intercomm_create(LocalComm, 0, MPI_COMM_WORLD, 2, Tag_InterComm12, &amp;InterComm2); //间接生成组1和组2之间的组间通信域InterComm2，使用标识Tag_InterComm12 //组1中的根进程在LocalComm中编号是0，而组2的根进程在原MPI_COMM_WORLD通信域里编号是2（{2,5,8}构成组2） } else if (2 == Color) //进入if的进程都属于组2，因为color是2的所有进程都被分到组2里 { MPI_Intercomm_create(LocalComm, 0, MPI_COMM_WORLD, 1, Tag_InterComm12, &amp;InterComm2); //间接生成组1和组2之间的组间通信域InterComm2，使用标识Tag_InterComm12 //组2中的根进程在LocalComm中编号是0，而组1的根进程在原MPI_COMM_WORLD通信域里编号是1（{1,4,7}构成组1） } MPI_Request Request; MPI_Status Status; int DataBuf[3] = {0}; if (CurrentRank == 0) { DataBuf[0] = 41; DataBuf[1] = 42; DataBuf[2] = 43; } if (InterComm1 != MPI_COMM_NULL) { if (0 == Color) //组间广播通信时，组0只有根进程可以发消息，而且根进程要用MPI_ROOT来指定，其他进程都不能发消息 { if (0 == CurrentRank) MPI_Bcast(DataBuf, 3, MPI_INT, MPI_ROOT, InterComm1); } else if (1 == Color) //组间广播通信时，组1使用MPI_Bcast接收消息时，root应该是发送方组0的进程号 { MPI_Bcast(DataBuf, 3, MPI_INT, 0, InterComm1); } /*if (0 == Color) //组间点对点通信 { int Rank0 = 0; MPI_Comm_rank(LocalComm, &amp;Rank0); if (0 == Rank0) MPI_Send(DataBuf, 3, MPI_INT, 1, 41, InterComm1); } else if (1 == Color) { int Rank1 = 0; MPI_Comm_rank(LocalComm, &amp;Rank1); if (1 == Rank1) { MPI_Recv(DataBuf, 3, MPI_INT, 0, 41, InterComm1, &amp;Status); } }*/ } std::cout &lt;&lt; "Current rankID = " &lt;&lt; CurrentRank &lt;&lt; ", Received Data are: " &lt;&lt; DataBuf[0] &lt;&lt; "," &lt;&lt; DataBuf[1] &lt;&lt; "," &lt;&lt; DataBuf[2] &lt;&lt; std::endl; switch (Color) { case 0: MPI_Comm_free(&amp;InterComm1); break; case 1: MPI_Comm_free(&amp;InterComm1); case 2: MPI_Comm_free(&amp;InterComm2); break; } MPI_Finalize(); return 0; } 运行结果如下： >mpiexec -n 9 MPI16(Intercomm).exe Current rankID = 0, Received Data are: 41,42,43 Current rankID = 3, Received Data are: 0,0,0 Current rankID = 6, Received Data are: 0,0,0 Current rankID = 2, Received Data are: 0,0,0 Current rankID = 5, Received Data are: 0,0,0 Current rankID = 1, Received Data are: 41,42,43 Current rankID = 4, Received Data are: 41,42,43 Current rankID = 7, Received Data are: 41,42,43 Current rankID = 8, Received Data are: 0,0,0 我们首先将MPI_COMM_WORLD分成了三个组内通信域{0,3,6}、{1,4,7}、{2,5,8}，然后间接通过MPI_COMM_WORLD建立0组和1组之间的组间通信域InterComm1，然后建立1组和2组之间的组间通信域InterComm2，接着我们在第一个组间通信域InterComm1中广播数据，从运行结果中可以看到进程1、4、7号进程都收到了广播的数据（0号进程的数据是广播前自身就有的），而这3个进程和0号进程在不同的组内通信域里，也就是说不同组内通信域的进程之间确实实现了组间通信。 组间通信时，如果使用的是广播方式MPI_Bcast，则发送方通信域只能是根进程在广播，其他进程都不能调用MPI_Bcast，而且根进程在广播时需要指定root参数为MPI_ROOT，而不能使用根进程的进程号来代替，接收方通信域可以使用MPI_Bcast来接收，接收时的root参数应该指定为发送方根进程的进程号（程序中是0）。 如果要在组间通信时使用点对点通信，可以用上面注释的代码来进行，值得注意的是，在点对点组间通信中，对发送和接收的进程都很严格，发送方通信域里只能有一个进程在发送，而接收方通信域里也只能有一个对应的进程在接收，否则会出现死锁（死锁原因没想明白~~~）。这点和组内点对点通信不一样，组内点对点通信时，所有进程都可以调用MPI_Recv函数，只有消息信封吻合时才真正接收消息；但是组间通信时，只能有一个对应的进程在调用MPI_Recv函数，消息信封不吻合的进程不能调用MPI_Recv函数（这段纯属个人yy，若发现不对，强烈欢迎留言指正）。 参考文献： 《高性能计算之并行编程技术— MPI并行程序设计》 《MPI学习记录》 《如何在win10+vs2013上配置MPI并行编程环境》 《MPI Tutorial》 《用MPI进行分布式内存编程》 《MPI中文手册》 本文所有源码可到这里下载。]]></content>
      <categories>
        <category>并行计算</category>
      </categories>
      <tags>
        <tag>MPI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++Primer第十六章 模板与泛型编程]]></title>
    <url>%2F2018%2F04%2F12%2FC%2B%2BPrimer%E7%AC%AC%E5%8D%81%E5%85%AD%E7%AB%A0%E6%A8%A1%E6%9D%BF%E4%B8%8E%E6%B3%9B%E5%9E%8B%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[定义模板 用关键字typename来指定模板类型参数比用class更为直观。 模板参数列表中，除了可以定义类型参数以外，还可以定义常量表达式： template&lt;unsigned N,unsigned M> int compare(const char(&amp;p1)[N], const char(&amp;p2)[M]) { return strcmp(p1, p2); } compare("the", "this"); 编译器会实例化出如下版本： int compare(const char(&amp;p1)[3], const char(&amp;p2)[4]) 所以在这种可变长度的情景下，模板也是很有用的，它不仅仅模板化某种类型，也模板化常量值。 非类型模板参数的模板实参必须是常量表达式。 函数模板可以声明为inline或constexpr的，如同非模板函数一样。inline或constexpr说明符放在模板参数列表之后，返回类型之前： template&lt;typename T> inline T min(const T&amp;, const T&amp;); 函数模板和类模板成员函数的定义通常放在头文件中。 编译器可以根据函数实参来推断函数模板的类型，所以在调用函数模板时可以不在尖括号中提供具体的模板信息；但是编译器无法推断类模板的模板参数类型，所以为了使用类模板，我们必须在模板名后的尖括号中提供额外信息，用来替代模板参数的模板实参列表。 在类外定义类模板的成员函数时，需要加上template，即使该成员函数并没有使用到模板信息。 默认情况下，对于一个实例化了的类模板，其成员只有在使用时才被实例化。 在一个类模板的作用域内，我们可以直接使用模板名而不必指定模板实参。 新标准允许我们为类模板定义一个类型别名： template&lt;typename T> using twin = std::pair&lt;T, T>; int main() { twin&lt;int> IntPair; //IntPair是一个std::pair&lt;int, int> return 0; } 类模板的static数据成员初始化时也需要使用template： template&lt;typename T> class CData { private: static int m_Data; }; template&lt;typename T> int CData&lt;T>::m_Data = 0; 先看如下程序： template&lt;typename T> class CData { public: using value_type = std::pair&lt;T, T>; value_type get(); private: value_type m_Data; }; template&lt;typename T> CData&lt;T>::value_type CData&lt;T>::get() { return m_Data; } 这段程序会在第14行报错，说value_type不是一个类型。这是因为默认情况下，C++语言假定通过作用域运算符访问的名字不是类型而是变量。为了通知编译器它是一个类型时，必须在前面加上typename关键字。值得注意的是这里只能用typename而不能用class。 template&lt;typename T> typename CData&lt;T>::value_type CData&lt;T>::get() { return m_Data; } 非模板类也可以有模板成员函数。 当我们在类模板外定义一个成员模板时，必须同时为类模板和成员模板提供模板参数列表。类模板的参数列表在前，成员模板的参数列表在后： template&lt;typename T> class CData { public: template &lt;typename It> It get(); }; template&lt;typename T> //类模板的模板参数列表 template&lt;typename It> //成员模板的模板参数列表 It CData&lt;T>::get() { } 在大系统中，在多个文件中实例化相同模板的额外开销可能非常严重。在新标准中，我们可以通过显式实例化来避免这种开销。一个显示实例化有如下形式：extern template declaration; //实例化声明 template declaration; //实例化定义 declaration是一个类或函数声明，其中所有模板参数已被替换为模板实参。例如：extern template class A &lt; std::string >; //声明 template int compare(const int&amp;, const int&amp;); //定义 当编译器遇到extern模板声明时，它不会在本文件中生成实例化代码。将一个实例化声明为extern就表示承诺在程序其他位置有该实例化的一个非extern声明（定义）。对一个给定的实例化版本，可能有多个extern声明，但必须只有一个定义。 显式实例化在定义时，会实例化模板类的所有成员，而普通实例化模板类，成员只有在被使用时才被实例化。 shared_ptr和unique_ptr的另一个差异是它们运行哟用户重载默认删除器的方式。我们可以很容易地重载一个shared_ptr的删除器，只要在创建或reset指针时传递给它一个可调用对象即可。与之相反，删除器的类型是一个unique_ptr对象的类型的一部分。用户必须在定义unique_ptr时以显式模板实参的形式提供删除器的类型。 shared_ptr不是将删除器直接保存为一个成员，因为删除器的类型直到运行时才会知道。而由于删除器的类型是unique_ptr类型的一部分，因此删除器成员的类型在编译时是知道的，从而删除器可以直接保存在unique_ptr对象中。通过在编译时绑定删除器。unique_ptr避免了间接调用删除器的运行时开销。通过在运行时绑定删除器，shared_ptr使用用户重载删除器更为方便。 模板实参推断 算术转换、派生类向基类的转换、用户自定义的转换等等，都不能应用到函数模板的模板参数中。 将实参传递给带模板类型的函数形参时，能够自动应用的类型转换只有const转换、数组或函数到指针的转换。 如果模板函数参数类型不是模板参数，则对实参进行正常的类型转换。 显式模板实参会按从左至右的顺序与对应的模板参数匹配。 如下面的程序，我们想要定义一个函数模板来返回迭代器范围中的首元素： template&lt;typename It> ??? &amp;f(It beg, It end) { return *beg; } 由于是模板函数，我们并不知道返回的准确类型，只知道返回类型和迭代器指向元素的类型相同，于是我们可以使用decltype(*beg)来获取返回类型，但是函数返回类型出现在函数参数之前，在编译器遇到参数列表之前，beg都是不存在的。为了解决这个问题，我们可以使用尾置返回类型： template&lt;typename It> auto f(It beg, It end) -> decltype(*beg) //尾置返回类型 { return *beg; } decltype推断的类型是beg所指向的元素的类型的引用，如果不想要引用，可以使用： template&lt;typename It> auto f(It beg, It end) -> typename remove_reference&lt;decltype(*beg)>::type { return *beg; } 其中使用typename的原因前面已经说过，不再赘述。而remove_reference&lt;&gt;是标准库定义的类型转换模板中的一种。这些类似的模板定义在头文件type_traits中，用于改变类型的引用、指针等等属性。比如上面去掉类型的引用属性。具体有哪些可参考《C++ Primer5》第16章。 type是这些类型转换模板的public成员，表示转换后的类型。 当我们用一个函数模板初始化一个函数指针或为一个函数指针赋值时，编译器使用指针的类型来推断模板实参： template&lt;typename T> int compare(const T&amp;, const T&amp;); int(*pf)(const int&amp;, const int&amp;) = compare; //编译器根据指针类型推断模板实参类型 如果一个函数参数是指向模板参数类型的右值引用（如T&amp;&amp;），则可以传递给它任意类型的实参。如果将一个左值传递给这样的参数，则函数参数被实例化为一个普通的左值引用（T&amp;）。也就是说模板参数可以被推断为一个引用类型，则对模板内的代码可能影响很大： template&lt;typename T> void f(T &amp;&amp;vValue) { T t = vValue; //拷贝还是绑定一个引用？ } 如果我们对一个左值int i调用f时，则T为int&amp;。对一个右值41调用f时，则T为int。 在实际中，右值引用通常用于两种情况：模板转发其实参或模板被重载（后续详述）。 标准库move是使用右值引用的模板的一个很好的例子。标准库的move是这样定义的： template&lt;typename T> typename remove_reference&lt;T>::type&amp;&amp; move(T&amp;&amp; t) { return static_cast&lt;typename remove_reference&lt;T>::type&amp;&amp;>(t); } 可以看到，std::move实际上是使用static_cast把一个左值强制转换为右值引用的一个模板函数。std::move的工作过程如下： 在std::move(std::string(“bye!”))中： 因为实参时右值，所以推断出T的类型为string 因此，remove_reference用string进行实例化 remove_reference的type成员是string move的返回类型是string&amp;&amp; move的函数参数t的类型为string&amp;&amp; 所以该move的实例化版本为string&amp;&amp; move(string &amp;&amp;t)。 在std::move(s1)中： 因为实参时左值，所以推断出T的类型为string&amp; 因此，remove_reference用string&amp;进行实例化 remove_reference的type成员是string move的返回类型仍然是string&amp;&amp; move的函数参数t的类型为string&amp; &amp;&amp;，会折叠为string&amp; 所以该move的实例化版本为string&amp;&amp; move(string &amp;t)。这就是我们想要的，使用std::move来获取一个左值的右值引用。 虽然不能隐式地将一个左值转换为右值引用，但我们可以用static_cast显式地将一个左值转换为一个右值引用。 某些函数需要将其一个或多个实参连同类型不变地转发给其他函数。在此情况下，我们需要保持被转发实参的所有性质，包括实参类型是否是const的以及实参是左值还是右值。 比如我们现在想把一个函数f的两个实参顺序翻转一下，形成另一个新的函数： template&lt;typename F,typename T1, typename T2> void flip1(F f, T1 t1, T2 t2) //flip1是f参数翻转后的版本，但是丢失了参数的顶层const和引用属性 { f(t2, t1); } 这个函数一般情况下工作得很好，但当我们希望用它调用一个接受引用参数的函数时就会出现问题： void f(int v1, int &amp;v2) { std::cout &lt;&lt; v1 &lt;&lt; " " &lt;&lt; ++v2 &lt;&lt; std::endl; } 在这段代码中，f改变了绑定到v2的实参的值。但是，如果我们通过flip1调用f，f所做的改变就不会影响实参： f(41, i); //f改变了实参i flip1(f, j, 41); //通过flip1调用f不会改变j 问题在于flip1的参数t1不是引用类型，f的参数v1被绑定到t1，而不是绑定到j上。所以其改变并不会影响实参j。 通过将一个函数参数定义为一个指向模板类型参数的右值引用，我们可以保持其对应实参的所有类型信息。如果我们将函数参数定义为T1&amp;&amp;和T2&amp;&amp;，通过引用折叠就可以保持翻转实参的左值/右值属性： template&lt;typename F,typename T1, typename T2> void flip2(F f, T1 &amp;&amp;t1, T2 &amp;&amp;t2) //flip2是f参数翻转后的版本，保持了实参的左值/右值以及const属性 { f(t2, t1); } 在调用flip2(f, j, 41);时，将传递给参数t1一个左值，但是因为是右值引用，所以推断出的T1的类型是int&amp;，那么t1的类型会折叠为int&amp;，也就是引用类型，所以t1会被绑定到j上，然后调用函数f时v2会被绑定到t1上，所以对v2的改变最终会影响到实参j。 值得注意的是，只有把左值传递给模板类型的右值，才会发生引用折叠，但是不能把左值传递给一个非模板类型的右值，因为不能直接把一个左值绑定到右值上。也就是说可以把左值赋给模板类型的右值，但是不能赋给普通类型的右值。 上面的flip2值解决了一半问题：它对于接受左值引用的函数工作得很好，但不能用于接受右值引用参数的函数。例如： void g(int &amp;&amp;i, int &amp;j) { std::cout &lt;&lt; i &lt;&lt; " " &lt;&lt; j &lt;&lt; std::endl; } 在如下调用时会编译报错： flip2(g, i, 41); //错误，不能把左值赋给一个右值int&amp;&amp; 这是因为在flip2在调用函数g时，t2本质上是一个变量，变量都是左值，所以我们无法把左值t2赋给函数g的右值参数i（注意这是普通右值，不是模板类型的右值）。 我们可以使用std::forward来保持原始实参42的右值属性。forward定义在头文件utility中，与move不同，forward必须显式指定它的模板实参，它会返回显式实参类型的右值引用，即forward的返回类型是T&amp;&amp;。所以我们可以重写flip2函数，让它在维持左值引用的同时，还能维持右值引用： template&lt;typename F,typename T1, typename T2> void flip3(F f, T1 &amp;&amp;t1, T2 &amp;&amp;t2) //flip3是f参数翻转后的版本，同时支持左值引用和右值引用 { f(std::forward&lt;T2>(t2), std::forward&lt;T1>(t1)); } 在调用flip3(g, i, 41);时，由于i是左值，所以T1是int&amp;；由于41是右值，所以T2是int。所以forward(t2)的返回类型是int&amp;&amp;，可以将右值传递给函数g的右值参数i；forward(t1)的返回类型是int&amp; &amp;&amp;，折叠后是int&amp;，可以将左值传递给g的左值参数j。 总结：当用于一个指向模板参数类型的右值引用函数参数（比如上面的t1、t2）时，forward会保持原始实参（右值引用形参t1、t2对应的实参i、41）的所有细节（原始实参的左/右值属性）。 可变参数模板 一个可变参数模板就是一个接受可变数目参数的模板函数或模板类。可变数目的参数被称为参数包。存在两种参数包：模板参数包（表示零个或多个模板参数）、函数参数包（表示零个或多个函数参数）。 我们用一个省略号来指出一个模板参数或函数参数表示一个包： //Args是一个模板参数包；rest是一个函数参数包 //Args表示零个或多个模板类型参数 //rest表示零个或多个函数参数 template&lt;typename T, typename... Args> void f(const T &amp;t, const Args&amp;... rest); 对一个可变参数模板，编译器还会推断包中参数的数目： int i = 0; double d = 3.14; std::string s = "Hello!"; f(i, s, 41, d); //包中有3个参数 f("Hi"); //空包 编译器会为f函数实例化出对应的两个不同的版本。其中T的类型都是从第一个实参的类型推断出来的，剩下的实参（如果有的话）提供函数额外实参的数目和类型。 当我们需要知道包中有多少个元素时，可以使用sizeof…运算符： template&lt;typename T, typename... Args> void f(const T &amp;t, const Args&amp;... rest) { std::cout &lt;&lt; sizeof...(Args) &lt;&lt; std::endl; //模板参数的数目 std::cout &lt;&lt; sizeof...(rest) &lt;&lt; std::endl; //函数参数的数目 } 我们可以使用一个initializer_list来定义一个可接受可变数目实参的函数。但是，所有实参必须具有相同的类型（或它们的类型可以转换为同一个公共类型）。如果所有实参的类型并不相同时，可变参数模板是很有用的： //用来终止递归并打印最后一个元素的函数 //此函数必须在可变参数版本的print定义之前声明 template&lt;typename T> ostream&amp; print(ostream &amp;os, const T &amp;t) { return os &lt;&lt; t; } //包中除了最后一个元素之外的其他元素都会调用这个版本的print template&lt;typename T, typename... Args> ostream&amp; print(ostream &amp;os, const T &amp;t, const Args&amp;... rest) //这里面的t很重要 { os &lt;&lt; t &lt;&lt; ","; //打印第一个实参 return print(os, rest..); //递归调用，打印其他实参 } 如果发现可变参数模板函数和非可变参数模板函数都满足调用匹配，那么编译器会选择非可变的模板，因为它更加特例化。比如当rest中的参数只剩下一个时，编译器会去调用第一个print而不是第二个print。 模板特例化 当我们不能（或不希望）使用模板版本时，可以定义类或函数模板的一个特例化版本。比如compare函数： //第一个版本，可以比较任意两个类型 template&lt;typename T> int compare(const T &amp;v1, const T &amp;v2) { return v1 &lt; v2; } 如果我们传字符指针，它会去比较两个指针的值： const char *p1 = "Hi", *p2 = "Girl"; compare(p1, p2); 但这并不是我们想要的，我们想要的是比较指针所指向的两个字符串，而不是两个指针的值。为了让该模板函数也可以正确处理字符指针，我们可以为它定义一个模板特例化版本。一个模板特例化版本就是模板的一个独立的定义，在其中一个或多个模板参数被指定为特定的类型。 为了指出我们正在实例化一个模板，应使用关键字template后跟一个空尖括号对（&lt;&gt;）。空尖括号指出我们将为原模板的所有模板参数提供实参： //compare的特例化版本，处理指向字符数组的指针 template&lt;> int compare(const char* const &amp;p1, const char* const &amp;p2) { return strcmp(p1, p2); } 其中p1、p2都是指向const char的const指针的引用。 从上面的程序可以看到，模板的特例化版本的函数内容可以和原模板函数的内容不同。 特例化的本质是实例化一个模板，而非重载它。因此，特例化不影响函数匹配。 编译器优先选择非模板版本，再选择模板特例化版本，再选择最佳匹配的模板版本。 模板及其特例化版本应该声明在同一个头文件中。所以同名模板的声明应该放在前面，然后是这些模板的特例化版本。 默认情况下，无序容器使用hash来组织其元素。标准库为内置类型和很多标准库类型定义了hash类的特例化版本，比如我们可以使用一个（未命名的）hash对象来生成一个字符串的hash值。所以我们可以把类似string这种标准库类型对象存入无序容器中，但是却无法把类似CData这种自定义类型放入无序容器中，因为标准库没有提供针对CData的hash类版本： std::unordered_map&lt;int,double> IntDoubleMap; //正确 std::unordered_map&lt;int, CData> IntCDataMap; //正确 std::unordered_map&lt;CData, int> CDataIntMap2; //错误，标准库没有为键CData提供对应的hash版本 std::unordered_set&lt;CData> DataSet; //错误，标准库没有为CData提供对应的hash版本 这时我们就需要自己为CData类定义一个特例化的hash版本了： namespace std //hash类定义在std命名空间中 { template&lt;> //我们正在定义一个特例化版本，模板参数为CData struct hash&lt;CData> { //用来散列一个无序容器的类型必须要定义下列类型 typedef size_t result_type; typedef CData argument_type; //默认情况下，此类型需要== size_t operator()(const CData&amp; vData) const; }; size_t hash&lt;CData>::operator()(const CData&amp; vData) const { return hash&lt;int>()(vData.getData()) ^ hash&lt;std::string>()(vData.getDataName()); } } 在上面的代码中我们为CData定义了一个特例化的hash模板，在调用运算符()里，返回CData每个成员hash值的异或，作为CData最终的hash值。因为hash类定义在std命名空间中，所以我们的特例化hash版本也需要在同一个命名空间下。有了这段代码以后，上面把CData存入无序容器的操作就是正确的了。 而且为了让CData的用户能够使用hash的特例化版本，我们应该在CData的头文件中定义该特例化版本。 hash模板函数的原型如下： template&lt;typename T> struct hash {} 从上面可以看出，对函数模板特例化时，模板实参是在函数参数类型中直接提供，如上面的compare函数；而类模板特例化时，模板实参是在类名后面加一个尖括号，在尖括号里指定模板实参（和实例化模板类比较像，如std::vector）。 与函数模板不同，类模板的特例化不必为所有模板参数提供实参。也就是说我们只能部分特例化类模板，而不能部分特例化函数模板。 标准库类型remove_reference类型就是一个部分特例化模板类的例子： //原始的、最通用的版本 template&lt;typename T> struct remove_reference { typedef T type; }; //部分特例化模板类，用于左值引用 template&lt;typename T> struct remove_reference&lt;T&amp;> { typedef T type; }; //部分特例化模板类，用于右值引用 template&lt;typename T> struct remove_reference&lt;T&amp;&amp;> { typedef T type; }; 后面两个版本都是第一个版本的部分特例化版本，分别将T&amp;和T&amp;&amp;作为模板实参，但是T具体是什么还不知道，这就是部分特例化，指定了模板实参，但是并不是所有的参数类型都明确知晓。 我们还可以只特例化模板类的成员函数，而不是特例化整个模板类： template &lt;typename T> class CData { public: CData() = default; ~CData() = default; CData(T vData) { m_Data = vData; } void print() const { std::cout &lt;&lt; m_Data &lt;&lt; std::endl; } private: T m_Data = 0; }; template&lt;> //我们正在特例化一个模板 void CData&lt;int>::print() const //我们正在特例化CData&lt;int>的成员函数print { std::cout &lt;&lt; m_Data * 2 &lt;&lt; std::endl; } CData&lt;double> Data1(41.0); Data1.print(); //输出41 CData&lt;int> Data2(41); Data2.print(); //输出82，使用我们为int定义的特例化版本CData&lt;int>::print() &nbsp; 参考文献：《C++Primer第五版》]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++Primer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++Primer第十五章 面向对象程序设计]]></title>
    <url>%2F2018%2F04%2F01%2FC%2B%2BPrimer%E7%AC%AC%E5%8D%81%E4%BA%94%E7%AB%A0%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[OOP：概述 OOP：面向对象程序设计，object-oriented programming 面向对象层序设计得核心思想是数据抽象、继承和动态绑定（多态）。通过使用数据抽象，我们可以将类的接口与实现分离；使用继承，可以定义相似的类型并对其相似关系建模；使用动态绑定，可以在一定程度上忽略相似类型的区别，而以统一的方式使用它们的对象。 C++11新标准允许派生类显式地注明它将使用哪个成员函数改写基类的虚函数，具体措施是在该函数的形参列表之后增加一个override关键字。 在C++语言中，当我们使用基类的引用或指针调用一个虚函数时将发生动态绑定。 定义基类和派生类 基类通常都应该定义一个虚析构函数，即使该函数不执行任何实际操作也是如此。 关键字virtual只能出现在类内部的声明语句之前而不能用于类外部的函数定义。 在一个对象中，继承自基类的部分和派生类自定义的部分不一定是连续存储的。 在派生类的构造函数初始化列表中，应该首先初始化基类的部分，然后按照声明的顺序依次初始化派生类的成员。 不要在派生类对象中直接初始化基类的成员。尽管从语法上来说我们可以在派生类构造函数体内给它的公有或保护的基类成员赋值，但是最好不要这么做。应该调用基类的构造函数来初始化那些从基类继承而来的成员。 如果我们想将某个类用作基类，则该类必须已经定义而非仅仅声明： class CBase; //声明但未定义 class CDerive :public CBase {...}; //错误：CBase必须被定义 这种情况下，通常应该#include CBase类所在的头文件，而不能仅仅是用class关键字声明它。 这一规定的原因显而易见：派生类中包含并且可以使用它从基类继承而来的成员，为了使用这些成员，派生类当然要知道它们是什么。 如果有时我们不希望一个类被继承，可以在定义时在类名后跟一个关键字final来防止阻止发生： class CNoDreived final {}; 当使用基类的引用（或指针）时，实际上我们并不清楚该引用（或指针）所绑定对象的真实类型。该对象可能是基类的对象，也可能是派生类的对象。 之所以存在派生类向基类的类型转换是因为每个派生类对象都包含一个基类部分，而基类的引用或指针可以绑定到该基类部分上。 即使一个基类指针或引用绑定在一个派生类对象上，我们也不能执行从基类向派生类的转换：CDerived DerivedObj; CBase *pBaseObj = &amp;DerivedObj; CDerived *pDerivedObj = pBaseObj; //错误，不能将基类转换成派生类 编译器在编译时无法确定某个特定的转换在运行时是否安全，这是因为编译器只能通过检查指针或引用的静态类型来推断该转换是否合法。想要成功地将基类指针转换为派生类指针，我们可以使用dynamic_cast来完成：CDerived *pDerivedObj = dynamic_cast&lt;CDerived*&gt;pBaseObj;，它会请求一个类型转换，该转换的安全检查将在运行时执行（当然前提是基类定义了虚函数才可以进行转换）。除此之外，如果我们已知某个基类向派生类的转换是安全的，则可以直接使用static_cast来强制覆盖掉编译器的检查工作。 派生类向基类的自动类型转换只对指针或引用类型有效，在派生类类型和基类类型之间不存在这样的转换。 虚函数 如果我们使用override标记了某个函数，但是发现基类中没有该函数或者该函数不是虚函数，那么编译器会报错。所以，建议在派生类重写虚函数时最好加上override关键字，这样就能让编译器帮忙检查重写虚函数是否有效。 我们还能把某个函数指定为final。如果我们已经把函数定义成final了，则之后（在子类中）任何尝试覆盖该函数的操作都将引发错误。 如果虚函数使用默认实参，则基类和派生类中定义的默认实参最好一致。因为使用基类指针调用虚函数时，使用的永远是基类虚函数里的默认实参，与基类指针实际绑定的动态对象无关： class CBase { public: virtual void printV(int vI = 41) { std::cout &lt;&lt; vI &lt;&lt; "CBase" &lt;&lt; std::endl; } }; class CDerived : public CBase { public: virtual void printV(int vI = 45) override { std::cout &lt;&lt; vI &lt;&lt; "CDerived" &lt;&lt; std::endl; } }; CDerived DerivedObj; CBase *pBaseObj = &amp;DerivedObj; pBaseObj->printV(); //输出的是41CDerived，而不是45CDerived 在某些情况下，我们可能希望不要执行虚函数的动态版本，而是希望执行父类的版本。我们可以在执行虚函数前加入作用域运算符来完成这一点。比如上面的程序，如果把调用虚函数的那句代码改成： //强行调用基类中定义的虚函数版本，而不管pBaseObj绑定的动态类型到底是什么 pBaseObj->CBase::print(); //输出的是41CBase 程序执行的将不再是子类的printV函数，而是基类的。 什么时候会出现这种情况呢？即什么时候需要回避虚函数的默认机制？通常是当一个派生类的虚函数需要调用它覆盖的基类的虚函数版本时。 值得注意的是，如果一个派生类虚函数需要调用它的基类版本，但是没有使用作用域运算符，则在运行时该调用将被解析为对派生类版本自身的调用，从而导致无限递归。 抽象基类 将一个虚函数声明为纯虚函数时使用的=0，只能出现在类内部的虚函数声明语句处。 值得注意的是，我们也可以为纯虚函数提供定义，不过函数体必须定义在类的外部。也就是说我们不能在类的内部为一个=0的函数提供函数体。 class CBase { public: virtual void print(int vI) = 0; }; void CBase::print(int vI) //在类外为纯虚函数提供函数体 { std::cout &lt;&lt; vI &lt;&lt; std::endl; } 我们不能创建抽象基类（定义了纯虚函数的类）的对象。 访问控制与继承 派生类的成员或友元只能通过派生类对象来访问基类的受保护成员，派生类对于一个基类对象中的受保护成员没有任何访问特权。即派生类想要访问到基类的保护成员，只能通过派生类对象，而不能通过基类对象： class CBase { protected: int m_BaseData; }; class CDerived :public CBase { public: void print(CDerived &amp;vDerivedObj) { std::cout &lt;&lt; vDerivedObj.m_BaseData &lt;&lt; std::endl; //正确，可以通过派生类对象访问其基类保护成员 } void print1(CBase &amp;vBaseObj) { std::cout &lt;&lt; vBaseObj.m_BaseData &lt;&lt; std::endl; //错误，不可以通过基类对象来访问基类保护成员 } }; 其实原因很简单，如果print1是合法的，即在子类里可以通过基类对象访问基类的保护成员，那么我们就可以随意定义一个子类，来规避掉基类保护成员的保护特性了。这显然与保护属性的设计初衷不符。 派生访问说明符对派生类成员/友元访问基类的权限没有任何影响，它只控制派生类对象对于基类成员的访问权限： class CBase { protected: int m_BaseData; }; class CDerived :private CBase { public: void print() { std::cout &lt;&lt; m_BaseData &lt;&lt; std::endl; //合法 } }; 可以看到，即使派生访问说明符是private（即私有派生），也不影响子类成员对基类非私有成员的访问权限，它只影响派生类对象从外界访问基类成员的权限。其实受影响的不只是派生类对象，也包括派生类的派生类。 只有公有继承时，派生类对象指针才能转换成基类指针： class CBase { protected: int m_BaseData; }; class CDerived :protected CBase { public: void print() { std::cout &lt;&lt; m_BaseData &lt;&lt; std::endl; } }; CDerived DerivedObj; CBase *pBaseObj = &amp;DerivedObj; //错误，只有公有继承时，子类指针才能转换为基类指针 就像友元关系不能传递一样，友元关系同样也不能继承。即父亲的朋友不一定是儿子的朋友，反之亦然。 我们可以使用using声明来改变派生类中继承自基类的成员的访问权限： class CBase { protected: int m_BaseData = 41; }; class CDerived :private CBase { public: using CBase::m_BaseData; //将继承自基类的m_BaseData的访问权限从private改变为public }; CDerived DerivedObj; //由于在子类中将继承成员m_BaseData的访问权限改成了public，所以可以直接使用子类对象访问该成员 std::cout &lt;&lt; DerivedObj.m_BaseData &lt;&lt; std::endl; 值得注意的是，派生类只能为那些它可以访问的名字提供using声明。如果上面的程序，在CBase里，m_BaseData 本身就是private的，那么子类因为访问不到它，所以就无法改变它的访问权限。 人们常常有一种错觉，认为在使用关键字struct和class定义的类之间还有更深层次的差别。事实上，唯一的差别就是默认成员访问说明符及默认派生访问说明符，除此之外，再无其他不同之处。 继承中的类作用域 编译器查找函数时，名字查找先于类型检查。和其他作用域一样，如果派生类的成员与基类的某个成员同名，则派生类将在其作用域内隐藏该基类成员。即使派生类成员和基类成员的形参列表不一致，基类成员也仍然会被隐藏掉： class CBase { public: void print() { std::cout &lt;&lt; "CBase" &lt;&lt; std::endl; } }; class CDerived :public CBase { public: void print(int vI) { std::cout &lt;&lt; "CDerived" &lt;&lt; vI &lt;&lt; std::endl; } }; CDerived DerivedObj; DerivedObj.print(41); //正确，调用派生类的print成员函数 DerivedObj.print(); //错误，因为名字相同而屏蔽掉了基类的print成员函数，即使参数类型不同 DerivedObj.CBase::print(); //正确，通过作用域符强行调用基类的print成员 因为编译器的名字查找优先于类型检查，当通过子类对象在子类中找到名为print的函数以后就不再查找了，这个时候不检查函数类型是否满足，直到编译的时候才发现类型并不满足，然后报错。 构造函数与拷贝控制 基类通常应该定义一个虚析构函数，这样我们就能动态析构继承体系中的对象了。 如果基类的析构函数不是虚函数，则delete一个指向派生类对象的基类指针将可能产生未定义的行为。 虚析构函数将阻止合成移动操作。如果一个类定义了析构函数，即使它通过=default的形式使用了合成的版本，编译器也不会为这个类合成移动操作。 如果基类缺少拷贝控制成员（也就是说基类中该拷贝控制成员是删除的或不可被子类访问的），它会阻止其子类合成对应的拷贝控制成员（删除的）。比如基类缺少移动操作会阻止派生类拥有自己的合成移动操作。 拷贝移动时，应该带上基类成员一起（子类显式地执行基类的拷贝移动操作）；而析构时不需要带上基类成员，因为基类的析构函数会被自动调用。 class CBase { public: CBase(const CBase &amp;vBase) {} CBase(CBase &amp;&amp;vBase) {} virtual ~CBase() {} }; class CDerived :public CBase { public: CDerived(const CDerived &amp;vDerived) :CBase(vDerived) {} //带上基类一起拷贝 CDerived(CDerived &amp;&amp;vDerived) :CBase(std::move(vDerived)) {} //带上基类一起移动 ~CDerived() {} //不需要带上基类 }; 在CDerived的拷贝构造函数中，对象vDerived被绑定到基类构造函数的CBase&amp;形参上，CBase的拷贝构造函数负责将vDerived的基类部分拷贝给要创建的对象。 如果构造函数或析构函数调用了某个虚函数，则我们应该执行与构造函数或析构函数所属类型相对应的虚函数版本。因为调用基类的构造函数时，子类的虚函数还是未完成状态，在调用基类的析构函数时，子类的虚函数已经被销毁。 类不能继承默认构造函数、拷贝构造函数和移动构造函数。我们可以使用using声明来显式继承基类的构造函数（不是太理解这个继承说的什么意思，因为在子类中确实可以调用基类的构造函数）： class CBase { public: CBase() { std::cout &lt;&lt; "CBase Copy Constructor" &lt;&lt; std::endl; }; CBase(const CBase &amp;vBase) {} CBase(CBase &amp;&amp;vBase) {} virtual ~CBase() {} }; class CDerived :public CBase { public: using CBase::CBase; //继承CBase里的所有构造函数 CDerived() = default; CDerived(const CDerived &amp;vDerived) :CBase(vDerived) {} CDerived(CDerived &amp;&amp;vDerived) :CBase(std::move(vDerived)) {} ~CDerived() {} }; 和普通成员的using声明不同，一个构造函数的using声明不会改变该构造函数的访问级别。 使用using声明来显式继承基类构造函数时：当一个基类构造函数含有默认实参时，这些实参并不会被继承，相反，派生类将获得多个继承的构造函数，其中每个构造函数分别省略掉一个含有默认实参的形参。 容器与继承 当派生类对象被赋值给基类对象时，其中的派生类部分将被“切掉”，因此容器和存在继承关系的类型无法兼容 文本查询程序再探 好吧，等有时间可以挥霍了再来写这一部分了。。。&nbsp; 参考文献：《C++Primer第五版》]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++Primer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++Primer第十四章 重载运算与类型转换]]></title>
    <url>%2F2018%2F03%2F31%2FC%2B%2BPrimer%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0%E9%87%8D%E8%BD%BD%E8%BF%90%E7%AE%97%E4%B8%8E%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[基本概念 重载的运算符本质上是一次函数调用，所以运算符原有的求值顺序的规则无法应用到重载的运算符上。特别是，逻辑与、或运算符、逗号运算符的重载版本其运算对象求值顺序规则无法保留下来。而且，&amp;&amp;和||运算符的重载版本也无法保留内置运算符的短路求值属性，两个运算对象总是会被求值。所以，不建议重载这些运算符。 通常情况下，不应该重载逗号、取地址、逻辑与和逻辑或运算符。 某些情况下，重载的运算符作为普通函数比作为成员函数更好。比如，具有对称性的运算符可能转换任意一端的运算对象，例如算术、相等比较、位运算符等等，因此它们通常应该是普通的非成员函数。 输入和输出运算符 输入输出运算符必须是非成员函数。与iostream标准库兼容的输入输出运算符必须是普通的非成员函数，而不能是类的成员函数。否则，它的左侧运算对象将是我们的类的一个对象： CData Data1; Data1 &lt;&lt; cout; //如果operator&lt;&lt;是CData的成员 显然不太对。因此，如果我们希望为类自定义IO运算符，则必须将其定义成非成员函数。而且，IO运算符通常需要读写类的非公有数据成员，所以IO运算符一般被声明为友元。 class CData { friend std::istream&amp; operator >> (std::istream &amp;vioIStream, CData &amp;voData); friend std::ostream&amp; operator&lt;&lt;(std::ostream &amp;voOstream, const CData &amp;vData); public: CData() = default; private: int m_Data = 0; std::string m_DataName; }; std::istream&amp; operator >> (std::istream &amp;vioIStream, CData &amp;voData) { vioIStream >> voData.m_Data >> voData.m_DataName; if (!vioIStream) //检查输入是否成功 voData = CData(); //输入失败，对象被赋予默认的状态 return vioIStream; } std::ostream&amp; operator&lt;&lt;(std::ostream &amp;voOstream, const CData &amp;vData) { voOstream &lt;&lt; vData.m_Data &lt;&lt; " " &lt;&lt; vData.m_DataName &lt;&lt; std::endl; return voOstream; } CData Data1; std::cin >> Data1; std::cout &lt;&lt; Data1; 在重载的输入运算符函数中，if语句检查读取操作是否成功，如果发生了IO错误，则运算符将给定的对象重置为默认状态。 &lt;font size=”5” color=”orange’&gt;算术和关系运算符 通常情况下，我们把算术和关系运算符定义成非成员函数以允许对左侧或右侧对象进行交换。 赋值运算符 不论形参的类型是什么，赋值运算符都必须定义为成员函数。而且复合赋值运算符（+=）通常情况下也应该这样做。它们都应该返回左侧运算对象的引用。 下标运算符 下标运算符必须是成员函数。 递增和递减运算符 递增和递减运算符应该同时定义前置版本和后置版本，而且通常应该被定义为类的成员。 为了与内置版本保持一致，前置运算符应该返回递增或递减后对象的引用，后置版本应该返回对象的原值（值而非引用）。 要想同时定义前置运算符和后置运算符，必须先解决一个问题：它们的重载函数的形式是一样的，无法区分。所以语法规定，后置版本的递增和递减运算符额外接受一个int类型的参数，这个参数的实参无须用户指定，由编译器自动为其传递一个值为0的实参： class CData { public: CData&amp; operator++() //前置版本的递增运算符，返回引用 { ++m_Data; return *this; } CData&amp; operator--() //前置版本的递减运算符，返回引用 { --m_Data; return *this; } CData operator++(int) //后置版本的递增运算符，返回值 { CData TempData = *this; ++*this; return TempData; } CData operator--(int) //后置版本的递减运算符，返回值 { CData TempData = *this; --*this; return TempData; } private: int m_Data = 0; }; 隐式调用后置版本时无须传递实参0，但是显式调用时需要传递参数0，否则调用的将是前置版本： CData Data1; Data1++; //调用后置版本的递增运算符 Data1.operator++(); //调用前置版本的递增运算符 Data1.operator++(0); //调用后置版本的递增运算符 函数调用运算符 如果类重载了函数调用运算符，则我们可以像使用函数一样使用该类的对象： class CData { public: void operator()(int i) { m_Data = i; std::cout &lt;&lt; ++m_Data &lt;&lt; std::endl; } private: int m_Data = 0; }; CData Data1; Data1(40); //调用CData类的调用运算符函数，输出41 即使Data1只是一个对象而非函数，我们也能调用该对象，因为调用该对象实际上是在运行重载的调用运算符。 函数调用运算符必须是成员函数。 当我们编写一个lambda后，编译器会将该表达式翻译成一个未命名类的未命名对象。 先看如下代码： class CShorterString { public: bool operator()(const std ::string &amp;vS1,const std::string &amp;vS2) { return vS1.size() &lt; vS2.size(); } }; std::vector&lt;std::string> SVec{ "The","Furthest","Distance" }; std::stable_sort(SVec.begin(), SVec.end(), CShorterString()); 可能会感觉很奇怪，为什么stable_sort的第三个参数（谓词）可以传入一个无名对象呢？这是因为这个对象所在的类定义了调用运算符，当stable_sort在调用这个对象时，实际上会去调用它的调用运算符函数。也就是说该无名对象是一个可调用的对象，所以它能够当做谓词使用。 标准库定义了一组表示算术运算符、关系运算符和逻辑运算符的类，每个类分别定义了一个执行命名操作的调用运算符。例如，plus类定义了一个函数调用运算符用于对一对运算对象执行+的操作；modulus类定义了一个调用运算符执行二元的%操作；equal_to类执行==，等等。它们都是模板的形式： std::plus&lt;int> IntAdd; //可执行int加法的函数对象 std::negate&lt;int> IntNegate; //可对int值取反的函数对象 int Sum = IntAdd(10, 20); //Sum = 30 Sum = IntNegate(Sum); //Sum = -30; 标准库定义的这种函数对象如下表： 算术 关系 逻辑 plus equal_to logical_and minus not_equal_to logical_or multiplies greater logical_not divides greater_equal modulus less negate less_equal 这些表示运算符的函数对象类通常用来替换算法中的默认运算符： std::vector&lt;int> IntVec{ 2,4,1,6,5 }; std::sort(IntVec.begin(), IntVec.end(), std::greater&lt;int>()); C++语言中有几种可调用的对象：函数、函数指针、lambda表达式、bind创建的对象、重载了函数调用运算符的类。 不同类型的可调用对象可能拥有同一种调用形式。调用形式指明了调用返回的类型以及传递给调用的实参类型。比如下面这几个可调用对象： //普通函数 int add(int i, int j) { return i + j; } //lambda，其产生一个未命名的函数对象类 auto mod = [](int i, int j) {return i%j; }; //函数对象类 class divide { public: int operator()(int i, int j) { return i / j; } }; 它们的调用形式都是： int(int, int) 假设我们现在想要写一个简单的计算器，希望定义一个函数表来存储指向这些可调用对象的“指针”： //构建从运算符名字到相应函数指针的映射关系，其中函数接受两个int、返回一个int std::map&lt;std::string, int(*)(int, int)> CalMaps; 我们可以把add添加进去： CalMaps.insert({ "+",add }); 但是我们却无法把mod或divide添加进去（在VS里mod似乎可以~）： CalMaps.insert({ "/",divide() }); //错误，mod不是一个函数指针 这是因为它们都有自己的类类型，并不是一个函数指针，所以无法作为值添加到CalMaps中。 我们可以用function模板类来把这些调用对象统一成它们相同的调用形式： std::function&lt;int(int,int)> 我们可以： std::function&lt;int(int, int)> f1 = add; std::function&lt;int(int, int)> f1 = mod; std::function&lt;int(int, int)> f1 = divide(); 所以我们可以解决这个问题了： //构建从运算符名字到相应函数指针的映射关系，其中函数接受两个int、返回一个int std::map&lt;std::string, std::function&lt;int(int, int)>> CalMaps; CalMaps.insert({ "+",add }); CalMaps.insert({ "%",mod }); CalMaps.insert({ "/",divide() }); 重载、类型转换与运算符 类型转换构造函数和类型转换运算符共同定义了类类型转换，也叫用户定义的类型转换。 类型转换运算符是类的一种特殊成员函数，它负责将一个类类型的值转换成其他类型。类型转换函数的一般形式如下： operator type() const; 其中type表示除了void之外的任意类型，比如int、int*、int(*)(int, int)等等。 class CData { public: CData(int vData) :m_Data(vData) {} //类型转换构造函数，负责把int转换为CData operator int()const { return m_Data; } //类型转换运算符，负责将CData转换为int private: int m_Data = 0; }; CData DataObj(40); DataObj = 41; //首先将41隐式地转换为CData，然后调用合成的CData::operator= int k = DataObj + 14; //首先将DataObj隐式地转换为int，然后执行整数的加法 类型转换运算符既没有显式的返回类型，也没有形参，而且必须定义成类的成员函数。而且它通常不应该改变待转换对象的内容，所以通常也被定义成const成员。 在实践中，类很少提供类型转换运算符。因为在多数情况下，如果类型转换自动发生，使用该类的用户可能会感觉比较意外，而不是感觉受到了帮助。如果我们确实需要这种类型转换，但有不想让编译器进行自动转换（隐式转换），我们可以把这个类型转换运算符成员函数定义成显式的：用explicit声明： class CData { public: CData(int vData) :m_Data(vData) {} explicit operator int()const { return m_Data; } //类型转换运算符，负责将CData转换为int private: int m_Data = 0; }; 这叫做显式的类型转换运算符。用户在需要类型转换时，需要使用static_cast来强制转换： int k = static_cast&lt;int>(DataObj) + 14; //首先将DataObj显式地转换为int，然后执行整数的加法 这样用户就不会感觉到意外了吧！ 大多数情况下，编译器都不会自动执行显式类型转换运算符的，不过将其用作条件时除外。比如把DataObj用作if、while的条件，这时编译器会自动执行显式的类型转换运算符。 不要令两个类执行相同的类型转换：如果Foo类有一个接受Bar类对象的构造函数，则不要在Bar类中再定义转换目标是Foo类的类型转换运算符。因为这个构造函数和这个类型转换运算符完成的功能都是：把Bar类型转换成Foo类型。如果需要执行Foo = Bar;这种类似的转换，那么到底是用那个构造函数还是那个类型转换运算符呢？这就出现了二义性，程序将报错。 最好不要创建两个转换源都是算术类型的转换构造函数；最好不要创建两个转换对象都是算术类型的类型转换运算符函数。 class CData { public: CData(int); //最好不要创建两个转换源都是算术类型的转换构造函数 CData(double); operator int() const; //最好不要创建两个转换对象都是算术类型的类型转换运算符函数 operator double() const; }; 如果出现CData(long);这种形式的转换，那到底是用第一个构造函数还是第二个构造函数呢？会出现二义性错误。如果出现long = CData;这种形式的转换，那到底是用int形式的类型转换运算符还是double形式的类型转换运算符呢？也会出现二义性错误。 除了显式地向bool类型的转换之外，我们应该尽量避免定义类型转换函数，并尽可能地限制那些“显然正确”的非显式构造函数。 如果我们对同一个类既提供了算术类型的类型转换构造函数和类型转换运算符，还提供了重载的运算符，则将会遇到重载运算符和内置运算符的二义性问题： class CData { public: CData(int vData) :m_Data(vData) {}; //类型转换构造函数 operator int() const { return m_Data; }; //类型转换运算符 CData&amp; operator+(const CData&amp; vData) { m_Data += vData.m_Data; return *this; }; private: int m_Data = 0; }; CData DataObj(41); int i = DataObj + 14; //二义性错误 在执行DataObj + 14时，可以先把DataObj用类型转换运算符转换成int，再执行内置类型的加法运算；也可以先把14用类型转换构造函数转换成CData类型，再用重载的加法运算符来执行加法运算。这就出现了二义性。&nbsp; 参考文献：《C++Primer第五版》]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++Primer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Boost序列化]]></title>
    <url>%2F2018%2F03%2F30%2FBoost%E5%BA%8F%E5%88%97%E5%8C%96%2F</url>
    <content type="text"><![CDATA[概述 Boost C++的序列化库允许将C++对象转换为一个字节序列（序列化），此序列可以被保存成字符串、文件等等形式，并且可以在需要的时候把字节序列恢复成一个对象（反序列化）。 序列化的主要概念是归档(archive)，就是指把一个对象序列化成字节序列然后反序列化的过程。 序列化到文件 Boost可以通过归档类boost::archive::text_oarchive来把对象序列化到文件里（该类定义在boost/archive/text_oarchive.hpp里），然后通过归档类boost::archive::text_iarchive从文件里恢复出对象来： //序列化归档的构造函数应该关联文件流 #include &lt;boost/archive/text_oarchive.hpp> #include &lt;boost/archive/text_iarchive.hpp> #include &lt;iostream> #include &lt;fstream> void save() { std::ofstream Fout("serialization.txt"); boost::archive::text_oarchive OA(Fout); //用Boost的text_oarchive关联输出流（代替输出流来执行序列化写入操作） int i = 41; OA &lt;&lt; i; } void load() { std::ifstream Fin("serialization.txt"); boost::archive::text_iarchive IA(Fin); //用Boost的text_iarchive关联输入流（代替输入流来执行序列化读取操作） int i = 0; IA >> i; std::cout &lt;&lt; i &lt;&lt; std::endl; } int main() { save(); load(); return 0; } 从上面的程序可以看到，在定义归档类text_oarchive的对象OA，或者text_iarchive的对象IA时，需要同时关联一个文件流对象，然后用这个归档类对象代替文件流对象，来执行文件的写入和读取操作。 在本地生成的文件serialization.txt里，被序列化入如下数据： 22 serialization::archive 13 41 可以看到变量i的值41确实被序列化到文件里了，当然程序使用load函数反序列化后，会把文件里的这个41赋给变量i，然后输出i的值。程序输出当然是41咯！ 序列化到字符串流 除了序列化到文件流，我们还可以序列化到文件流： //序列化归档的构造函数关联字符串流 #include &lt;boost/archive/text_oarchive.hpp> #include &lt;boost/archive/text_iarchive.hpp> #include &lt;iostream> #include &lt;sstream> std::stringstream ss; void save() { boost::archive::text_oarchive OA(ss); //用Boost的text_oarchive关联输出流（代替输出流来执行序列化写入操作） int i = 41; OA &lt;&lt; i; } void load() { boost::archive::text_iarchive IA(ss); //用Boost的text_iarchive关联输入流（代替输入流来执行序列化读取操作） int i = 0; IA >> i; std::cout &lt;&lt; i &lt;&lt; std::endl; } int main() { save(); load(); return 0; } 和之前程序不同的只是：关联的是字符串流而不是文件流罢了。 序列化和反序列化自定义类 如果想要序列化我们自己定义的类呢？我们可以通过在自定义类中加入serialize模板函数来实现： //序列化和反序列化自定义类 #include &lt;boost/archive/text_oarchive.hpp> #include &lt;boost/archive/text_iarchive.hpp> #include &lt;iostream> #include &lt;fstream> class CData { friend class boost::serialization::access; //友元访问 public: CData() = default; CData(int vData) :m_Data(vData) {} int getData()const { return m_Data; } private: template&lt;typename Archive> void serialize(Archive&amp; Ar, const unsigned int vVersion)//自定义类想要被序列化必须定义serialize函数，为了不区分text_oarchive和text_iarchive所以定义成模板 { Ar &amp; m_Data; //&amp;既可以表示&lt;&lt;又可以表示>>，视模板Archive类型而定，这个&amp;的意义在于不用去区分serialize到底是完成序列化还是反序列化了 } int m_Data = 0; }; void save() { std::ofstream Fout("Serialization.txt"); boost::archive::text_oarchive OA(Fout); CData DataObj(41); //序列化CData类对象到文件中 OA &lt;&lt; DataObj; } void load() { std::ifstream Fin("Serialization.txt"); boost::archive::text_iarchive IA(Fin); CData DataObj; IA >> DataObj; //从文件中反序列化到CData类对象中 std::cout &lt;&lt; DataObj.getData() &lt;&lt; std::endl; } int main() { save(); load(); return 0; } 为了序列化自定义的类，serialize模板函数必须被定义，它在对象被序列化或反序列化时被调用。我们可以使用&amp;操作符来代替&lt;&lt;和&gt;&gt;，这样就不用在serialize函数里区分到底是序列化还是反序列化了。serialize函数应该是私有的，因为它不会再被别的对象调用了，而且需要将boost::serialization::access类声明为友元，这样才能让Boost.Serialization来序列化该类的私有成员。 把serialize函数拆分为序列化函数save和反序列化函数load 上面那样把序列化和反序列都用serialize函数来实现是通常的做法，但是如果有时候想要序列化和反序列化执行一些不同的操作呢？当然就不能用同一个函数来实现了： //把类内的serialize函数拆分为save和load，因为有的时候不想要序列化和反序列化都使用相同的serialize函数内容 #include &lt;boost/archive/text_oarchive.hpp> #include &lt;boost/archive/text_iarchive.hpp> #include &lt;iostream> #include &lt;fstream> class CData { friend class boost::serialization::access; public: CData() = default; CData(int vData) :m_Data(vData) {} int getData()const { return m_Data; } private: template&lt;typename Archive> void save(Archive&amp; Ar, const unsigned int vVersion) const //save必须有const，否则无法编译 { Ar &lt;&lt; m_Data &lt;&lt; vVersion; } template&lt;typename Archive> void load(Archive&amp; Ar, const unsigned int vVersion) //无const { Ar >> m_Data; if (vVersion > 0) Ar >> m_VersionIndex; } BOOST_SERIALIZATION_SPLIT_MEMBER(); int m_Data = 0; int m_VersionIndex = -1; }; BOOST_CLASS_VERSION(CData, 1); void save() { std::ofstream Fout("Serialization.txt"); boost::archive::text_oarchive OA(Fout); CData DataObj(41); OA &lt;&lt; DataObj; } void load() { std::ifstream Fin("Serialization.txt"); boost::archive::text_iarchive IA(Fin); CData DataObj; IA >> DataObj; std::cout &lt;&lt; DataObj.getData() &lt;&lt; std::endl; } int main() { save(); load(); return 0; } 上面的程序把原来的serialize函数拆分成了save和load函数，来分别实现序列化和反序列化。其中序列化函数save必须有const声明，否则会编译报错，而load函数不需要const。 在load函数中会判断当前归档的版本号，如果当前版本号大于0就反序列化进成员m_VersionIndex中。可以通过BOOST_CLASS_VERSION(CData, 1);来设置当前归档的版本号。 非侵入式serialize函数 之前代码里的serialize函数都是侵入式的，即必须在原有类的代码里加入serialize函数，如果不想要去改变原有类的代码怎么办呢？答案是写一个非成员版本的serialize函数，将需要序列化的类对象作为第二个参数传入： //serialize不作为成员函数 #include &lt;boost/archive/text_iarchive.hpp> #include &lt;boost/archive/text_oarchive.hpp> #include &lt;iostream> #include &lt;fstream> class CData { template&lt;typename Archive> friend void serialize(Archive&amp; Ar, CData &amp;vioData, const unsigned int vVersion); public: CData() = default; CData(int vData) :m_Data(vData) {} int getData()const { return m_Data; } int m_Data = 0; }; template&lt;typename Archive> void serialize(Archive&amp; Ar, CData &amp;vioData,const unsigned int vVersion) //CData&amp; { Ar &amp; vioData.m_Data; } void save() { std::ofstream Fout("Seriliazation.txt"); boost::archive::text_oarchive OA(Fout); CData DataObj(41); OA &lt;&lt; DataObj; } void load() { std::ifstream Fin("Seriliazation.txt"); boost::archive::text_iarchive IA(Fin); CData DataObj; IA >> DataObj; std::cout &lt;&lt; DataObj.getData() &lt;&lt; std::endl; } int main() { save(); load(); return 0; } 但是这种情况下会要求需要序列化的类成员是公有的，才能在外部的serialize函数里通过类对象访问到。这无疑会破坏原有类的封装性。还有一个折中的方案就是在原有类代码中将非成员的serialize函数声明为其友元函数： //serialize不作为成员函数，只是友元函数 #include &lt;boost/archive/text_iarchive.hpp> #include &lt;boost/archive/text_oarchive.hpp> #include &lt;iostream> #include &lt;fstream> class CData { friend class boost::serialization::access; template&lt;typename Archive> friend void serialize(Archive&amp; Ar, CData &amp;vioData, const unsigned int vVersion); public: CData() = default; CData(int vData) :m_Data(vData) {} int getData()const { return m_Data; } private: int m_Data = 0; }; template&lt;typename Archive> void serialize(Archive&amp; Ar, CData &amp;vioData,const unsigned int vVersion) //CData&amp; { Ar &amp; vioData.m_Data; } void save() { std::ofstream Fout("Seriliazation.txt"); boost::archive::text_oarchive OA(Fout); CData DataObj(41); OA &lt;&lt; DataObj; } void load() { std::ifstream Fin("Seriliazation.txt"); boost::archive::text_iarchive IA(Fin); CData DataObj; IA >> DataObj; std::cout &lt;&lt; DataObj.getData() &lt;&lt; std::endl; } int main() { save(); load(); return 0; } 但是对于C++标准库里的类肯定无法修改其原有代码，连友元都无法增加，不过还好，Boost.Serialization为许多C++标准库的类提供了serialize函数。为了序列化标准库的类，需要添加对应的头文件，比如序列化vector时需要添加boost/serialization/vector.hpp。 序列化STL中的数据结构 我们可以通过添加对应的头文件，来序列化STL中的数据结构，比如vector： //序列化数据中加入STL数据结构 #include &lt;boost/archive/text_oarchive.hpp> #include &lt;boost/archive/text_iarchive.hpp> #include &lt;boost/serialization/vector.hpp> //string可以不加对应的头文件，vector等还是要的 #include &lt;iostream> #include &lt;fstream> #include &lt;string> class CData { friend class boost::serialization::access; public: CData() = default; CData(int vData, const std::string &amp;vDataName, const std::vector&lt;int> &amp;vValues) :m_Data(vData),m_DataName(vDataName),m_Values(vValues) {} int getData()const { return m_Data; } const std::string&amp; getDataName() const { return m_DataName; } const std::vector&lt;int>&amp; getValues() const { return m_Values; } private: template&lt;typename Archive> void serialize(Archive&amp; Ar, const unsigned int vVersion) { Ar &amp; m_Data &amp; m_DataName &amp; m_Values; } int m_Data = 0; std::string m_DataName; std::vector&lt;int> m_Values; }; void save() { std::ofstream Fout("Serialization.txt"); boost::archive::text_oarchive OA(Fout); CData DataObj(41, "Jia", { 1,2,3,4 }); OA &lt;&lt; DataObj; } void load() { std::ifstream Fin("Serialization.txt"); boost::archive::text_iarchive IA(Fin); CData DataObj; IA >> DataObj; std::cout &lt;&lt; DataObj.getData() &lt;&lt; " " &lt;&lt; DataObj.getDataName(); for (auto e : DataObj.getValues()) std::cout &lt;&lt; " " &lt;&lt; e; } int main() { save(); load(); return 0; } 序列化对象指针或引用 在save里我们还可以直接序列化对象指针，这个时候序列化的不是指针表示的地址，而不是指针所指向的对象。在load里也可以直接反序列化给一个指针或引用，只不过这时是指向反序列化后一个新创建的对象，该对象的地址与序列化之前的对象地址不同，它们不是一个对象，只是数据内容相同而已： //序列化对象指针或引用，值得注意的是不能直接序列化基本类型的指针 #include &lt;boost/archive/text_oarchive.hpp> #include &lt;boost/archive/text_iarchive.hpp> #include &lt;iostream> #include &lt;fstream> class CData { friend class boost::serialization::access; public: CData() = default; CData(int vData) :m_Data(vData) {} int getData()const { return m_Data; } private: template&lt;typename Archive> void serialize(Archive&amp; Ar, const unsigned int vVersion) { Ar &amp; m_Data; } int m_Data = 0; }; void save() { std::ofstream Fout("Serialization.txt"); boost::archive::text_oarchive OA(Fout); CData *pDataObj = new CData(41); OA &lt;&lt; pDataObj; //序列化的是pDataObj指向的对象，而不是指针 delete pDataObj; //int i = 41; //不能直接序列化基本类型指针，但是可以序列化定义了serialize函数的类类型指针，需要改成OA&lt;&lt; *j; //int *j = &amp;i; //如果是xml归档，需要改成OA&lt;&lt; boost::serialization::make_nvp("name", *j);而不能使用OA &lt;&lt; BOOST_SERIALIZATION_NVP(*j) //OA &lt;&lt; j; } void load() { std::ifstream Fin("Serialization.txt"); boost::archive::text_iarchive IA(Fin); CData *pDataObj; IA >> pDataObj; //序列化会新创建一个对象赋给pDataObj（和序列化之前的对象地址不一定相同） std::cout &lt;&lt; pDataObj->getData() &lt;&lt; std::endl; delete pDataObj; } int main() { save(); load(); return 0; } 值得注意的是，我们不能直接序列化一个基本类型的指针，而只能直接序列化定义了serialize函数的类类型指针。对于txt归档，想要序列化基本类型的指针必须用OA&lt;&lt; *j;，而对于xml归档（后续详述）需要用OA&lt;&lt; boost::serialization::make_nvp(&quot;name&quot;, *j);，用OA &lt;&lt; BOOST_SERIALIZATION_NVP(*j);都不行，必须用make_nvp函数。 序列化智能指针对象 想要序列化智能指针，必须先包含对应的头文件，比如boost/serialization/shared_ptr.hpp： //序列化智能指针对象 #include &lt;boost/archive/text_iarchive.hpp> #include &lt;boost/archive/text_oarchive.hpp> #include &lt;boost/serialization/shared_ptr.hpp> //需要加入序列化智能指针所对应的头文件 #include &lt;iostream> #include &lt;fstream> class CData { friend class boost::serialization::access; public: CData() = default; CData(int vData) :m_Data(vData) {} int getData()const { return m_Data; } private: template&lt;typename Archive> void serialize(Archive&amp; Ar, const unsigned int vVersion) { Ar &amp; m_Data; } int m_Data = 0; }; void save() { std::ofstream Fout("Serialization.txt"); boost::archive::text_oarchive OA(Fout); std::shared_ptr&lt;CData> pDataObj = std::make_shared&lt;CData>(41); OA &lt;&lt; pDataObj; } void load() { std::ifstream Fin("Serialization.txt"); boost::archive::text_iarchive IA(Fin); std::shared_ptr&lt;CData> pDataObj; IA >> pDataObj; std::cout &lt;&lt; pDataObj->getData() &lt;&lt; std::endl; } int main() { save(); load(); return 0; } 序列化类内指针 和序列化基本类型指针一样，如果类内指针也是基本类型的，那么也需要先解指针以后才能进行序列化。而且在序列化和反序列化时，一定要确保对应的指针成员是有效的（即指向有效的内存地址），否则会编译报错： //序列化类内指针 #include &lt;boost/archive/text_iarchive.hpp> #include &lt;boost/archive/text_oarchive.hpp> #include &lt;iostream> #include &lt;fstream> class CData { friend class boost::serialization::access; public: CData() { m_pData = new int(); } //一定要确保指针是有效的 CData(int vData) { m_pData = new int(); *m_pData = vData; } //一定要确保指针是有效的 int getData()const { return *m_pData; } private: template&lt;typename Archive> void serialize(Archive&amp; Ar, const unsigned int vVersion) { Ar &amp; *m_pData; //不能直接序列化基本类型指针，需要先解指针 } int *m_pData = nullptr; }; void save() { std::ofstream Fout("Serialization.txt"); boost::archive::text_oarchive OA(Fout); CData DataObj(41); OA &lt;&lt; DataObj; } void load() { std::ifstream Fin("Serialization.txt"); boost::archive::text_iarchive IA(Fin); CData DataObj; IA >> DataObj; //一定要确保指针是有效的，否则反序列化时会出错 std::cout &lt;&lt; DataObj.getData() &lt;&lt; std::endl; } int main() { save(); load(); return 0; } 直接序列化子类对象 在序列化子类对象时，父类和子类都要有serialize函数，而且在子类的serialize函数里，需要用Ar &amp; boost::serialization::base_object&lt;CBase&gt;(*this);这句代码，来确保(继承自)基类的属性也能被正确序列化： //序列化派生类 #include &lt;boost/archive/text_iarchive.hpp> #include &lt;boost/archive/text_oarchive.hpp> #include &lt;iostream> #include &lt;fstream> class CBase { friend class boost::serialization::access; public: CBase() = default; CBase(int vData) :m_BaseData(vData) {} int getData()const { return m_BaseData; } private: template&lt;typename Archive> void serialize(Archive&amp; Ar, const unsigned int vVersion) { Ar &amp; m_BaseData; } int m_BaseData = 0; }; class CDerived :public CBase { friend class boost::serialization::access; public: CDerived() = default; CDerived(int vDerivedData) :m_DerivedData(vDerivedData) {} CDerived(int vBaseData, int vDerivedData) :CBase(vBaseData), m_DerivedData(vDerivedData) {} int getData() { return m_DerivedData; } private: template&lt;typename Archive> void serialize(Archive&amp; Ar, const unsigned int vVersion) { Ar &amp; boost::serialization::base_object&lt;CBase>(*this); //子类必须在serialize函数中序列化基类，确保继承自基类的属性也能正确地序列化，否则load时 //输出的BaseData就是0，而不是41 Ar &amp; m_DerivedData; } int m_DerivedData = 0; }; void save() { std::ofstream Fout("Serialization.txt"); boost::archive::text_oarchive OA(Fout); CDerived DerivedObj(41, 45); OA &lt;&lt; DerivedObj; } void load() { std::ifstream Fin("Serialization.txt"); boost::archive::text_iarchive IA(Fin); CDerived DerivedObj; IA >> DerivedObj; std::cout &lt;&lt; "DerivedData: " &lt;&lt; DerivedObj.getData() &lt;&lt; " BaseData: " &lt;&lt; DerivedObj.CBase::getData() &lt;&lt; std::endl; } int main() { save(); load(); return 0; } 使用虚基类指针来序列化子类对象（通过宏BOOST_CLASS_EXPORT的方式） 如果想要通过基类指针来序列化子类对象（子类对象的所有数据成员都被序列化，不仅仅是继承自基类的那些），一种方案是通过宏BOOST_CLASS_EXPORT来显式声明需要被序列化的子类： //用虚基类指针序列化子类对象（使用BOOST_CLASS_EXPORT方式） #include &lt;boost/archive/text_iarchive.hpp> #include &lt;boost/archive/text_oarchive.hpp> #include &lt;boost/serialization/export.hpp> #include &lt;iostream> #include &lt;fstream> class CBase { friend class boost::serialization::access; public: CBase() = default; CBase(int vData) :m_BaseData(vData) {} virtual int getData()const { return m_BaseData; } private: template&lt;typename Archive> void serialize(Archive&amp; Ar, const unsigned int vVersion) { Ar &amp; m_BaseData; } int m_BaseData = 0; }; class CDerived :public CBase { friend class boost::serialization::access; public: CDerived() = default; CDerived(int vDerivedData) :m_DerivedData(vDerivedData) {} CDerived(int vBaseData, int vDerivedData) :CBase(vBaseData), m_DerivedData(vDerivedData) {} virtual int getData()const { return m_DerivedData; } private: template&lt;typename Archive> void serialize(Archive&amp; Ar, const unsigned int vVersion) { Ar &amp; boost::serialization::base_object&lt;CBase>(*this); Ar &amp; m_DerivedData; } int m_DerivedData = 0; }; BOOST_CLASS_EXPORT(CDerived) //基类如果不是虚基类这行代码过不了 void save() { std::ofstream Fout("Serialization.txt"); boost::archive::text_oarchive OA(Fout); CBase *pBaseObj = new CDerived(41, 45); OA &lt;&lt; pBaseObj; delete pBaseObj; } void load() { std::ifstream Fin("Serialization.txt"); boost::archive::text_iarchive IA(Fin); CBase *pBaseObj; IA >> pBaseObj; CDerived *pDerivedObj = dynamic_cast&lt;CDerived*>(pBaseObj); //使用宏BOOST_CLASS_EXPORT的时候必须强制类型转换才可以，而不能直接写成IA>>pDerivedObj（无法进行隐式转换） std::cout &lt;&lt;"DerivedData: " &lt;&lt; pDerivedObj->getData() &lt;&lt; std::endl; delete pDerivedObj; } int main() { save(); load(); return 0; } 值得注意的是，如果使用的是这种宏定义显式声明子类的方式，在反序列化时必须先反序列化到基类指针里，再通过强制转换才能真正访问到子类对象，然后访问其成员。无法直接反序列化为子类指针，因为这种方式下不能进行指针的隐式转换。而下面所述的register_type方式可以直接反序列化到子类指针里。 还有一点需要注意的是，这毕竟是通过基类指针来序列化子类对象（多态），那么基类就必须要有虚函数，否则宏定义BOOST_CLASS_EXPORT(CDerived)是过不了的啊！ 使用虚基类指针来序列化子类对象（通过register_type模板的方式) 除了使用宏定义显式声明子类的方式以外，我们还可以通过register_type的方式，来实现用虚基类指针序列化子类对象： //用虚基类指针序列化子类对象（使用register_type模板方式） #include &lt;boost/archive/text_iarchive.hpp> #include &lt;boost/archive/text_oarchive.hpp> #include &lt;iostream> #include &lt;fstream> class CBase { friend class boost::serialization::access; public: CBase() = default; CBase(int vData) :m_BaseData(vData) {} virtual int getData()const { return m_BaseData; } private: template&lt;typename Archive> void serialize(Archive&amp; Ar, const unsigned int vVersion) { Ar &amp; m_BaseData; } int m_BaseData = 0; }; class CDerived :public CBase { friend class boost::serialization::access; public: CDerived() = default; CDerived(int vDerivedData) :m_DerivedData(vDerivedData) {} CDerived(int vBaseData, int vDerivedData) :CBase(vBaseData), m_DerivedData(vDerivedData) {} virtual int getData() const override { return m_DerivedData; } private: template&lt;typename Archive> void serialize(Archive&amp; Ar, const unsigned int vVersion) { Ar &amp; boost::serialization::base_object&lt;CBase>(*this); Ar &amp; m_DerivedData; } int m_DerivedData = 0; }; void save() { std::ofstream Fout("Serialization.txt"); boost::archive::text_oarchive OA(Fout); OA.register_type&lt;CDerived>(); //没有这行将无法用虚基类指针去序列化子类对象 CBase *pBaseObj = new CDerived(41, 45); OA &lt;&lt; pBaseObj; delete pBaseObj; } void load() { std::ifstream Fin("Serialization.txt"); boost::archive::text_iarchive IA(Fin); IA.register_type&lt;CDerived>(); CDerived *pDerivedObj; IA >> pDerivedObj; //基类必须有虚函数才可以进行转换 std::cout &lt;&lt;"DerivedData: " &lt;&lt; pDerivedObj->getData() &lt;&lt; std::endl; } int main() { save(); load(); return 0; } 值得注意的是，save和load函数里必须都调用register_type模板函数才能正确序列化和反序列化。 register_type的优点是只有需要序列化的类才注册。比如在开发一个库时，我们并不知道开发人员将来要序列化哪些类。BOOST_CLASS_EXPORT宏用起来更简单，但是它却可能注册那些不需要的类型。 使用make_array函数来优化类似数组的类型的归档字符串长度 我们可以在序列化和反序列化之前，为vector这种类似数组的类型，加上boost::serialization::make_array函数，来缩短它们被序列化到归档文件中的字符串长度。该函数的第一个参数是指向容器内容的指针，第二个参数是需要序列化的容器元素的个数。 //对标准容器的优化函数(make_array)，缩短归档字符串长度 #include &lt;boost/archive/text_iarchive.hpp> #include &lt;boost/archive/text_oarchive.hpp> #include &lt;boost/serialization/vector.hpp> #include &lt;iostream> #include &lt;fstream> #include &lt;vector> void save() { std::ofstream Fout("Serialization.txt"); boost::archive::text_oarchive OA(Fout); std::vector&lt;int> IntVec{ 1,2,3,4 }; OA &lt;&lt; boost::serialization::make_array(IntVec.data(), IntVec.size()); //用make_array函数来优化归档字符串长度 Fout.close(); } void load() { std::ifstream Fin("Serialization.txt"); boost::archive::text_iarchive IA(Fin); std::vector&lt;int> IntVec; IntVec.resize(4); //需要事先初始化好足够的元素数量 IA >> boost::serialization::make_array(IntVec.data(), IntVec.size()); //必须用make_array来反序列化，且保证有足够的元素数量，否则无法正确反序列化出所有数据 for (auto e : IntVec) std::cout &lt;&lt; e &lt;&lt; " "; Fin.close(); } int main() { save(); load(); return 0; } 序列化后本地文件Serialization.txt中的内容如下： 22 serialization::archive 13 1 2 3 4 如果不使用make_array函数，序列化后文件中的内容如下： 22 serialization::archive 13 4 0 1 2 3 4 至于另一个优化函数boost::serialization::make_binary_object ()，哎，没试验成功。。。没找到这个函数在哪里。。。 序列化到xml文件 如果想要序列化到xml文件，我们需要使用boost::archive::xml_iarchive和boost::archive::xml_oarchive来分别代替boost::archive::text_iarchive和boost::archive::text_oarchive，它们分别定义在boost/archive/xml_iarchive.hpp文件和boost/archive/xml_oarchive.hpp文件中。同时在所有的序列化操作之前，都必须先加上BOOST_SERIALIZATION_NVP宏定义或者boost::serialization::make_nvp： //序列化成XML文档(BOOST_SERIALIZATION_NVP或boost::serialization::make_nvp) #include &lt;boost/archive/xml_iarchive.hpp> #include &lt;boost/archive/xml_oarchive.hpp> #include &lt;iostream> #include &lt;fstream> class CData { friend class boost::serialization::access; public: CData() = default; CData(int vData) :m_Data(vData) {} private: template&lt;typename Archive> void serialize(Archive&amp; Ar, const unsigned int vVersion) { Ar &amp; BOOST_SERIALIZATION_NVP(m_Data); } int m_Data = 0; }; void save() { std::ofstream Fout("Serialization.xml"); boost::archive::xml_oarchive OA(Fout); CData DataObj(41); OA &lt;&lt; boost::serialization::make_nvp("CustomDataObj", DataObj); //在定义该数据在xml中的标签名 Fout.close(); } void load() { std::ifstream Fin("Serialization.xml"); boost::archive::xml_iarchive IA(Fin); CData DataObj; IA >> BOOST_SERIALIZATION_NVP(DataObj); Fin.close(); } int main() { save(); load(); return 0; } 先序列化实际对象，再序列化指向对象的指针 如果定义了一个对象，又定义了一个指向该对象的指针，并且要同时序列化这个对象和这个指针，那么必须先序列化这个对象，再序列化指向这个对象的指针，否则会运行出错： //需要先序列化实际对象，再序列化指向对象的指针（反过来的话会出错，两者都需要序列化的情况下） #include &lt;boost/archive/xml_iarchive.hpp> #include &lt;boost/archive/xml_oarchive.hpp> #include &lt;iostream> #include &lt;fstream> class CData { friend class boost::serialization::access; public: CData() = default; CData(int vData) :m_Data(vData) {} private: template&lt;typename Archive> void serialize(Archive&amp; Ar, const unsigned int vVersion) { Ar &amp; BOOST_SERIALIZATION_NVP(m_Data); } int m_Data = 0; }; void save() { std::ofstream Fout("Serialization.xml"); boost::archive::xml_oarchive OA(Fout); CData DataObj(41); CData *pDataObj = &amp;DataObj; OA &lt;&lt; BOOST_SERIALIZATION_NVP(DataObj); //如果要同时序列化DataObj和pDataObj，需要先序列化前者，再序列化后者，反过来的话会出错 OA &lt;&lt; BOOST_SERIALIZATION_NVP(pDataObj); Fout.close(); } int main() { save(); return 0; } 上面的程序如果我们在save函数中先序列化pDataObj，再序列化DataObj就会运行报错。我们可以先看一下正常情况下，Serialization.xml中的内容： &lt;?xml version="1.0" encoding="UTF-8" standalone="yes" ?> &lt;!DOCTYPE boost_serialization> &lt;boost_serialization signature="serialization::archive" version="13"> &lt;DataObj class_id="0" tracking_level="1" version="0" object_id="_0"> &lt;m_Data>41&lt;/m_Data> &lt;/DataObj> &lt;pDataObj class_id_reference="0" object_id_reference="_0">&lt;/pDataObj> 可以看到pDataObj是引用的DataObj的内容，因为它们两个代表的其实是同一个对象，所以(聪明的)boost序列化之后只存储了一个对象的内容，并没有存成两份相同的内容。所以当我们同时序列化源对象和指向该对象的指针时，必须先序列化源对象，指针才可以去引用嘛。当然，只序列化指向该对象的指针而不序列化源对象也是可以的，这里说的报错仅针对两者都要序列化的情况。]]></content>
      <categories>
        <category>Boost</category>
      </categories>
      <tags>
        <tag>序列化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++Primer第十三章 拷贝控制]]></title>
    <url>%2F2018%2F03%2F25%2FC%2B%2BPrimer%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0%E6%8B%B7%E8%B4%9D%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[当定义一个类时，我们显式地或隐式地指定在此类型的对象拷贝、移动、赋值和销毁时做什么。一个类通过定义五种特殊的成员函数来控制这些操作，包括：拷贝构造函数、拷贝赋值运算符、移动构造函数、移动赋值运算符和析构函数。拷贝和移动构造函数定义了当相同类型的另一个对象初始化本对象时做什么。拷贝和移动赋值运算符定义了将一个对象赋予同类型的另一个对象时做什么。析构函数定义了当此类型对象销毁时做什么。我们称这些操作为拷贝控制操作。 拷贝、赋值与销毁 如果一个构造函数的第一个参数是自身类类型的引用，且任何额外参数都有默认值，则此构造函数是拷贝构造函数： class Foo { public: Foo(); //默认构造函数 Foo(const Foo&amp;); //拷贝构造函数 //... }; 拷贝构造函数的第一个参数必须是一个引用类型。 与合成默认构造函数不同，即使我们定义了其他构造函数，编译器也会为我们合成一个拷贝构造函数。 直接初始化通常是使用()运算符，而拷贝初始化通常是使用=运算符： std::string s1(10, 'a'); //直接初始化 std::string s2(s1); //直接初始化 std::string s3 = s1; //拷贝初始化 std::string s4 = "Hello World!"; //拷贝初始化 std::string s5 = std::string("Hello"); //拷贝初始化 当使用直接初始化时，我们实际上是要求编译器使用普通的函数匹配来选择与我们提供的参数最匹配的构造函数。当我们使用拷贝初始化时，我们要求编译器将右侧运算对象拷贝到正在创建的对象中，如果需要的话还要进行类型转换。 如果一个类有移动构造函数，则拷贝初始化有时会使用移动构造函数而非拷贝构造函数来完成。 当我们初始化标准库容器或是调用其insert或push成员时，容器会对其元素进行拷贝初始化。与之相对，用emplace成员创建的元素都直接进行直接初始化（参见第9章第3节）。 拷贝构造函数被用来初始化非引用类类型参数，这一特性解释了为什么拷贝构造函数自己的参数必须是引用类型。如果其参数不是引用类型，则调用永远也不会成功，会因为存在拷贝而一直循环调用拷贝构造函数（死循环）。 与拷贝构造函数一样，如果类未定义自己的拷贝赋值运算符，编译器会为它合成一个。赋值运算符就是一个名为operator=的函数。 赋值运算符通常返回一个指向其左侧运算对象的引用： class Foo { public: Foo&amp; operator=(const Foo&amp; vFooObj); //赋值运算符 private: int m_Data; }; Foo&amp; Foo::operator=(const Foo&amp; vFooObj) { m_Data = vFooObj.m_Data; return *this; //返回一个此对象的引用 } 一个构造函数中，成员的初始化是在函数体执行之前完成的，且按照它们在类中出现的顺序进行初始化，在一个析构函数中，首先执行函数体，然后又销毁成员。成员按初始化顺序的逆序销毁。 认识到析构函数体自身并不直接销毁成员是非常重要的。成员是在析构函数体之后隐含的析构阶段中被销毁的。在整个对象销毁过程中，析构函数体是作为成员销毁步骤之外的另一部分而进行的。 如果一个类需要析构函数，我们几乎可以肯定它也需要一个拷贝构造函数和一个拷贝赋值运算符。比如如下程序： class HasPtr { public: HasPtr(int vData=0) :m_pData(new int(vData)) {} ~HasPtr() { delete m_pData; } int *m_pData; }; //函数f结束时，vHp和Temp都会调用其析构函数，但是它们的m_pData成员却指向同一块内存 void f(HasPtr vHp) { HasPtr Temp = vHp; } int main() { HasPtr Obj1(41); f(Obj1); std::cout &lt;&lt; *Obj1.m_pData &lt;&lt; std::endl; return 0; } 由于HasPtr类只定义了析构函数，它的拷贝构造函数和赋值运算符都是编译器合成的，所以在调用函数f时，把Obj1拷贝给参数vHp，指针成员m_pData也是直接简单拷贝，导致Obj1和vHp的指针指向同一块内存，同理，Temp和vHp的指针也是指向同一块内存。在函数f结束时，vHp和Temp会被释放，执行其析构函数，这样指向同一块内存的指针会被delete两次。显然出错了。而且Obj1的m_pData也不再指向有效的内存。 如果一个类需要拷贝构造函数，几乎可以肯定它也需要一个拷贝赋值运算符。反之亦然。 我们可以通过将拷贝控制成员定义为=default来显式地要求编译器生成合成的版本（当然只能对具有合成版本的成员函数使用=default，即默认构造函数和拷贝控制成员）： class CData { public: CData() = default; //内联 CData(const CData&amp;) = default; //内联 CData&amp; operator=(const CData&amp;); //非内联 ~CData() = default; //内联 }; CData&amp; CData::operator=(const CData&amp;) = default; 在类内用=default修饰成员的声明时，合成的函数将隐式地声明为内联的。如果不希望合成的成员是内联函数，则应该像上面operator=一样，只在类外定义的时候使用=default。 在新标准下，我们可以通过将拷贝构造函数和拷贝赋值运算符定义为删除的函数来阻止拷贝。删除的函数时这样一种函数：我们虽然声明了它们，但不能以任何方式使用它们。在函数的参数列表后面加上=delete来指出我们希望将它定义为删除的：class CData { public: CData() = default; //合成的默认构造函数 CData(const CData&amp;) = delete; //阻止拷贝 CData&amp; operator=(const CData&amp;)=delete; //阻止赋值 ~CData() = default; //合成的析构函数 }; 与=default的另一个不同之处是，我们可以对任何函数指定=delete，但是我们只能对编译器可以合成的默认构造函数或拷贝控制成员使用=default。 值得注意的是，我们不能删除析构函数。如果析构函数被删除，就无法销毁此类型的对象了。 如果一个类有数据成员但不能默认构造、拷贝、复制或销毁，则对应的成员函数将被定义为删除的。 对一个类对象进行初始化赋值调用的是其拷贝构造函数而非赋值运算符，而非初始化赋值调用的是才是赋值运算符： CData::CData(const CData&amp; vData) { m_Data = vData.m_Data; std::cout &lt;&lt; "Copy Constructor" &lt;&lt; std::endl; } CData&amp; CData::operator=(const CData&amp; vData) { m_Data = vData.m_Data; std::cout &lt;&lt; "Assignment Operator" &lt;&lt; std::endl; return *this; } CData Data1; CData Data2 = Data1; //初始化赋值，调用拷贝构造函数，而非赋值运算符，输出Copy Constructor Data2 = Data1; //非初始化赋值，调用赋值运算符，输出Assignment Operator 交换操作 与拷贝控制成员不同，swap并不是必要的。但是，对于分配了资源的类，定义swap可能是一种很重要的优化手段（指针交换比其内容赋值快多了）。 如果存在类型特定的swap版本，swap调用会与之匹配。如果不存在类型特定的版本，则会使用std中的版本。 拷贝控制示例 -_-||，最近比较忙，比较忙。。。有时间再来补上了(*￣︶￣) 动态内存管理类 有一些标准类库，包括string，都定义了所谓的“移动构造函数”。移动构造函数通常是将资源从给定对象“移动”而不是拷贝到正在创建的对象。而且标准库保证“移后源”string仍然保持一个有效的、可析构的状态。对于string，我们可以想象每个string都有一个指向char数组的指针，可以假定string的移动构造函数进行了指针的拷贝，而不是为字符分配内存空间然后拷贝字符（这只是猜想，因为string的移动构造函数的工作细节尚未公开，实际上这种猜想只是为了说明移动构造函数避免了拷贝操作，但是严格来说是不对的，移后对象和移后源对象实际上是两个完全独立的对象，它们并不共享指向同一块内存区域的指针…）。 我们可以使用一个名为move的标准库函数来显式使用string的移动构造函数： std::vector&lt;std::string> SVec{ "abc","def","ghi" }; std::allocator&lt;std::string> Alloc; auto p = Alloc.allocate(SVec.size()); auto dest = p; for (auto e:SVec) { Alloc.construct(dest++, std::move(e)); } auto q = p; std::cout &lt;&lt; *q &lt;&lt; std::endl; //输出abc std::cout &lt;&lt; *++q &lt;&lt; std::endl; //输出def std::cout &lt;&lt; *++q &lt;&lt; std::endl; //输出ghi *p = "hello"; //*p指向的内容变为了hello，但是不会影响移后源对象SVec的内容 调用move返回的结果会令construct使用string的移动构造函数。由于我们使用了移动构造函数，这些string管理的内存将不会被拷贝。而且即使我们对新创建的内存区p的内容作出改变，也不会影响到移后源对象SVec中的保存的内容，它们是独立的，互不影响。 用allocator来模拟vector的完整代码以后再补上了(*￣︶￣） 对象移动 移动构造函数可以减少拷贝，优化性能（只涉及指针复制，不拷贝内存数据）。 新标准的一个最主要的特性是可以移动而非拷贝对象的能力。很多情况下都会发生对象拷贝，在其中某些情况下，对象拷贝后就立即被销毁了。在这些情况下，移动而非拷贝对象会大幅度提升性能。 使用移动而不是拷贝的另一个原因源于IO类或unique_ptr这样的类，这些类都包含不能被共享的资源（如指针或IO缓冲）。因此，这些类型的对象不能拷贝但可以移动。 为了支持移动操作，新标准引入了一种新的引用类型：右值引用，即必须绑定到右值的引用。我们通过&amp;&amp;而不是&amp;来获得右值引用。 右值引用一个重要的性质：只能绑定到一个将要销毁的对象。 不能将一个右值引用直接绑定到一个左值上，通俗地说就是不能将右值引用绑定到一个可修改其内容的对象上（如果想要绑定到左值需要使用std::move，后文详述）： int i = 41; int &amp;l = i; //正确，左值引用 int &amp;&amp;r = i; //错误，不能将一个右值引用直接绑定到左值上 int &amp;l2 = i * 42; //错误，i*42的结果是一个右值 const int &amp;l3 = i * 42; //正确，可以把const左值引用直接绑定到右值上 int &amp;&amp;r2 = i * 42; //正确，可以将右值引用直接绑定到i*42的结果上 左值和右值的区别很明显：左值有持久的状态，而右值要么是字面常量，要么是在表达式求值过程中创建的临时对象。 由于右值引用只能绑定到临时对象，所以： 右值引用所指的对象将要被销毁 该对象没有其他用户（没有其他指针或者引用指向该对象） 变量是左值，因此我们不能直接将一个右值引用绑定到一个变量上，即使这个变量是右值引用类型也不行： int &amp;&amp;r1 = 41; //正确，字面值常量是右值 int &amp;&amp;r2 = r1; //错误，变量r1是左值 虽然不能直接将一个右值引用绑定到一个左值上，但我们可以通过调用一个名为move的新标准库函数来获得绑定到左值上的右值引用。move函数定义在头文件utility中。move函数的具体实现机制将在16章中详述。int i = 41; int &amp;&amp;r = std::move(i); //正确 move调用告诉编译器：我们有一个左值，但我们希望像一个右值一样处理它。我们必须认识到：调用move就意味着承诺：除了对左值i进行赋值或销毁它外，我们将不再使用它。也就是说，我们可以销毁一个移后源对象（使用move函数作用后的对象），也可以给它赋予新值，但不能使用一个移后源对象的值。 类似string等标准库类都定义了移动构造函数和移动赋值运算符，所以我们能对其使用std::move来获得右值引用。为了让我们自己的类型也支持移动操作，需要为其定义移动构造函数和移动赋值运算符。这两个成员类似对应的拷贝操作，但它们从给定对象窃取资源而不是拷贝资源： class CData { public: CData() = default; CData(CData &amp;&amp;vData) noexcept:m_Data(vData.m_Data),m_pDataName(vData.m_pDataName) { m_pDataName = nullptr; } CData&amp; operator=(CData &amp;&amp;vData) noexcept { m_Data = vData.m_Data; m_pDataName = vData.m_pDataName; m_pDataName = nullptr; return *this; } private: int m_Data; std::vector&lt;int> *m_pDataName = nullptr; }; CData Data1; CData Data2(std::move(Data1)); 可以看到移动构造函数和移动赋值运算符函数中，最重要的在于指针赋值，通过指针赋值来避免大型数据成员的拷贝操作，即窃取了另一个对象（源对象）的数据地址并且把源对象的指针赋空（狸猫换太子的操作）。赋空的原因在于：一旦资源完成移动，源对象必须不再指向被移动的资源，因为这些资源的所有权已经归属新创建的对象。需要注意的是，需要保证移后源对象是可以被安全析构的。 在上面代码中，noexcept是我们承诺一个函数不抛出异常的一种方法。使用noexcept的原因如下： 因为移动操作只是窃取资源，通常不会分配任何资源，所以移动操作通常不会抛出任何异常。通过把移动操作函数声明为noexcept，可以减少标准库为处理异常可能性而做出的一些额外操作。 移动一个对象通常会改变它的值。如果在使用移动构造函数的过程中，移动了部分而不是全部元素时抛出了一个异常，就会产生问题：旧空间中被移动的源元素已经发生了改变，而新空间中未构造的元素可能尚不存在。这会导致移后对象和移后源对象都只有残缺的一部分数据。所以，应该使用noexcept承诺在移动过程中不会发生异常而导致移动操作被中断。 如果一个函数想要声明为noexcept，则必须在声明和定义时都同时指定noexcept。 当我们编写一个移动操作时，必须确保移后源对象进入一个可安全析构的状态。 在移动操作后，移后源对象必须保持有效的、可析构的状态，但是用户不能对其值进行任何假设，尽量不要使用移后源对象的数据。 与处理拷贝构造函数和拷贝赋值运算符一样，编译器也会合成移动构造函数和移动赋值运算符，但是，合成移动操作的条件与合成拷贝操作的条件大不相同。如果一个类定义了自己的拷贝构造函数、拷贝赋值运算符或者析构函数，编译器就不会为它合成移动构造函数和移动赋值运算符了。只有当一个类没有定义任何自己版本的拷贝控制成员，且类的每个非static数据成员都可以移动时，编译器才会为它合成移动构造函数或移动赋值运算符。 使用default让编译器生成默认的移动操作函数，但是却存在有类成员无法移动时，则该移动操作函数会被定义为删除的。 定义了移动构造函数和移动赋值运算符的类必须也定义自己的拷贝操作。否则，这些成员默认地被定义为删除的。 如果同时定义了移动操作函数和拷贝控制函数，则如果传入函数的实参是右值就调用移动操作函数，是左值就调用拷贝控制函数： class CData { public: CData() = default; CData(const CData&amp; vData) { m_Data = vData.m_Data; *m_pDataName = *vData.m_pDataName; } CData&amp; operator=(const CData &amp;vData) { m_Data = vData.m_Data; *m_pDataName = *vData.m_pDataName; return *this; } CData&amp; operator=(CData &amp;&amp;vData) noexcept { m_Data = vData.m_Data; m_pDataName = vData.m_pDataName; m_pDataName = nullptr; return *this; } int m_Data; std::vector&lt;int> *m_pDataName = nullptr; }; CData getOrCreateDataObj() { CData DataObj; DataObj.m_Data = 41; return DataObj; } CData Data1, Data2, Data3; Data2 = Data1; //Data1是左值，调用赋值运算符 Data3 = getOrCreateDataObj(); //getOrCreateDataObj()返回的是临时对象，是一个右值，所以调用移动赋值运算符，Data3.m_Data = 41 但是如果我们没有定义移动操作函数，即使我们试图通过调用move函数来移动一个对象，实际上也还是会去调用对应的拷贝控制函数（因为没有定义移动操作函数嘛~）。 一般来说，一个迭代器的解引用运算符返回一个指向元素的左值，而移动迭代器解引用会得到一个右值引用。我们可以通过调用标准库的make_move_iterator函数来将一个普通迭代器转换为移动迭代器。由于移动迭代器支持正常的迭代器操作，所以我们可以将一对移动迭代器传递给标准库算法，尤其是uninitialized_copy函数（函数参见12章）：std::vector&lt;std::string> SVec{ "The","Furthest","Distance" }; std::allocator&lt;std::string> SAlloc; auto First = SAlloc.allocate(41); //将元素移动到原始内存First中 auto Last = std::uninitialized_copy(std::make_move_iterator(SVec.begin()), std::make_move_iterator(SVec.end()), First); 通过在类代码中小心地适用move，可以大幅度提升性能。而如果随意在普通用户代码（与类实现代码相对）中使用移动操作，很可能导致莫名其妙的、难以查找的错误，而难以提升应用程序性能。 如果一个成员函数有引用限定符，则具有相同参数列表的所有版本（重载版本）都必须有引用限定符（关于引用限定符的详述可以参考《C++Primer》第13章第6节）。&nbsp; 参考文献：《C++Primer第五版》]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++Primer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++Primer第十二章 动态内存]]></title>
    <url>%2F2018%2F03%2F11%2FC%2B%2BPrimer%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0%E5%8A%A8%E6%80%81%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[概述 静态内存用来保存局部static对象、类static数据成员以及定义在任何函数之外的变量。栈内存用来保存定义在函数内的非static对象。分配在静态或栈内存中的对象由编译器自动创建和销毁。对于栈对象，仅在其定义的程序块运行时才存在；static对象在使用之前分配，在程序结束时销毁。 除了静态内存和栈内存，每个程序还拥有一个内存池。这部分内存被称作自由空间或堆。程序用堆来存储动态分配的对象，即那些在程序运行时分配的对象。动态对象的生存期由程序来控制，也就是说，当动态对象不再使用时，我们的代码必须显式地销毁它们。 动态内存与智能指针 为了更容易、更安全地使用动态内存，新标准库提供了三种智能指针类型来管理动态对象：shared_ptr和unique_ptr。它们和普通指针的重要区别是它们负责自动释放所指向的对象。shared_ptr允许多个指针指向同一个对象；unique_ptr则独占所指向的对象。 标准库还定义了一个名为weak_ptr的伴随类，它是一种弱引用，指向shared_ptr所管理的对象。 shared_ptr、unique_ptr和weak_ptr都定义在头文件memory中。 智能指针其实是在普通指针上作了一些包装，包括自动释放内存、指向同一对象的指针指针数量（用智能指针类中的计数器保存）等等。 智能指针也是模板类，默认初始化的智能指针中保存着一个空指针： std::shared_ptr&lt;std::string> p1; //shared_ptr，可以指向string对象，现在还是空指针 使用智能指针的get成员函数可以获得对应的普通指针： std::shared_ptr&lt;std::string> p1; auto p = p1.get(); //p是string*类型 shared_ptr独有的操作如下表： 函数 含义 make_shared(args) 返回一个shared_ptr，指向一个动态分配的类型为T的对象，使用args初始化该对象 shared_ptrp(q) p是shared_ptr q的拷贝，此操作会递增q中的计算器。q中的指针必须能转换为T* p=q p和q都是shared_ptr，所保存的指针必须能相互转换。此操作会递减p的引用计数，递增q的引用计数；若p的引用计数变为0，则将其管理的原内存释放 p.unique() 若p.use_count()为1，返回true，否则返回false p,use_count() 返回一个与p共享对象的智能指针数量；可能很慢，主要用于测试 我们可以用make_shared函数代替new来生成一个指针，这样更安全，同时不需要匹配的delete操作，因为智能指针在计算器变为0时会自动调用delete： std::shared_ptr&lt;std::string> p1 = std::make_shared&lt;std::string>("Hello"); 当然用auto来保存make_shared的结果更简单： auto p1 = std::make_shared&lt;std::string>("Hello"); 每个shared_ptr都有一个关联的计数器，通常称其为引用计数。无论何时我们拷贝一个shared_ptr，计数器都会增加，当我们给shared_ptr赋予一个新值或是shared_ptr被销毁（例如局部shared_ptr离开其作用域）时，计数器就会递减。一旦一个shared_ptr的计数器变为0，它就会自动释放自己所管理的对象。 当指向一个对象的最后一个shared_ptr被销毁时，shared_ptr类会自动销毁此对象。它是通过析构函数来完成销毁工作的。shared_ptr的析构函数会递减它所指向的对象的引用计数。如果引用计数变为0，shared_ptr的析构函数就会销毁对象，并释放它占用的内存。 如果将shared_ptr存放于一个容器中，而后不再需要全部元素，而只使用其中一部分，要记得用erase删除不再使用的那些元素，否则它们占用的内存将无法释放。 使用动态内存的一个常见原因是允许多个对象共享相同的状态。 使用new进行动态内存分配时，不带()的执行默认初始化，值是未定义的，带()的执行值初始化：int *p = new int; //*p的值是未定义的 int *p2 = new int(); //*p2 = 0 std::cout &lt;&lt; *p &lt;&lt; std::endl; //本机输出-842150451 std::cout &lt;&lt; *p2 &lt;&lt; std::endl; //输出0 默认情况下，如果new不能分配所要求的内存空间，它会抛出一个类型为bad_alloc的异常。我们可以改变使用new的方式来阻止它抛出异常：int *p1 = new int; //如果分配失败，new抛出std::bad_alloc异常 int *p2 = new (std::nothrow) int; //如果分配失败，new返回一个空指针，不抛出异常 我们称这种形式的new为定位new。定位new表达式允许我们向new传递额外的参数。这里我们传递的是标准库的一个名为nothrow的对象，告诉它不能抛出异常。bad_alloc和nothrow都定义在头文件new中。 通常情况下，编译器不能分辨一个指针指向的是静态还是动态分配的对象。类似的，编译器也不能分辨一个指针所指向的内存是否已经被释放了。 使用new和delete管理动态内存存在三个问题： 忘记delete内存。忘记释放动态内存会导致人们常说的“内存泄漏”问题，因为这种内存永远不可能被归还给自由空间了。 使用已经释放掉的对象。通过在释放内存后将指针置位空，有时可以检测出这种错误（delete p; p = nullptr）。 同一块内存释放两次。 坚持使用智能指针，就可以避免所有这些问题。对于一块内存，只有在没有任何智能指针指向它的情况下，智能指针才会自动释放它。 接受指针参数的智能指针构造函数时explicit的，我们不能进行内置指针到智能指针之间的隐式转换： std::shared_ptr&lt;int> p1(new int(41)); //正确：使用了直接初始化形式 std::shared_ptr&lt;int> p2 = new int(41); //错误：不能将普通指针隐式转换为智能指针 std::shared_ptr&lt;int> clone(int i) { return new int(i); //错误：不能将普通指针隐式转换为智能指针 } std::shared_ptr&lt;int> clone1(int i) { return std::shared_ptr&lt;int>(new int(i)); //正确，显式创建智能指针 } 定义智能指针时还可以增加一个参数来代替delete，这个参数必须是一个可调用对象：int *p = new int(41); std::shared_ptr&lt;int> p1(p, [](int *vp) {delete vp; std::cout &lt;&lt; "delete" &lt;&lt; std::endl; }); 当智能指针p1离开其作用域时，如果其计数器变为0，将会执行这个可调用的lambda表达式，输出字符串delete。 智能指针还有一个名叫reset的成员函数： p.reset(); ：若p是唯一指向其对象的shared_ptr，reset会释放此对象 p.reset(q);：令p指向指针q p.reset(q, d);：令p指向q，并且调用对象d而不是delete来释放q 不要混合使用普通指针和智能指针： void process(std::shared_ptr&lt;int> vp) { } int *p = new int(41); process(std::shared_ptr&lt;int>(p)); //合法，但函数退出后p指向的内存会被释放，p称为悬空指针 int j = *p; 当将一个shared_ptr绑定到一个普通指针时，我们就将内存的管理责任交给了这个shared_ptr。一旦这样做了，我们就不应该再使用内置指针来问shared_ptr所指向的内存了。 不要用智能指针的get成员函数返回的普通指针，去初始化另一个智能指针：std::shared_ptr&lt;int> p(new int(41)); auto q = p.get(); { std::shared_ptr&lt;int> TempP(q); //逻辑错误：两个独立的shared_ptr指向相同的内存 } int foo = *p; //未定义：p指向的内存已经被释放了 发生异常后，智能指针指向的内存会被正常释放，但是普通指针指向的内存就永远不会被释放了（在delete之前发生异常）： void f() { std::shared_ptr&lt;int> sp(new int(41)); //这段代码发生异常 } //函数结束时，shared_ptr自动释放内存 void f1() { int *p = new int(41); //这段代码发生异常 delete p; } //发生异常后，p指向的内存永远不会被释放 无论是否发生异常，局部对象都会被销毁，所以发生异常后sp会被销毁，但是delete p永远执行不到。这个特性对建立局部网络连接的代码很有用，如果代码是这样的： struct SDestination; struct SConnection; SConnection connect(SDestination*); //打开连接 void disconnect(SConnection); //关闭连接 void f(SDestination &amp;d) { SConnection Conn = connect(&amp;d); //使用连接 //如果我们在f退出前忘记调用disconnect，或者在调用它之前发生了异常，就无法关闭连接Conn了 } 为了保证函数退出时关闭连接，我们可以使用智能指针： struct SDestination; struct SConnection; SConnection connect(SDestination*); //打开连接 void disconnect(SConnection); //关闭连接 void f(SDestination &amp;d) { SConnection Conn = connect(&amp;d); std::shared_ptr&lt;SConnection> p(&amp;Conn, [](SConnection *p) {disconnect(*p); }); //使用连接 //即使我们在f退出前忘记调用disconnect，或者在调用它之前发生了异常，Conn也会被正确关闭 } 即使发生了异常或者忘记调用disconnect，连接也会被正常关闭，因为函数退出时会释放局部对象p，p在被销毁时会调用lambda表达式来关闭连接。 为了正确使用智能指针，我们必须坚持一些规范： 不使用相同的内置指针初始化（或reset）多个智能指针 不delete get()返回的指针 不使用get()返回的指针去初始化或reset另一个智能指针 如果使用get返回的普通指针，记住当最后一个对应的智能指针被销毁后，这个普通指针就失效了 如果使用智能指针管理的资源不是new分配的内存，记住传递给它一个删除器（代替delete的可调用对象） 与shared_ptr不同，某个时刻只能有一个unique_ptr指向一个给定对象。当unique_ptr被销毁时，它所指向的对象也被销毁。而且没有类似make_shader的标准库函数来返回一个unique_ptr。当我们定义一个unique_ptr时，需要将其绑定到一个new返回的指针上或默认初始化，因为它不支持拷贝和赋值操作（独占内存所致）：std::unique_ptr&lt;int> p1; //p1是一个指向int类型的空指针 std::unique_ptr&lt;int> p2(new int(41)); //p2指向一个值为42的int std::unique_ptr&lt;int> p3(p2); //错误：unique_ptr不支持拷贝 p1 = p2; //错误：unique_ptr不支持赋值 虽然不能拷贝或赋值unique_ptr，但可以通过release算法unique_ptr对指针的控制权，然后将其转移给另一个unique_ptr：std::unique_ptr&lt;int> p1(new int(41)); //p2指向一个值为42的int std::unique_ptr&lt;int> p2(p1.release()); //将p1的控制权转移给p2 p1.reset(p2.release()); //将p2的控制权转移给p1 如果我们不用另一个智能指针来保存release返回的普通指针，我们的程序就要负责delete掉该指针。 不能拷贝unique_ptr的规则有一个例外：我们可以拷贝或赋值一个将要被销毁的unique_ptr（因为通常会对它们指向移动拷贝或移动赋值，见13章）：std::unique_ptr&lt;int> clone(int p) { std::unique_ptr&lt;int> sp(new int(p)); return sp; //正确：可以对一个将要被销毁的unique_ptr赋值或拷贝 } 和shared_ptr类似，我们也可以像unique_ptr传递一个自定义的删除器，不同的是，定义时必须显式制定出删除器的模板类型：void deleteFunc(int *p) { delete p; std::cout &lt;&lt; "delete" &lt;&lt; std::endl; } std::unique_ptr&lt;int, decltype(deleteFunc)*> p1(new int(41), deleteFunc); weak_ptr是一种不控制所指向对象生存期的智能指针，它指向由一个shared_ptr管理的对象。将一个weak_ptr绑定到一个shared_ptr不会改变shared_ptr的引用计数。一旦最后一个指向对象的shared_ptr被销毁，对象就会被释放，即使有weak_ptr指向对象，对象也还是会被释放。 当我们创建一个weak_ptr时，要用一个shared_ptr来初始化它： auto sp = std::make_shared&lt;int>(41); std::weak_ptr&lt;int> wp(sp); //wp弱共享sp，sp的引用计数未改变 weak_ptr特有的成员操作如下： w.use_count()：与w共享对象的shared_ptr的数量 w.expired()：若w.use_count()为0，返回true，否则返回false w.lock()：如果expired为true，返回一个空的shared_ptr；否则返回一个指向w的对象的shared_ptr 从上面可以看出weak_ptr所指向的对象可能不存在，所以我们不能使用weak_ptr直接访问对象，而必须调用lock： if (std::shared_ptr&lt;int> vSp = wp.lock()) { //在if中使用vSp访问共享对象是安全的 } 动态数组 标准库包含一个名为allocator的类，允许我们将分配和初始化分离。使用allocator通常会提供更好的性能和更灵活的内存管理能力。 大多数应用应该使用标准库容器而不是动态分配的数组。使用容器更为简单、更不容易出现内存管理错误并且可能有更好的性能。 我们用new分配的动态数组并不是数组类型，所以不能对动态数组调用begin或end： int a[10]; auto it = std::begin(a); //正确：可以对数组类型调用begin函数 int *b = new int[10]; memset(b, 0, 10); auto it2 = std::begin(b); //错误：不能对动态数组调用begin函数 释放动态数组时，需要在delete之后、指针名之前加上一个[ ]： int *b = new int[10]; delete[] b; 动态数组中的元素按逆序销毁，即最后一个元素先被销毁，然后是倒数第二个…。 标准库提供了一个可以管理new分配的数组的unique_ptr版本，需要在模板参数的对象类型后面跟一个方括号： std::unique_ptr&lt;int[]> up(new int[10]); up.release(); //自动调用delete[]销毁其指针 但是如果要使用shared_ptr来管理一个动态数组，必须提供自定义的删除器： std::shared_ptr&lt;int> sp(new int[10], [](int *p) {delete[] p; }); sp.reset(); //使用我们提供的lambda释放数组，它使用delete[] unique_ptr管理的动态数组可以通过下标来访问元素，但是shared_ptr不可以，它没有定义下标运算符。而且智能指针类型不支持指针算术运算。因此shared_ptr为了访问数组中的元素，必须先用get获取一个内置指针，然后用它来访问素组元素： std::unique_ptr&lt;int[]> up(new int[10]); for (size_t i = 0; i &lt; 10; ++i) up[i] = i; std::shared_ptr&lt;int> sp(new int[10], [](int *p) {delete[] p; }); for (size_t i = 0; i &lt; 10; ++i) *(sp.get() + i) = i; 当分配一大块内存时，我们通常计划在这块内存还是那个按需构造对象。在此情况下，我们希望将内存分配和对象构造分离。这意味着我们可以分配大块内存，但只在真正需要时才真正执行对象创建操作。 标准库allocator类定义在头文件memory中，它帮助我们将内存分配和对象构造分离开来。allocator也是一个模板，它会根据给定的对象类型来确定恰当的内存大小和对齐位置： std::allocator&lt;std::string> Alloc; //可以分配string的allocator对象 auto const p = Alloc.allocate(n); //分配n个未初始化的string allocator类的成员操作如下表： 函数 含义 allocator a 定义一个allocator对象，它可以为类型为T的对象分配内存 a.allocate(n) 分配一段原始的、未构造的内存，保存n个类型为T的对象 a.deallocate(p, n) 释放从T*指针p中地址开始的内存，这块内存保存了n个类型为T的对象；p必须是一个先前由allocate返回的指针，且n必须是p创建时所要求的大小。在调用deallocate之前，用户必须对每个在这块内存中创建的对象调用destroy a.construct(p, args) p必须是一个类型为T*的指针，指向一块原始内存；args被传递给类型为T的构造函数，用来在p指向的内存中构造一个对象 a.destroy(p) p为T*类型的指针，此算法对p指向的对象执行析构函数 allocator分配的内存是未构造的，我们需要在此内存中构造对象，而construct成员函数接受一个指针和零个或多个额外参数，在指针所指的位置构造一个元素： auto q = p; Alloc.construct(q++); //*q为空字符串 Alloc.construct(q++, 10, 'c'); //*q为10个字符c组成的字符串 Alloc.construct(q++, "hello"); //*q为字符串hello 还未构造对象的情况下就使用原始内存是错误的： std::allocator&lt;std::string> Alloc; //可以分配string的allocator对象 auto const p = Alloc.allocate(10); //分配n个未初始化的string std::cout &lt;&lt; *p &lt;&lt; std::endl; //错误：程序崩溃，因为p指向未构造的内存 当我们用完对象后，必须对每个构造的元素调用destroy来销毁它们。函数destroy接受一个指针，对指向的对象执行析构函数：while (q != p) Alloc.destroy(--q); 销毁这些被构造出来的元素以后，我们就可以使用deallocate成员函数把内存归还给系统了（当然也可以拿这些内存再去构造新的对象）。所以allocator使用四部曲就是：allocate、construct、destroy、deallocate：std::allocator&lt;std::string> Alloc; //可以分配string的allocator对象 auto const p = Alloc.allocate(10); //分配n个未初始化的string auto q = p; Alloc.construct(q++); //*q为空字符串 Alloc.construct(q++, 10, 'c'); //*q为10个字符c组成的字符串 Alloc.construct(q++, "hello"); //*q为字符串hello while (q != p) Alloc.destroy(--q); //销毁每个构造出来的对象 Alloc.deallocate(p, 10); //第二个参数必须与allocate分配内存时指定的参数相同 标准库还为allocator类定义了两个伴随算法：copy和fill，用于在未初始化内存（原始内存）中创建对象，定义在头文件memory中：std::vector&lt;std::string> SVec{ "Hello","World","Nice" }; std::allocator&lt;std::string> Alloc; auto p = Alloc.allocate(SVec.size() * 2); //通过拷贝SVec中的元素来构造原始内存从p开始的元素 auto q = std::uninitialized_copy(SVec.begin(), SVec.end(), p); //将原始内存中剩余的未构造元素初始化为字符串Same std::uninitialized_fill_n(q, SVec.size(), "Same"); 函数 含义 uninitialized_copy(b, e, b2) 将迭代器b到e范围内的元素拷贝到迭代器b2指向的未构造的原始内存中 uninitialized_copy_n(b, n, b2) 从迭代器b指向的元素开始，拷贝n个元素到b2指向的原始内存中 uninitialized_fill(b, e, t) 在迭代器b到e的元素内存范围内构造对象，对象的值均为t的拷贝 uninitialized_fill_n(b, n, t) 从迭代器b指向的元素内存开始创建n个对象，对象的值均为t的拷贝 使用标准库：文本查询程序 -_-||，最近比较忙，比较忙。。。有时间再来补上了(*￣︶￣) 概述 静态内存用来保存局部static对象、类static数据成员以及定义在任何函数之外的变量。栈内存用来保存定义在函数内的非static对象。分配在静态或栈内存中的对象由编译器自动创建和销毁。对于栈对象，仅在其定义的程序块运行时才存在；static对象在使用之前分配，在程序结束时销毁。 除了静态内存和栈内存，每个程序还拥有一个内存池。这部分内存被称作自由空间或堆。程序用堆来存储动态分配的对象，即那些在程序运行时分配的对象。动态对象的生存期由程序来控制，也就是说，当动态对象不再使用时，我们的代码必须显式地销毁它们。 动态内存与智能指针 为了更容易、更安全地使用动态内存，新标准库提供了三种智能指针类型来管理动态对象：shared_ptr和unique_ptr。它们和普通指针的重要区别是它们负责自动释放所指向的对象。shared_ptr允许多个指针指向同一个对象；unique_ptr则独占所指向的对象。 标准库还定义了一个名为weak_ptr的伴随类，它是一种弱引用，指向shared_ptr所管理的对象。 shared_ptr、unique_ptr和weak_ptr都定义在头文件memory中。 智能指针其实是在普通指针上作了一些包装，包括自动释放内存、指向同一对象的指针指针数量（用智能指针类中的计数器保存）等等。 智能指针也是模板类，默认初始化的智能指针中保存着一个空指针： std::shared_ptr&lt;std::string> p1; //shared_ptr，可以指向string对象，现在还是空指针 使用智能指针的get成员函数可以获得对应的普通指针： std::shared_ptr&lt;std::string> p1; auto p = p1.get(); //p是string*类型 shared_ptr独有的操作如下表： 函数 含义 make_shared(args) 返回一个shared_ptr，指向一个动态分配的类型为T的对象，使用args初始化该对象 shared_ptrp(q) p是shared_ptr q的拷贝，此操作会递增q中的计算器。q中的指针必须能转换为T* p=q p和q都是shared_ptr，所保存的指针必须能相互转换。此操作会递减p的引用计数，递增q的引用计数；若p的引用计数变为0，则将其管理的原内存释放 p.unique() 若p.use_count()为1，返回true，否则返回false p,use_count() 返回一个与p共享对象的智能指针数量；可能很慢，主要用于测试 我们可以用make_shared函数代替new来生成一个指针，这样更安全，同时不需要匹配的delete操作，因为智能指针在计算器变为0时会自动调用delete： std::shared_ptr&lt;std::string> p1 = std::make_shared&lt;std::string>("Hello"); 当然用auto来保存make_shared的结果更简单： auto p1 = std::make_shared&lt;std::string>("Hello"); 每个shared_ptr都有一个关联的计数器，通常称其为引用计数。无论何时我们拷贝一个shared_ptr，计数器都会增加，当我们给shared_ptr赋予一个新值或是shared_ptr被销毁（例如局部shared_ptr离开其作用域）时，计数器就会递减。一旦一个shared_ptr的计数器变为0，它就会自动释放自己所管理的对象。 当指向一个对象的最后一个shared_ptr被销毁时，shared_ptr类会自动销毁此对象。它是通过析构函数来完成销毁工作的。shared_ptr的析构函数会递减它所指向的对象的引用计数。如果引用计数变为0，shared_ptr的析构函数就会销毁对象，并释放它占用的内存。 如果将shared_ptr存放于一个容器中，而后不再需要全部元素，而只使用其中一部分，要记得用erase删除不再使用的那些元素，否则它们占用的内存将无法释放。 使用动态内存的一个常见原因是允许多个对象共享相同的状态。 使用new进行动态内存分配时，不带()的执行默认初始化，值是未定义的，带()的执行值初始化：int *p = new int; //*p的值是未定义的 int *p2 = new int(); //*p2 = 0 std::cout &lt;&lt; *p &lt;&lt; std::endl; //本机输出-842150451 std::cout &lt;&lt; *p2 &lt;&lt; std::endl; //输出0 默认情况下，如果new不能分配所要求的内存空间，它会抛出一个类型为bad_alloc的异常。我们可以改变使用new的方式来阻止它抛出异常：int *p1 = new int; //如果分配失败，new抛出std::bad_alloc异常 int *p2 = new (std::nothrow) int; //如果分配失败，new返回一个空指针，不抛出异常 我们称这种形式的new为定位new。定位new表达式允许我们向new传递额外的参数。这里我们传递的是标准库的一个名为nothrow的对象，告诉它不能抛出异常。bad_alloc和nothrow都定义在头文件new中。 通常情况下，编译器不能分辨一个指针指向的是静态还是动态分配的对象。类似的，编译器也不能分辨一个指针所指向的内存是否已经被释放了。 使用new和delete管理动态内存存在三个问题： 忘记delete内存。忘记释放动态内存会导致人们常说的“内存泄漏”问题，因为这种内存永远不可能被归还给自由空间了。 使用已经释放掉的对象。通过在释放内存后将指针置位空，有时可以检测出这种错误（delete p; p = nullptr）。 同一块内存释放两次。 坚持使用智能指针，就可以避免所有这些问题。对于一块内存，只有在没有任何智能指针指向它的情况下，智能指针才会自动释放它。 接受指针参数的智能指针构造函数时explicit的，我们不能进行内置指针到智能指针之间的隐式转换： std::shared_ptr&lt;int> p1(new int(41)); //正确：使用了直接初始化形式 std::shared_ptr&lt;int> p2 = new int(41); //错误：不能将普通指针隐式转换为智能指针 std::shared_ptr&lt;int> clone(int i) { return new int(i); //错误：不能将普通指针隐式转换为智能指针 } std::shared_ptr&lt;int> clone1(int i) { return std::shared_ptr&lt;int>(new int(i)); //正确，显式创建智能指针 } 定义智能指针时还可以增加一个参数来代替delete，这个参数必须是一个可调用对象：int *p = new int(41); std::shared_ptr&lt;int> p1(p, [](int *vp) {delete vp; std::cout &lt;&lt; "delete" &lt;&lt; std::endl; }); 当智能指针p1离开其作用域时，如果其计数器变为0，将会执行这个可调用的lambda表达式，输出字符串delete。 智能指针还有一个名叫reset的成员函数： p.reset(); ：若p是唯一指向其对象的shared_ptr，reset会释放此对象 p.reset(q);：令p指向指针q p.reset(q, d);：令p指向q，并且调用对象d而不是delete来释放q 不要混合使用普通指针和智能指针： void process(std::shared_ptr&lt;int> vp) { } int *p = new int(41); process(std::shared_ptr&lt;int>(p)); //合法，但函数退出后p指向的内存会被释放，p称为悬空指针 int j = *p; 当将一个shared_ptr绑定到一个普通指针时，我们就将内存的管理责任交给了这个shared_ptr。一旦这样做了，我们就不应该再使用内置指针来问shared_ptr所指向的内存了。 不要用智能指针的get成员函数返回的普通指针，去初始化另一个智能指针：std::shared_ptr&lt;int> p(new int(41)); auto q = p.get(); { std::shared_ptr&lt;int> TempP(q); //逻辑错误：两个独立的shared_ptr指向相同的内存 } int foo = *p; //未定义：p指向的内存已经被释放了 发生异常后，智能指针指向的内存会被正常释放，但是普通指针指向的内存就永远不会被释放了（在delete之前发生异常）： void f() { std::shared_ptr&lt;int> sp(new int(41)); //这段代码发生异常 } //函数结束时，shared_ptr自动释放内存 void f1() { int *p = new int(41); //这段代码发生异常 delete p; } //发生异常后，p指向的内存永远不会被释放 无论是否发生异常，局部对象都会被销毁，所以发生异常后sp会被销毁，但是delete p永远执行不到。这个特性对建立局部网络连接的代码很有用，如果代码是这样的： struct SDestination; struct SConnection; SConnection connect(SDestination*); //打开连接 void disconnect(SConnection); //关闭连接 void f(SDestination &amp;d) { SConnection Conn = connect(&amp;d); //使用连接 //如果我们在f退出前忘记调用disconnect，或者在调用它之前发生了异常，就无法关闭连接Conn了 } 为了保证函数退出时关闭连接，我们可以使用智能指针： struct SDestination; struct SConnection; SConnection connect(SDestination*); //打开连接 void disconnect(SConnection); //关闭连接 void f(SDestination &amp;d) { SConnection Conn = connect(&amp;d); std::shared_ptr&lt;SConnection> p(&amp;Conn, [](SConnection *p) {disconnect(*p); }); //使用连接 //即使我们在f退出前忘记调用disconnect，或者在调用它之前发生了异常，Conn也会被正确关闭 } 即使发生了异常或者忘记调用disconnect，连接也会被正常关闭，因为函数退出时会释放局部对象p，p在被销毁时会调用lambda表达式来关闭连接。 为了正确使用智能指针，我们必须坚持一些规范： 不使用相同的内置指针初始化（或reset）多个智能指针 不delete get()返回的指针 不使用get()返回的指针去初始化或reset另一个智能指针 如果使用get返回的普通指针，记住当最后一个对应的智能指针被销毁后，这个普通指针就失效了 如果使用智能指针管理的资源不是new分配的内存，记住传递给它一个删除器（代替delete的可调用对象） 与shared_ptr不同，某个时刻只能有一个unique_ptr指向一个给定对象。当unique_ptr被销毁时，它所指向的对象也被销毁。而且没有类似make_shader的标准库函数来返回一个unique_ptr。当我们定义一个unique_ptr时，需要将其绑定到一个new返回的指针上或默认初始化，因为它不支持拷贝和赋值操作（独占内存所致）：std::unique_ptr&lt;int> p1; //p1是一个指向int类型的空指针 std::unique_ptr&lt;int> p2(new int(41)); //p2指向一个值为42的int std::unique_ptr&lt;int> p3(p2); //错误：unique_ptr不支持拷贝 p1 = p2; //错误：unique_ptr不支持赋值 虽然不能拷贝或赋值unique_ptr，但可以通过release算法unique_ptr对指针的控制权，然后将其转移给另一个unique_ptr：std::unique_ptr&lt;int> p1(new int(41)); //p2指向一个值为42的int std::unique_ptr&lt;int> p2(p1.release()); //将p1的控制权转移给p2 p1.reset(p2.release()); //将p2的控制权转移给p1 如果我们不用另一个智能指针来保存release返回的普通指针，我们的程序就要负责delete掉该指针。 不能拷贝unique_ptr的规则有一个例外：我们可以拷贝或赋值一个将要被销毁的unique_ptr（因为通常会对它们指向移动拷贝或移动赋值，见13章）：std::unique_ptr&lt;int> clone(int p) { std::unique_ptr&lt;int> sp(new int(p)); return sp; //正确：可以对一个将要被销毁的unique_ptr赋值或拷贝 } 和shared_ptr类似，我们也可以像unique_ptr传递一个自定义的删除器，不同的是，定义时必须显式制定出删除器的模板类型：void deleteFunc(int *p) { delete p; std::cout &lt;&lt; "delete" &lt;&lt; std::endl; } std::unique_ptr&lt;int, decltype(deleteFunc)*> p1(new int(41), deleteFunc); weak_ptr是一种不控制所指向对象生存期的智能指针，它指向由一个shared_ptr管理的对象。将一个weak_ptr绑定到一个shared_ptr不会改变shared_ptr的引用计数。一旦最后一个指向对象的shared_ptr被销毁，对象就会被释放，即使有weak_ptr指向对象，对象也还是会被释放。 当我们创建一个weak_ptr时，要用一个shared_ptr来初始化它： auto sp = std::make_shared&lt;int>(41); std::weak_ptr&lt;int> wp(sp); //wp弱共享sp，sp的引用计数未改变 weak_ptr特有的成员操作如下： w.use_count()：与w共享对象的shared_ptr的数量 w.expired()：若w.use_count()为0，返回true，否则返回false w.lock()：如果expired为true，返回一个空的shared_ptr；否则返回一个指向w的对象的shared_ptr 从上面可以看出weak_ptr所指向的对象可能不存在，所以我们不能使用weak_ptr直接访问对象，而必须调用lock： if (std::shared_ptr&lt;int> vSp = wp.lock()) { //在if中使用vSp访问共享对象是安全的 } 动态数组 标准库包含一个名为allocator的类，允许我们将分配和初始化分离。使用allocator通常会提供更好的性能和更灵活的内存管理能力。 大多数应用应该使用标准库容器而不是动态分配的数组。使用容器更为简单、更不容易出现内存管理错误并且可能有更好的性能。 我们用new分配的动态数组并不是数组类型，所以不能对动态数组调用begin或end： int a[10]; auto it = std::begin(a); //正确：可以对数组类型调用begin函数 int *b = new int[10]; memset(b, 0, 10); auto it2 = std::begin(b); //错误：不能对动态数组调用begin函数 释放动态数组时，需要在delete之后、指针名之前加上一个[ ]： int *b = new int[10]; delete[] b; 动态数组中的元素按逆序销毁，即最后一个元素先被销毁，然后是倒数第二个…。 标准库提供了一个可以管理new分配的数组的unique_ptr版本，需要在模板参数的对象类型后面跟一个方括号： std::unique_ptr&lt;int[]> up(new int[10]); up.release(); //自动调用delete[]销毁其指针 但是如果要使用shared_ptr来管理一个动态数组，必须提供自定义的删除器： std::shared_ptr&lt;int> sp(new int[10], [](int *p) {delete[] p; }); sp.reset(); //使用我们提供的lambda释放数组，它使用delete[] unique_ptr管理的动态数组可以通过下标来访问元素，但是shared_ptr不可以，它没有定义下标运算符。而且智能指针类型不支持指针算术运算。因此shared_ptr为了访问数组中的元素，必须先用get获取一个内置指针，然后用它来访问素组元素： std::unique_ptr&lt;int[]> up(new int[10]); for (size_t i = 0; i &lt; 10; ++i) up[i] = i; std::shared_ptr&lt;int> sp(new int[10], [](int *p) {delete[] p; }); for (size_t i = 0; i &lt; 10; ++i) *(sp.get() + i) = i; 当分配一大块内存时，我们通常计划在这块内存还是那个按需构造对象。在此情况下，我们希望将内存分配和对象构造分离。这意味着我们可以分配大块内存，但只在真正需要时才真正执行对象创建操作。 标准库allocator类定义在头文件memory中，它帮助我们将内存分配和对象构造分离开来。allocator也是一个模板，它会根据给定的对象类型来确定恰当的内存大小和对齐位置： std::allocator&lt;std::string> Alloc; //可以分配string的allocator对象 auto const p = Alloc.allocate(n); //分配n个未初始化的string allocator类的成员操作如下表： 函数 含义 allocator a 定义一个allocator对象，它可以为类型为T的对象分配内存 a.allocate(n) 分配一段原始的、未构造的内存，保存n个类型为T的对象 a.deallocate(p, n) 释放从T*指针p中地址开始的内存，这块内存保存了n个类型为T的对象；p必须是一个先前由allocate返回的指针，且n必须是p创建时所要求的大小。在调用deallocate之前，用户必须对每个在这块内存中创建的对象调用destroy a.construct(p, args) p必须是一个类型为T*的指针，指向一块原始内存；args被传递给类型为T的构造函数，用来在p指向的内存中构造一个对象 a.destroy(p) p为T*类型的指针，此算法对p指向的对象执行析构函数 allocator分配的内存是未构造的，我们需要在此内存中构造对象，而construct成员函数接受一个指针和零个或多个额外参数，在指针所指的位置构造一个元素： auto q = p; Alloc.construct(q++); //*q为空字符串 Alloc.construct(q++, 10, 'c'); //*q为10个字符c组成的字符串 Alloc.construct(q++, "hello"); //*q为字符串hello 还未构造对象的情况下就使用原始内存是错误的： std::allocator&lt;std::string> Alloc; //可以分配string的allocator对象 auto const p = Alloc.allocate(10); //分配n个未初始化的string std::cout &lt;&lt; *p &lt;&lt; std::endl; //错误：程序崩溃，因为p指向未构造的内存 当我们用完对象后，必须对每个构造的元素调用destroy来销毁它们。函数destroy接受一个指针，对指向的对象执行析构函数：while (q != p) Alloc.destroy(--q); 销毁这些被构造出来的元素以后，我们就可以使用deallocate成员函数把内存归还给系统了（当然也可以拿这些内存再去构造新的对象）。所以allocator使用四部曲就是：allocate、construct、destroy、deallocate：std::allocator&lt;std::string> Alloc; //可以分配string的allocator对象 auto const p = Alloc.allocate(10); //分配n个未初始化的string auto q = p; Alloc.construct(q++); //*q为空字符串 Alloc.construct(q++, 10, 'c'); //*q为10个字符c组成的字符串 Alloc.construct(q++, "hello"); //*q为字符串hello while (q != p) Alloc.destroy(--q); //销毁每个构造出来的对象 Alloc.deallocate(p, 10); //第二个参数必须与allocate分配内存时指定的参数相同 标准库还为allocator类定义了两个伴随算法：copy和fill，用于在未初始化内存（原始内存）中创建对象，定义在头文件memory中：std::vector&lt;std::string> SVec{ "Hello","World","Nice" }; std::allocator&lt;std::string> Alloc; auto p = Alloc.allocate(SVec.size() * 2); //通过拷贝SVec中的元素来构造原始内存从p开始的元素 auto q = std::uninitialized_copy(SVec.begin(), SVec.end(), p); //将原始内存中剩余的未构造元素初始化为字符串Same std::uninitialized_fill_n(q, SVec.size(), "Same"); 函数 含义 uninitialized_copy(b, e, b2) 将迭代器b到e范围内的元素拷贝到迭代器b2指向的未构造的原始内存中 uninitialized_copy_n(b, n, b2) 从迭代器b指向的元素开始，拷贝n个元素到b2指向的原始内存中 uninitialized_fill(b, e, t) 在迭代器b到e的元素内存范围内构造对象，对象的值均为t的拷贝 uninitialized_fill_n(b, n, t) 从迭代器b指向的元素内存开始创建n个对象，对象的值均为t的拷贝 使用标准库：文本查询程序 -_-||，最近比较忙，比较忙。。。有时间再来补上了(*￣︶￣) 概述 静态内存用来保存局部static对象、类static数据成员以及定义在任何函数之外的变量。栈内存用来保存定义在函数内的非static对象。分配在静态或栈内存中的对象由编译器自动创建和销毁。对于栈对象，仅在其定义的程序块运行时才存在；static对象在使用之前分配，在程序结束时销毁。 除了静态内存和栈内存，每个程序还拥有一个内存池。这部分内存被称作自由空间或堆。程序用堆来存储动态分配的对象，即那些在程序运行时分配的对象。动态对象的生存期由程序来控制，也就是说，当动态对象不再使用时，我们的代码必须显式地销毁它们。 动态内存与智能指针 为了更容易、更安全地使用动态内存，新标准库提供了三种智能指针类型来管理动态对象：shared_ptr和unique_ptr。它们和普通指针的重要区别是它们负责自动释放所指向的对象。shared_ptr允许多个指针指向同一个对象；unique_ptr则独占所指向的对象。 标准库还定义了一个名为weak_ptr的伴随类，它是一种弱引用，指向shared_ptr所管理的对象。 shared_ptr、unique_ptr和weak_ptr都定义在头文件memory中。 智能指针其实是在普通指针上作了一些包装，包括自动释放内存、指向同一对象的指针指针数量（用智能指针类中的计数器保存）等等。 智能指针也是模板类，默认初始化的智能指针中保存着一个空指针： std::shared_ptr&lt;std::string> p1; //shared_ptr，可以指向string对象，现在还是空指针 使用智能指针的get成员函数可以获得对应的普通指针： std::shared_ptr&lt;std::string> p1; auto p = p1.get(); //p是string*类型 shared_ptr独有的操作如下表： 函数 含义 make_shared(args) 返回一个shared_ptr，指向一个动态分配的类型为T的对象，使用args初始化该对象 shared_ptrp(q) p是shared_ptr q的拷贝，此操作会递增q中的计算器。q中的指针必须能转换为T* p=q p和q都是shared_ptr，所保存的指针必须能相互转换。此操作会递减p的引用计数，递增q的引用计数；若p的引用计数变为0，则将其管理的原内存释放 p.unique() 若p.use_count()为1，返回true，否则返回false p,use_count() 返回一个与p共享对象的智能指针数量；可能很慢，主要用于测试 我们可以用make_shared函数代替new来生成一个指针，这样更安全，同时不需要匹配的delete操作，因为智能指针在计算器变为0时会自动调用delete： std::shared_ptr&lt;std::string> p1 = std::make_shared&lt;std::string>("Hello"); 当然用auto来保存make_shared的结果更简单： auto p1 = std::make_shared&lt;std::string>("Hello"); 每个shared_ptr都有一个关联的计数器，通常称其为引用计数。无论何时我们拷贝一个shared_ptr，计数器都会增加，当我们给shared_ptr赋予一个新值或是shared_ptr被销毁（例如局部shared_ptr离开其作用域）时，计数器就会递减。一旦一个shared_ptr的计数器变为0，它就会自动释放自己所管理的对象。 当指向一个对象的最后一个shared_ptr被销毁时，shared_ptr类会自动销毁此对象。它是通过析构函数来完成销毁工作的。shared_ptr的析构函数会递减它所指向的对象的引用计数。如果引用计数变为0，shared_ptr的析构函数就会销毁对象，并释放它占用的内存。 如果将shared_ptr存放于一个容器中，而后不再需要全部元素，而只使用其中一部分，要记得用erase删除不再使用的那些元素，否则它们占用的内存将无法释放。 使用动态内存的一个常见原因是允许多个对象共享相同的状态。 使用new进行动态内存分配时，不带()的执行默认初始化，值是未定义的，带()的执行值初始化：int *p = new int; //*p的值是未定义的 int *p2 = new int(); //*p2 = 0 std::cout &lt;&lt; *p &lt;&lt; std::endl; //本机输出-842150451 std::cout &lt;&lt; *p2 &lt;&lt; std::endl; //输出0 默认情况下，如果new不能分配所要求的内存空间，它会抛出一个类型为bad_alloc的异常。我们可以改变使用new的方式来阻止它抛出异常：int *p1 = new int; //如果分配失败，new抛出std::bad_alloc异常 int *p2 = new (std::nothrow) int; //如果分配失败，new返回一个空指针，不抛出异常 我们称这种形式的new为定位new。定位new表达式允许我们向new传递额外的参数。这里我们传递的是标准库的一个名为nothrow的对象，告诉它不能抛出异常。bad_alloc和nothrow都定义在头文件new中。 通常情况下，编译器不能分辨一个指针指向的是静态还是动态分配的对象。类似的，编译器也不能分辨一个指针所指向的内存是否已经被释放了。 使用new和delete管理动态内存存在三个问题： 忘记delete内存。忘记释放动态内存会导致人们常说的“内存泄漏”问题，因为这种内存永远不可能被归还给自由空间了。 使用已经释放掉的对象。通过在释放内存后将指针置位空，有时可以检测出这种错误（delete p; p = nullptr）。 同一块内存释放两次。 坚持使用智能指针，就可以避免所有这些问题。对于一块内存，只有在没有任何智能指针指向它的情况下，智能指针才会自动释放它。 接受指针参数的智能指针构造函数时explicit的，我们不能进行内置指针到智能指针之间的隐式转换： std::shared_ptr&lt;int> p1(new int(41)); //正确：使用了直接初始化形式 std::shared_ptr&lt;int> p2 = new int(41); //错误：不能将普通指针隐式转换为智能指针 std::shared_ptr&lt;int> clone(int i) { return new int(i); //错误：不能将普通指针隐式转换为智能指针 } std::shared_ptr&lt;int> clone1(int i) { return std::shared_ptr&lt;int>(new int(i)); //正确，显式创建智能指针 } 定义智能指针时还可以增加一个参数来代替delete，这个参数必须是一个可调用对象：int *p = new int(41); std::shared_ptr&lt;int> p1(p, [](int *vp) {delete vp; std::cout &lt;&lt; "delete" &lt;&lt; std::endl; }); 当智能指针p1离开其作用域时，如果其计数器变为0，将会执行这个可调用的lambda表达式，输出字符串delete。 智能指针还有一个名叫reset的成员函数： p.reset(); ：若p是唯一指向其对象的shared_ptr，reset会释放此对象 p.reset(q);：令p指向指针q p.reset(q, d);：令p指向q，并且调用对象d而不是delete来释放q 不要混合使用普通指针和智能指针： void process(std::shared_ptr&lt;int> vp) { } int *p = new int(41); process(std::shared_ptr&lt;int>(p)); //合法，但函数退出后p指向的内存会被释放，p称为悬空指针 int j = *p; 当将一个shared_ptr绑定到一个普通指针时，我们就将内存的管理责任交给了这个shared_ptr。一旦这样做了，我们就不应该再使用内置指针来问shared_ptr所指向的内存了。 不要用智能指针的get成员函数返回的普通指针，去初始化另一个智能指针：std::shared_ptr&lt;int> p(new int(41)); auto q = p.get(); { std::shared_ptr&lt;int> TempP(q); //逻辑错误：两个独立的shared_ptr指向相同的内存 } int foo = *p; //未定义：p指向的内存已经被释放了 发生异常后，智能指针指向的内存会被正常释放，但是普通指针指向的内存就永远不会被释放了（在delete之前发生异常）： void f() { std::shared_ptr&lt;int> sp(new int(41)); //这段代码发生异常 } //函数结束时，shared_ptr自动释放内存 void f1() { int *p = new int(41); //这段代码发生异常 delete p; } //发生异常后，p指向的内存永远不会被释放 无论是否发生异常，局部对象都会被销毁，所以发生异常后sp会被销毁，但是delete p永远执行不到。这个特性对建立局部网络连接的代码很有用，如果代码是这样的： struct SDestination; struct SConnection; SConnection connect(SDestination*); //打开连接 void disconnect(SConnection); //关闭连接 void f(SDestination &amp;d) { SConnection Conn = connect(&amp;d); //使用连接 //如果我们在f退出前忘记调用disconnect，或者在调用它之前发生了异常，就无法关闭连接Conn了 } 为了保证函数退出时关闭连接，我们可以使用智能指针： struct SDestination; struct SConnection; SConnection connect(SDestination*); //打开连接 void disconnect(SConnection); //关闭连接 void f(SDestination &amp;d) { SConnection Conn = connect(&amp;d); std::shared_ptr&lt;SConnection> p(&amp;Conn, [](SConnection *p) {disconnect(*p); }); //使用连接 //即使我们在f退出前忘记调用disconnect，或者在调用它之前发生了异常，Conn也会被正确关闭 } 即使发生了异常或者忘记调用disconnect，连接也会被正常关闭，因为函数退出时会释放局部对象p，p在被销毁时会调用lambda表达式来关闭连接。 为了正确使用智能指针，我们必须坚持一些规范： 不使用相同的内置指针初始化（或reset）多个智能指针 不delete get()返回的指针 不使用get()返回的指针去初始化或reset另一个智能指针 如果使用get返回的普通指针，记住当最后一个对应的智能指针被销毁后，这个普通指针就失效了 如果使用智能指针管理的资源不是new分配的内存，记住传递给它一个删除器（代替delete的可调用对象） 与shared_ptr不同，某个时刻只能有一个unique_ptr指向一个给定对象。当unique_ptr被销毁时，它所指向的对象也被销毁。而且没有类似make_shader的标准库函数来返回一个unique_ptr。当我们定义一个unique_ptr时，需要将其绑定到一个new返回的指针上或默认初始化，因为它不支持拷贝和赋值操作（独占内存所致）：std::unique_ptr&lt;int> p1; //p1是一个指向int类型的空指针 std::unique_ptr&lt;int> p2(new int(41)); //p2指向一个值为42的int std::unique_ptr&lt;int> p3(p2); //错误：unique_ptr不支持拷贝 p1 = p2; //错误：unique_ptr不支持赋值 虽然不能拷贝或赋值unique_ptr，但可以通过release算法unique_ptr对指针的控制权，然后将其转移给另一个unique_ptr：std::unique_ptr&lt;int> p1(new int(41)); //p2指向一个值为42的int std::unique_ptr&lt;int> p2(p1.release()); //将p1的控制权转移给p2 p1.reset(p2.release()); //将p2的控制权转移给p1 如果我们不用另一个智能指针来保存release返回的普通指针，我们的程序就要负责delete掉该指针。 不能拷贝unique_ptr的规则有一个例外：我们可以拷贝或赋值一个将要被销毁的unique_ptr（因为通常会对它们指向移动拷贝或移动赋值，见13章）：std::unique_ptr&lt;int> clone(int p) { std::unique_ptr&lt;int> sp(new int(p)); return sp; //正确：可以对一个将要被销毁的unique_ptr赋值或拷贝 } 和shared_ptr类似，我们也可以像unique_ptr传递一个自定义的删除器，不同的是，定义时必须显式制定出删除器的模板类型：void deleteFunc(int *p) { delete p; std::cout &lt;&lt; "delete" &lt;&lt; std::endl; } std::unique_ptr&lt;int, decltype(deleteFunc)*> p1(new int(41), deleteFunc); weak_ptr是一种不控制所指向对象生存期的智能指针，它指向由一个shared_ptr管理的对象。将一个weak_ptr绑定到一个shared_ptr不会改变shared_ptr的引用计数。一旦最后一个指向对象的shared_ptr被销毁，对象就会被释放，即使有weak_ptr指向对象，对象也还是会被释放。 当我们创建一个weak_ptr时，要用一个shared_ptr来初始化它： auto sp = std::make_shared&lt;int>(41); std::weak_ptr&lt;int> wp(sp); //wp弱共享sp，sp的引用计数未改变 weak_ptr特有的成员操作如下： w.use_count()：与w共享对象的shared_ptr的数量 w.expired()：若w.use_count()为0，返回true，否则返回false w.lock()：如果expired为true，返回一个空的shared_ptr；否则返回一个指向w的对象的shared_ptr 从上面可以看出weak_ptr所指向的对象可能不存在，所以我们不能使用weak_ptr直接访问对象，而必须调用lock： if (std::shared_ptr&lt;int> vSp = wp.lock()) { //在if中使用vSp访问共享对象是安全的 } 动态数组 标准库包含一个名为allocator的类，允许我们将分配和初始化分离。使用allocator通常会提供更好的性能和更灵活的内存管理能力。 大多数应用应该使用标准库容器而不是动态分配的数组。使用容器更为简单、更不容易出现内存管理错误并且可能有更好的性能。 我们用new分配的动态数组并不是数组类型，所以不能对动态数组调用begin或end： int a[10]; auto it = std::begin(a); //正确：可以对数组类型调用begin函数 int *b = new int[10]; memset(b, 0, 10); auto it2 = std::begin(b); //错误：不能对动态数组调用begin函数 释放动态数组时，需要在delete之后、指针名之前加上一个[ ]： int *b = new int[10]; delete[] b; 动态数组中的元素按逆序销毁，即最后一个元素先被销毁，然后是倒数第二个…。 标准库提供了一个可以管理new分配的数组的unique_ptr版本，需要在模板参数的对象类型后面跟一个方括号： std::unique_ptr&lt;int[]> up(new int[10]); up.release(); //自动调用delete[]销毁其指针 但是如果要使用shared_ptr来管理一个动态数组，必须提供自定义的删除器： std::shared_ptr&lt;int> sp(new int[10], [](int *p) {delete[] p; }); sp.reset(); //使用我们提供的lambda释放数组，它使用delete[] unique_ptr管理的动态数组可以通过下标来访问元素，但是shared_ptr不可以，它没有定义下标运算符。而且智能指针类型不支持指针算术运算。因此shared_ptr为了访问数组中的元素，必须先用get获取一个内置指针，然后用它来访问素组元素： std::unique_ptr&lt;int[]> up(new int[10]); for (size_t i = 0; i &lt; 10; ++i) up[i] = i; std::shared_ptr&lt;int> sp(new int[10], [](int *p) {delete[] p; }); for (size_t i = 0; i &lt; 10; ++i) *(sp.get() + i) = i; 当分配一大块内存时，我们通常计划在这块内存还是那个按需构造对象。在此情况下，我们希望将内存分配和对象构造分离。这意味着我们可以分配大块内存，但只在真正需要时才真正执行对象创建操作。 标准库allocator类定义在头文件memory中，它帮助我们将内存分配和对象构造分离开来。allocator也是一个模板，它会根据给定的对象类型来确定恰当的内存大小和对齐位置： std::allocator&lt;std::string> Alloc; //可以分配string的allocator对象 auto const p = Alloc.allocate(n); //分配n个未初始化的string allocator类的成员操作如下表： 函数 含义 allocator a 定义一个allocator对象，它可以为类型为T的对象分配内存 a.allocate(n) 分配一段原始的、未构造的内存，保存n个类型为T的对象 a.deallocate(p, n) 释放从T*指针p中地址开始的内存，这块内存保存了n个类型为T的对象；p必须是一个先前由allocate返回的指针，且n必须是p创建时所要求的大小。在调用deallocate之前，用户必须对每个在这块内存中创建的对象调用destroy a.construct(p, args) p必须是一个类型为T*的指针，指向一块原始内存；args被传递给类型为T的构造函数，用来在p指向的内存中构造一个对象 a.destroy(p) p为T*类型的指针，此算法对p指向的对象执行析构函数 allocator分配的内存是未构造的，我们需要在此内存中构造对象，而construct成员函数接受一个指针和零个或多个额外参数，在指针所指的位置构造一个元素： auto q = p; Alloc.construct(q++); //*q为空字符串 Alloc.construct(q++, 10, 'c'); //*q为10个字符c组成的字符串 Alloc.construct(q++, "hello"); //*q为字符串hello 还未构造对象的情况下就使用原始内存是错误的： std::allocator&lt;std::string> Alloc; //可以分配string的allocator对象 auto const p = Alloc.allocate(10); //分配n个未初始化的string std::cout &lt;&lt; *p &lt;&lt; std::endl; //错误：程序崩溃，因为p指向未构造的内存 当我们用完对象后，必须对每个构造的元素调用destroy来销毁它们。函数destroy接受一个指针，对指向的对象执行析构函数：while (q != p) Alloc.destroy(--q); 销毁这些被构造出来的元素以后，我们就可以使用deallocate成员函数把内存归还给系统了（当然也可以拿这些内存再去构造新的对象）。所以allocator使用四部曲就是：allocate、construct、destroy、deallocate：std::allocator&lt;std::string> Alloc; //可以分配string的allocator对象 auto const p = Alloc.allocate(10); //分配n个未初始化的string auto q = p; Alloc.construct(q++); //*q为空字符串 Alloc.construct(q++, 10, 'c'); //*q为10个字符c组成的字符串 Alloc.construct(q++, "hello"); //*q为字符串hello while (q != p) Alloc.destroy(--q); //销毁每个构造出来的对象 Alloc.deallocate(p, 10); //第二个参数必须与allocate分配内存时指定的参数相同 标准库还为allocator类定义了两个伴随算法：copy和fill，用于在未初始化内存（原始内存）中创建对象，定义在头文件memory中：std::vector&lt;std::string> SVec{ "Hello","World","Nice" }; std::allocator&lt;std::string> Alloc; auto p = Alloc.allocate(SVec.size() * 2); //通过拷贝SVec中的元素来构造原始内存从p开始的元素 auto q = std::uninitialized_copy(SVec.begin(), SVec.end(), p); //将原始内存中剩余的未构造元素初始化为字符串Same std::uninitialized_fill_n(q, SVec.size(), "Same"); 函数 含义 uninitialized_copy(b, e, b2) 将迭代器b到e范围内的元素拷贝到迭代器b2指向的未构造的原始内存中 uninitialized_copy_n(b, n, b2) 从迭代器b指向的元素开始，拷贝n个元素到b2指向的原始内存中 uninitialized_fill(b, e, t) 在迭代器b到e的元素内存范围内构造对象，对象的值均为t的拷贝 uninitialized_fill_n(b, n, t) 从迭代器b指向的元素内存开始创建n个对象，对象的值均为t的拷贝 使用标准库：文本查询程序 -_-||，最近比较忙，比较忙。。。有时间再来补上了(*￣︶￣) 概述 静态内存用来保存局部static对象、类static数据成员以及定义在任何函数之外的变量。栈内存用来保存定义在函数内的非static对象。分配在静态或栈内存中的对象由编译器自动创建和销毁。对于栈对象，仅在其定义的程序块运行时才存在；static对象在使用之前分配，在程序结束时销毁。 除了静态内存和栈内存，每个程序还拥有一个内存池。这部分内存被称作自由空间或堆。程序用堆来存储动态分配的对象，即那些在程序运行时分配的对象。动态对象的生存期由程序来控制，也就是说，当动态对象不再使用时，我们的代码必须显式地销毁它们。 动态内存与智能指针 为了更容易、更安全地使用动态内存，新标准库提供了三种智能指针类型来管理动态对象：shared_ptr和unique_ptr。它们和普通指针的重要区别是它们负责自动释放所指向的对象。shared_ptr允许多个指针指向同一个对象；unique_ptr则独占所指向的对象。 标准库还定义了一个名为weak_ptr的伴随类，它是一种弱引用，指向shared_ptr所管理的对象。 shared_ptr、unique_ptr和weak_ptr都定义在头文件memory中。 智能指针其实是在普通指针上作了一些包装，包括自动释放内存、指向同一对象的指针指针数量（用智能指针类中的计数器保存）等等。 智能指针也是模板类，默认初始化的智能指针中保存着一个空指针： std::shared_ptr&lt;std::string> p1; //shared_ptr，可以指向string对象，现在还是空指针 使用智能指针的get成员函数可以获得对应的普通指针： std::shared_ptr&lt;std::string> p1; auto p = p1.get(); //p是string*类型 shared_ptr独有的操作如下表： 函数 含义 make_shared(args) 返回一个shared_ptr，指向一个动态分配的类型为T的对象，使用args初始化该对象 shared_ptrp(q) p是shared_ptr q的拷贝，此操作会递增q中的计算器。q中的指针必须能转换为T* p=q p和q都是shared_ptr，所保存的指针必须能相互转换。此操作会递减p的引用计数，递增q的引用计数；若p的引用计数变为0，则将其管理的原内存释放 p.unique() 若p.use_count()为1，返回true，否则返回false p,use_count() 返回一个与p共享对象的智能指针数量；可能很慢，主要用于测试 我们可以用make_shared函数代替new来生成一个指针，这样更安全，同时不需要匹配的delete操作，因为智能指针在计算器变为0时会自动调用delete： std::shared_ptr&lt;std::string> p1 = std::make_shared&lt;std::string>("Hello"); 当然用auto来保存make_shared的结果更简单： auto p1 = std::make_shared&lt;std::string>("Hello"); 每个shared_ptr都有一个关联的计数器，通常称其为引用计数。无论何时我们拷贝一个shared_ptr，计数器都会增加，当我们给shared_ptr赋予一个新值或是shared_ptr被销毁（例如局部shared_ptr离开其作用域）时，计数器就会递减。一旦一个shared_ptr的计数器变为0，它就会自动释放自己所管理的对象。 当指向一个对象的最后一个shared_ptr被销毁时，shared_ptr类会自动销毁此对象。它是通过析构函数来完成销毁工作的。shared_ptr的析构函数会递减它所指向的对象的引用计数。如果引用计数变为0，shared_ptr的析构函数就会销毁对象，并释放它占用的内存。 如果将shared_ptr存放于一个容器中，而后不再需要全部元素，而只使用其中一部分，要记得用erase删除不再使用的那些元素，否则它们占用的内存将无法释放。 使用动态内存的一个常见原因是允许多个对象共享相同的状态。 使用new进行动态内存分配时，不带()的执行默认初始化，值是未定义的，带()的执行值初始化：int *p = new int; //*p的值是未定义的 int *p2 = new int(); //*p2 = 0 std::cout &lt;&lt; *p &lt;&lt; std::endl; //本机输出-842150451 std::cout &lt;&lt; *p2 &lt;&lt; std::endl; //输出0 默认情况下，如果new不能分配所要求的内存空间，它会抛出一个类型为bad_alloc的异常。我们可以改变使用new的方式来阻止它抛出异常：int *p1 = new int; //如果分配失败，new抛出std::bad_alloc异常 int *p2 = new (std::nothrow) int; //如果分配失败，new返回一个空指针，不抛出异常 我们称这种形式的new为定位new。定位new表达式允许我们向new传递额外的参数。这里我们传递的是标准库的一个名为nothrow的对象，告诉它不能抛出异常。bad_alloc和nothrow都定义在头文件new中。 通常情况下，编译器不能分辨一个指针指向的是静态还是动态分配的对象。类似的，编译器也不能分辨一个指针所指向的内存是否已经被释放了。 使用new和delete管理动态内存存在三个问题： 忘记delete内存。忘记释放动态内存会导致人们常说的“内存泄漏”问题，因为这种内存永远不可能被归还给自由空间了。 使用已经释放掉的对象。通过在释放内存后将指针置位空，有时可以检测出这种错误（delete p; p = nullptr）。 同一块内存释放两次。 坚持使用智能指针，就可以避免所有这些问题。对于一块内存，只有在没有任何智能指针指向它的情况下，智能指针才会自动释放它。 接受指针参数的智能指针构造函数时explicit的，我们不能进行内置指针到智能指针之间的隐式转换： std::shared_ptr&lt;int> p1(new int(41)); //正确：使用了直接初始化形式 std::shared_ptr&lt;int> p2 = new int(41); //错误：不能将普通指针隐式转换为智能指针 std::shared_ptr&lt;int> clone(int i) { return new int(i); //错误：不能将普通指针隐式转换为智能指针 } std::shared_ptr&lt;int> clone1(int i) { return std::shared_ptr&lt;int>(new int(i)); //正确，显式创建智能指针 } 定义智能指针时还可以增加一个参数来代替delete，这个参数必须是一个可调用对象：int *p = new int(41); std::shared_ptr&lt;int> p1(p, [](int *vp) {delete vp; std::cout &lt;&lt; "delete" &lt;&lt; std::endl; }); 当智能指针p1离开其作用域时，如果其计数器变为0，将会执行这个可调用的lambda表达式，输出字符串delete。 智能指针还有一个名叫reset的成员函数： p.reset(); ：若p是唯一指向其对象的shared_ptr，reset会释放此对象 p.reset(q);：令p指向指针q p.reset(q, d);：令p指向q，并且调用对象d而不是delete来释放q 不要混合使用普通指针和智能指针： void process(std::shared_ptr&lt;int> vp) { } int *p = new int(41); process(std::shared_ptr&lt;int>(p)); //合法，但函数退出后p指向的内存会被释放，p称为悬空指针 int j = *p; 当将一个shared_ptr绑定到一个普通指针时，我们就将内存的管理责任交给了这个shared_ptr。一旦这样做了，我们就不应该再使用内置指针来问shared_ptr所指向的内存了。 不要用智能指针的get成员函数返回的普通指针，去初始化另一个智能指针：std::shared_ptr&lt;int> p(new int(41)); auto q = p.get(); { std::shared_ptr&lt;int> TempP(q); //逻辑错误：两个独立的shared_ptr指向相同的内存 } int foo = *p; //未定义：p指向的内存已经被释放了 发生异常后，智能指针指向的内存会被正常释放，但是普通指针指向的内存就永远不会被释放了（在delete之前发生异常）： void f() { std::shared_ptr&lt;int> sp(new int(41)); //这段代码发生异常 } //函数结束时，shared_ptr自动释放内存 void f1() { int *p = new int(41); //这段代码发生异常 delete p; } //发生异常后，p指向的内存永远不会被释放 无论是否发生异常，局部对象都会被销毁，所以发生异常后sp会被销毁，但是delete p永远执行不到。这个特性对建立局部网络连接的代码很有用，如果代码是这样的： struct SDestination; struct SConnection; SConnection connect(SDestination*); //打开连接 void disconnect(SConnection); //关闭连接 void f(SDestination &amp;d) { SConnection Conn = connect(&amp;d); //使用连接 //如果我们在f退出前忘记调用disconnect，或者在调用它之前发生了异常，就无法关闭连接Conn了 } 为了保证函数退出时关闭连接，我们可以使用智能指针： struct SDestination; struct SConnection; SConnection connect(SDestination*); //打开连接 void disconnect(SConnection); //关闭连接 void f(SDestination &amp;d) { SConnection Conn = connect(&amp;d); std::shared_ptr&lt;SConnection> p(&amp;Conn, [](SConnection *p) {disconnect(*p); }); //使用连接 //即使我们在f退出前忘记调用disconnect，或者在调用它之前发生了异常，Conn也会被正确关闭 } 即使发生了异常或者忘记调用disconnect，连接也会被正常关闭，因为函数退出时会释放局部对象p，p在被销毁时会调用lambda表达式来关闭连接。 为了正确使用智能指针，我们必须坚持一些规范： 不使用相同的内置指针初始化（或reset）多个智能指针 不delete get()返回的指针 不使用get()返回的指针去初始化或reset另一个智能指针 如果使用get返回的普通指针，记住当最后一个对应的智能指针被销毁后，这个普通指针就失效了 如果使用智能指针管理的资源不是new分配的内存，记住传递给它一个删除器（代替delete的可调用对象） 与shared_ptr不同，某个时刻只能有一个unique_ptr指向一个给定对象。当unique_ptr被销毁时，它所指向的对象也被销毁。而且没有类似make_shader的标准库函数来返回一个unique_ptr。当我们定义一个unique_ptr时，需要将其绑定到一个new返回的指针上或默认初始化，因为它不支持拷贝和赋值操作（独占内存所致）：std::unique_ptr&lt;int> p1; //p1是一个指向int类型的空指针 std::unique_ptr&lt;int> p2(new int(41)); //p2指向一个值为42的int std::unique_ptr&lt;int> p3(p2); //错误：unique_ptr不支持拷贝 p1 = p2; //错误：unique_ptr不支持赋值 虽然不能拷贝或赋值unique_ptr，但可以通过release算法unique_ptr对指针的控制权，然后将其转移给另一个unique_ptr：std::unique_ptr&lt;int> p1(new int(41)); //p2指向一个值为42的int std::unique_ptr&lt;int> p2(p1.release()); //将p1的控制权转移给p2 p1.reset(p2.release()); //将p2的控制权转移给p1 如果我们不用另一个智能指针来保存release返回的普通指针，我们的程序就要负责delete掉该指针。 不能拷贝unique_ptr的规则有一个例外：我们可以拷贝或赋值一个将要被销毁的unique_ptr（因为通常会对它们指向移动拷贝或移动赋值，见13章）：std::unique_ptr&lt;int> clone(int p) { std::unique_ptr&lt;int> sp(new int(p)); return sp; //正确：可以对一个将要被销毁的unique_ptr赋值或拷贝 } 和shared_ptr类似，我们也可以像unique_ptr传递一个自定义的删除器，不同的是，定义时必须显式制定出删除器的模板类型：void deleteFunc(int *p) { delete p; std::cout &lt;&lt; "delete" &lt;&lt; std::endl; } std::unique_ptr&lt;int, decltype(deleteFunc)*> p1(new int(41), deleteFunc); weak_ptr是一种不控制所指向对象生存期的智能指针，它指向由一个shared_ptr管理的对象。将一个weak_ptr绑定到一个shared_ptr不会改变shared_ptr的引用计数。一旦最后一个指向对象的shared_ptr被销毁，对象就会被释放，即使有weak_ptr指向对象，对象也还是会被释放。 当我们创建一个weak_ptr时，要用一个shared_ptr来初始化它： auto sp = std::make_shared&lt;int>(41); std::weak_ptr&lt;int> wp(sp); //wp弱共享sp，sp的引用计数未改变 weak_ptr特有的成员操作如下： w.use_count()：与w共享对象的shared_ptr的数量 w.expired()：若w.use_count()为0，返回true，否则返回false w.lock()：如果expired为true，返回一个空的shared_ptr；否则返回一个指向w的对象的shared_ptr 从上面可以看出weak_ptr所指向的对象可能不存在，所以我们不能使用weak_ptr直接访问对象，而必须调用lock： if (std::shared_ptr&lt;int> vSp = wp.lock()) { //在if中使用vSp访问共享对象是安全的 } 动态数组 标准库包含一个名为allocator的类，允许我们将分配和初始化分离。使用allocator通常会提供更好的性能和更灵活的内存管理能力。 大多数应用应该使用标准库容器而不是动态分配的数组。使用容器更为简单、更不容易出现内存管理错误并且可能有更好的性能。 我们用new分配的动态数组并不是数组类型，所以不能对动态数组调用begin或end： int a[10]; auto it = std::begin(a); //正确：可以对数组类型调用begin函数 int *b = new int[10]; memset(b, 0, 10); auto it2 = std::begin(b); //错误：不能对动态数组调用begin函数 释放动态数组时，需要在delete之后、指针名之前加上一个[ ]： int *b = new int[10]; delete[] b; 动态数组中的元素按逆序销毁，即最后一个元素先被销毁，然后是倒数第二个…。 标准库提供了一个可以管理new分配的数组的unique_ptr版本，需要在模板参数的对象类型后面跟一个方括号： std::unique_ptr&lt;int[]> up(new int[10]); up.release(); //自动调用delete[]销毁其指针 但是如果要使用shared_ptr来管理一个动态数组，必须提供自定义的删除器： std::shared_ptr&lt;int> sp(new int[10], [](int *p) {delete[] p; }); sp.reset(); //使用我们提供的lambda释放数组，它使用delete[] unique_ptr管理的动态数组可以通过下标来访问元素，但是shared_ptr不可以，它没有定义下标运算符。而且智能指针类型不支持指针算术运算。因此shared_ptr为了访问数组中的元素，必须先用get获取一个内置指针，然后用它来访问素组元素： std::unique_ptr&lt;int[]> up(new int[10]); for (size_t i = 0; i &lt; 10; ++i) up[i] = i; std::shared_ptr&lt;int> sp(new int[10], [](int *p) {delete[] p; }); for (size_t i = 0; i &lt; 10; ++i) *(sp.get() + i) = i; 当分配一大块内存时，我们通常计划在这块内存还是那个按需构造对象。在此情况下，我们希望将内存分配和对象构造分离。这意味着我们可以分配大块内存，但只在真正需要时才真正执行对象创建操作。 标准库allocator类定义在头文件memory中，它帮助我们将内存分配和对象构造分离开来。allocator也是一个模板，它会根据给定的对象类型来确定恰当的内存大小和对齐位置： std::allocator&lt;std::string> Alloc; //可以分配string的allocator对象 auto const p = Alloc.allocate(n); //分配n个未初始化的string allocator类的成员操作如下表： 函数 含义 allocator a 定义一个allocator对象，它可以为类型为T的对象分配内存 a.allocate(n) 分配一段原始的、未构造的内存，保存n个类型为T的对象 a.deallocate(p, n) 释放从T*指针p中地址开始的内存，这块内存保存了n个类型为T的对象；p必须是一个先前由allocate返回的指针，且n必须是p创建时所要求的大小。在调用deallocate之前，用户必须对每个在这块内存中创建的对象调用destroy a.construct(p, args) p必须是一个类型为T*的指针，指向一块原始内存；args被传递给类型为T的构造函数，用来在p指向的内存中构造一个对象 a.destroy(p) p为T*类型的指针，此算法对p指向的对象执行析构函数 allocator分配的内存是未构造的，我们需要在此内存中构造对象，而construct成员函数接受一个指针和零个或多个额外参数，在指针所指的位置构造一个元素： auto q = p; Alloc.construct(q++); //*q为空字符串 Alloc.construct(q++, 10, 'c'); //*q为10个字符c组成的字符串 Alloc.construct(q++, "hello"); //*q为字符串hello 还未构造对象的情况下就使用原始内存是错误的： std::allocator&lt;std::string> Alloc; //可以分配string的allocator对象 auto const p = Alloc.allocate(10); //分配n个未初始化的string std::cout &lt;&lt; *p &lt;&lt; std::endl; //错误：程序崩溃，因为p指向未构造的内存 当我们用完对象后，必须对每个构造的元素调用destroy来销毁它们。函数destroy接受一个指针，对指向的对象执行析构函数：while (q != p) Alloc.destroy(--q); 销毁这些被构造出来的元素以后，我们就可以使用deallocate成员函数把内存归还给系统了（当然也可以拿这些内存再去构造新的对象）。所以allocator使用四部曲就是：allocate、construct、destroy、deallocate：std::allocator&lt;std::string> Alloc; //可以分配string的allocator对象 auto const p = Alloc.allocate(10); //分配n个未初始化的string auto q = p; Alloc.construct(q++); //*q为空字符串 Alloc.construct(q++, 10, 'c'); //*q为10个字符c组成的字符串 Alloc.construct(q++, "hello"); //*q为字符串hello while (q != p) Alloc.destroy(--q); //销毁每个构造出来的对象 Alloc.deallocate(p, 10); //第二个参数必须与allocate分配内存时指定的参数相同 标准库还为allocator类定义了两个伴随算法：copy和fill，用于在未初始化内存（原始内存）中创建对象，定义在头文件memory中：std::vector&lt;std::string> SVec{ "Hello","World","Nice" }; std::allocator&lt;std::string> Alloc; auto p = Alloc.allocate(SVec.size() * 2); //通过拷贝SVec中的元素来构造原始内存从p开始的元素 auto q = std::uninitialized_copy(SVec.begin(), SVec.end(), p); //将原始内存中剩余的未构造元素初始化为字符串Same std::uninitialized_fill_n(q, SVec.size(), "Same"); 函数 含义 uninitialized_copy(b, e, b2) 将迭代器b到e范围内的元素拷贝到迭代器b2指向的未构造的原始内存中 uninitialized_copy_n(b, n, b2) 从迭代器b指向的元素开始，拷贝n个元素到b2指向的原始内存中 uninitialized_fill(b, e, t) 在迭代器b到e的元素内存范围内构造对象，对象的值均为t的拷贝 uninitialized_fill_n(b, n, t) 从迭代器b指向的元素内存开始创建n个对象，对象的值均为t的拷贝 使用标准库：文本查询程序 -_-||，最近比较忙，比较忙。。。有时间再来补上了(*￣︶￣) &nbsp; 参考文献：《C++Primer第五版》]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++Primer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++Primer第十一章 关联容器]]></title>
    <url>%2F2018%2F03%2F05%2FC%2B%2BPrimer%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0%E5%85%B3%E8%81%94%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[概述 关联容器支持高效的关键字查找和访问。两个主要的关联容器是map和set。map是键值对集合，而set只是关键字集合，set支持高效的关键字查询工作：检查一个给定关键字是否存在set中。 允许重复关键字的关联容器的名字中都包含单词multi；不保持关键字按顺序存储的容器的名字都以单词unordered开头。 类型map和multimap定义在头文件map中，set和multiset定义在头文件set中，无序容器定义在头文件unordered_map和unordered_set中。 使用关联容器 当只想知道一个值是否存在时，set是最有用的。 可以使用map来统计字符串中每个字符出现的次数： std::string Str = "The farthest distance in the world is not between death and life."; std::map&lt;char, size_t> CharCount; for (auto e : Str) { ++CharCount[e]; } for (const auto &amp;e : CharCount) { std::cout &lt;&lt; e.first &lt;&lt; ":" &lt;&lt; e.second &lt;&lt; std::endl; } 当从一个map中提取一个元素时，会得到一个pair类型的对象，所以访问map中的元素时使用了first成员和second成员。 对于上述例子，如果我们不想统计空格、标点符号等等字符，可以先用set来保存想要忽略的字符，只对不在set中的字符统计出现次数： std::string Str = "The farthest distance in the world is not between death and life."; std::map&lt;char, size_t> CharCount; std::set&lt;char> IgnoreSet{ ' ',',','.','!',':' }; for (auto e : Str) { if(IgnoreSet.find(e)==IgnoreSet.end()) //查找当前字符是否在忽略字符的集合中 ++CharCount[e]; } for (const auto &amp;e : CharCount) { std::cout &lt;&lt; e.first &lt;&lt; ":" &lt;&lt; e.second &lt;&lt; std::endl; } 关联容器概述 关联容器的迭代器都是双向的。 map和set的关键字必须是唯一的，而multimap和multiset没有此限制： int Array[]{ 1,1,2,2,3,3,4,4 }; std::set&lt;int> ISet(std::begin(Array), std::end(Array)); std::multiset&lt;int> IMultiSet(std::begin(Array), std::end(Array)); std::cout &lt;&lt; ISet.size() &lt;&lt; std::endl; //输出4 std::cout &lt;&lt; IMultiSet.size() &lt;&lt; std::endl; //输出8 默认情况下，标准库使用关键字类型的&lt;运算符来比较两个关键字。如果一个类型定义了“行为正常”的&lt;运算符，则它可以用作关键字类型。 我们也可以使用关联容器的第二个模板参数来自定义比较操作（通常是一个函数指针类型）： bool compare(int v1, int v2) { return v1 > v2; } std::set&lt;int, decltype(compare)*> ISet(compare); ISet.insert({ 1,2 }); //ISet中元素为：2 1 我们使用decltype来指出自定义比较操作的类型，由于用decltype获得的是函数类型而非函数指针，所以还需要在后面加上一个*。在定义容器时，需要将比较函数的地址作为实参传入。当我们向set容器中添加元素时，通过调用compare函数来为这些元素排序。 pair这个标准库类型定义在头文件utility中。pair的默认构造函数会对数据成员进行值初始化： std::pair&lt;std::string, int> Pair1; //默认值初始化，Pair1保存一个空string和整型值0 pair的数据成员是public的，两个成员分别命名为first和second。我们还可以使用make_pair(v1, v2)函数来生成一个pair，pair的类型根据参数的类型出来： auto Pair1 = std::make_pair("good", 100); //Pair1的类型是pair&lt;string, int> 关联容器操作 关联容器还定义了key_type等等类型别名： key_type：关联容器的关键字类型 mapped_type：值的类型，只适用于map value_type：关联容器中元素的类型。对于set就是关键字类型，和key_type相同；对于map，为pairstd::set&lt;std::string>::value_type v1; //v1是一个string std::map&lt;std::string, int>::value_type v2; //v2是一个pair&lt;const string, int> 对于map，value_type是一个pair类型，其fisrt成员保存const的关键字，second成员保存值。 一个set中的关键字也是const的。可以用一个set迭代器来读取元素的值，但不能修改，因为set迭代器是只读的。 我们通常不对关联容器使用泛型算法。关键字是const这一特性意味着不能将关联容器传递给修改或重排容器元素的算法，因为这类算法需要向元素写入值，而set类型中的元素是const的，map的关键字也是const的。关联容器可用于只读取元素的算法。但是，很多这类算法都要搜索序列。由于关联容器中的元素不能通过它们的关键字进行快速查找，因此对其使用泛型算法几乎总是个坏主意。比如使用关联容器自己定义的find成员会比调用泛型find快得多。 向关联容器中添加元素可以使用insert成员函数。对于set有两个版本：一个是接受范围迭代器，一个是接受初始值列表： std::vector&lt;int> IVec{ 1,2,3,4 }; std::set&lt;int> ISet;; ISet.insert(IVec.begin(), IVec.end()); //ISet现在有4个元素 ISet.insert({ 3,4,5,6 }); //ISet现在有6个元素 向map中添加元素时，insert的参数是必须是pair： std::map&lt;std::string, size_t> Map1; Map1.insert({ "First",1 }); Map1.insert(std::pair&lt;std::string, size_t>("Second", 2)); Map1.insert(std::make_pair("Third", 3)); Map1.insert(std::map&lt;std::string, size_t>::value_type("Forth", 4)); Map1.emplace("Fifth", 5); 除了用insert插入外，还可以使用emplace成员函数来插入元素，和insert不同的是，emplace可以直接从参数构造一个元素，所以上面代码插入Fifth，5时并没有加花括号，但是insert不行。 对于set和map这种不包含重复关键字的容器，添加单一元素的insert和emplace版本返回一个pair，告诉我们插入操作是否成功，pair的first成员是一个迭代器，指向具有给定关键字的元素；second成员是一个bool值，指出元素是插入成功，还是因为已经存在于容器中而插入失败。 对于multiset和multimap这种允许重复关键字的容器接受单个元素的insert和emplace操作返回一个指向新元素的迭代器，无须再返回一个bool值，因为插入总是成功的。 关联容器使用成员函数erase来进行删除操作，它的参数是一个要删除元素的关键字、或要删除元素的迭代器或者迭代器范围： std::set&lt;int> ISet{ 1,2,3,4 }; ISet.erase(1); //删除ISet中关键字为1的元素 ISet.erase(ISet.begin()); //删除ISet中第一个元素 ISet.erase(ISet.begin(), ++ISet.begin()); //删除ISet中第一个迭代器到第二个迭代器之间的范围（不包括第二个迭代器指向的元素） 对于保存不重复关键字的容器，erase的返回值总是0或1，若返回值为0，则表明想要删除的元素并不在容器中。对于允许重复关键字的容器，删除元素的数量可能大于1。 我们不能对一个multimap或unordered_multimap进行下标操作，因为这些容器中可能有多个值与一个关键字相关联。map和unordered_map的下标操作如下： c[k]：返回关键字为k的元素的引用；如果k不在c中，添加一个关键字为k的元素，对其进行值初始化 c.at[k]：访问关键字为k的元素，带参数检查：若k不在c中，抛出一个out_of_range异常 关联容器的下标运算符在查找关键字时，如果关键字不在容器中，可能会向容器中插入一个新元素，所以我们只可以对非const的map使用下标操作。 如果只是想知道一个元素是否在map中，但不存在是并不想添加元素，在这种情况下就不能使用下标运算符，而应该使用at或者find成员函数。 std::map&lt;int, int> Map1; if (Map1[1]) //Map1中会加入一个{1, 0}键值对 { } if (Map1.find(2)!=Map1.end()) //不会向Map1中插入新元素 { } if (Map1.at(2)) //抛出异常，不会向Map1中插入新元素 { } 对一个map进行下标操作时，会获得一个mapped_type对象，但当解引用一个map迭代器时，会得到一个value_type对象。 在一个关联容器中查找元素的操作如下，其中lower_bound和upper_bound不适用于无序容器，下标和at操作只适用于非const的map和unordered_map： 函数 含义 c.find(k) 返回一个迭代器，指向第一个关键字为k的元素，若k不在容器中，则返回尾后迭代器 c.count(k) 返回关键字等于k的元素数量 c.lower_bound(k) 返回一个迭代器，指向第一个关键字不小于k的元素 c.upper_bound(k) 返回一个迭代器，指向第一个关键字大于k的元素 c.equal_range(k) 返回一个迭代器pair，表示关键字等于k的元素的范围，若k不存在，则pair的两个成员均等于c.end() 如果一个multimap或multiset中有多个元素具有相同的关键字，则这些元素在容器中会相邻存储。 如果想要输出一个map中具有给定关键字的所有元素，可以使用以下三种方案：std::multimap&lt;std::string, size_t> Map1{ {"Bob",1},{"Lucy",2},{"Bob",3},{"Smith",4},{"Bob",5} }; auto BobCount = Map1.count("Bob"); auto Iter = Map1.find("Bob"); for (int i = 0; i &lt; BobCount; ++i) { std::cout &lt;&lt; (Iter++)->first &lt;&lt; ":" &lt;&lt; Iter->second &lt;&lt; std::endl; } std::multimap&lt;std::string, size_t> Map1{ {"Bob",1},{"Lucy",2},{"Bob",3},{"Smith",4},{"Bob",5} }; auto Iter1 = Map1.lower_bound("Bob"); auto Iter2 = Map1.upper_bound("Bob"); for (auto CurIter = Iter1; CurIter != Iter2; ++CurIter) { std::cout &lt;&lt; CurIter->first &lt;&lt; ":" &lt;&lt; CurIter->second &lt;&lt; std::endl; } std::multimap&lt;std::string, size_t> Map1{ {"Bob",1},{"Lucy",2},{"Bob",3},{"Smith",4},{"Bob",5} }; auto IterRange = Map1.equal_range("Bob"); for (auto CurIter = IterRange.first; CurIter != IterRange.second; ++CurIter) { std::cout &lt;&lt; CurIter->first &lt;&lt; ":" &lt;&lt; CurIter->second &lt;&lt; std::endl; } C++Primer P391页中所述的单词转换程序如下： std::map&lt;std::string,std::string> buildMap(const std::string&amp; vFileName) { std::map&lt;std::string, std::string> TransformMap; std::ifstream Fin(vFileName); std::string Value; std::string Key; while (Fin >> Key &amp;&amp; getline(Fin, Value)) { TransformMap[Key] = Value.substr(1); //跳过第一个空格 } return TransformMap; Fin.close(); } std::string transform(const std::string&amp; vFileName, std::map&lt;std::string, std::string>&amp; vTransformMap) { std::string Result; std::ifstream Fin(vFileName); std::string Value; std::string Line; while (getline(Fin,Line)) { std::istringstream Stream(Line); bool FirstWord = false; while (Stream >> Value) { if (!FirstWord) { FirstWord = true; } else { Result.append(" "); } if (vTransformMap.find(Value) != vTransformMap.end()) { Result.append(vTransformMap[Value]); } else { Result.append(Value); } } Result.append("\n"); } Fin.close(); return Result; } int main() { std::map&lt;std::string, std::string> TransformMap = buildMap("TransformRules.txt"); std::cout &lt;&lt; transform("InputText.txt", TransformMap) &lt;&lt; std::endl; return 0; } 文件TransformRules.txt的内容如下： brb be right back k okay ? y why r are u you pic picture thk thanks 18r later 文件InputText.txt的内容如下： where r u y dont u send me a pic k thk 18r 无序容器 新标准定义了4个无序关联容器，这些容器不是使用比较运算符来组织元素，而是使用一个哈希函数和关键字类型的==运算符。在关键字类型的元素没有明显的序关系的情况下，无序容器是非常有用的。在某些应用中，维护元素的序代价非常高昂，此时无序容器也很有用。 如果关键字类型固有就是无序的，或者性能测试发现问题可以用哈希技术解决，就可以使用无序容器。 除了哈希管理操作之外，无序容器还提供了与有序容器相同的操作（find、insert等）。这意味着我们曾用于map和set的操作也能用于unordered_map和unordered_set。类似的，无序容器也有允许重复关键字的版本。 用无序容器重写之前统计字符串中字符出现次数的程序如下： std::string Str = "The farthest distance in the world is not between death and life."; std::unordered_map&lt;char, size_t> CharCount; std::unordered_set&lt;char> IgnoreSet{ ' ',',','.','!',':' }; for (auto e : Str) { if (IgnoreSet.find(e) == IgnoreSet.end()) //查找当前字符是否在忽略字符的集合中 ++CharCount[e]; } for (const auto &amp;e : CharCount) { std::cout &lt;&lt; e.first &lt;&lt; ":" &lt;&lt; e.second &lt;&lt; std::endl; } 无序容器在存储上组织为一组桶，每个桶保存零个或多个元素。无序容器使用一个哈希函数将元素映射到桶。为了访问一个元素，容器首先计算元素的哈希值，它指出应该搜索哪个桶。容器将具有一个特定哈希值的所有元素保存在相同的桶中。如果容器允许重复关键字，所有具有相同关键字的元素都会在同一个桶中。因此，无序容器的性能依赖于哈希函数的质量和桶的数量和大小。 计算一个元素的哈希值和在桶中搜索都是很快的操作。但是，如果一个桶中保存了很多元素，那么查找一个特定元素就需要大量比较操作（哈希表特性）。 无序容器的管理操作如下： 函数 含义 c.bucket_count() 正在使用的桶的数目 c.max_bucket_count() 容器能容纳的最多的桶的数量 c.bucket_size(n) 第n个桶中有多少个元素 c.bucket(k) 关键字为k的元素在哪个桶中 local_iterator 可以用来访问桶中元素的迭代器类型 const_local_iterator 桶迭代器的const版本 c.begin(n), c.end(n) 桶n的首元素迭代器和尾后迭代器 c.cbegin(n), c.cend(n) 与前两个函数类似，但是返回const_local_iterator c.load_factor() 每个桶的平均元素数量，返回float值 c.max_load_factor() c试图维护的平均桶大小，返回float值。c会在需要时添加新的桶，以使得load_factor &lt;= max_load_factor c.rehash(n) 重组存储，使得bucket_count &gt;= n且bucket_count &gt; size/max_load_factor c.reserve(n) 重组存储，使得c可以保存n个元素且不必rehash 无序容器使用一个hash类型的对象来生成每个元素的哈希值。标准库为内置类型（包括指针）提供了hash模板。还未一些标准库类型，包括string和智能指针类型定义了hash。因此，我们可以直接定义关键字是内置类型（包括指针类型）、string或是智能指针类型的无序容器。但是，我们不能直接定义关键字类型为自定义类型的无序容器，必须先提供我们自己的hash模板版本（见16章），也可以在定义无序容器时增加生成hash值得函数模板参数和相等函数模板参数，来为自定义的类建立无序容器： class CData { public: const std::string&amp; getDataName() const { return m_DataName; } private: std::string m_DataName; }; size_t hasher(const CData &amp;vData) //生成自定义类的hash值 { return std::hash&lt;std::string>()(vData.getDataName()); } bool equal(const CData &amp;vData1, const CData &amp;vData2) { return vData1.getDataName() == vData2.getDataName(); } //定义元素类型为自定义类类型的无序容器，参数是桶大小、哈希函数指针和相等函数指针 std::unordered_set&lt;CData, decltype(hasher)*, decltype(equal)*> DataSet(42, hasher, equal); &nbsp; 参考文献：《C++Primer第五版》]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++Primer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++Primer第十章 泛型算法]]></title>
    <url>%2F2018%2F03%2F04%2FC%2B%2BPrimer%E7%AC%AC%E5%8D%81%E7%AB%A0%E6%B3%9B%E5%9E%8B%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[概述 大多数泛型算法都定义在头文件algorithm中。标准库还在头文件numeric中定义了一组数值泛型算法。 一般情况下，这些算法并不直接操作容器，而是遍历由两个迭代器指定的一个元素范围来进行操作。 由于内置数组的指针就像数组上的迭代器一样，所以我们可以使用find在数组中查找值： int IntArray[] = { 1,2,3,4,5,6 }; int Value = 2; int *pResult = std::find(std::begin(IntArray), std::end(IntArray), Value); find的工作是在一个未排序的元素序列中查找一个特定元素。 泛型算法永远不会改变底层容器的大小，可能改变容器中保存的元素的值，也可能在容器内移动元素，但永远不会直接添加或删除元素。 初识泛型算法 求和算法accumulate如下： std::vector&lt;int> IntVec = { 1,2,3,4,5,6 }; int Sum = std::accumulate(IntVec.begin(), IntVec.end(), 0); accumulate函数的前两个参数指出了需要求和的元素的范围，第三个参数是和的初值。第三个参数的类型决定了函数中使用哪个加法运算符以及返回值类型。accumulate函数定义在头文件numeric中。 由于string也定义了+运算符，所以可以使用accumulate函数将字符串连接起来： std::vector&lt;std::string> StrVec = { "This ","is ","an ","apple" }; std::string SumStr = std::accumulate(StrVec.begin(), StrVec.end(), std::string("")); // SumStr = "This is an apple" 但是如果是下面这样就会发生错误： std::string SumStr = std::accumulate(StrVec.begin(), StrVec.end(), ""); //错误，const char*上没有定义+运算符 如果我们把第三个参数指定的是一个字符串字面值，则用于保存和的对象的类型将是const char*，如前所述，此类型决定了使用哪个+运算符，由于const char*并没有+运算符，所以此调用将产生编译错误。 确定两个序列值是否相同的算法equal如下： std::vector&lt;int> IntVec = { 1,2,3 }; std::list&lt;int> IntList = { 1,2,3 }; bool IsEqual = std::equal(IntVec.cbegin(), IntVec.cend(), IntList.cbegin()); //IsEqual = true equal函数的前两个参数是第一个序列的元素范围，第三个参数是第二个序列范围的首元素。 使用操作两个序列但只有3个参数（前两个表示第一个序列的元素范围，第三个表示第二个序列范围的首元素）的算法时，一定要保证后一个序列至少与第一个序列一样长。 使用特定值填充容器某个范围的fill算法如下： std::vector&lt;int> IntVec(10); std::fill(IntVec.begin(), IntVec.begin() + IntVec.size() / 2, 3); //将容器的一个子序列用3填充 还有个fill_n算法，它填充的是从某个迭代器到该迭代器加n的范围： std::fill_n(IntVec.begin(), IntVec.size() / 2, 3); //与上面那句等价 插入迭代器是一种向容器中添加元素的迭代器，当我们给容器的一个插入迭代器赋值时，它会把一个与赋值号右侧相等的元素新增到容器中（拷贝值、新增）。 使用back_inserter函数可以获得一个容器的插入迭代器。当我们通过此迭代器赋值时，赋值运算符会调用push_back将一个具有给定值的元素添加到容器中： std::vector&lt;int> IntVec; auto Iter = std::back_inserter(IntVec); *Iter = 41; //IntVec中现在有一个元素，值为41 std::fill_n(std::back_inserter(IntVec), 10, 22); //IntVec中新增了10个值为22的元素 值得注意的是，fill_n中第一个参数不能是Iter，因为在插入元素之后，Iter这个迭代器就失效了，需要重新更新。 可以使用copy函数来对数组这种自身没有拷贝构造函数的容器来进行拷贝操作： int Array1[] = { 1,2,3,4 }; int Array2[sizeof(Array1) / sizeof(*Array1)]; auto Ret = std::copy(std::begin(Array1), std::end(Array1), Array2); //Ret指向拷贝到Array2的尾元素之后的位置 不过如果把第三个参数改成std::begin(Array2)，会发生错误，因为该模板函数的第三个参数类型不能和前两个相同。 替换范围内某个指定值的函数replace如下： std::vector&lt;int> IntVec = { 1,2,3,4,2,2,4 }; std::replace(IntVec.begin(), IntVec.end(), 2, 20); //把所有值为2的元素替换为20 std::vector&lt;int> IntVec2; //把所有值为4的元素替换为40，并且把替换后的序列拷贝到新序列里，原序列不受影响 std::replace_copy(IntVec.begin(), IntVec.end(), back_inserter(IntVec2), 4, 40); 其中replace_copy函数相当于replace和copy函数的结合，该算法接受额外第三个迭代器参数，表示新序列的起始位置。 可以用如下的程序把容器中的元素进行排序并消除重复元素： std::vector&lt;int> IntVec = { 1,2,3,4,2,2,4 }; std::sort(IntVec.begin(), IntVec.end()); //排序后的元素为：1 2 2 2 3 4 4 auto EndIterator = std::unique(IntVec.begin(), IntVec.end()); //消除重复元素后可能为：1 2 3 4 3 4 4 IntVec.erase(EndIterator, IntVec.end()); //删除重复元素后为：1 2 3 4 其中，sort使用了内置类型的小于操作来排序， unique会消除相邻的重复项。不过unique毕竟只是泛型算法，它无法真正删除容器内的元素，只是把那些相邻的重复元素覆盖了，使得不重复元素出现在序列开始部分，并返回指向最后一个不相邻重复元素的迭代器，此迭代器之后的元素依然存在，只是值不确定罢了，并没有被删除。 想要真正删除那些重复的元素，只能调用容器的erase成员函数。 定制操作 现在有一堆字符串，如果把我们想把它们先按长度排序，长度相同的再按字典序排序，则可以设计如下程序： bool isShorter(const std::string &amp;vS1, const std::string &amp;vS2) { return vS1.size() &lt; vS2.size(); } std::vector&lt;std::string> StrVec = { "the","my","that","god","good" }; std::sort(StrVec.begin(), StrVec.end()); //排序后：god good my that the std::stable_sort(StrVec.begin(), StrVec.end(), isShorter); //排序后：my god the good that 需要先按字典序排序，再按长度进行稳定排序。其中stable_sort函数就是稳定排序，它会维持相等元素原有的顺序。 上面stable_sort函数还包含有第三个参数，它是一个谓词。谓词是一个可调用的表达式，其返回结果是一个能用作条件的值。stable_sort使用第三个参数指定的谓词来进行排序，而不再是使用string类的&lt;运算符。 上面的程序可以得到按长度排序再按字典序排序后的一堆字符串，现在我们想要输出一个长度大于给定值3的所有字符串。当然首先需要在这个已经排好序的一堆字符串里，找到第一个长度大于3的字符串。除了手动循环遍历以外，我们还可以直接调用标准库算法find_if，它前两个参数是查找的范围，第三个参数是一个谓词： auto It = std::find_if(StrVec.begin(), StrVec.end(), isLonger3); 但是如果是大于1、大于2、大于4…呢？不可能再去重载多个函数吧？把给定值写入函数isLonger中？ bool isLonger(const std::string &amp;vS, std::string::size_type vN) { return vS.size() > vN; } 但是find_if的第三个参数是一个谓词，只能传可调用对象的地址进去，那么那个参数vN怎么传进去？find_if只支持3个参数。 其中一个解决方案就是使用lambda表达式。 一个lambda表达式表示一个可调用的代码单元。我们可以将其理解为一个未命名的内联函数。但与函数不同，lambda可能定义在函数内部。lambda表达式形式如下： [capture list](parameter list)->return type {function body} 其中，capture list（捕获列表）是一个lambda所在函数中定义的局部变量的列表（通常为空），与普通函数不同的是，lambda的返回类型是尾置返回。而且其中的参数列表和返回类型是可选的（可以省略）。 auto f = [] {return 41; }; //省略参数列表和返回类型的lambda lambda的调用方式与普通函数的调用方式相同，都是使用调用运算符： std::cout &lt;&lt; f() &lt;&lt; std::endl; 一个lambda通过将局部变量包含在其捕获列表中来指出将会使用这些变量。这样我们就可以通过lambda的捕获列表来获取那个给定长度值，从而解决之前3中提到的问题： int SpecifiedLength = 3; auto It = std::find_if(StrVec.begin(), StrVec.end(), [SpecifiedLength](const std::string&amp; vS) {return vS.size() > SpecifiedLength; }); 在lambda的捕获列表中捕获局部变量SpecifiedLength ，这样一来当给定长度发生变化时，只需要更改该局部变量的值即可，无需去重载多个谓词函数。 现在我们只是找到了第一个长度大于给定值的字符串，剩下的就是在这堆有序字符串里打印所有长度大于给定值的字符串了。我们可以使用for_each函数来遍历，它的前两个参数是遍历范围，第三个参数可调用对象，它会对遍历的每个元素调用此可调用对象： std::for_each(It, StrVec.end(), [](const std::string&amp; vS) {std::cout &lt;&lt; vS &lt;&lt; std::endl; }); //可调用对象是一个lambda 当定义一个lambda时，编译器生成一个与lambda对应的新的未命名的类类型。默认情况下，从lambda生成的类都包含对应该lambda所捕获变量的数据成员。类似任何普通类的数据成员，lambda的数据成员也在lambda对象创建时被初始化。不过值得注意的是，与参数不同，被捕获的变量的值是在lambda被创建时拷贝，而不是调用时拷贝： size_t Value = 41; auto f = [Value] {return Value; }; //创建lambda时，局部变量Value被拷贝到捕获列表中 Value = 0; auto Value1 = f(); //Value1的值为41而不是0，因为f保存了我们创建它时Value的拷贝 上面的捕获列表是值捕获，如果想要引用捕获，需要在Value前加上引用符号&amp;： auto f = [&amp;Value] {return Value; }; 采用引用方式捕获一个变量，必须确保被引用的对象在lambda执行的时候是存在的。lambda捕获的都是局部变量，这些变量在函数结束后就不复存在了。如果lambda可能在函数结束后执行，捕获的引用所指向的局部变量已经消失。 隐式捕获：除了在捕获列表中显式列出我们希望使用的局部变量之外，还可以让编译器根据lambda体中的代码来推断我们要使用哪些变量。为了指示编译器推断捕获列表，应在捕获列表中写一个&amp;或=。&amp;告诉编译器采用引用捕获方式，=是值捕获方式：auto It = std::find_if(StrVec.begin(), StrVec.end(), [=](const std::string&amp; vS) {return vS.size() > SpecifiedLength; }); //隐式值捕获 如果我们希望对一部分变量采用值捕获，对其他变量采用引用捕获，可以混合使用隐式捕获和显式捕获：char C = ' '; std::ostream &amp;OS = std::cout; std::for_each(It, StrVec.end(), [=, &amp;OS](const std::string&amp; vS) {OS &lt;&lt; vS &lt;&lt; C; }); 当我们混合使用隐式捕获和显式捕获时，捕获列表中的第一个元素必须是&amp;或=，它指明默认隐式捕获方式是引用捕获还是值捕获。而且如果隐式捕获是引用方式，则显式捕获命名必须是值捕获，不能在捕获变量名字前面用&amp;，反之亦然（道理很简单，显式捕获和隐式捕获如果采用相同的引用或值捕获，会发生冲突）。 在lambda函数体内部不能修改值捕获变量的值：int i = 41; auto f = [i] { return ++i; }; //错误：i必须是可修改的左值 如果确实想要修改值捕获变量的值，可以在参数列表后使用关键字mutable：int i = 41; auto f = [i] ()mutable { return ++i; }; //需要加上参数列表 注意需要加上参数列表，至少也要有个空的()。 对于那种只在一两个地方使用的简单操作，lambda表达式是最有用的。如果我们需要在很多地方使用相同的操作，通常应该定义一个函数，而不是多次编写相同的lambda表达式。类似的，如果一个操作需要很多语句才能完成，通常使用函数更好。 如果lambda的捕获列表为空，通常可以用函数来代替它。 除了使用lambda来解决上面无法传递给定值的问题以外，还可以使用标准库的bind函数来解决。可以把bind函数看作一个通用的函数适配器，它接受一个可调用对象，生成一个新的可调用对象来“适应”原对象的参数列表。说得更通俗点，bind其实就是把一个函数包装成另一个可能参数更少、可能参数顺序发生变化的另一个函数。bind函数定义在functional头文件中。 调用bind函数的形式为： auto newCallable = std::bind(callable, arg_list); 其中callable是一个可调用对象，arg_list是一个逗号分隔的参数列表，对应给定的callable的参数，返回一个新的可调用对象newCallable。也就是当我们调用newCallable 时，newCallable 会调用callable，并依次传递给它arg_list中的参数。 arg_list中的参数可能包含形如_n的名字，其中n是一个整数。这些参数是占位符，表示newCallable的参数，它们占据了传递给newCallable的参数的“位置”，_1为newCallable的第一个参数，_2为newCallable的第二个参数…。这些占位符都定义在命名空间std::placeholders中。 例如下面的函数： int minus(int v1, int v2) { return v1 - v2; } 如果我们想要调用减数和被减数的位置，则可以用bind来生成一个新的可调用对象： int minus(int v1, int v2) { return v1 - v2; } auto minusReverse = std::bind(minus, std::placeholders::_2, std::placeholders::_1); std::cout &lt;&lt; minusReverse(2, 3) &lt;&lt; std::endl; //输出1而非-1 既然isLonger函数因为需要两个参数而无法作为find_if函数的第三个参数，那么我们现在可以用bind函数把isLonger函数包装成只需要一个参数的新函数：int SpecifiedLength = 3; auto f = std::bind(isLonger, std::placeholders::_1, SpecifiedLength); auto It = std::find_if(StrVec.begin(), StrVec.end(), f); find_if函数为范围内的每个元素调用f，并且把该元素传递当做参数传递给f，f是只有一个参数的新函数，在调用f时，f会去调用isLonger函数，并且把这个元素（这里其实就是字符串）传递给isLonger函数的第一个参数，把变量SpecifiedLength传递给isLonger函数的第二个参数。 一般情况下，我们传递给bind的实参都是值传递，如果想要引用传递而避免拷贝 ，可以使用标准库ref函数： std::ostream&amp; print(std::ostream&amp; vOS, const std::string&amp; vS) { return vOS &lt;&lt; vS; } auto f1 = std::bind(print, std::ref(std::cout), std::placeholders::_1); //ostream无法拷贝，所以要用ref std::for_each(It, StrVec.end(), f1); 函数ref返回一个对象，包含给定的引用，此对象是可以拷贝的，相当于生成了一个给定对象的引用形式。标准库中还有一个cref函数，生成一个保存const引用的类。与bind一样，函数ref和cref也定义在头文件functional中。 再探迭代器 上一章接触过插入迭代器。插入迭代器有三种类型，差异在于元素插入的位置： back_inserter：创建一个使用push_back的迭代器。 front_inserter：创建一个使用push_front的迭代器。 inserter：创建一个使用insert的迭代器。此函数接受第二个参数，是一个迭代器，表示元素被插入到这个迭代器之前的位置。std::list&lt;int> List = {20}; *std::back_inserter(List) = 30; //容器中含有元素：20 30 *std::front_inserter(List) = 10; //容器中含有元素：10 20 30 *std::inserter(List, List.begin()) = 0; //容器中含有元素0 10 20 30 std::list&lt;int> List = { 1,2,3,4 }; std::list&lt;int> List2, List3; //拷贝完成后，List2中含有元素：4 3 2 1 std::copy(List.cbegin(), List.cend(), std::front_inserter(List2)); //拷贝完成后，List3中含有元素：1 2 3 4 std::copy(List.cbegin(), List.cend(), std::inserter(List3, List3.begin())); 虽然iostream不是类型，但是标准库定义了可以用于这些IO类型对象的迭代器。istream iterator读取输入流，ostream_iterator向一个输出流写入数据。通过使用迭代器，我们可以用泛型算法从流对象读取数据以及向其写入数据。 创建一个istream_iterator时，我们可以把它绑定到一个流。如果不绑定任何流（即默认初始化），则创建的是istream_iterator类型的尾后迭代器。 std::istream_iterator&lt;int> IIterator(std::cin); //迭代器可以从cin读取int std::istream_iterator&lt;int> EndIterator; //尾后迭代器 std::ifstream Fin("test.txt"); std::istream_iterator&lt;std::string> SIterator(Fin); //迭代器可以从文件test.txt读取string 我们可以用流迭代器来从IO流读取数据： std::vector&lt;int> IVec; std::istream_iterator&lt;int> IIter(std::cin); std::istream_iterator&lt;int> EndIter; //尾后迭代器 while (IIter != EndIter) { IVec.push_back(*IIter); ++IIter; } 对于一个流迭代器，一旦其关联的流遇到文件尾或遇到IO错误，迭代器的值就与尾后迭代器EndIter相等。 其实可以直接把程序重写为如下形式，这体现了流迭代器更有用的地方： std::istream_iterator&lt;int> IIter(std::cin), EndIter; std::vector&lt;int> IVec(IIter, EndIter); //从迭代器范围构造IVec 当创建ostream_iterator时，我们可以提供可选的第二参数，它是一个字符串，在输出每个元素后都会打印此字符串。此字符串必须是一个C风格字符串。而且和istream_itertor不同的是，必须将ostream_iterator绑定到一个IO流，不存在表示尾后迭代器的空ostream_iterator。 std::vector&lt;int> Vec{ 1,2,3,4 }; std::ostream_iterator&lt;int> OIter(std::cout,","); for (auto e : Vec) *OIter++ = e; //赋值语句实际上将元素写到cout，每输出一个元素都输出字符串“,” 其实向ostream_iterator赋值时，可以忽略解引用和递增运算符，所以上面的循环可以写成下面这样： for (auto e : Vec) OIter = e; 但是为了方便阅读代码还是第一种形式比较好，不过正因为这种特性，我们可以用copy函数来简化该循环： std::vector&lt;int> Vec{ 1,2,3,4 }; std::ostream_iterator&lt;int> OIter(std::cout,","); std::copy(Vec.cbegin(), Vec.cend(), OIter); 当然流迭代器也可以处理那些定义了输入运算符（&gt;&gt;）和输出运算符（&lt;&lt;）的类。 除了forward_list之外，其他容器都支持反向迭代器。获取反向迭代器的函数只是比正向迭代器在名字上多了一个r，比如c.begin()和c.rbegin()。其中c.rbegin()指向容器中的最后一个元素，而c.rend()是首前迭代器，指向容器中第一个元素之前的位置（原理类似c.end()尾后迭代器）。 std::vector&lt;int> IVec{ 1,6,5,3,2 }; std::sort(IVec.rbegin(), IVec.rend()); //按逆序排序，将最小的元素放在IVec的末尾 因为不可能在一个流中反向移动，所以流迭代器不支持递减运算，所以流迭代器也不存在方向迭代器。 如果我们有一个字符串“Tomorrow will be nice”，希望打印出它的最后一个单词，我们可以先用反向迭代器逆序找到最后一个空格出现的地方，然后打印它到字符串末尾的部分： std::string Str = "Tomorrow will be nice"; auto Start = std::find(Str.crbegin(), Str.crend(), ' '); std::cout &lt;&lt; std::string(Str.crbegin(), Start) &lt;&lt; std::endl; //输出ecin 注意由于是反向迭代器，进行的是递减运算而不是递增运算，所以构造字符串时需要从迭代器Str.crbegin()到迭代器Start的方向来构造字符串。但是最后得到的是最后一个单词nice的逆序结果。原因在于我们构造字符串时用的是反向迭代器，我们可以用反向迭代器的base成员函数来将其转换为正向迭代器： std::cout &lt;&lt; std::string(Start.base(),Str.cend()) &lt;&lt; std::endl; //输出nice 泛型算法结构 接受谓词参数的泛型算法都有附加的_if前缀： std::find(beg, end, val); //在输入范围中查找val第一次出现的位置 std::find_if(beg, end, pred); //在输入范围中查找第一个令pred为真的元素 写到额外目的空间的泛型算法都会在名字后面附加一个_copy： std::reverse(beg, end); //反转输入范围中元素的顺序 std::reverse_copy(beg, end, dest); //将输入范围中的元素按逆序拷贝到dest 还有一些算法同时提供_copy和_if。它们接受一个目的位置迭代器和一个谓词： std::vector&lt;int> IVec{ 1,2,3,4,5,6 }, IVec2, IVec3; //将IVec中的奇数元素拷贝到IVec2 std::copy_if(IVec.begin(), IVec.end(), std::back_inserter(IVec2), [](int i) {return i % 2; }); //从IVec2中删除奇数元素，返回的迭代器指向删除范围的后一个位置（泛型算法并不真正删除容器里的元素） auto Iter = std::remove_if(IVec2.begin(), IVec2.end(), [](int i) {return i % 2; }); //将IVec中的偶数元素拷贝到IVec3(先删除奇数，再把剩余的偶数拷贝到IVec3)，IVec不变 std::remove_copy_if(IVec.begin(), IVec.end(), std::back_inserter(IVec3), [](int i) {return i % 2; }); 在调用remove_if这个泛型算法时，并不真正删除容器中的元素，需要真正删除元素，还需要调用容器的erase成员函数。 特定容器算法 对于list和forward_list这些链表容器，应该优先使用成员函数版本的算法而不是对应的泛型算法，因为泛型版本的算法需要交换输入序列中的元素，而成员函数版本的算法只需要改变元素之间的链接即可，性能要好得多。 链表的成员函数包括remove、remove_if、reverse、sort、merge、unique、splice等等。其中merge表示把一个链表合并进另一个链表中： std::list&lt;int> List1{ 1,3,5,7 }; std::list&lt;int> List2{ 2,4,6,8 }; List1.merge(List2); //合并后List1为：1 2 3 4 5 6 7 8，List2为空 合并前List1和List2都必须是有序的。合并后List2变为空，List1中元素合并排序时默认使用的是&lt;运算符。它还有第二个版本，可以接受自定义的比较操作： std::list&lt;int> List1{ 1,3,5,7 }; std::list&lt;int> List2{ 2,4,6,8 }; List1.reverse(); List2.reverse(); List1.merge(List2, compare); //合并后List1为：8 7 6 5 4 3 2 1，List2为空 splice可以把一个链表中的元素移动另一个链表中的指定位置之前： std::list&lt;int> List1{ 1,3,5,7 }; std::list&lt;int> List2{ 2,4,6,8 }; //将List2中的所有元素移动到List1第一个元素之前 List1.splice(List1.begin(), List2); //List1为：2 4 6 8 1 3 5 7，List2为空 //将List1中的第一个元素移动到List2中 List2.splice(List2.begin(), List1, List1.begin(), ++List1.begin()); //List1为：4 6 8 1 3 5 7，List2为：2 //将List1中第二个元素移动到List2中 List2.splice(List2.begin(), List1, ++List1.begin()); //List1为：4 8 1 3 5 7，List2为：6 2 forward_list的对应版本是splice_after。 链表的迭代器不支持加减算术运算（++和–可以）： auto it = List1.begin() + 4; //错误 根本原因在于链表的存储空间不是连续的，不支持随机访问。&nbsp; 参考文献：《C++Primer第五版》]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++Primer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++Primer第九章 顺序容器]]></title>
    <url>%2F2018%2F03%2F01%2FC%2B%2BPrimer%E7%AC%AC%E4%B9%9D%E7%AB%A0%E9%A1%BA%E5%BA%8F%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[顺序容器概述 标准库中的顺序容器类型如下： 函数 含义 vector 可变大小数组。支持随机访问。在尾部之外的位置插入或删除元素可能很慢 deque 双端队列。支持快速随机访问。在头尾位置插入/删除速度很快 list 双向链表。支持双向顺序访问。在list中任何位置插入/删除都很快 forward_list 单向链表。只支持单向顺序访问。在链表中任何位置插入/删除都很快 array 固定大小数组。支持快速随机访问。不能添加或删除元素 string 与vector相似的容器，但专门用于保存字符。随机访问块，在尾部插入/删除速度很快 链表容器（list和forward_list）相比于vector、deque、array这些容器，其额外内存开销会很大。 与内置数组相比，array是一种更安全、更容易使用的数组类型。 forward_list的设计目标是达到与最好的手写的单向链表数据结构相当的性能。因此，forward_list没有size操作，因为保存和计算其大小就会比手写链表多出额外的开销。 新标准的容器比旧版本快得多。新标准容器的性能几乎肯定与最精心优化过的同类数据结构一样好（通常会更好）。现代C++程序应该使用标准库容器，而不是更原始的数据结构，如内置数组。 如果程序只有在读取输入时才需要在容器中间位置插入元素，随后需要随机访问元素，则： 首先确定是否真的需要在容器中间位置添加元素。当处理输入数据时，通常可以很容易地向vector追加数据，然后再调用标准库的sort函数来重排容器中的元素，从而避免在中间位置添加元素（这条准则需要容器是有序的）。 如果必须在中间位置插入元素，考虑在输入阶段使用list，一旦输入完成，将list中的内容拷贝到一个vector中。 容器库概述 标准库容器均为模板类。 容器的公共操作中（Container是某种容器），Container::size_type表示容器可能的最大容量大小，是无符号整数类型，Container::difference_type用于保存两个迭代器之间的距离，是有符号整数类型，Container::value_type是容器里的元素类型，Container::reference是容器里元素的左值类型，相当于Container::value_type&amp;。 forward_list迭代器不支持递减运算符，毕竟是单向链表嘛。 容器的begin和end成员函数其实是有重载版本的。非常量对象调用这两个函数时，会返回iterator；而常量对象调用这两个函数时，会返回const_iterator。 当不需要写访问时，迭代器应使用cbegin和cend函数（这两函数无论调用它们的是不是常量对象，都总是会返回const_iterator）。 用一个容器拷贝给另一个容器时，容器类型必须相同。而用迭代器范围来拷贝时要求低一点，不需要容器类型完全相同，只要容器里的元素可以进行隐式转换即可。 std::vector&lt;const char*> CVec = { "This","There","Here" ,"Good" }; std::vector&lt;std::string> SVec2(Vec1); //错误：直接拷贝时，容器类型必须匹配 //使用范围迭代器拷贝时，元素能隐式转换即可，不需要容器类型完全相同 std::vector&lt;std::string> SVec3(CVec.cbegin(), CVec.cend()); //正确 std::forward_list&lt;std::string> SList(CVec.cbegin(), CVec.cend()); 当定义一个array时，除了指定元素类型，还要指定容器大小，使用时也是一样。毕竟array是一个固定大小的数组嘛： std::array&lt;int, 10> Datas; //类型为：保存10个int的数组 std::array&lt;int, 10>::size_type i; 虽然我们不能对内置数组类型进行拷贝操作，但是array是可以的： int Data1[] = { 1,2,3,4 }; decltype(Data1) Data2 = Data1; //错误：内置数组不支持拷贝或赋值 std::array&lt;int, 4> Data3 = { 0,1,2,3 }; std::array&lt;int, 4> Data4 = Data3; //正确，只要数组类型匹配即合法 顺序容器（array除外）还定义了一个名为assign的成员函数，它用其参数所指定的元素的拷贝去替换左边容器中的所有元素（不要求容器相同，只要元素类型可以隐式转换即可）。assign操作不适用于array和关联容器。因为旧元素会被替换，所以传递给assign的迭代器不能指向调用assign的容器。 函数 含义 seq.assign(b, e) 将seq中的元素替换为迭代器b和e所表示的范围内的元素。迭代器b和e不能指向seq中的元素 seq.assign(il) 将seq中的元素替换为初始化列表il中的元素 seq.assign(n, t) 将seq中的元素替换为n个值为t的元素 ```cpp std::vector&lt;const char*&gt; Vec = { &quot;This&quot;,&quot;There&quot;,&quot;Here&quot; ,&quot;Good&quot; }; std::list&lt;std::string&gt; List; List.assign(Vec.cbegin(), Vec.cend()); ``` 赋值相关运算符会导致指向左边容器内部的迭代器、引用和指针失效。不过swap(Container1, Container2)或者Container1.swap(Container2)操作不会。而且在容器之间swap操作通常比拷贝元素要快。 除array外，交换两个容器内容的swap操作保证会很快，因为元素本身并未交换，只是交换了两个容器的内部数据结构，它不对任何元素进行拷贝、删除或插入操作，因此可以保证在常数时间内完成。与其他容器不同，swap两个array会真正交换它们的元素，因此其所需的时间与array中元素的数目成正比。 除string外，指向容器的迭代器、引用和指针在swap操作之后都不会失效，它们仍指向swap操作之前所指向的那些元素。但是在swap操作之后，这些元素已经属于不同的容器了。例如，假定iter在swap之前指向svec[3]的元素，那么在swap操作之后它指向svec2[3]的元素。与其他容器不同，对一个string调用swap操作会导致迭代器、引用和指针失效。 在新标准中，容器提供成员函数版本的swap，也提供非成员版本的swap。统一使用非成员版本的swap是一个好习惯。 只有当内部的元素类型也定义了相应的比较运算符时，我们才可以使用关系运算符来比较两个容器。 顺序容器操作 向容器中添加元素的insert函数的几个版本： 函数 含义 c.insert(p, t) 在迭代器p指向的元素之前插入一个值为t的元素。返回指向新添加元素的迭代器 c.insert(p, n, t) 在迭代器p指向的元素之前插入n个值为t的元素 c.insert(p, b, e) 将迭代器b和e指定的范围内的元素插入到迭代器p所指向的元素之前。b和e不能指向c中的元素 c.insert(p, il) 将花括号包围的元素值列表il插入到迭代器p指向的元素之前 向一个vector、string或deque插入元素会使所有指向容器的迭代器、引用和指针失效。 向一个vector或string添加元素可能引起整个对象存储空间的重新分配。重新分配一个对象的存储空间需要分配新的内存，并将元素从旧的空间移动到新的空间中。 vector、deque、list和string都支持insert成员，但是forward_list有点不同，它提供了自己特殊版本的insert成员（后文详述）。 由于迭代器有可能指向尾后迭代器（容器中不存在的元素的位置），所以是在迭代器之前的位置插入元素。 将元素插入到连续容器vector、deque、string中的任何位置都是合法的，但这样做可能很耗时。 新标准引入了三个新成员：emplace_front、emplace和emplace_back，这些操作构造而不是拷贝元素。这些操作分别对应push_front、insert和push_back，允许我们将元素放在容器头部、一个指定位置之前或容器尾部。调用一个emplace成员函数时，是将参数传递给元素类型的构造函数。emplace成员使用这些参数在容器管理的内存空间中直接构造元素。其实emplace相当于比push或insert多了一个隐式转换。 顺序容器的front和back成员函数返回的是元素的引用，begin和end成员函数返回的是迭代器。 使用容器的at成员函数来代替下标运算符[]，可以安全地随机访问容器中的元素。因为下标运算符在下标越界时函数行为未定义，但是at成员函数在索引越界时会抛出out_of_range异常。 c.erase(p)和c.erase(b, e)操作是顺序容器的删除操作，前者删除迭代器p指向的元素，后者删除迭代器b和e所指定范围内的元素。都返回删除元素的下一个位置的迭代器。 删除deque中除首位之外的任何元素都会使所有迭代器、引用和指针失效。vector或string中删除点之后的迭代器、引用和指针都会失效。 由于forward_list是单向链表，无法获取链表中某个结点的前驱结点，导致无法在某个元素之前进行插入、删除等等操作，所以forward_list并未定义insert、emplace和earse等操作，而是定义了名为insert_after、emplace_after和erase_after的操作。在执行插入、删除等操作时，需要首先获取到前驱结点，再调用这些函数来完成相应工作。除此之外，forward_list还定义了名为before_begin的成员函数来获取首前迭代器（即链表首元素之前的位置，用于在链表首元素之前添加删除元素）。 如下程序可以删除存储在forward_list中的所有奇数，其中PrevIter用于存储用于遍历的当前迭代器的前驱迭代器。通过这个前驱迭代器来删除forward_list中的元素。 std::forward_list&lt;int> IList{ 0,1,2,3,4,5,6,7,8,9 }; auto PrevIter = IList.cbefore_begin(); auto CurrIter = ++PrevIter; while (CurrIter != IList.end()) { if (*CurrIter % 2) CurrIter = IList.erase_after(PrevIter); else { PrevIter = CurrIter; ++CurrIter; } } 可以用顺序容器的c.resize(n)或c.resize(n, t)成员函数来改变容器大小。前者更改容器大小后，多出的元素被丢弃，新添加的元素进行值初始化；而后者新添加的元素被初始化为t。当然，resize操作不适用于array。 值得注意的是，resize操作只改变容器里的元素数目，并不改变容器的容量。而且使用resize后，指针、迭代器或引用都有可能失效。 总结一下，哪些情况下，会使容器的迭代器、指针和引用等失效： 向容器添加元素后： 对于vector和string。且存储空间被重新分配，则指向容器的迭代器、指针和引用都会失效。如果存储空间未重新分配，指向插入位置之后的元素的迭代器等会失效，之前的依然有效。 对于deque，插入到除首尾位置之外的任何位置都会导致迭代器等失效。如果在首尾位置添加元素，只会使迭代器失效，指针和引用依然有效。 对于list和forward_list，添加元素后迭代器、指针和引用等总是有效的。 从容器删除一个元素后： 对于vector和string，指向被删元素之后元素的迭代器、引用和指针失效，之前的依然有效。 对于deque，在除首尾位置之外的任何位置删除元素都会导致迭代器等失效。如果删除的是尾元素，则尾后迭代器会失效，但是其他迭代器、指针、引用等依然有效；如果删除的是首元素，迭代器等也依然有效。 对于list和forward_list，删除元素之后，除了指向被删除元素的其他迭代器等依然有效。 可以看出，其实添加和删除情况都差不多，主要是看添加删除元素后，迭代器所指向的地址是否还是原来的地址。在涉及到向容器添加或删除元素时，一定要注意之前的迭代器是否还指向正确的元素，尤其是在循环中。 不要保存end返回的迭代器。当我们添加/删除vector或string的元素后，或在deque中首元素之外的任何位置添加/删除元素后，原来end返回的迭代器总是会失效。所以，在循环中必须返回调用end成员函数，而不能在循环之前保存end返回的迭代器，当做容器的尾后迭代器来使用。比如如下程序就是错误的：std::vector&lt;int> Vec{ 0,1,2,3,4,5,6,7,8,9 }; auto Iter = Vec.begin(); auto EndIter = Vec.end(); while (Iter != EndIter) //错误，插入或删除元素后EndIter就失效了 { if (*Iter % 2) { Iter = Vec.insert(Iter, *Iter); Iter += 2; } else { Iter = Vec.erase(Iter); } } 不应该在循环之前把尾后迭代器保存下来，循环条件应该写成下面这样：while (Iter != Vec.end()) //每次调用返回当前最新的尾后迭代器 vector对象是如何增长的 诸如vector和string，如果容器没有足够的空间容纳新的元素，而不得不获取新的内存空间时，vector和string的实现通常会分配比新的空间需求更大的内存空间。容器预留这些空间作为备用，可用来保存更多的新元素。这样，就不需要每次添加新元素都重新分配容器的内存空间了。虽然vector在每次重新分配内存空间时都需要移动所有元素，但使用此策略后，其扩张操作通常比list和deque还要快。 容器大小的管理操作函数如下表： 函数 含义 c.shrink_to_fit() 将capacity()减少为与size()相同大小 c.capacity() 不重新分配内存空间的话，容器c可以保存多少元素 c.reserve(n) 分配至少能容纳n个元素的内存空间 reserve并不改变容器中元素的数量，它仅影响vector预先分配多大的内存空间。如果需求的n小于或等于当前容量，reserve什么也不做，而且容器不会退回多余的内存空间。这样，调用reserve永远也不会减少容器占用的内存空间。 如果确实需要容器退回不需要的内存空间，可以调用shrink_to_fit成员函数。但是，它只是一个请求，标准库并不保证一定会退还内存空间，需要更具具体的实现而定。 额外的string操作 用字符串字面值赋给char类型的指针时，末尾会有一个空字符’\0’作为结尾标志，但以字符数组（非字符串变量值）赋给char型指针时，末尾没有这样一个空字符： char *cp = "This"; //cp里保存的是：T、h、i、s、\0 char ca[] = { 'T','h','i','s' }; //ca里在s后面没有\0 所以，可以使用cp去构造一个string对象，但是不能使用ca： std::string s1(cp); //s1是：This std::string s2(ca); //s2可能是："This烫烫烫烫坃\xe\x1烫烫飧f\xev" string的substr成员函数返回一个string，它是原始string的一部分的拷贝： std::string s = "This is ..."; std::string s1 = s.substr(5); // s1 = is... std::string s2 = s.substr(2, 8); // s2 = is is .. 除了如前面所述的顺序容器接受迭代器的insert和erase版本以外，string还额外提供了接受下标的版本： std::string s = "This is"; s.insert(5, "dog "); // s = This dog is s.insert(s.size(), 3, '.'); // s = This dog is... s.erase(4,4); //从序号为4的位置开始删除4个元素, s = This is... s.erase(s.size() - 3); //从倒数第3个位置开始删除后面的所有元素，s = This is string类还定义了两个额外的操作：append和replace。append用于在string末尾进行追加（插入）操作。而replace是把字符串中的某一段字符替换成另外的字符，相当于连续调用了erase和insert： std::string s = "This is"; s.append(" a dog"); // s = This is a dog s.replace(0, 4, "There"); //把从0号位置开始的4个元素替换为There，s = There is a dog string提供了6个不同的搜索函数（其中args时包含要查找的字符串，还可能包含要查找的起始位置，它默认为0）： 函数 含义 s.find(args) 查找s中args第一次出现的位置 s.rfind(args) 查找s中args最后一次出现的位置 s.find_first_of(args) 在s中查找args中任何一个字符第一次出现的位置 s.find_last_of(args) 在s中查找args中任何一个字符最后一次出现的位置 s.find_first_not_of(args) 在s中查找第一个不在args中的字符 s.find_last_not_of(args) 在s中查找最后一个不在args中的字符 上面的6个搜索操作都返回string::size_type类型的值，该类型其实是一个unsigned类型，表示匹配发生位置的下标。如果搜索失败，会返回一个名为string::npos的static成员，它也是string::size_type类型。例如在一个字符串中搜索子串出现的所有位置： std::string s = "aaabbaa"; std::string::size_type pos = 0; //输出为0 1 5 while ((pos = s.find("aa", pos)) != std::string::npos) { std::cout &lt;&lt; pos &lt;&lt; " "; ++pos; //移动到下一个字符，在剩余的子串中查找 } 由于string的搜索操作返回的是一个无符号类型，所以通常不要用一个带符号类型来保存这些函数的返回值。 string的compare成员函数还可以比较string对象和C风格字符串，通常返回正数、负数或0，分别表示大于、小于或等于： std::string s = "aab"; std::string s2 = "ab"; std::cout &lt;&lt; s.compare(s2); //本机输出-1 把数值类型转换成string可以用to_string(val)函数，任何数值类型都可以。而把string转换成数值类型需要用stoi(s)、stod(s)、stof(s)、stol(s)…等等函数，它们还有额外的参数可以指定转换的进制（具体参考C++Premier中文版P328）: float Value = 123.4; std::string Str = std::to_string(Value); float Value1 = std::stof(Str); 容器适配器 本质上，一个适配器是一种机制，能使某种事物的行为看起来像另外一种事物一样。一个容器适配器接受一种已有的容器类型，使其行为看起来像另外一种不同的类型。例如stack、queue和priority_queue： std::deque&lt;int> Deque{ 1,2,3 }; std::stack&lt;int> Stk; //空栈 std::stack&lt;int> Stk1(Deque); //基于Deque创建的适配器：栈，会把Deque中的元素拷贝到Stk1 std::stack&lt;int> IntStack; for (size_t i = 0; i &lt; 10; ++i) IntStack.push(i); while (!IntStack.empty()) { int Value = IntStack.top(); IntStack.pop(); //pop返回的是void类型 } 默认情况下，stack和queue是基于双端队列deque实现的，而priority_queue是在vector上实现的。不过我们也可以自己指定在哪种容器上来实现这些适配器，只需要在定义时添加第二个模板参数即可： std::stack&lt;int, std::vector&lt;int>> Stk2; //基于vector创建的栈 对于一个给定的适配器，可以使用哪些容器是有限制的。stack只要求push_back、pop_back和back操作，因此可以使用除array和forward_list之外的任何容器类型来构造stack。queue适配器要求back、push_back、front和push_front，因此它可以构造于list或deque之上，但不能基于vector构造。priority_queue除了front、push_back和pop_back操作之外还要求随机访问能力，因此它可以构造于vector或deque之上，但不能基于list构造。 priority_queue允许我们为队列中的元素建立优先级。新加入的元素会排在所有优先级比它低的已有元素之前。默认情况下，标准库在元素类型上使用&lt;运算符来确定相对优先级。&nbsp; 参考文献：《C++Primer第五版》]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++Primer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++Primer第八章 IO库]]></title>
    <url>%2F2018%2F01%2F22%2FC%2B%2BPrimer%E7%AC%AC%E5%85%AB%E7%AB%A0IO%E5%BA%93%2F</url>
    <content type="text"><![CDATA[IO类 可以将IO理解为读写，而非输入输出。 我们不能拷贝或对IO对象赋值。因此，我们也不能将形参或返回类型设置为流类型。进行IO操作的函数通常以引用方式传递和返回流。读写一个IO对象会改变其状态，因此传递和返回的引用都不能是const的。即不能用const修饰IO流对象。 IO库定义了4个iostate类型（与机器无关的一种类型）的位模式：badbit、failbit、eofbit、goodbit。其中badbit表示系统级错误，如不可恢复的读写错误。通常情况下，一旦badbit被置位，流就无法再使用了。在发生可恢复错误后，failbit被置位，如期望读取数值却读出一个字符等错误。这种问题通常是可以修正的，流还可以继续使用。如果达到文件结束位置，eofbit和failbit都会被置位。goodbit的值为0，表示流未发生错误。如果badbit、failbit、eofbit任意一个被置位，则检测流状态的条件会失败。 IO库条件状态（位模式）及相关查询函数如下表所示（其中strm是某一种IO类型，如istream）： 位模式及相关函数 含义 strm::iostate iostate是一种机器相关的类型，提供了表达条件状态的完整功能。 strm::badbit 表示流已奔溃 strm::failbit 表示一个IO操作失败了 strm::eofbit 表示流到达了文件结束位置 strm::goodbit 表示流未处于错误状态 s.eof() 若流s的eofbit置位，则返回true s.fail() 若流s的failbit或badbit置位，则返回true s.bad() 若流s的badbit置位，则返回true s.good() 若流s处于有效状态，则返回true s.clear() 将流s的所有条件状态位复位，将流的状态设置为有效。返回void。 s.clear(flags) 根据给定的flags标志位，将流s中对应条件状态位复位。flags的类型为strm::iostate。返回void。 s.setstate(flags) 将流s中的flags条件状态位置位。flags类型同上，返回void。 s.rdstate() 返回流s的当前条件状态，返回值类型为strm::iostate。 每个输出流都管理一个缓冲区，用来保存程序读写的数据。例如，如果程序执行如下语句： std::cout &lt;&lt; "Please enter a value:"; 文本串可能立即打印出来，但也可能被操作系统保存在缓冲区中，随后再打印。而导致缓冲刷新的原因有很多： 程序正常结束，即main函数的return被执行时，会刷新缓冲。 缓冲区满时，会刷新缓冲。 使用endl等操纵符，会显式刷新缓冲区。 用操纵符unitbuf设置流的内部状态，从而清空缓冲区。 因为cerr是默认设置unitbuf的，所以写到cerr的内容会立即刷新，会被立即打印出来 当读写被关联的流时，关联到的流的缓冲区会被刷新。例如，默认情况下，cin和cerr都关联到cout，所以读写cin或cerr都会导致cout的缓冲区被刷新。 除了使用操纵符endl刷新缓冲区外，还可以使用flush和ends： std::cout &lt;&lt; "hi!" &lt;&lt; std::endl; //换行后刷新缓冲区 std::cout &lt;&lt; "hi!" &lt;&lt; std::ends; //输出空字符后刷新缓冲区 std::cout &lt;&lt; "hi!" &lt;&lt; std::flush; //直接刷新缓冲区，不附加任何额外字符 如果想在每次输出操作后都立即刷新缓冲区，可以使用unitbuf操纵符。它告诉流在接下来的每次写操作后都执行一次flush操作，直到使用nounitbuf重置流为止，才会恢复使用正常的系统管理的缓冲区刷新机制。 std::cout &lt;&lt; std::unitbuf; //之后的所有输出操作都会立即刷新缓冲区 //任何输出操作都立即刷新，无缓冲 std::cout &lt;&lt; std::nounitbuf; //回到正常的缓冲方式 如果程序异常终止，输出缓冲区是不会被刷新的。就有可能会导致程序崩溃后，输出的数据依然留在缓冲区中等待被打印。这对一些输出的调试代码可能会有影响，导致调试困难。应该尽量让调试输出的错误或者警告信息立即刷新缓冲区。 交互式系统通常应该关联输入流和输出流。这意味着在读操作之前，缓冲区都会被刷新一次，留在缓冲区中的内容都会被打印出来。 文件输入输出 当一个fstream对象被销毁时，其成员函数close会自动被调用。 每个流都有一个关联的文件模式，用来支出如何使用文件。 文件模式 含义 in 以读方式打开 out 以写方式打开 app 每次写操作前都定位到文件末尾 ate 打开文件后立即定位到文件末尾 trunc 截断文件，及文件内容会被清除 binary 以二进制方式进行IO 与ifstream关联的文件默认以in模式打开；与ofstream关联的文件默认以out模式打开；与fstream关联的文件默认以in和out模式打开。 默认情况下，即使没有指定trunc，以out模式打开的文件也会被截断。为了保留以out模式打开的文件的内容，必须同时指定app模式（将数据追加写到文件末尾）或in模式（同时读写文件）。 //下面三条语句中，文件的原有内容都会被丢弃 std::ofstream out("file1"); //隐含以out模式打开文件并截断文件 std::ofstream out2("file1",std::ofstream::out); //隐含地截断文件 std::ofstream out3("file1", std::ofstream::out | std::ofstream::trunc); //下面两条语句，打开文件后会保留文件原有内容 std::ofstream out4("file1", std::ofstream::app); std::ofstream out5("file1", std::ofstream::out | std::ofstream::app); string流 stringstream特有的相关函数如下（其中sstream是istringstream、ostringstream、stringstream中的一种）： 函数 含义 sstream strm strm是一个未绑定的stringstream对象 sstream strm(s) strm是一个sstream对象，保存string s的一个拷贝。其构造函数是explicit的。即不支持隐式类型转换。 strm.str() 返回strm所保存的string的拷贝 strm.str(s) 将string s拷贝到strm中，返回void 在Info.txt中有如下信息（姓名和电话号码）： lee 13281171818 13381171810 liu 13531471012 ma 15542171568 13081151819 13232273848 现在设计如下程序，可读出并保存文件中的人物的电话信息： struct CPersonInfo { public: std::string m_Name; std::vector &lt;std::string> m_PhonesNumber; }; int main() { std::vector&lt;CPersonInfo> PersonsInfo; std::ifstream Fin("Info.txt"); std::string Line; while (getline(Fin, Line)) { CPersonInfo Info; std::istringstream Sin(Line); Sin >> Info.m_Name; std::string Number; while (Sin >> Number) Info.m_PhonesNumber.push_back(Number); PersonsInfo.push_back(Info); } Fin.close(); return 0; } 其中，字符串Line中的数据被全部读出后，同样会触发“文件结束”信号，在Sin上的下一个读取操作会失败。 istringstream通常被用来作字符串的拆分、解析等等操作。 当我们逐步构造输出，希望最后一起打印时，ostringstream是很有用的。例如，我们希望把上面代码PersonsInfo中存储的电话号码转换一下格式（把13281171818转换成132-8117-1818），然后把所有人的信息输出到窗口上： struct CPersonInfo { public: std::string m_Name; std::vector &lt;std::string> m_PhonesNumber; }; void formatPhoneNumber(std::string &amp;vioPhoneNumber) { if (vioPhoneNumber.size() != 11) { std::cerr &lt;&lt; "Phone number is not valid!" &lt;&lt; std::endl; return; } vioPhoneNumber.insert(vioPhoneNumber.begin() + 3, '-'); vioPhoneNumber.insert(vioPhoneNumber.begin() + 8, '-'); } int main() { std::vector&lt;CPersonInfo> PersonsInfo; std::ifstream Fin("Info.txt"); std::string Line; while (getline(Fin, Line)) { CPersonInfo Info; std::istringstream Sin(Line); Sin >> Info.m_Name; std::string Number; while (Sin >> Number) Info.m_PhonesNumber.push_back(Number); PersonsInfo.push_back(Info); } Fin.close(); std::ostringstream Sout; for (auto &amp;Info : PersonsInfo) { Sout &lt;&lt; Info.m_Name&lt;&lt;" "; for (auto &amp;PhoneNumber : Info.m_PhonesNumber) { formatPhoneNumber(PhoneNumber); Sout &lt;&lt; PhoneNumber &lt;&lt; " "; } Sout &lt;&lt; std::endl; } std::cout &lt;&lt; Sout.str(); return 0; } &nbsp; 参考文献：《C++Primer第五版》]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++Primer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++Primer第七章 类]]></title>
    <url>%2F2018%2F01%2F21%2FC%2B%2BPrimer%E7%AC%AC%E4%B8%83%E7%AB%A0%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[定义抽象数据类型 定义在类内部的函数是隐式的内联(inline)函数。调用内联函数是没有运行时开销的。 用对象obj调用其成员函数getName时： CObj obj; std::string Name = obj.getName(); 编译器会把obj对象的地址传递给getName函数的隐式形参this，可以等价地认为编译器将该调用重写成了如下形式： //伪代码，用于说明成员函数调用的实际执行过程 std::string Name = CObj::getName(&amp;obj); this是一个常量指针，不允许改变this中保存的地址。 C++允许把const放在成员函数的形参列表之后，此时该const表示this是一个指向常量的指针，声明的函数也是常量成员函数。由于常量成员函数里的this是指向常量的指针，所以常量成员函数不能改变其对象的数据成员。 常量对象，以及常量对象的引用或指针都只能调用常量成员函数。 编译器分两步处理类：首先编译成员的声明，然后才轮到成员函数体（如果有的话）。因此，成员函数体可以随意使用类中的其他成员而无须在意这些成员出现的次序。 一般来说，如果非成员函数是类接口的组成部分，则这些函数的声明应该与类在同一个头文件内。 对如下函数： void print(std::ostream &amp;os) { os &lt;&lt; "There is an ostream parameter." &lt;&lt; std::endl; } 因为IO类属于不能被拷贝的类型，因此我们只能通过引用来传递它们。而且因为读写操作都会改变流的内容，所以都只是普通引用类型的参数，而非常量引用。 不同于其他成员函数，构造函数不能被声明成const的。当我们创建一个const对象时，直到构造函数完成初始化过程，对象才能真正取得其“常量”属性。因此，构造函数在const对象的构造过程中可以向其写值。 含有内置类型或符合类型成员的类应该在类的内部初始化这些成员，或者定义一个自己的默认构造函数。否则用户在创建类的对象时就可能得到未定义的值。11.有的时候编译器不能为某些类合成默认的构造函数。例如，如果类中包含一个其他类类型的成员且这个成员的类型没有默认构造函数，那么编译器将无法初始化该成员。 我们可以使用类内初始值来初始化数据成员：class CData { private: int m_Data = 0; }; 如果类的内置变量没有类内初始值，且没有构造函数来初始化它，那么它的值有可能就会是未定义的（有的编译器可能不支持类内初始值）。 在C++11新标准中，如果我们需要默认的行为，可以通过在参数列表后面写上=default来要求编译器生成默认构造函数。和其他函数一样，如果=default在类的内部，则默认构造函数是内联的；如果它在类的外部，则默认情况下不是内联的。class CData { public: CData() = default; private: int m_Data = 0; }; 构造函数不应该轻易覆盖掉类内的初始值，除非新赋的值与原值不同。如果编译器不能使用类内初始值，则所有构造函数都应该显式地初始化每个内置类型的成员。 使用vector或者string的类能避免分配和释放内存带来的复杂性，比直接使用动态数组要好。 访问控制与封装 类可以允许其他类或者函数访问它的非公有成员，方法是令其他类或者函数称成为它的友元。 友元不是类的成员也不受所在区域访问控制级别的约束。 一般来说，最好在类定义或结束前的位置中声明友元。 class CData { friend void printData(const CData&amp; vData); public: CData(int vData) :m_Data(vData) { printData(*this); } private: int m_Data = 0; }; void printData(const CData&amp; vData) { std::cout &lt;&lt; vData.m_Data &lt;&lt; std::endl; } 类的其他特性 如果我们已经定义了一个构造函数，则编译器不会自动生成默认构造函数。如果此时需要默认构造函数需要显式地把它声明出来（可以使用=default）。 一个可变数据成员（mutable）永远不会是const，即使它是const对象的成员。因此，一个const成员函数可以改变一个可变成员的值： class CData { public: CData() = default; int fetchData() const; private: mutable int m_Data = 0; }; int CData::fetchData() const { return ++m_Data; } 当我们提供一个类内初始值时，必须以=或者花括号表示。 class CData { public: CData(int vData) :m_Data(vData) {} private: int m_Data = 0; }; class CDataSet { private: std::vector&lt;CData> m_DataSet{ CData(41) }; }; 一个const成员函数如果以引用的形式返回*this，那么它的返回类型将是常量引用。 我们可以仅声明类而暂时不定义它： class CData; 这种声明有时被称作前向声明，它向程序中引入了名字CData并且指明CData是一种类类型。对于类型CData来说，在它声明之后定义之前，它都一直是一个不完全类型，也就是说，此时我们只知道CData是一个类类型，但是不清楚它到底包含哪些成员。 友元函数能定义在类的内部，这样的函数是隐式内联的。需要注意的是，友元关系不存在传递性，即朋友的朋友不一定是我的朋友，它不一定可以访问我。 类的作用域 在类的外部定义成员函数时，一旦遇到类名，剩余的部分（包括参数列表、函数体等等）就都在类的作用域之类了。所以在参数列表以及函数体中可以直接使用类内的成员而无须通过作用域符显示声明其作用域，但是由于函数返回类型位于类名之前，所以函数返回类型中一旦用到类内的成员，需要显示声明其属于哪一个类： class CData { public: CData() = default; CData(int vData) :m_Data(vData) {} private: int m_Data = 0; }; class CDataSet { public: using DataSet = std::vector&lt;CData>; const DataSet&amp; getDataSet() const; private: DataSet m_DataSet{ CData(41) }; }; const CDataSet::DataSet&amp; CDataSet::getDataSet() const { return m_DataSet; } 如果在类外定义getDataSet函数时，去掉DataSet&amp;前面的CDataSet::将无法通过编译，因为函数返回值类型在类名之前，处于类作用域之外。 编译器处理完类中的全部声明后才会处理成员函数的定义。 构造函数再探 如果成员是const、引用或者属于某种未提供默认构造函数的类类型时，我们必须通过内类初始值或者构造函数初始化列表的方式来初始化这些成员，而不能再构造函数体内部通过赋值语句来初始化： class CData { public: CData()= default; CData(int vData) :m_Data(vData), m_DataID2(0) { m_DataID3 = 0; //错误，不能在构造函数体内部为const成员赋值 } private: int m_Data = 0; const int m_DataID = 0; const int m_DataID2; const int m_DataID3; }; 上面程序中，对成员m_DataID和m_DataID2的初始化都是合法的，但是对m_DataID3的赋值是不合法的 。 在很多类中，初始化和赋值的区别事关底层效率：前者直接初始化数据成员，后者先初始化再赋值。 成员的初始化顺序与它们在类定义中的出现顺序一致：第一个成员先被初始化，然后第二个…。而构造函数初始值列表中初始值的前后位置关系不会影响实际的初始化顺序。 class CData { friend void printData(const CData&amp; vData); public: CData()= default; //m_DataID是未定义的，因为m_Data先定义，m_DataID2后定义 CData(int vData) :m_Data(vData), m_DataID2(0), m_DataID(m_DataID2) { printData(*this); } private: int m_Data = 0; int m_DataID = 1; int m_DataID2 = 2; }; void printData(const CData&amp; vData) { std::cout &lt;&lt; vData.m_DataID &lt;&lt; " " &lt;&lt; vData.m_DataID2 &lt;&lt; std::endl; } 所以，最好令构造函数初始值列表里的顺序与成员成名的顺序一致。而且如果可能的话，尽量避免使用一个成员去初始化另一个成员。 C++11允许定义所谓的委托构造函数。一个委托构造函数使用它所属类的其他构造函数执行它自己的初始化过程，或者说把它自己的一些（或者全部）职责委托给了其他构造函数。 class CData { public: CData()= default; CData(int vData) :CData(vData, 0) { } //委托构造函数 CData(int vData, int vDataID) :m_Data(vData), m_DataID(vDataID) {} private: int m_Data = 0; int m_DataID = 1; }; 值得注意的是，委托构造函数不能具有其他成员初始值设定项。如下面的委托构造函数是非法的： CData(int vData, int vDataID) :m_DataID(vDataID), CData(vData) {} //非法，委托构造函数不能具有其他成员初始值设定项 在实际中，如果定义了其他构造函数，那么最好也提供一个默认构造函数。 如下程序： class CData { public: CData()= default; CData(const std::string&amp; vDataName) :m_DataName(vDataName) { } void printOtherName(const CData&amp; vData) { std::cout &lt;&lt; vData.m_DataName &lt;&lt; std::endl; } private: int m_Data = 0; std::string m_DataName; }; int main() { CData Data("FirstData"); std::string str = "SecondData"; Data.printOtherName(str); //合法 Data.printOtherName("ThirdData"); //非法 return 0; } 在执行Data.printOtherName(str);函数时，编译器会把str隐式地转换为CData对象，但是编译器只会自动地执行一步类型转换，所以无法将C字符串ThirdData先转换为string对象，再转换为CData对象。 值得注意的是，这种隐式转换仅在调用时只有一个实参的时候才有效。如下程序是非法的： class CData { public: CData()= default; CData(const std::string&amp; vDataName, int vData) :m_DataName(vDataName),m_Data(vData) { } void printOtherName(const CData&amp; vData) { std::cout &lt;&lt; vData.m_DataName &lt;&lt; std::endl; } private: int m_Data = 0; std::string m_DataName; }; int main() { CData Data("FirstData",1); std::string str = "SecondData"; Data.printOtherName(str, 2); //非法，实参不止一个时，无法执行隐式转换 return 0; } 如果不想要构造函数执行这种隐式转换，可以为构造函数添加explicit关键字： class CData { public: CData()= default; explicit CData(const std::string&amp; vDataName) :m_DataName(vDataName) { } void printOtherName(const CData&amp; vData) { std::cout &lt;&lt; vData.m_DataName &lt;&lt; std::endl; } private: int m_Data = 0; std::string m_DataName; }; int main() { CData Data("FirstData"); std::string str = "SecondData"; Data.printOtherName(str); //非法，explicit构造函数不允许执行隐式转换 CData Data3 = "ThirdData"; //非法，explicit构造函数不允许执行隐式转换 return 0; } 甚至CData Data3 = &quot;ThirdData&quot;;这样的初始化都不可以，因为它需要先把字符串隐式转换为CData对象，再拷贝给Data3。 还要注意的是，只能在内类声明构造函数时使用explicit关键字，不能在类外部定义构造函数时也加上explicit关键字。 尽管构造函数不能是const的，但是字面值常量类的构造函数可以是constexpr函数。事实上，一个字面值常量类必须至少提供一个constexpr构造函数。 constexpr构造函数通常都应该是空的。 类的静态成员 类的静态成员存在于任何对象之外，对象中不包含任何与静态数据成员有关的数据。类似的，静态成员函数也不与任何对象绑定在一起，它们不包含this指针。所以，静态成员函数不能声明成const的，而且我们也不能在static函数体内使用this指针，这一限制既适用于this的显式使用，也对调用非静态成员的隐式使用有效（因为调用非静态成员函数需要隐式用到this）。 当在类的外部定义静态成员时，不能重复static关键字，它只能出现在类内部的声明语句中。 即使一个常量静态数据成员在类内部被初始化了，通常情况下也应该在类的外部定义一下该成员。 静态成员可以是不完全类型，而非静态数据成员必须是完全类型。如下程序 class CData { public: //... private: static CData m_DataObj; //正确，静态成员可以是不完全类型 CData *m_pDataObj2; //正确，指针成员可以是不完全类型 CData m_DataObj3; //错误，非静态数据成员不可以是不完整类型 }; 静态成员可以作为函数的默认实参，但是非静态成员不可以： class CData { public: void print(const CData&amp; vData = m_DataObj); private: static CData m_DataObj; }; &nbsp; 参考文献：《C++Primer第五版》]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++Primer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Blog迁移]]></title>
    <url>%2F2018%2F01%2F03%2FBlog%E8%BF%81%E7%A7%BB%2F</url>
    <content type="text"><![CDATA[安装git和nodejs。 在任意路径下安装hexo：npm install -g hexo 在博客文件夹下，初始化hexo和安装依赖包：hexo init npm install 在新机器上生成SSH密钥：ssh-keygen -t rsa -C “你的邮箱地址” 会提示输入用户名密码等，连续按3个回车就行（即设置密码为空） 在C:\Users\Administrator.ssh路径下，打开id_rsa.pub文件，复制全文，在GitHub里Add SSH key，粘贴进去。 检查密钥是否设置成功：$ ssh -T git@github.com 如果是类似下面的反馈：The authenticity of host 'github.com (207.97.227.239)' can't be established. RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48. Are you sure you want to continue connecting (yes/no)? 输入yes就好，然后类似得到反馈：Hi cnfeat! You've successfully authenticated, but GitHub does not provide shell access. 表明以及可以通过SSH链接到GitHub了。 接下来需要设置用户名和邮箱信息：$ git config --global user.name "cnfeat"//用户名 $ git config --global user.email "cnfeat@gmail.com"//填写自己的邮箱 将原来博客根目录下的.deploy_git、public、source、themes、_config.yml等文件夹或文件拷贝到新机器的博客根目录下。 到此，博客就迁移成功了，可以在新机器上正常使用。]]></content>
      <categories>
        <category>博客配置</category>
      </categories>
      <tags>
        <tag>Blog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++Primer第六章 函数]]></title>
    <url>%2F2017%2F12%2F20%2FC%2B%2BPrimer%E7%AC%AC%E5%85%AD%E7%AB%A0%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[函数基础 用void作形参是C语言风格。 局部静态变量会被默认初始化。 如果我们修改了项目中的一个源文件，那么只需要重新编译那个改动了的文件。大多数编译器提供了分离式编译每个文件的机制，这一过程通常会产生一个后缀名是.obj（Windows）或.o（UNIX）的文件，后缀名的含义是该文件包含对象代码（object code）。 参数传递 在C++语言中，建议使用引用类型的形参替代指针。 和其他初始化过程一样，当用实参初始化形参时会忽略掉形参的顶层const。即对于函数void fcn(const int i){}，传入的形参既能是const int，也能是int。 因为不能拷贝数组，所以我们无法以值传递的方式使用数组参数。因为数组会被转换成指针，所以当我们为函数传递一个数组时，实际上传递的是指向数组首元素的指针。 如果确实像传递数组作为参数怎么办呢？有以下几种方案： 在数组末尾指定一个特殊标记表示数组结束。如C风格字符串在末尾会有一个空字符’\0’，则可以按照如下方式处理C风格字符数组： void print(const char *vCP) { if (vCP) while (*vCP) std::cout &lt;&lt; *vCP++; } 传递数组的首元素指针和尾后指针： void print(const char *vBeg, const char *vEnd) { while (vBeg != vEnd) std::cout &lt;&lt; *vBeg++; } 额外传递一个表示数组大小的参数： void print(const char *vCP, int vSize) { for (size_t i = 0; i != vSize; ++i) std::cout &lt;&lt; vCP[i]; } 用数组的引用作为形参： void print(char(&amp;vArr)[7]) { for (auto Elem : vArr) std::cout &lt;&lt; Elem; } 这种方式虽然可以直接传递数组，但是缺点也很明显：数组大小是固定的。在后面第十六章会介绍怎样让它可以作用与任意大小数组的方式。 数组实际上是数组的数组，所以传递多维数组作为参数的形式如下： void print(int(*vMatrix)[3], int vRowSize, int vColSize) { for (size_t i = 0; i &lt; vRowSize; ++i) { for (size_t k = 0; k &lt; vColSize; ++k) std::cout &lt;&lt; vMatrix[i][k] &lt;&lt; " "; std::cout &lt;&lt; std::endl; } } int main() { int Arr[4][3] = { 1,2,3, 4,5,6, 7,8,9, 10,11,12 }; print(Arr, 4, 3); return 0; } 有形参的main函数形式如下： int main(int argc, char *argv[]) {} 第二个形参argv是一个数组，它的元素是指向C风格字符串的指针；第一个形参argv表示数组中字符串的数量。 因为第二个形参是数组，所以main函数也可以是如下形式： int main(int argc, char **argv) {} 其中argv指向char*。 当实参传给main函数之后，argv的第一个元素指向程序的名字或者一个空字符串，接下来的元素依次传递命令行提供的实参。最后一个指针之后的元素值保证为0。以下面的命令行为例： prog -d -o ofile data0 命令行提供的实参传入main函数之后，形参argc应该等于5，argv应该包含如下C风格字符串： argv[0] = "prog"; argv[1] = "-d"; argv[2] = "-o"; argv[3] = "ofile"; argv[4] = "data0"; argv[5] = 0; 当使用argv中的实参时，一定要记得可选的实参从argv[1]开始，argv[0]保存程序的名字，而非用户输入。 为了编写能处理不同数量实参的函数，C++11新标准提供了两种主要的方法：如果所有的实参类型相同，可以传递一个名为initializer_list的标准库类型；如果实参的类型不同，我们可以编写一种特殊的函数，也就是所谓的可变参数模板，这在第16章会有详细介绍。 initializer_list用于表示某种特定类型的值的数组，定义在同名的头文件中。和vector类似，它也是一种模板类型；和vector不一样的是，initializer_list对象中的元素永远是常量值，所以我们无法修改initializer_list对象中元素的值。实例代码如下： void Msg(std::initializer_list&lt;std::string> vIL) { for (const auto &amp;Elem : vIL) std::cout &lt;&lt; Elem &lt;&lt; " "; std::cout &lt;&lt; std::endl; } int main() { Msg({ "function","okay" }); return 0; } 可以看到，如果想向initializer_list形参中传递一个值的序列，则必须把序列放在一对花括号内。而且因为initializer_list由begin和end成员，所以可以使用范围for循环访问其中的元素。 返回类型和return语句 不要返回局部对象的引用或指针。因为函数终止意味着局部变量的引用或指针将指向不再有效的区域，值将是未定义的（不可预知的任意值）。 C++11新标准规定，函数可以返回花括号包围的值的列表： std::vector&lt;std::string> getInfo() { return{ "function","okay" }; } 如果程序达到了main函数的结尾处而且没有return语句，编译器将隐式地插入一条返回0的return语句。 main函数返回0表示执行成功，返回其他值表示执行失败。其中非0值得具体含义视机器而定。 为了让返回值与机器无关，cstdlib头文件定义了两个预处理变量：EXIT_FAILURE、EXIT_SUCCESS，分别表示失败和成功。 if (Success) return EXIT_SUCCESS; else return EXIT_FAILURE; 如果我们想定义一个返回数组指针的函数，则数组的维度必须跟在函数名字之后。形式如下： int(*func(int i))[10] {} 我们先从内向外理解：func(int i)说明func是一个函数，参数是整型，右边的*表示函数func的返回值是一个指针，然后从右至左理解：(*func(int i))的右边是[10]，表示(*func(int i))是一个大小为10的数组的名字，左边是int，说明数组中的元素是整型。所以func函数返回的是一个指向大小为10的数组的指针。 可以看出，上面的定义比较繁琐，可以使用类型别名来简化： using ArrI = int[10]; ArrI *func(int i) {} 注意ArrI只代表一个大小为10的数组，想要函数返回指向数组的指针，别忘了函数名前面的*。 C++11还提供了另一种简化定义返回数组指针的函数的方法：使用尾置返回类型。如下： auto func(int i)->int(*)[10] {} 表示函数接受一个int类型的实参，返回一个指针，该指针指向含有10个整数的数组。 当然，如果我们明确知道函数返回的是指向哪个数组的指针，那么我们可以直接使用decltype来指定函数返回类型： int g_Odd[] = { 1,3,5,7 }; int g_Even[] = { 0,2,4,6 }; decltype(g_Odd) *func(int i) { return (i % 2) ? &amp;g_Odd : &amp;g_Even; } 由于decltype不会把数组名转换为对应的指针，所以decltype的结果仍然是个数组，所以必须在函数名前面加上一个*符号才能表示返回的是指针。 函数重载 如果形参是某种类型的指针或引用，则通过区分其指向的是常量对象还是非常量对象可以实现函数重载，此时的const是底层的： void func(CData &amp;vData); void func(const CData &amp;vData); const_cast和重载： 如下代码： const std::string &amp;getShorterString(const std::string &amp;vS1, const std::string &amp;vS2) { return vS1.size() &lt;= vS2.size() ? vS1 : vS2; } 可以对这个函数传入两个非常量的string对象，但是如果我们想得到的也是非常量的返回结果呢？这时我们可以重载一个函数： std::string &amp;getShorterString(std::string &amp;vS1, std::string &amp;vS2) { auto &amp;r = getShorterString(const_cast&lt;const std::string&amp;>(vS1), const_cast&lt;const std::string&amp;>(vS2)); return const_cast&lt;std::string&amp;>(r); } 这个重载的函数首先将它的实参强制转换为对const的引用，然后调用了原先的const版本的getShortString函数，最后将返回值又强制转换回非常量的string&amp;。由于返回的字符串实际上是初始时是非常量的，所以这种转换是安全的。 值得注意的是，auto后面一定要有引用符&amp;，否则就是新生成了一个局部变量，然后返回了这个局部变量的引用。 有多余一个函数可以匹配，但是每一个都不是明显的最佳选择，此时也将发生错误，称为二义性调用。 特殊用途语言特性 调用函数一般比直接求等价表达式的值要慢一些，因为调用函数时会存在保存寄存器、拷贝实参等等操作。 内联函数可以避免函数调用的开销。因为将函数指定为内联函数，通常就是将它在每个调用点上“内联地”展开。形式如下： inline const std::string &amp;getShorterString(const std::string &amp;vS1, const std::string &amp;vS2) { return vS1.size() &lt;= vS2.size() ? vS1 : vS2; } 一般来说，内联机制用于优化规模较小、流程直接、频繁调用的函数。 constexpr函数是指能够用于常量表达式的函数。即下面这样的函数： constexpr int new_sz() { return 42; } constexpr int foo = new_sz(); 需要注意的是，要能作用于常量表达式才能算作真正的constexpr函数。编译器在执行上述初始化过程的时候，会把对constexpr函数的调用替换成其结果值。为了能在编译过程中随时展开，constexpr函数被隐式地指定为内联函数。 定义它时需要遵循几项约定：函数的返回类型及所有形参的类型都得是字面值类型（即内置的基础类型），而且函数体中必须有且只有一条return语句： class CData { public: int m_Data = 10; }; constexpr CData&amp; getData(const CData &amp;vData) { if (vData.m_Data) //流程控制语句不允许出现在constexpr函数中，因为可能出现多个return return vData; else return new CData; //只能有一个return语句 } int main() { const CData Data; constexpr CData Data1 = getData(Data); //constexpr函数的参数和返回值都必须是字面值类型 return 0; } 虽然下面的程序可以通过，但由于它并没有把constexpr函数用于常量表达式，所以不能说明getData函数就是一个真正的constexpr函数： class CData { public: int m_Data = 10; }; constexpr CData&amp; getData(const CData &amp;vData) { return vData; } int main() { const CData Data; std::cout &lt;&lt; getData(Data).m_Data &lt;&lt; std::endl; return 0; } 还有一点需要注意的是，constexpr函数不一定返回常量表达式。 通常将内联函数和constexpr函数定义在头文件中。 assert是一种预处理宏，它定义在cassert头文件中。因为宏处理名字由预处理器而非编译器管理，所以使用预处理名字时可以直接使用而无须提供using声明。 assert的行为依赖于一个名为NDEBUG的预处理变量的状态。如果定义了NDEBUG，则assert什么也不做。默认状态下没有定义NDEBUG，此时assert将执行运行时检查。我们可以使用#define语句定义NDEBUG，从而关闭调试状态。也可以通过编译器的命令行选项来做这件事。 我们可以把assert当成调试程序的一种辅助手段，但是不能用它替代真正的运行时逻辑检查，也不能替代程序本身应该包含的错误检查。 除了用于assert外，我们也可以使用NDEBUG编写自己的条件调试代码。如下程序： void print() { #ifndef NDEBUG std::cerr &lt;&lt; __FUNCTION__ &lt;&lt; " To do..." &lt;&lt; std::endl; #endif } 如果NDEBUG未定义，将执行#ifndef和#endif之间的代码；如果定义了NDEBUG，这些代码将被忽略掉。 在VS环境下，__FUNCTION__表示当前调试的函数的名字。编译器为每个函数都定义了FUNCTION，它是const char的一个静态数组，用于存放函数的名字。 除此之外，C++编译器还定义了另外4个对程序调试很有用的名字： __FILE__：存放当前文件名的字符串字面值 __LINE__：存放当前行号的整型字面值 __TIME__：存放文件编译时间的字符串字面值 __DATE__：存放文件编译器日期的字符串字面值 函数匹配 函数匹配的基本思想是：实参类型与形参类型越接近，它们匹配得越好。具体匹配标准是：如果有且只有一个函数满足最佳匹配（类型最接近），则匹配成功。 如下面两个重载函数： void f(int, int); void f(double, double); 如果调用f(41,3.14);，对一个实参来说，f(int,int)是其最佳匹配函数，对第二个参数来说f(double,double)是其最佳匹配函数。因为杜宇不同的实参会有不同的最佳匹配函数，编译器无法从整体上判断孰优孰劣，所以会发出二义性调用的错误。 调用重载函数时，实参应尽量避免强制类型转换（const_cast除外）。否则，说明我们设计的形参集合不合理。 对于下列重载函数调用也是有二义性的： void f(long); void f(float); f(3.14); //错误，二义性调用 字面值3.14的类型是double，它既能转换成long也能转换成float，所以具有二义性调用。 函数指针 函数的类型由它的返回类型和形参共同决定，与函数名无关。对于下面的函数： bool compareLength(const std::string &amp;, const std::string &amp;); 想要声明指向该函数的指针，只需要用指针替换函数名即可： bool (*pf)(const std::string &amp;, const std::string &amp;); pf指向一个函数，该函数具有两个const string引用类型的参数，返回值是bool。 注意，*pf两端一定要加上括号，否则pf是一个返回值为bool指针的函数，而不是函数指针。 对于pf的赋值，下面两种方式都可以： pf = compareLength; pf = &amp;compareLength; //取地址符是可选的 对于pf的调用，下面两种方式都可以： (*pf)("hello", "goodbye"); pf("hello", "goodbye"); //解引用符是可选的 把函数作为参数时，会自动把函数转换成指向函数的指针： void print(const std::string &amp;vS1, const std::string &amp;vS2, bool compareLength(const std::string &amp;, const std::string &amp;)); 其中第三个参数是函数类型，会被自动转换为函数指针。等价于下面的形式： void print(const std::string &amp;vS1, const std::string &amp;vS2, bool(*pf)(const std::string &amp;, const std::string &amp;)); 可以使用别名来简化函数指针类型： typedef bool(*FuncP)(const std::string &amp;, const std::string &amp;); typedef decltype(compareLength) *FuncP2; //等价的类型 需要注意的是，decltype返回函数类型，它不会将函数类型自动转换成指针类型。所以需要在前面加上*才能得到指针。 此时，print函数可以是如下形式： void print(const std::string &amp;vS1, const std::string &amp;vS2, FuncP); void print(const std::string &amp;vS1, const std::string &amp;vS2, FuncP2); //等价的声明 将函数类型作为形参时，会自动转换为函数指针，但将函数类型最为返回值类型时，这种转换不会发生。如下： using F = bool(const std::string &amp;, const std::string &amp;); //F是函数类型，不是指针 using PF = bool(*)(const std::string &amp;, const std::string &amp;); //PF是函数指针 F f1(int); //错误：F是函数类型，f1不能返回一个函数 F *f2(int); //正确：显式指定返回类型是指向函数的指针 PF f3(int); //正确：PF是函数指针，f3返回指向函数的指针 当然，我们也可以使用尾置返回类型的方式来声明返回函数指针的函数： auto f1(int) -> int(*)(const std::string &amp;, const std::string &amp;); 而且，如果我们明确知道返回的函数是哪一个，就可以使用decltype来简化函数指针的形式： bool smallerString(const std::string &amp;, const std::string &amp;); bool largerString(const std::string &amp;, const std::string &amp;); decltype(smallerString) *getFunc(int vFuncType); 牢记decltype不会把函数类型转换为函数指针，想要表示指针必须得加上*。&nbsp; 参考文献：《C++Primer第五版》]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++Primer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++Primer第五章 语句]]></title>
    <url>%2F2017%2F12%2F16%2FC%2B%2BPrimer%E7%AC%AC%E4%BA%94%E7%AB%A0%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[简单语句 使用空语句时应该加上注释，从而令读这段代码的人知道该语句是有意省略的。 条件语句 对于switch-case语句，case后的值必须是整型常量表达式。如下： char ch; std::cin >> ch; int ival = 41; switch (ch) { case 3.14: //错误，3.14不是整数 case ival: //错误，ival不是常量 //... } 即使不在default标签下做任何工作，定义一个default标签也是有用的。其目的在于告诉程序的读者，我们已经考虑到了默认的情况，只是目前什么也没做。 尽量不要在switch-case中定义新的局部变量。如下： bool b = false; switch (b) { case true: int jval = 0; //错误，不能绕过一个显示初始化的变量 std::string str; //错误，不能绕过一个隐式初始化的变量 break; case false: jval = 10; break; } 上面的代码编译会报错，但是下面的代码能够正常运行： bool b = false; switch (b) { case true: int jval; break; case false: jval = 10; break; } 这是因为case会跳过一些语句的执行，在第一份代码中int jval = 0;这个初始化语句有其对应的汇编代码mov dword ptr [jval],0，在b为false时会被跳过，导致在case b下不能使用jval这个变量（为什么不能使用还是个迷，是没有分配内存还是怎么的？），所以程序报错；对于std::string str;也是一样的，因为string类有其构造函数，会隐式的初始化string类对象。还有一个原因，switch结束后会调用str的析构函数，但是由于定义str的语句可能被跳过，导致其没有执行配对的构造函数，析构的时候就很容易出错。而第二份代码中，int jval;只是对变量的定义，不是初始化，没有对应的汇编代码，所以并不会被跳过，而且case只是一个标签（类似goto语句的标签），在任何一个case下定义的变量，其作用域会从定义处一直到switch结束（不加大括号时case下的语句虽然形式上有缩进，但并不是一个作用域块，可以看作是一段顺序排列的语句）。所以在case true下定义的jval变量，在case false下依然是可见的，所以第二份代码能够正常运行。 不过，在switch-case中定义变量很容易出错，还是尽量不要在里面定义变量，即使要定义变量，也要在case后加上大括号，如下： bool b = false; switch (b) { case true: { int jval = 0; break; } case false: { break; } } 迭代语句 定义在while条件部分或者while循环体内的变量每次迭代都经历从创建到销毁的过程。即while循环中定义的变量会被反复创建和销毁。 for小括号里定义的所有变量都必须是同一个类型。如下： for (int i = 0, double = 0.0; i &lt; 10; ++i) {} //错误，只能定义同种类型的变量 范围for语句(for(auto a : array){})执行时，每次迭代都会重新定义循环控制变量a，并将其初始化为序列中的下一个值。 不能通过范围for语句增加或删除vector对象（或其他容器）中的元素。因为在范围for语句中预存了end的值，一旦序列中添加（删除）元素，end函数的值就可能变得无效了。 和while、for不同的是，do-while语句应该在循环最后用一个分号表示语句结束： int i = 0; do { ++i; } while (i &lt; 10); 而且不允许在do-while的while条件部分定义变量。 跳转语句 对于for循环：for(; ; ++i){}，在内部continue之后++i还是要执行的，因为不执行的话循环变量i就不会有变化，循环下去就会一直continue；但是循环内部break之后是不会执行++i的，如下： int i = 0; for (; i &lt; 10; ++i) if (i == 5) break; std::cout &lt;&lt; i &lt;&lt; std::endl; //输出5 try语句块和异常处理 try用于检测原本程序的部分代码，在其中可能用throw抛出一些异常，try外面会有一些catch块来捕获抛出的这些异常。如下： int ival = 0, jval = 0; std::cin >> ival >> jval; if (ival == jval) std::cout &lt;&lt; ival + jval &lt;&lt; std::endl; else std::cerr &lt;&lt; "ival and jval must be same" &lt;&lt; std::endl; 在真实项目中，我们应该尽量让逻辑代码（相加部分的代码）和用户交互的代码（输出错误信息的代码）分离开来。这里我们选择抛出一个异常： try { int ival = 0, jval = 0; std::cin >> ival >> jval; if (ival != jval) throw std::runtime_error("ival and jval must be same"); std::cout &lt;&lt; ival + jval &lt;&lt; std::endl; } catch (std::runtime_error err) { std::cout &lt;&lt; err.what(); } 抛出异常将终止当前try语句块的执行（也有可能终止当前函数，见后面所述），并把控制权移交给能处理该异常的代码。 类型runtime-error是标准库异常类型的一种，定义在stdexcept头文件中。每个标准库异常类都定义了一个名为what的成员函数，这些函数吧没有参数，返回值是C风格字符串（即const char*）。其中runtime-error的what成员函数返回的是初始化一个具体对象时所用的string类型参数的副本。 try-catch寻找处理代码（即catch）的过程与函数调用链刚好相反，会从当前函数开始向上查找对应的处理代码。当异常被抛出时们首先搜索抛出该异常的函数。如果没找到匹配的catch子句，终止该函数，并在调用该函数的函数中继续寻找。以此类推，沿着程序的执行路径逐层回退，直到找到适当类型的catch子句为止。如果最终还是没能找到任何匹配的catch子句，程序转到名为terminate的标准函数库。该函数的行为与系统有关，一般情况下，执行该函数将导致程序非正常退出。对于那些没有任何try语句块的异常，也按照类似的方式处理。 可以看到，try-catch其实还是有一些性能消耗的。 通常情况下，略过部分程序意味着对象处理到一半就戛然而止，从而导致对象处于无效或未完成的状态，或者资源没有正常释放，等等。那些在异常发生期间正确执行了“清理”工作的程序被称作异常安全的代码。然而经验表明，编写异常安全的代码非常困难。 所以对于那些确实要处理异常并继续执行的程序，就要加倍注意了。我们必须清楚异常何时发生，异常发生后程序应如何确保对象有效、资源无泄漏、程序处于合理状态，等等。 当然，对于那些异常发生后终止即可的程序，不需要太关心这些问题。 标准异常： C++定义的标准异常分别定义在4个头文件中： exception头文件定义了最通用的异常类exception。它只报告异常的发生。不提供任何额外信息。 stdexcept头文件定义了几种常用的异常类，详细信息如下： 定义的异常类 含义 exception 最常见的问题 runtime_error 只有在运行时才能检测出的问题 range_error 运行时错误：生成的结果超出了有意义的值域范围 overflow_error 运行时错误：计算上溢 underflow_error 运行时错误：计算下溢 logic_error 程序逻辑错误 domain_error 逻辑错误：参数对应的结果值不存在 invalid_argument 逻辑错误：无效参数 length_error 逻辑错误：试图创建一个超出类型最大长度的对象 out_of_range 逻辑错误：使用一个超出有效范围的值 我们只能以默认初始化的方式初始化exception、bad_alloc和bad_cast对象，不允许为这些对象提供初始值。 其他异常类型的行为恰好相反：应该使用string对象或者C风格字符串初始化这些类型的对象，但是不允许使用默认初始化的方式。当创建此类对象时，必须提供初始值，该初始值含有错误相关的信息。 异常类型只定义了一个名为what的成员函数，该函数没有任何参数，返回值是一个指向C风格字符串的const char*。该字符串的目的是提供关于异常的一些文本信息。如果异常类型有一个字符串初始值，则what返回该字符串，对于其他无初始值的异常类型来说，what返回的内容由编译器决定。&nbsp; 参考文献：《C++Primer第五版》]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++Primer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++Primer第四章 表达式]]></title>
    <url>%2F2017%2F12%2F14%2FC%2B%2BPrimer%E7%AC%AC%E5%9B%9B%E7%AB%A0%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[基础 小整数类型（如bool、char、short等）通常会被提升成较大的整数类型（主要是int）。 当一个对象被用作右值的时候，用的是对象的值（内容）；当对象被用作左值的时候，用的是对象的身份（在内存中地址）。总之，左值是用址，右值是用值。左值右值并不是等号=左侧右侧的意思。 对于如下表达式： int i = f1()*f2(); 我们无法知道到底是f1先执行还是f2先执行，这个调用顺序是不固定的。 对于这种没有指定执行顺序的运算符来说，如果表达式指向并修改了同一个对象，将会引发错误并产生未定义的行为,，程序结果将是不可预知的。如下： int i = 0; std::cout &lt;&lt; i &lt;&lt; " " &lt;&lt;++i &lt;&lt; std::endl; //未定义的 编译器可能先求++i的值再求i的值，此时输出结果是1 1；也可能先求i的值再求++i的值，输出结果是0 1；甚至编译器还可能做完全不同的操作。 建议： - 拿不准的时候最好用括号来强制让表达式的组合关系符合程序逻辑的要求。 - 如果改变了某个运算对象的值，在表达式的其他地方不要再使用这个运算对象。 算术运算符 对大对数运算符来说，布尔类型的运算对象将被提升为int类型。如下： bool b = true; bool b2 = -b; std::cout &lt;&lt; b2 &lt;&lt; std::endl; //输出1，b2是ture！ 参与运算时b将被提升成整数值1，对它求负后的结果是-1，将-1再转换会布尔值将其作为b2的初始值，显然这个初始值不等于0，转换成布尔值后应该为1，所以b2的值是true。 再一次证明，布尔值不应该参与运算。 参与取余运算的运算对象必须是整数类型。余数的符号总是和余数表达式中的被除数一致。m%(-n)等于m%n，(-m)%n等于-(m%n)。 赋值运算符 C++11新标准允许使用花括号括起来的初始值列表作为赋值语句的右侧运算对象： int a = 3.14; int b = { 3.14 }; //运行错误 std::vector&lt;int> vi; vi = { 0,1,2,3,4,5,6 }; 第一条语句运行时正常，a的值将是3，而第二条语句运行时报错：懂double转换到int需要收缩转换。这是因为使用初始值列表来进行赋值的时候，初始值列表里值所占的空间不应该大于目标类型的空间。 赋值运算符满足右结合律，这一点与其他二元运算符不太一样： int ival, jval, *pval; ival = jval = 0; //正确，相当于ival = (jval = 0); ival = pval = 0; //错误，相当于ival = (pval = 0);，不能把指针的值赋给int 递增和递减运算符 对于递增和递减运算符，其前置版本（++i）将对象本身作为左值返回，后置版本则将对象原始值的副本作为右值返回。 前置版本的递增递减运算符避免了不必要的工作，它把值加1后直接返回改变了的运算对象。与之相比，后置版本需要将原始值存储下来以便于返回这个未修改的内容。如果我们不需要修改前的值，那么后置版本的操作就是一种浪费。 后置递增运算符的优先级高于解引用运算符，因此*pbeg++等价于*(pbeg++)。pbeg++把pbeg的值加1，然后返回pbeg的初始值的副本作为其求值结果。 成员访问运算符 解引用运算符的优先级低于点运算符，所以ptr-&gt;mem等价于(*ptr).mem，而非*ptr.mem。后者会报错，因为指针没有名为mem的成员。 对于*pval++，解引用运算符的优先级低于++，所以等价于*(pval++)。 条件运算符 &lt;&lt;运算符比一般的关系运算符、条件运算符的优先级要高（即比逻辑运算符优先级高）。所以： std::cout &lt;&lt; grade &lt; 60 ? "fail" : "pass"; //错误，试图比较cout和60 std::cout &lt;&lt; (grade &lt; 60) ? "fail" : "pass"; //输出1或者0 std::cout &lt;&lt; (grade &lt; 60 ? "fail" : "pass"); //输出pass或者fail 位运算符 位运算符作用于整数类型的运算对象。如果作用于类似char这种类型，会先把char类型的运算对象提升成int型。 由于关于符号位如何处理没有明确的规定，所以强烈建议仅将位运算符用于处理无符号类型。 左移运算符（&lt;&lt;）在右侧插入值为0的二进制位；右移运算符（&gt;&gt;）的行为则依赖于其左侧运算对象的类型，如果该运算对象是无符号类型，则在左侧插入值为0的二进制位；如果该运算符对象是带符号类型，则在左侧插入符号位的副本或值为0的二进制位，如何选择具体视环境而定。 不过对于移出边界之外，两者都是直接舍弃掉。 移位运算符满足左结合律，所以std::cout &lt;&lt; &quot;hi&quot; &lt;&lt; &quot;here&quot; &lt;&lt; std::endl等价于((std::cout &lt;&lt; &quot;hi&quot;) &lt;&lt; &quot;here&quot;) &lt;&lt; std::endl。 移位运算符的优先级不高不低，介于中间：比算术运算符的优先级低，但比关系运算符、赋值运算符和条件运算符的优先级高。 sizeof运算符 sizeof运算符满足右结合律，其所得的值是一个size_t类型的常量表达式，它有两种形式，都是合法的： sizeof(type); sizeof expr; sizeof并不实际计算其运算对象的值，如： CData Data; sizeof Data; //Data的类型的大小，即sizeof(CData) 对引用类型执行sizeof运算得到被引用对象所占空间的大小，但是对指针执行sizeof运算得到指针本身所占空间的大小。 对数组执行sizeof运算得到整个数组所占空间的大小，等价于对数组中所有的元素各执行一次sizeof运算并将所得结果求和。注意，sizeof运算不会把数组转换成指针来处理。 对string对象或vector对象执行sizeof运算只返回该类型固定部分的大小，不会计算对象中的元素占用了多少空间。即只计算静态数据的大小，而非对象里动态分配的数据。 sizeof运算的优先级低于算术运算符，但大于关系运算符等。所以sizeof x + y等价于sizeof (x + y)，sizeof a &lt; b等价于sizeof (a) &lt; b。 逗号运算符 逗号运算符含有两个运算对象，按照从左向右的顺序依次求值，真正的运算结果是右侧表达式的值： int a = (1, 2); // a = 2 int b; b = 1, 2; // b = 1 逗号运算符的优先级是所有运算符中最低的，比赋值运算符还低。 类型转换 在大多数表达式中，比int类型小的整型值首先提升为较大的整数类型。 当数组被用作decltype关键字的参数，或者作为取地址符（&amp;）、sizeof及typeid等运算符的运算对象时，数组名不会被转换为指针。 虽然有时不得不使用强制类型转换，但这种方法本质上是非常危险的。 一个命名的强制类型转换具有如下形式： cast-name&lt;type>(expression) type是转换的目标类型。如果type是引用类型，则结果是左值。cast-name是static_cast、dynamic_cast、const_cast和reinterpret_cast中的一种。 dynamic_cast支持运行时类型识别，第十九章再做详细说明。 static_cast： 任何具有明确定义的类型转换，只要不包含底层const，都可以使用static_cast。如： int i = 3, j = 2; double slope = static_cast&lt;double>(i) / j; 当需要把一个较大的算术类型赋值给较小的类型时，static非常有用（比如上面把double赋给int类型的i）。此时，强制类型转换告诉程序的读者和编译器，我们知道并且不在乎潜在的精度损失。一般来说，如果编译器发现一个较大的算术类型试图赋值给一个较小的类型，就会给出警告信息；但是当我们执行了显示的类型转换后，警告信息就会被关闭了。 static_cast对于编译器无法自动执行的类型转换也非常有用。例如，我们可以使用static_cast找回存在于void*指针中的值： int i = 10; void *p = &amp;i; int *ip = static_cast&lt;int*>(p); double *dp = static_cast&lt;double*>(p); //dp的值不是10.0，是未定义的（本机输出是-9.25596e+61） 不过我们必须保证static_cast强制转换回原来的类型，否则将产生未定义的后果。因为由于类型不同，可能转换后的地址与原始地址不相等了，再加上由于类型大小不一样，也很可能得不到和原来相等的值。 const_cast： const_cast只能改变运算对象的底层const。如： int i = 10; const int *p = &amp;i; int *p2 = const_cast&lt;int*>(p); *p2 = 20; std::cout &lt;&lt; i &lt;&lt; std::endl; //输出20 如果对象本身不是一个常量，使用强制类型转换获得写权限是合法的行为；但是如果对象是一个常量，再使用const_cast后执行写操作将会产生未定义的后果。如下： const int i = 10; const int *p = &amp;i; int *p2 = const_cast&lt;int*>(p); *p2 = 20; std::cout &lt;&lt; i &lt;&lt; std::endl; //输出10 const_cast常常用于有函数重载的上下文中（第六章会有介绍），但是用于其他地方就说明有设计缺陷。 reinterpret_cast： reinterpret_cast通常为运算对象的位模式提供较低层次上的重新解释。如下程序： int i = 10; int *ip = &amp;i; char *cp = reinterpret_cast&lt;char*>(ip); std::cout &lt;&lt; std::string(cp) &lt;&lt; std::endl; //可能导致异常的运行时行为 我们必须牢记cp所指的真实对象是一个int而非字符，如果把cp当做普通的字符指针使用时就可能在运行时发生错误。可以看出，使用reinterpret_cast是非常危险的。 reinterpret_cast本质上依赖于机器，想要安全地使用reinterpret_cast必须对涉及的类型和编译器实现转换的过程都非常了解。 强制类型转换干扰了正常的类型检查，因此强烈建议避免使用强制类型转换，尤其是reinterpret_cast。即使是static_cast和dynamic_cast都不应该频繁使用。 旧式的强制类型转换形式为：type (expr); //函数形式的强制类型转换 (type) expr; //C语言风格的强制类型转换 与命名的强制类型转换相比，旧式的强制类型转换从表现形式上来说不那么清晰明了，容易被看漏，所以一旦转换过程出现问题，追踪起来也更加困难。&nbsp; 参考文献：《C++Primer第五版》]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++Primer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++Primer第三章 字符串、向量和数组]]></title>
    <url>%2F2017%2F12%2F12%2FC%2B%2BPrimer%E7%AC%AC%E4%B8%89%E7%AB%A0%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%90%91%E9%87%8F%E5%92%8C%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[命名空间的using声明 比如我们需要在程序中用cin时，可以用using声明可以从命名空间std中获取它： #include &lt;iostream> using std::cin; int main() { int i; cin >> i; std::cout &lt;&lt; i; return 0; } 头文件里不应该包含using声明。因为头文件的内容会被拷贝到所有引用它的文件中去，如果头文件里有某个using声明，那么每个使用了该头文件的文件就都会有这个声明，对于某些程序来说，由于不经意间包含了一些名字，反而可能会产生始料未及的名字冲突。 标准库类型string C++标准库在实现时已经考虑到了性能需求，所以标准库类型对于一般应用场合来说有足够的效率。 编译器虽然会给字符串字面值自动添加空字符，但是把这个字符串字面值赋给string对象时，却不会把空字符也赋值过去： std::string str("Lova"); std::cout &lt;&lt; str.size(); //输出4，其中str[4]是未定义的，并不是空字符 虽然如下两种对string对象赋值的结果是一样的： std::string s1("hello"); //直接初始化 std::string s2 = "hello"; //拷贝初始化 但是，使用等号初始化一个变量，实际上执行的是拷贝初始化，编译器把等号右侧的初始值拷贝到新创建的对象中去。与之相反，如果不使用等号，则执行的是直接初始化。 用cin执行读取操作时，string对象会自动忽略开头的空白（即空格符、换行符、制表符等）并从第一个真正的字符开始读起，直到遇见下一处空白为止。如下程序： std::string s1, s2; std::cin >> s1 >> s2; std::cout &lt;&lt; s1 &lt;&lt; s2 &lt;&lt; std::endl; 如果输入“&nbsp;&nbsp;&nbsp; &nbsp; Hello World &nbsp;&nbsp; &nbsp;&nbsp; ”，则输出是“HelloWorld”。 有时我们希望能在最终得到的字符串中保留输入时的空白符，这时应该用getline函数代替原来的&gt;&gt;运算符。如下： std::string line; getline(std::cin, line); std::cout &lt;&lt; line &lt;&lt; std::endl; 如果输入“&nbsp;&nbsp;&nbsp; &nbsp; Hello World &nbsp;&nbsp; &nbsp;&nbsp; ”，则输出也是“&nbsp;&nbsp;&nbsp; &nbsp; Hello World &nbsp;&nbsp; &nbsp;&nbsp; ”。 getline函数会从给定的输入流中读入内容，直到遇到换行符为止（注意换行符也被读进来了），然后把所读的内容存入到那个string对象中去（注意不存换行符）。 触发getline函数返回的那个换行符实际上被丢弃了，得到的string对象中并不包含该换行符。 如下程序： std::string str("Hello"); auto len = str.size(); 其中size函数返回的是一个string::size_type类型的值。 string类及其他大多数标准库类型都定义了几种配套的类型，这些配套类型体现了标准库类型与机器无关的特性，类型size_type即是其中的一种。它是一种无符号整型值，而且能够存放下任何string对象的大小。 由于size函数返回的是无符号整型，所以需要注意表达式中不要再使用int这种有符号整型了，否则可能会因为混用有符号和无符号数而产生意想不到的bug。 因为某些历史原因，也为了与C兼容，所以C++语言中的字符串字面值并不是标准库类型string的对象。切记，字符串字面值与string是不同的类型。 可以把string对象和字符串字面值相加，但不能直接把两个字符串字面值相加（因为这两个字符串字面值都不是string对象，无法使用string类中才重载的字符串相加运算符）。 在cctype头文件中定义了一组标准库函数可以用来处理字符： 函数 含义 isalnum(c) 当c是字母或数字时为真 isalpha(c) 当c是字母时为真 iscntrl(c) 当c是控制字符时为真 isdigit(c) 当c是数字时为真 isgraph(c) 当c不是空格但可以打印时为真 islower(c) 当c是小写字母时为真 isprint(c) 当c是可打印字符时为真（即c是空格或c具有可视形式） ispunct(c) 当c是标点符号时为真（即c不是控制字符、数字、字母、可打印空白中的一种） isspace(c) 当c是空白时为真（即c是空格、制表符、回车符、换行符、进纸符的一种） issupper(c) 当c是大写字母时为真 isxdigit(c) 当c是十六进制数字时为真 tolower(c) 如果c是大写字母，输出对应的小写字母；否则原样输出 tosupper(c) 如果c是小写字母，输出对应的大写字母；否则原样输出 范围for语句： 范围for语句遍历给定序列中的每个元素并对序列中的每个值执行某种操作，其语法形式是： for(declaration : expression) statement 每次迭代，declaration部分的变量会被初始化为expression部分的下一个元素值。如下代码是统计给定字符串中标点符号的个数： std::string s("this elay's blog!"); decltype(s.size()) NumPunct = 0; for (auto c : s) { if (std::ispunct(c)) //记得添加cctype头文件 NumPunct++; } std::cout &lt;&lt; NumPunct &lt;&lt; std::endl; 如果想要改变string对象中字符的值，必须把循环变量（上面的代码里是c）定义成引用类型。 string对象的下标运算符[ ]接收的输入参数是string::size_type类型的值，这个参数表示要访问的字符的位置；返回值是该位置上字符的引用。如果某个下标索引是带符号类型的值，讲自动转换成由string::size_type表达的无符号类型。使用下标时必须确定其大于等于0，而且小于字符串的size()的值。一种简便的方法是：总是设下标的类型为string::size_type类型，因为它是无符号类型，可以确保下标不会小于0，然后只需要再保证下标小于size()的值就可以了。 标准库类型vector 标准库类型vector表示对象的集合，其中所有对象的类型都相同。 vector是模板而非类型，由vector生成的类型必须带尖括号声明元素的具体类型，如vector。 vector能容纳绝大多数类型的对象作为其元素，但是因为引用不是对象。所以不存在包含引用的vector。 在早期的C++标准中，声明双重vector，需要在外层vector对象的右尖括号和其元素类型之间添加一个空格，即： std::vector&lt;std::vector&lt;int> > Array; 不过在C++11标准中，这个空格不是必须的了。 类似数组，C++11还提供了使用列表初始化vector的方式： std::vector&lt;int> V1 = { 1,2,3 }; //列表初始化 std::vector&lt;int> V2 = (1, 2, 3); //错误，应该使用花括号 std::vector&lt;int> V3(10, 0); //V3里有10个int类型的元素，每个都被初始化为0 std::vector&lt;int> V4{10, 0}; //V4里有2个int类型的元素，值分别是10和0 std::vector&lt;int> V5(10); //V5里有10个int类型的元素，初始值都是0 std::vector&lt;int> V6{10}; //V6里有1个int类型的元素，初始值是10 在初始化时，如果用的是圆括号，可以说提供的值是用来构造vector对象的；如果用的是花括号，就是用列表初始化该vector对象的。 其实vector对象能够高效增长，不需要在初始化时指定其大小，初始化时设定其大小可能性能反而不好，更有效的办法是先定义一个空的vector对象，再在运行时向其中添加具体值。 和string类似，vector也支持&lt;，&gt;等关系运算符，也是按字典顺序进行比较的，而且V1[n]也是返回V1中第n个元素的引用。 对于vector，要使用size_type（vector的下标的类型是size_type），需要先指定具体的vector类型： std::vector::size_type //错误 std::vector&lt;int>::size_type //正确 迭代器介绍 所有标准库容器都可以使用迭代器，但是其中只有少数几种才同时支持下标运算符。 像string、vector这种有迭代器的类型都拥有begin和end成员函数： std::vector&lt;int> v; auto b = v.begin(), e = v.end(); 其中，begin函数返回指向第一个元素的迭代器；end函数返回指向容器“尾元素的下一位置”的迭代器，也就是说该迭代器指向的是容器的一个本不存在的“尾后”元素，没有什么实际含义，仅是个标记而已，表示我们已经处理完了容器中的所有元素，所以通常被称为尾后迭代器，或简称尾迭代器。 如果容器为空，则begin和end返回的是同一个迭代器，都是尾后迭代器。 由于end返回的迭代器并不指示某个元素，所以不能对其进行递增或解引用的操作。如下代码： std::string s("some string"); std::cout &lt;&lt; *s.begin() &lt;&lt; std::endl; std::cout &lt;&lt; *s.end() &lt;&lt; std::endl; //非法，不能对尾后迭代器解引用 通常我们不需要care迭代器的具体类型到底是什么，一个auto就足够了。 迭代器的访问方法类似指针，如*iter表示迭代器iter指向的元素的引用，iter-&gt;mem表示迭代器iter指向的对象中名为mem的成员。 我们通常不知道，也无须知道迭代器的精准类型，用auto就可以了。其实，迭代器的类型是iterator和const_iterator，如下： std::vector&lt;int>::iterator it; //it能读写vector&lt;int>中的元素 std::vector&lt;int>::const_iterator it2; //it2只能读vector&lt;int>中的元素，不能写 std::vector&lt;int> v; const std::vector&lt;int> cv; auto it3 = v.begin(); //it3的类型是vector&lt;int>::iterator auto it4 = cv.begin(); //it4的类型是vector&lt;int>::const_iterator 为了便于专门得到const_iterator类型的返回值，C++11引入了两个新函数，分别是cbegin和cend： auto it5 = v.cbegin(); //it5的类型是vector&lt;int>::const_iterator 其中即使vector对象（或string对象）不是常量，这两个函数返回值也都是const_iterator。 C++语言的箭头运算符（-&gt;）实际上是把解引用和成员访问两个操作结合在一起，也就是说，it-&gt;mem和(*it).mem表达的意思相同。 谨记，但凡是使用的迭代器的循环体，都不要向迭代器所属的容器添加元素，因为这样会使迭代器失效的。 两个迭代器的距离，在C++中用类型difference_type来表示，它是带符号整型数（因为两个迭代器之间的距离是可正可负的）。 数组 如果不清楚元素的个数，请使用vector，而非数组。 定义数组的时候必须指定数组的类型，不允许使用auto关键字由初始值的列表推断类型，这一点与vector不同。如下： std::vector&lt;int> v = { 1,2,3 }; //合法 auto a[] = { 1,2,3 }; //非法 使用列表初始化数组时，不够的元素一定会被默认初始化，无论是不是函数的局部变量。如下： int a[4]; int b[4] = {}; std::cout &lt;&lt; a[0] &lt;&lt; std::endl; //a中的元素是未定义的 std::cout &lt;&lt; b[0] &lt;&lt; std::endl; //b中的元素被默认初始化为0 想要理解数组声明的含义，最好的办法是从数组的名字开始，从内向外、从右向左的顺序阅读。如下： int *ptrs[10]; //ptrs是含有10个整型指针的数组，是指针数组 int (*pArray)[10]; //pArray指向含有10个整型的数组，是数组指针 从右向左，ptrs右边是[10]，所以定义的是一个大小为10的数组，数组名称是ptrs；ptrs左边是int*，即数组中的所有元素都是int型指针，所以ptrs是含有10个整型指针的数组的名称，是10个指针构成的数组。 先从内向外，在括号内部，pArray右边没有东西，左边是*，所以知道pArray是一个指针，然后从右向左，（*pArray）右边是[10]，所以（*pArray）是一个大小为10的数组的名称，（*pArray）右边是int，说明数组中的所有元素都是int型，所以pArray是一个指向整型数组的指针。 所以，对于如下： int *(&amp;arry)[10] = ptrs; //arry是数组的引用，该数组含有10个整型指针 从内向外，可以知道arry是一个引用，然后从右至左，在(&amp;arry)右边是[10]，所以(&amp;arry)是一个大小为10的数组的名称，在(&amp;arry)左边是int*，即数组中的每个元素是int型指针，所以arry是在引用一个大小为10的整型指针数组。 在使用数组下标时，通常将其定义为size_t类型，它是一种机器相关的无符号类型，它被设计得足够大以便能表示内存中任意对象的大小。在cstddef头文件中定义了size_t类型，这个文件是C标准库stddef.h头文件的C++版本。 使用auto时，用数组名作初始值推断出来的变量类型是指针；而使用decltype时，用数组名作初始值推断出来的变量类型依然是数组： int Array[] = { 1,2,3,4 }; auto pArray2 = Array; //pArray2是一个整型指针，指向Array的第一个元素 decltype(Array) Array3 = { 0,1,2,3 }; //Array3含有4个整数的数组 Array3[1] = 10; decltype(Array) Array4 = { 0,1,2,3,4 }; //错误，Array4必须是含有4个整数的数组 decltype(Array) Array4 = { 0,1,2, }; //正确 使用auto时，编译器实际上作了类似如下的转化： auto pArray2 = &amp;Array[0]; 而在使用decltype时并没有发生这种转化，所以推断出来的依然是数组类型。值得注意的是推断出来的4个整型的数组类型，就不能给把数量比它多的初始化列表赋给它，但是可以把数量比它少的初始化列表赋给它，因为不够的元素默认被初始化为0了。 为了得到数组的首指针和尾后指针，C++11也为数组定义了begin和end函数，与vector这种容器不同的是，作用与数组的begin和end函数并非是其成员函数，而且返回值也是指针类型，而非迭代器类型。 int Array[] = { 1,2,3,4 }; int *beg = std::begin(Array); 再次特别注意，尾后指针不能执行解引用和递增操作，不过可以获取其地址（即指针存储的值）。 两个指针相减的结果的类型是一种名为ptrdiff_t的标准库类型。和size_t一样，ptrdiff_t也是一种定义在cstddef头文件中的机器相关的带符号类型。 标准库类型（如string、vector等等）限定使用的下标必须是无符号类型，而内置的下标运算无此要求。如下：int Array[] = { 1,2,3 }; int *p = &amp;Array[2]; int j = p[-2]; //p[-2]是Array[0]表示的那个元素 用char*定义的字符数组就是C风格的字符串，如下：const char cs[] = "This is a C string."; 尽管C++支持C风格字符串，但在C++程序中最好还是不要使用它们。这是因为C风格字符串不仅使用起来不太方便，而且还极易引发程序漏洞，是诸多安全问题的根本原因。const char cs1[] = { 'C','+','+'}; //末尾没有空字符 const char cs2[] = "This is a C string."; //末尾有空字符 std::cout &lt;&lt; strlen(cs1) &lt;&lt; std::endl; //错误，cs1没有以空字符结束，输出的可能不是3 std::cout &lt;&lt; strlen(cs2) &lt;&lt; std::endl; //正确 对大多数应用来说，使用标准库string要比使用C风格字符串更安全、高效。 允许使用以空字符结束的字符数组来初始化string对象或为string对象赋值，但是不能用string对象直接初始化指向字符的指针：const char cs1[] = { 'C','+','+','\0' }; std::string s1 = cs1; //正确 char *cs2 = s1; //错误，不能用string对象初始化char*指针 为了完成该功能，string专门提供了一个名为c_str的成员函数：const char *cs2 = s1.c_str(); //正确 顾名思义，c_str函数的返回值是一个C风格的字符串指针，结果指针的类型是const char*。由于返回的实际上是指向字符串s1的指针，所以当s1的内容改变时，cs2的内容也会随之改变。 不允许使用vector对象初始化数组，但是允许使用数组来初始化vector对象，只需要在初始化时指明待拷贝区域的首地址和尾后地址就可以了：int Array[] = { 1,2,3,4,5 }; std::vector&lt;int> ivec(std::begin(Array) + 1, std::end(Array) - 1); //ivec的内容是2,3,4 std::vector&lt;int> ivec2(Array + 1, Array + 3); //ivec2的内容是2,3 注意第二个参数是待拷贝区域的尾后地址，所以ivec的内容是2、3、4，而不是2、3、4、5。 现代C++程序应当尽量使用vector和迭代器，避免使用内置数组和指针；应该尽量使用string，避免使用C风格的基于数组的字符串。 多维数组 严格来说，C++没有多维数组，通常所说的多维数组其实是数组的数组。谨记！如下： int Array[3][4]; //大小为3的数组，每个元素是含有4个整数的数组 按照由内而外、由左至右的顺序阅读多维数组的定义有助于更好地理解其真实含义。 多维数组初始化： int Array[3][4]= { {0, 1, 2, 3}, {4, 5, 6, 7}, {8, 9, 10, 11} }; 其中内层嵌套的花括号并非必需的，但是如果内层花括号中元素个数不够时，会执行默认初始化，这时有没有花括号还是有很大区别的： int Array[3][4] = { {0},{4},{8} }; int Array2[3][4] = { 0 , 4 , 8 }; 此时的Array和Array2内容是不一样的，Array是每一行不足的用0进行默认初始化，而Array2是前三个元素分别是0、4、8，但是后面的元素都是默认初始化为0。 要使用范围for语句处理多维数组时，除了最内层的循环外，其他所有循环的控制变量都应该是引用类型。这时最内层获取到的变量是只读的，如果要可写的话，还需要给最内层循环的控制变量加上引用。如下： int Array[3][4]; size_t cnt = 0; for (auto &amp;row : Array) { for (auto &amp;col : row) { col = cnt; ++cnt; } } 上面的代码是正确的，但是下面这样就不合法了： int Array[3][4]; size_t cnt = 0; for (auto row : Array) { for (auto &amp;col : row) { col = cnt; ++cnt; } } 因为row不是引用类型，所以编译器初始化row时会自动将这些数组形式的元素（谨记多维数组实际上是数组的数组）转换成指向该数组内首元素的指针。这样得到的row的类型就是int*，显然内层的循环就不合法了，因为编译器将试图在一个int*内进行遍历，显然和程序的初衷相去甚远。 所以，谨记没有使用引用的数组名都是会被自动转换为指针的。 因为多维数组实际上是数组的数组，所以由多维数组名转换得来的指针实际上是指向第一个内层数组的指针。如下代码： int Array[3][4]; int(*p)[4] = Array; p = &amp;Array[2]; 通过p的声明形式可以知道，p是一个指针，指向含有4整数的数组，而数组名Array也是指向第一个内层数组的指针，所以第二句代码是合法的。由于Array[2]表示Array的第三个元素，这个元素是一个含有4个整数的数组，所以对Array[2]取地址，再赋给p也是合法的。 &nbsp; 参考文献：《C++Primer第五版》]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++Primer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在OpenGL中踩过的坑]]></title>
    <url>%2F2017%2F12%2F02%2FOpenGL%E4%B8%AD%E7%9A%84%E5%9D%91%2F</url>
    <content type="text"><![CDATA[重新链接着色器程序后uniform失效 如果链接着色器程序后，为着色器程序设置好了uniform变量，然后再链接一次。着色器程序将会回到初始状态，所有设置好的uniform变量也会还原（可能变成0）。 这个情况在Transform Feedback中很容易发生。因为通常会有如下程序： m_pFLCPassShader = new CShader("FLC_VS.glsl", "FLC_FS.glsl", "FLC_GS.glsl"); m_pFLCPassShader->activeShader(); glUniform1i(glGetUniformLocation(m_pFLCPassShader->getProgram(), "u_Test"), 300); ...... const GLchar * const Varyings[] = //为Transform Feedback设置要读回哪些变量 { "VERTEX_WORLD_POSITION", "VERTEX_NORMAL", "VERTEX_TEXCOORD", "VERTEX_COLOR" }; glTransformFeedbackVaryings(vShader.getProgram(), 4, Varyings, GL_INTERLEAVED_ATTRIBS); glLinkProgram(vShader.getProgram()); 在第一句CShader类里会第一次链接好着色器程序，然后我为该着色器设置了u_Test这个uniform变量的值，后面我们针对着色器程序里要用到的Transform Feedback，为它设置要读回哪些变量，这个时候不得不再链接一次程序（不链接的话Transform Feedback将无效）。因为又链接了一次程序，我们发现之前为u_Test设置的值300失效了，被重新还原为初始状态：0。 解决方案当然就是确保先链接着色器程序，再设置uniform值了。 深度测试无效在自定义帧缓冲中应用深度测试时，一定要记得给自定义的帧缓冲添加深度附件，否则开启的深度测试是无效的。 GLuint fbo; glGenFramebuffers(1, &amp;fbo); glBindFramebuffer(GL_FRAMEBUFFER, fbo); GLuint texColorBuffer; glGenTextures(1, &amp;texColorBuffer); glBindTexture(GL_TEXTURE_2D, texColorBuffer); glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, NULL); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); glBindTexture(GL_TEXTURE_2D, 0); glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, texColorBuffer, 0); GLuint rbo; glGenRenderbuffers(1, &amp;rbo); glBindRenderbuffer(GL_RENDERBUFFER, rbo); glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH24_STENCIL8, width, height); glBindRenderbuffer(GL_RENDERBUFFER, 0); glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_STENCIL_ATTACHMENT, GL_RENDERBUFFER, rbo); if (glCheckFramebufferStatus(GL_FRAMEBUFFER) != GL_FRAMEBUFFER_COMPLETE) { std::cout &lt;&lt; "Framebuffer is not complete!" &lt;&lt; std::endl; } glBindFramebuffer(GL_FRAMEBUFFER, 0); 绑定TFB后不能再激活着色器 在使用glBeginTransformFeedback激活Transform Feedback Buffer之后，就不能再使用glUseProgram去激活任何着色器了，直到glEndTransformFeedback之后才可以。如下程序： glBindBufferBase(GL_TRANSFORM_FEEDBACK_BUFFER, 0, *CForwardLightCuts::getInstance()->fetchTF_VBO()); glBeginTransformFeedback(GL_TRIANGLES); vModel.render(vShader); glEndTransformFeedback(); glBindBufferBase(GL_TRANSFORM_FEEDBACK_BUFFER, 0, 0); 如果在render函数中使用了glUseProgram函数将会报错，正确的做法应该是在激活TFB的前面激活一次着 色器程序就可以了： glUseProgram(vShader.getProgram()); glBindBufferBase(GL_TRANSFORM_FEEDBACK_BUFFER, 0, *CForwardLightCuts::getInstance()->fetchTF_VBO()); glBeginTransformFeedback(GL_TRIANGLES); vModel.render(vShader); glEndTransformFeedback(); glBindBufferBase(GL_TRANSFORM_FEEDBACK_BUFFER, 0, 0); 注意同时需要移除render及其子函数中的所有glUseProgram调用。 Transform Feedback Buffer（TFB）虽然也是个Buffer，但是它和Uniform Buffer（UBO）、Shader Storage Buffer（SSBO）这些不同，UBO、SSBO这些通常意义上的Buffer都是可以在不同着色器程序（即不同Pass）之间共享的，在不同的着色器程序中都能访问同一个这样的Buffer。但是TFB却只是专属于某一个shader program，因为TFB会针对某个shader里的varying重新link其着色器程序，也就是说TFB只针对有varying的那个着色器有效，而对其他着色器程序是无效的，所以TFB是不能在不同着色器程序之间共享的，其他的着色器并不能通过绑定GL_TRANSFORM_FEEDBACK来访问TFB里的内容（需要将Buffer重新绑定到其他绑定点上，比如VBO）。 纹理格式 在为帧缓冲添加纹理附件时，使用浮点型格式（GL_FLOAT），其帧率可能比使用无符号整型（GL_UNSIGNED_BYTE）低上一倍，所以在不需要用到-1到1之外的浮点型数据时，纹理格式还是最好使用（内部格式GL_RGBA等、外部格式GL_RGBA等，数据类型GL_UNSIGNED_BYTE）。因为OpenGL默认情况下会以无符号归一化格式存储纹理，纹素值在内存中以整数存储，整数在读进着色器时会转换到[0.0, 1.0]之间（如果指定是有符号归一化格式，如GL_R8_SNORM，则转换到[-1.0, 1.0]之间）。 GL_RGBA、GL_RGB这些不带数字大小的纹理内部格式，就是以无符号归一化格式存储的。]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>OpenGL天坑</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Forward Light Cuts]]></title>
    <url>%2F2017%2F11%2F16%2FForwardLightCuts%2F</url>
    <content type="text"><![CDATA[Introduction 很多已有的辐射度缓存（Radiance Caching）方法会给场景中已经生成好的VPLs（即很多个虚拟点光源）建立树形结构，来计算给定点的入射辐射度（Incoming Radiance）。它们会把VPL作为树的叶子结点，然后把相似度相近的两个光源合成一个父结点。父结点中包含两个光源的总亮度值和轴对称包围盒（AABB）信息。重复该步骤，一直到只剩下一个结点为止，即根结点。这个过程有点像哈夫曼树的构建过程，只是这里是以光源的相识度作为标准而已。 其中相似度通过如下公式来计算： $$ W = I_c(\alpha_c^2 + c^2(1 - \cos\beta_c)^2) $$ 其中$I_c$为两个光源的亮度之和，$\alpha_c$表示两个光源轴对齐包围盒（AABB）的对角线长度。对于聚光灯，常量c控制着空间大小与聚光灯方向相似性的相对缩放比例，常量c的大小与场景包围盒的对角线长度有关，$\beta_c$则是两个光源包围锥体的半角。对于点光源和平行光，常量c恒为0。W的值越小，则两个光源的相似度越高。 但是这类方法至少有两个缺点： 对于动态场景，每帧都要重新建树。 VPL太多。 《Forward Light Cuts》这篇文章解决了这两个问题： 用场景的三角形自己来触发创建VPL（使用几何着色器和细分着色器），其中会把太大的三角形（Divergent Triangle）进一步细分，把太过密集的三角形（Small Triangle）简化，即抛弃小三角形，不在上面创建VPL。 提出了一种随机聚类方法，把VPLs的子集和其影响到的有界区域关联起来，以此来计算其中某个点的辐射度。 FLC方法的优点是可以适应完全动态的场景，无需任何像树这样的层次数据结构。 Previous Work 基于屏幕空间的方法用深度缓冲来替代实际的场景，虽然能够降低光照计算的复杂度，而且拥有很好的实时性和适应完全的动态场景，但是这类方法都依赖于深度剔除和多视角渲染，这样就需要考虑到离摄像机最近深度，以及视锥之外的场景了，这样一来，还是会导致渲染速率急剧下降，而且还存在一些视角依赖的问题，比如拖影（Ghosting Artifacts）。值得注意的是，在基于屏幕空间的方法中，VPL是在几何、细分着色器里基于每个三角形，借助GPU硬件的优势来生成的。 基于模型空间的方法能够避免这些视角依赖问题，比如立即辐射度（Indirect Radiance）方法，而RSM（Reflective Shadow Maps）方法更进一步，它提出了从光源视角（也叫光源空间）下生成VPLs的方法，在后来的发展中，又在RSM的基础上加上了针对RSM Pixels的聚类策略，只保留相关的光源，从而减少VPL的数量。但是在大场景下还是需要大量的VPL。 这个问题可以用分层的方案来解决，典型的比如Light Cuts、Point-Based Global Illumination，它们可以用LOD点采样广场的形式来管理VPL，后来又用clustring shading（分开着色的改进版）来进一步达到大规模光源+复杂场景的实时性能。 但是，这些基于模型空间的方法都是需要树形结构的，需要把建树的过程分摊到多帧来完成才能降低对帧率的影响，但是这却阻碍了完全动态场景的实现。 使用立即辐射度方法模拟间接光照有个难题：VPL和像素之间的可见性怎么确定。有很多方法来解决这个问题，比如用可以快速生成的不完全阴影贴图（Imperfect Shadow Maps，ISM），来近似计算可见性；再比如可以用虚拟面光源（Virtual Area Lights，VALs）方法能够减少可见性查询的次数，再从软阴影贴图计算软阴影时就能近似计算出可见性。后来又有人提出了记录VPL帧到帧的位置，直到VPL影响不到帧缓存里的像素才剔除它们，然后通过光线跟踪去采样VPLs来计算可见性。不过《Forward Light Cuts》这篇文章并没有解决可见性问题。 DDS（Deep Screen Space）方法剔除同时利用屏幕空间和模型空间的辐射度缓存。和模型空间策略一样，它同样是在几何表面上生成VPLs；和屏幕空间策略一样，它也同样地利用几何着色器和细分着色器来生成VPLs。虽然DDS在小中型场景中表现很好，但是却无法适用于大型场景，因为该方法为了达到实时性，会自动去掉大场景里的一些几何形状（比如Divergent Triangle），而不是进一步去细化它。 FLC方法比DDS更进一步，提出了一个Diffuse Global Illumination管线，用两个pass去细化和简化由几何驱动生成的VPL。优点是能够适应完全动态的大场景，而且无需任何层次数据结构。 参考文献：Laurent G, Delalandre C, Grégoire D L R, et al. Forward Light Cuts: A Scalable Approach to Real‐Time Global Illumination[J]. Computer Graphics Forum, 2016, 35(4):79-88.]]></content>
      <categories>
        <category>全局光照</category>
      </categories>
      <tags>
        <tag>实时全局光照</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++Primer第二章变量和基本类型]]></title>
    <url>%2F2017%2F11%2F10%2FC%2B%2BPrimer%E7%AC%AC%E4%BA%8C%E7%AB%A0%E5%8F%98%E9%87%8F%E5%92%8C%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[基本内置类型 可寻址的最小内存块称为字节，存储的基本单元称为字。 字符型有3种：char、signed char和unsigned char。所以类型char和signed char并不一样，char既可能是有符号，有可能是无符号的，具体哪一种是由编译器决定的。 所以，在算术表达式中不要使用char和bool，只有在存放字符或布尔值时才使用它们。因为类型char在一些机器上是有符号的，而在另一些机器上又是无符号的，所以如果使用char进行运算特别容易出问题。如果需要使用一个不大的整数，那么明确指定它的类型是signed char或者unsigned char。int、short、long和long long都是有符号的。 执行浮点数运算时选用double，这是因为float通常精度不够而且双精度浮点数和单精度浮点数的计算代价相差无几。事实上，对于某些机器来说，双精度运算甚至比单精度还快。 可以给无符号char赋以可表示范围之外的值，但是有符号char却不能，否则它的值将是未定义的： unsigned char c = 256; //c的值等于0 signed char c2 = 256; //c2的值未定义 std::cout &lt;&lt; (int)c &lt;&lt; " " &lt;&lt; (int)c2 &lt;&lt; std::endl; 虽然上面的程序可能正常运行，但是c2的值确实是未定义的。当给有符号类型赋以一个超出它可表示范围之外的值时，结果是未定义的。此时，程序可能继续工作、可能崩溃、也可能产生垃圾数据。 不要在表达式中混用带符号和无符号类型。比如对于无符号数的自减操作： for (unsigned int u = 10; u >= 0; --u) std::cout &lt;&lt; u &lt;&lt; std::endl; 这个程序会陷入死循环。因为u是无符号数，减到0时，再减1会变成unsigned int类型可表示的最大整数，永远不会小于0。再比如在混用带符号数和无符号数的表达式中，带符号数会自动转换为无符号数： unsigned u = 10; int i = -42; std::cout &lt;&lt; u + i &lt;&lt; std::endl; //，如果int占32位，输出4294967264 如下面一组整型数字： 20 /*十进制*/ 024 /*八进制*/ 0x14 /*十六进制*/ 虽然这些数字都表示数字20，但是实际上它们不都是一样的。因为默认情况下，十进制字面值是带符号数，而八进制和十六进制既可能是带符号的也可能是无符号的。十进制字面值的类型是能够容纳其数值的int、long和long long中尺寸最小的那个，而八进制和十六进制字面值的类型是能够容纳其数字的int、unsigned int、long、unsigned long、long long和unsigned long long中的尺寸最小者。 默认的浮点型字面值是一个double，可以加f后缀让其变成float型，加L变成long double型。还有一些不太常见的字面值前缀或者后缀： L'a' //宽字符型字面值，类型是wchar_t u8"hi!" //utf-8字符串字面值（utf-8用8位编码一个Unicode字符） 编译器会在每一个字符串字面值的结尾处添加一个空字符’\0’。 C++除了’\n’等等转义字符外，还可以使用泛化的转义序列，其形式是\x后紧跟1个或多个十六进制数字，或者\后紧跟1个、2个或3个八进制数字。如下： std::cout &lt;&lt; "\x4d" &lt;&lt; " " &lt;&lt; "\115" &lt;&lt; std::endl; //输出M M 要注意的是，反斜线\后面跟着的八进制数字超过3个时，只有前3个数字与\构成转义序列，如下： std::cout &lt;&lt; "\1234" &lt;&lt; std::endl; //输出S4 “\1234”只表示2个字符，八进制数123对应的字符S以及字符4。 变量 初始化不是赋值，初始化的含义是创建变量时赋予其一个某一个初始值，而赋值的含义是把对象的当前值擦除，而以一个新值来替代。 在C++11中，可以用花括号来初始化变量（也叫列表初始化）： int n{ 10 }; 当用于内置类型的变量时，这种初始化形式有一个重要特点：如果我们使用列表初始化且初始值存在丢失信息的风险，编译器会报错。这在C++11之前通过等号或者括号来初始化变量是做不到的，如下： int a{ 3.14 }; //编译失败，因为存在信息丢失的危险 int b(3.14); //编译通过，但是因为类型转换丢失了部分值 int c = 3.14; //编译通过，但是因为类型转换丢失了部分值 定义在函数体外的变量会被默认初始化，但定义在函数内部的局部变量是不会被默认初始化的，它的值将是未定义的，如果试图拷贝或以其他形式访问此类值将引发错误： int m; //初始化为0 char c; //初始化为空字符'\0' int main() { std::string str; std::cout &lt;&lt; str &lt;&lt; std::endl; //编译通过，因为str是对象，std::string规定该对象默认初始化为空串"" int n; std::cout &lt;&lt; n &lt;&lt; std::endl; //编译报错，n没有被默认初始化 return 0; } 不过类对象如果没有显示地初始化，则其值由类确定，如上面的str对象。 所以，建议初始化每一个内置类型的变量。为初始化的变量含有一个不确定的值，使用未初始化变量的值是一种错误的编程行为并且很难调试，因为严格来说，编译器并未被要求检查此类错误（虽然大多数编译器都会对一部分使用未初始化变量的行为提出警告），使用未初始化的变量将带来无法预计的后果。 如果想要声明一个变量而非定义它，可以在变量名前面加关键字extern，而不要显式地初始化变量： int i; //声明并定义i extern int j; //声明j而非定义j 但是如果给extern声明的变量赋初值，那么就变成定义了： extern double PI = 3.1415926; //声明并定义PI（不能在函数内部对extern声明的变量赋初值） 变量只能被定义一次，但是可以被多次声明，即可以多次extern同一变量。 复合类型 引用本身不是一个对象，只是某一个对象的别名。 因为无法令引用重新绑定到另外一个对象上，所以引用必须被初始化（重新绑定的话会重复定义标识符）。 因为引用本身不是一个对象，所以不能定义引用的引用，即不能给别名再起一个别名。 允许在一条语句中定义多个引用，其中每个引用标识符都必须以符号&amp;开头（指针也是类似）： int n = 10; int &amp;i = n, j = n; //i是n的引用，但j是int int &amp;i2 = n, &amp;j2 = n; //i2和j2都是n的引用 引用和指针的类型都要和与之绑定的对象严格匹配： double d = 3.14; int &amp;i = d; //编译报错，引用类型和绑定的对象类型不符 int n = 10; double &amp;m = n; //编译报错，引用类型和绑定的对象类型不符 double dd = 3.14; int *pi = &amp;d; //编译报错，指针类型和指向的对象类型不符 int nn = 10; double *pm = &amp;nn; //编译报错，指针类型和指向的对象类型不符 引用和指针有很多不同点： 指针本身就是一个对象，允许对指针赋值和拷贝，而且在指针的生命周期内它可以先后指向几个不同的对象，但是引用本身不是对象，一旦初始化后就不能被重新绑定到其他对象上。 指针无须在定义时赋初值，但是引用必须在定义时初始化。 和其他内置类型一样，在函数内部的指针也不会被默认初始化，也将拥有一个不确定的值。 因为引用不是对象，没有实际地址，所以不能定义指向引用的指针。 因为指针类型代表了其所指向对象的类型，通过类型才知道其指向对象的存储大小等等信息，才可以对它进行操作，所以指针类型和其指向对象的类型必须匹配（引用也是同理）。 编译器可能不会检查无效指针和未初始化的变量，所以一定要记得初始化。 “*“不仅是指针声明符，也是解引用符，所以通过*p能够访问到指针p所指向的对象。 给指针赋空值有以下3种方法：int *p1 = nullptr; //等价于int *p1 = 0; int *p2 = 0; int *p3 = NULL; //等价于int *p3 = 0;不过需要先#include cstdlib 得到空指针最好的方法就是使用字面值nullptr来初始化指针，因为它可以被转换成任意其他的指针类型。nullptr也是在C++11新标准中引入的。尽量避免使用NULL。 使用未经初始化的指针是引发运行时错误的一大原因。尽量先有对象，再有指向对象的指针，如果实在不清楚指针应该指向何处，也应该把它初始化为nullptr。 void*是一种特殊的指针类型，可用于存放任意类型对象的地址。不能直接操作void*指针所指的对象，因为我们并不知道这个对象到底是什么类型，也就无法确定能在这个对象上做哪些操作。 在声明或者定义指针（或引用）时，最好把*（或&amp;）与变量名连在一起。 对于如下类型语句： int *&amp;r = p; 想弄清楚r的类型到底是什么，最简单的方法是从右向左阅读r的定义，离变量名最近的符号对变量的类型有最直接的影响。上面离变量名r最近的符号是&amp;，说明r是一个引用。那么声明符的其余部分说明了它引用的对象是什么类型，上面声明符中剩余的是int *，说明r是对一个int型指针的引用。 所以，面对一条比较复杂的指针或引用的声明语句时，从右向左阅读有助于弄清楚它的真实含义。 const限定符 因为const对象一旦创建后其值就不能再改变，所以const对象必须初始化。 既可以用非const对象去初始化const对象，也可以用const对象去初始化非const对象。在拷贝时，无需在意双方是否是const，因为拷贝只是值传递，不会影响到原来的对象。 默认情况下，const对象被设定为仅在文件内有效。什么意思呢？我们先来看看下面的程序： A.h: #pragma once class A { public: A(); }; A.cpp: #include "A.h" #include &lt;iostream> int N = 10; A::A() { std::cout &lt;&lt; "A: " &lt;&lt; N &lt;&lt; std::endl; } main.cpp: #include &lt;iostream> #include "A.h" extern int N; int main() { A a; std::cout &lt;&lt; "main: " &lt;&lt; N &lt;&lt; std::endl; return 0; } 由于在main.cpp文件里，并没有包含A.cpp，所以它不知道变量N的存在，想要使用变量N，需要在main.cpp里用extern关键字声明变量N，表示该变量是一个外部链接，在别的编译单元里有它的定义，所以在链接时，程序会因为它是外部链接而去找它的定义，所以main函数里也就可以识别到变量N了。那么我们再看下面的程序： A.h: #pragma once class A { public: A(); }; A.cpp: #include "A.h" #include &lt;iostream> const int N = 10; A::A() { std::cout &lt;&lt; "A: " &lt;&lt; N &lt;&lt; std::endl; } main.cpp: #include &lt;iostream> #include "A.h" extern const int N; int main() { A a; std::cout &lt;&lt; "main: " &lt;&lt; N &lt;&lt; std::endl; return 0; } 程序变动很小，只是给变量N加上了const属性，但是此时编译却无法通过，main.cpp中识别不到变量N。这是因为默认情况下，const对象被设定为仅在文件内有效。所以在A.cpp中声明的常量N只能在该文件内被访问了。如果想要在不同的相互独立的文件之间共享这个常量怎么办呢？可以在A.cpp中定义该常量的时候加上extern关键字，即： A.cpp: #include "A.h" #include &lt;iostream> extern const int N = 10; A::A() { std::cout &lt;&lt; "A: " &lt;&lt; N &lt;&lt; std::endl; } 所以，如果想在多个独立的文件之间共享const对象，必须在变量的定义之前添加extern关键字。 【注】：注意是在相互独立的文件之间，比如上面main.cpp和A.cpp文件并不存在#include这种包含关系。如果把定义常量A的语句写到A.h中，main.cpp当然可以访问到了，因为它包含了A.h，这时A.h和main.cpp不是相互独立的文件。不过在头文件中定义全局变量通常不是好的做法。 如下语句： const int i = 10; int &amp;j = i; //错误：试图让一个非常量引用绑定到常量引用上 这时非法的，因为如果合法的话，则可以通过j来改变它引用对象i的值，这显然是不正确的。 看如下程序： double d = 10.0; int &amp;i = d; //错误：不能用double类型的值去初始化int &amp;类型的引用 错误还是很明显的，如果正确的话，那我们就可以用用操作整型变量的方式来改变d的值了，这显然是和double类型的d冲突。 再看如下程序： double d = 10.0; const int &amp;i = d; //正确 为什么加上const之后就正确了？这是因为加上const之后，我们就不能再改变i的值了，也就不能通过整型变量i来改变double型变量d了，所以合法。 我们再从编译的角度来看一下这个程序： 在初始化引用或者指针时，编译器会自动进行类型检查，如果类型不符，会先生成临时量。比如上面的const int &amp;i = d;，由于d是double型而非int型，所以编译器会把上述代码变成如下形式： const int temp = d; const int &amp;i = temp; 虽然此时i实际上是临时量的别名，但是由于i是常量对象的引用，i的值不可能再变，所以它到底是临时量还是原对象的引用都无关紧要了。如果输出i和d的地址，会得到不同的结果： double d = 10.0; const int &amp;i = d; std::cout &lt;&lt; &amp;d &lt;&lt; " " &lt;&lt; &amp;i &lt;&lt; std::endl; //输出00E7FD84 00E7FD6C 但是对于之前的int &amp;i = d;，如果合法的话，编译器也会有类似上面的变换： int temp = d; int &amp;i = temp; 同样的，i还是临时量的引用，改变i的值其实改变的是临时量的值，而不是d的，但是int &amp;i = d;的语义就包括了可以通过改变i来改变d的潜在意图，所以矛盾了，所以该语句是非法的。 类似的，下面的语句也是非法的： const int *i = &amp;d; //错误 如果合法的话，编译器会把它转换成如下形式： const int temp = d; const int *i = &amp;temp; 虽然*i是常量，不会被改变，但是指针i本身是可以被改变的。比如对于i++，对于前者应该得到的是d的地址加4个字节，但是对于后者得到的却是临时量temp的地址加4个字节，所以该语句也是非法的。 注意区分常量指针和指向常量的指针： int i = 10; int *const pi = &amp;i; //常量指针 const int *pI = &amp;i; //指向常量的指针 常量指针必须被初始化，而且一旦初始化完成，则它的值（也就是存放在指针中的那个地址）就不能再改变了： int i = 10; int *const pi = &amp;i; 顶层const表示指针本身是个常量，而底层const表示指针所指的对象是一个常量。其实不止指针，普通变量也可以有底层/顶层const属性。 常量和常量表达式是不一样的，常量是变量在被初始化后就不能再被修改，而常量表达式更严格，还需要在编译时就能确定其初始值。如下代码： const int sz = getSize(); sz是一个常量，但不是常量表达式。因为它的初始值，需要getSize函数运行后才能知道，不是在编译时就确定的。 C++11规定，用constexpr声明的变量是常量表达式，如果它的初始值不是常量表达式，那么语句会报错： constexpr int i = 20; //正确，因为初始值20是常量表达式 constexpr int j = i + 1; //正确，因为初始值i+1是常量表达式 constexpr int sz = getSize(); //只有getSize是一个constexpr函数时才正确 int n = 10; constexpr int m = n; //错误，因为初始值n需要在运行时才能确定具体值 constexpr std::string str = "asd"; //错误，因为string类型不属于字面值类型 为了在编译时就确定值，所以常量表达式的初始值都是字面值类型，包括算术类型、引用和指针，但是不包括string等复杂类型。所以string类型变量不能被声明为常量表达式，即不能用constrexpr声明。 如果我们认为某个变量是一个常量表达式，那么就应该把它声明为constexpr类型。 用constexpr声明的指针是常量指针，初始值必须为空，或者存在在固定地址的某个对象的地址。限定符constexpr仅仅对指针有效，对指针所指向的对象无关。 如下语句：int &amp;i = 10; //非法，因为10是一个常量 const int &amp;j = 10; //合法，因为10是一个常量 constexpr int &amp;k = 10; //非法，因为10的内存地址不是编译时确定的 处理类型 using和typedef基本等价，都可以为内置类型和自定义类型设置别名。 typedef double _Double; _Double d = 10.0; using _Int = int; _Int i = 14; 如下语句： typedef char *pstr; const pstr str = nullptr; //str是指向char型对象的常量指针 对于声明中的别名不要把它替换回原来的内容来理解，比如上面的语句把pstr替换后成为如下形式： const char *str = nullptr; //str是指向char型常量的指针 这种理解是错误的。pstr实际上是指向char的指针，所以const pstr就是指向char的常量指针，而非指向常量字符的指针。 auto这个类型说明符可以让编译器通过初始值来推算变量的类型，所以，Auto定义的变量必须有初始值。 如果使用auto一次声明多个变量，那么这些变量的初始值类型都应该一样： auto i = 14, d = 3.14; //错误，i和d的类型不一致 auto一般会忽略掉顶层const，保留底层const。即auto会去掉变量自己的const性质，但不会影响变量指向const对象的这个事实： int i = 0; const int ci = i, &amp;cr = ci; auto b = ci; //b是int型（ci的顶层const特性被忽略掉了） auto c = cr; //c是int型（cr是ci的别名，ci本身是一个顶层const） auto d = &amp;i; //d是int*类型（整型变量i的地址） auto e = &amp;ci; //d是指向常量的int*类型（整型常量ci的地址，对常量取地址是一种底层const） 如果需要推断出的auto类型是一个顶层const，需要明确指出： const auto f = ci; //auto去掉了ci的const特性，但是显式指定const让f变成了const int类型 auto是通过初始值来推断声明的变量的类型，比如auto i = 3.14;，i的变量会被推断为double型，但是如果我们想要i的变量被推断为int型怎么办呢？可以用decltype这个类型指示符： int j = 0; decltype(j) i = 3.14; decltype可以根据表达式的值来推断变量的声明类型。括号里的表达式不止是变量，还可以是任何复杂表达式，甚至函数调用。 decltype和auto不一样，它会保留变量的顶层const和底层const以及引用符号&amp;。如下： const int ci = 0, &amp;cj = ci; decltype(ci) x = 0; //x是const int类型 decltype(cj) y = x; //y是const int&amp;类型，y绑定到x decltype(cj) z; //错误，z是一个引用，必须初始化 decltype中如果表达式的内容是解引用操作，则decltype将得到引用类型。如下： int i = 41, *p = &amp;i; decltype(*p) j; //错误，j是int&amp;类型，必须被初始化 decltype((variable))（注意是双层括号）的结果永远是引用，而decltype（variable）结果只有当variable本身就是一个引用时才是引用。 自定义数据结构 C++11规定，可以为类的成员数据提供类内初始值。创建对象时，类内初始值将用于初始化成员数据。没有初始值的成员将默认被初始化。 class A { private: int m_Data = 100; double m_Vlaue = 0.0; }; 头文件一旦改变，相关的源文件必须重新编译以获取更新过得声明。 确保头文件多次包含仍能安全工作的常用技术是预处理器，它由C++语言从C语言继承而来。预处理器是在编译之前执行的一段程序，可以部分地改变我们所写的程序。比如当预处理器看到#include标记时就会用指定的头文件的内容代替#include。 预处理变量有两种状态：已定义和未定义。#define指定把一个名字设定为预处理变量，#ifdef当且仅当变量已定义时为真，#ifndef当且仅当变量未定义时为真。一旦检查结果为真，则执行后续操作直至遇到#endif为止。如下程序： #ifndef A_H #define A_H class A { private: int m_Data = 100; double m_Vlaue = 0.0; }; #endif 第一次包含A.h时，#ifndef的检查结果为真，预处理器将顺序执行后面的操作直至遇到#endif为止。此时，预处理变量A_H的将变为已定义，而且A.h也会被包含到主程序中来。后面如果再一次包含A.h，则#ifndef将为假，编译器将会忽略#ifndef到#endif之间的部分。 预处理变量无视C++语言中关于作用域的规则。 一般预处理变量的名字全部大写。&nbsp; 参考文献：《C++Primer第五版》]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++Primer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++Primer第一章开始]]></title>
    <url>%2F2017%2F11%2F04%2FC%2B%2BPrimer%E7%AC%AC%E4%B8%80%E7%AB%A0%E5%BC%80%E5%A7%8B%2F</url>
    <content type="text"><![CDATA[编写一个简单的C++程序 在一些系统中，即使文件就在当前目录或文件夹中，也必须显式指出文件的位置。在此情况下，我们可以输入：$ .\prog1 “.”后面跟一个反斜线可以指出该文件在当前目录中。 运行GNU编译器的命令是g++：$ g++ -o prog1 prog1.cc 其中，$是系统提示符；-o prog1是编译器参数，指定可执行文件的文件名；prog1.cc是代码源文件名。 运行微软VS编译器的命令为cl：C:\User\me\Programs> cl /EHsc prog1.cpp 其中，C:\User\me\Programs&gt;是系统提示符，表示当前处于哪个路径下；命令cl可以调用编译器；/EHsc是编译器选项，用来打开标准异常处理。 初识输入输出 术语“流”想要表达的是：随之时间的推移，字符是顺序生成或消耗的。 cerr通常用来输出警告和错误消息，clog用来输出程序运行时的一般性信息。如果是控制台程序的话，它俩和cout一样都是输出到控制台的。 如下语句： std::cout &lt;&lt; "Enter two numbers:" &lt;&lt; std::endl; 我们在输出语句中用了两次&lt;&lt;运算符。因为此运算符返回其左侧的运算对象，因此第一个运算符的结果成为了第二个运算符的左侧运算对象，即等价于： (std::cout &lt;&lt; "Enter two numbers:") &lt;&lt; std::endl; 其中std::endl被称为操纵符，写入endl的效果是结束当前行，并将于设备关联的缓冲区(buffer)中的内容刷到设备中。缓冲刷新操作可以保证到目前为止程序所产生的所有输出都真正写入输出流中，而不是仅停留在内存中等待写入流。所以： 程序员常常在调试时添加打印语句。这类语句应该保证“一直”刷新流。否则，如果程序崩溃，输出可能还留在缓冲区中，从而导致关于程序崩溃位置的错误推断。 标准库定义的所有名字都在命名空间std中。 注释简介 编译器会忽略注释，因此注释对程序的行为或性能不会有任何影响。 当我们修改代码时，不要忘记同时更新注释。 控制流 如下程序：```cpp#include int main() { int sum = 0, value = 0; while (std::cin &gt;&gt; value) sum += value; std::cout &lt;&lt; “Sum is: “ &lt;&lt; sum &lt;&lt; std::endl; return 0; } 当遇到文件结束符（end-of-file），或遇到一个无效输入时（例如读入的值不是一个整数），istream对象的状态才会变为无效，才会退出上面的while循环。所以仅仅输入空格或者回车，是无法让上述循环终止的。可以输入一个字符来终止循环： ```cpp 1 2 3 4 5 6 7 a Sum is: 28 除此之外，还可以输入文件结束符。在Windows系统中，输入文件结束符的方法是Ctrl+Z，然后按回车（Enter键），Unix系统中（包括Mac OS X系统），文件结束符输入是用Ctrl+D。 1 2 3^Z Sum is: 6 类简介 标准库头文件通常不带后缀（string.h不属于标准库头文件，string头文件才是）。 是旧的C头文件，对应的是基于char*的字符串处理函数（C++为了兼容C的标准库）；是位于std中的C++头文件，对应的是基于string类的字符串处理函数；是旧C头文件对应的std版本，所以也是基于char*的。 文件重定向：$ addIems &lt;infile> outfile $是操作系统提示符，addItems代表程序的可执行文件addItems.exe，则上述命令会从一个名为infile的文件读取输入，并将输出结果写入到一个名为outfile的文件中。用这种方法，我们就不必每次运行程序都往控制台手动输入一堆数据了。&nbsp; 参考文献：《C++Primer第五版》]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++Primer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL28：阴影映射]]></title>
    <url>%2F2017%2F11%2F03%2FOpenGL28%E9%98%B4%E5%BD%B1%E6%98%A0%E5%B0%84%2F</url>
    <content type="text"><![CDATA[阴影的重要意义 阴影是光线被阻挡的结果，它能够使场景看起来真实很多，可以让观察者获得物体之间的空间位置关系。如下图所示： 图1 可以看到，有阴影的时候能够更容易的看出立方体是悬浮在地板上的。 当前实时渲染领域还没找到一种完美的阴影算法，目前有几种近似阴影技术，但他它们都有自己的弱点和不足。游戏中常用的技术是阴影贴图（shadow mapping），效果不错，而且相对容易实现，性能也挺高，比较容易扩展为更高级的算法，如 Omnidirectional Shadow Maps和 Cascaded Shadow Maps。 阴影映射原理 在绘制物体的某个片元时，要确定它是否在阴影中，就是要判断它是否被别的片元挡住了。而这个挡住其实是光线被挡住了，所以应该从光源位置看过去，看这个片元是否被其他片元挡住。如下图所示： 图2判断是否被遮挡可以用深度贴图来实现：从光源处看过去（相当于把摄像机调整到光源的位置，即更改观察矩阵和投影矩阵，只是不渲染场景颜色而已），渲染一次场景（开启深度测试），将场景的深度值渲染到自定义帧缓冲的深度纹理附件中，此时深度纹理中存储的深度值就是离光源（或者说摄像机）最近的深度值，然后再渲染一次场景，这次渲染过程中判断当前片元的深度是否比对应位置上深度纹理中的深度更靠近光源（在屏幕空间里就是深度值更小），如果不是则说明该片元被挡住了，在阴影里。如下图所示： 图3右图中，在光源看来C点和P点处在同一xy位置（以光源为原点的坐标系）上，但是深度z不同，P点的深度是0.9，C点的深度是0.4，存储在深度纹理中的应该是最靠近光源的0.4，在绘制点P时由于其深度值0.9比从深度纹理中取出的0.4大，所以判定点P被挡住了，应该位于阴影里。 综上，深度映射通过两个步骤完成： 渲染深度纹理。 正常渲染场景，同时采样深度纹理来判断片元是否在阴影中。 用代码表示如下： // 1. 首先渲染深度贴图 glViewport(0, 0, SHADOW_WIDTH, SHADOW_HEIGHT); glBindFramebuffer(GL_FRAMEBUFFER, depthMapFBO); glClear(GL_DEPTH_BUFFER_BIT); ConfigureShaderAndMatrices(); RenderScene(); glBindFramebuffer(GL_FRAMEBUFFER, 0); // 2. 像往常一样渲染场景，但这次使用深度贴图 glViewport(0, 0, SCR_WIDTH, SCR_HEIGHT); glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); ConfigureShaderAndMatrices(); glBindTexture(GL_TEXTURE_2D, depthMap); RenderScene(); 渲染深度纹理我们需要从光源的视角去渲染得到一张场景的深度纹理，最后需要用它来计算阴影。为了将场景的深度保存到纹理中，我们需要用到帧缓冲，并且为它添加深度纹理附件： GLuint DepthMap; glGenTextures(1, &DepthMap); glBindTexture(GL_TEXTURE_2D, DepthMap); glTexImage2D(GL_TEXTURE_2D, 0, GL_DEPTH_COMPONENT, WIDTH, HEIGHT, 0, GL_DEPTH_COMPONENT, GL_FLOAT, NULL); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST); glBindTexture(GL_TEXTURE_2D, 0); GLuint DepthMapFBO; glGenFramebuffers(1, &DepthMapFBO); glBindFramebuffer(GL_FRAMEBUFFER, DepthMapFBO); glFramebufferTexture2D(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_TEXTURE_2D, DepthMap, 0); glDrawBuffer(GL_NONE); glReadBuffer(GL_NONE); if (glCheckFramebufferStatus(GL_FRAMEBUFFER) != GL_FRAMEBUFFER_COMPLETE) std::cout < "Framebuffer is not complete!" < std::endl; glBindFramebuffer(GL_FRAMEBUFFER, 0); = texture(u_DepthMapSampler2, LightClipSpacePos.xy).r + 0.01) { Color = vec4(AmbientColor * ObjectColor, 1.0); return; } 这里对阴影的处理方式是让片元的颜色等于环境光颜色，不再对它做漫反射和镜面反射光照了。 对于不满足这个条件，即不在阴影里的片元，照常执行blinn-phong光照即可。 剩下的就是在应用程序里把着色器需要的顶点数据和uniform变量传进来就可以了，由于这些内容和之前的文章里几乎是一样的，所以不再赘述了，所有源码都在这里。 运行结果如下图所示： 改进阴影贴图 阴影fighting可以看到上面的阴影并不好，有很多条纹，这是由于深度贴图所能保存的精度有限，相邻的很多片元可能用的是同一个深度，如下图所示：可能表示的最大深度只有6位，那么图中0.9276355到0.9276364的部分都只能用0.927636来表示了，但是getDepthInLightSpace函数计算出来的片元深度精度通常更大，导致在比较时，0.9276355到0.927636的部分，比深度纹理中存储的0.927636小，不处于阴影中，而0.927636到0.9276364的部分比深度纹理中存储的0.927636更大，处于阴影中，所以会出现一半不在阴影中，而另一半在阴影中，而这种精度情况在每一个类似的精度范围内都会出现，所以造成了上图里的条纹状。【注：】 这里只是举了个例子，最大精度不一定是6位小数，也不一定是四舍五入，要视具体运行环境和硬件决定。 那么我们怎么避免这种深度精度问题呢？ 我们可以在判断条件上加一个很小的偏移量： if(LightClipSpacePos.z >= texture(u_DepthMapSampler2, LightClipSpacePos.xy).r + 0.0009) { Color = vec4(AmbientColor * ObjectColor, 1.0); return; } 运行结果如下图所示：可以看到虽然很大程度上解决了条纹状问题，但是由于偏移量加得太小，在箱子的垂直表面上，坡度很大，导致上面还是有一些黑点，有两种方法可以解决：一种是加大偏移量，但是有可能会产生彼得潘效应（后文会介绍），另一种就是利用表面法线和光线的夹角来计算出一个偏移值，这样对于坡度大的地方偏移就大、对坡度小的地方偏移就很小： float Offset = max(0.0009, 0.0025 * (1.0 - dot(Normal, LightDir))); if(LightClipSpacePos.z >= texture(u_DepthMapSampler2, LightClipSpacePos.xy).r + Offset) { Color = vec4(AmbientColor * ObjectColor, 1.0); return; } 运行结果如下： 但是，偏移量加多少合适需要多次微调，加少了会有黑点，加多了会有彼得潘效应，其实即使是上面的代码，运行程序后拉近看依然有彼得潘效应。想要调出合适的偏移量很难，很容易出现彼得潘效应。下面来看看什么是彼得潘效应。 彼得潘效应当偏移加的偏大时，可以看到阴影相对实际物体的偏移，如下图所示（这个偏移值加得很大0.01）：看起来像箱子漂浮在地面之上，但是实际上从顶点数据来看箱子是紧贴着地面的，这种错觉就是彼得潘效应（童话里彼得潘是个会飞的男孩……）。 经过代码实现，渲染阴影贴图时开启正面剔除依然不能消除彼得潘效应，只能用更精确的偏移值来让彼得潘效应更小，直到看不出来。 光视锥外的阴影在之前的片元着色器里，对于不在光源视角下的正交投影视锥里的片元，经过getDepthInLightSpace函数算出来的裁剪坐标绝对值将大于1，用这个坐标去索引深度纹理，当然得不到正确的深度值。因为默认深度纹理的环绕方式是repeat，所以导致在视锥之外的片元都处于阴影里，如下图所示： 有两个解决方案： 把正交投影矩阵的参数加大，让正交视锥能包含更大的区域。 如果当前正交视锥之外没有物体（或者没有需要投射阴影的物体），可以让视锥外的片元索引深度纹理得到的深度值总是1.0，这样这些片元就不会处在阴影里了。其实也就是想用绝对值大于1的坐标去索引深度纹理，总是得到1.0这个值，所以我们可以把深度纹理的环绕方式设为GL_CLAMP_TO_BORDER，让超出1.0的坐标永远得到的都是边界上的值，同时要设置边界颜色的r分量为1.0：glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_BORDER); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_BORDER); GLfloat BorderColor[] = { 1.0,0.0,0.0,1.0 }; glTexParameterfv(GL_TEXTURE_2D, GL_TEXTURE_BORDER_COLOR, BorderColor); 结果如下图所示： 可以发现在视锥横截面之外的片元都不再处于阴影里了，远处还有片元处于阴影里，是因为那块区域超过视锥的远平面，计算出来的深度值是大于1.0的，会永远比从深度纹理中取出来的值要大，所以会处于阴影里。有两种解决方案： 在正交投影矩阵里加大远平面的距离。 在片元着色器里计算裁剪坐标的时候，如果最后发现裁剪坐标的z值大于1.0，则把其z值强制更改为0：vec3 getDepthInLightSpace(vec4 vLightSpacePos) { vec3 Temp = (vLightSpacePos / vLightSpacePos.w).xyz; Temp = Temp * 0.5 + 0.5; if(Temp.z > 1.0) Temp.z = 0.0; return Temp; } 运行结果如下图：到此的所有源码都在这里。其中解开一些注释代码就能看到这一小节说过的各种结果。 PCF拉近了看，会发现阴影边缘走样很严重，有明显的锯齿，如下图所示：这是因为深度纹理的分辨率有限，多个片元可能对应同一个阴影，这样采样计算阴影时就会产生锯齿边。当然可以通过增加深度纹理分辨率的方式来降低锯齿块。但是这样会增加很多内存开销。 我们可以用一种叫做PCF（percentage-closer filtering）的技术来得到更柔和一点的阴影：对片元裁剪坐标的四周多次采样，对采样的结果（在或者不在阴影里）求均值。实现代码如下： #version 330 core in vec2 VS_TexCoords; in vec3 VS_Normal; in vec3 VS_WorldPos; in vec4 VS_LightSpacePos; out vec4 Color; uniform sampler2D u_DiffuseMapSampler1; uniform sampler2D u_DepthMapSampler2; uniform vec3 u_LightPos; uniform vec3 u_LightDirection; uniform vec3 u_ViewPos; uniform vec3 u_LightColor; vec3 getDepthInLightSpace(vec4 vLightSpacePos) { vec3 Temp = (vLightSpacePos / vLightSpacePos.w).xyz; Temp = Temp * 0.5 + 0.5; //远平面外的深度值更改为0.0 if(Temp.z > 1.0) Temp.z = 0.0; return Temp; } void main() { vec3 ObjectColor = texture(u_DiffuseMapSampler1, VS_TexCoords).rgb; //Ambient Lighting float AmbientStrength = 0.3f; vec3 AmbientColor = AmbientStrength * ObjectColor; vec3 LightClipSpacePos = getDepthInLightSpace(VS_LightSpacePos); vec3 Normal = normalize(VS_Normal); vec3 LightDir = normalize(-u_LightDirection); //PCF阴影测试 float Offset = max(0.002, 0.0025 * (1.0 - dot(Normal, LightDir))); float Shadow = 0.0; vec2 texelSize = 1.0 / textureSize(u_DepthMapSampler2, 0); if(LightClipSpacePos.z != 0.0) { for(int x = -1; x]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>ShadowMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[老张培训笔记第五课责任链模式和适配器模式]]></title>
    <url>%2F2017%2F08%2F31%2F%E8%80%81%E5%BC%A0%E5%9F%B9%E8%AE%AD%E7%AC%94%E8%AE%B0%E7%AC%AC%E4%BA%94%E8%AF%BE%2F</url>
    <content type="text"><![CDATA[感谢老张！ 案例：实现员工请假系统，要求如下： 公司有三个级别的可以批假的员工，其批假权限为： TeamLeader：可以批准10天以内的请假。 ProjectLeader：可以批准20天以内的请假。 HR：可以批准30天以内的请假。 30天以上的假期不能批准，只能离职。 审批流程：先由TeamLeader进行审批，若权限不够则交由ProjectLeader处理，若权限还不够则交由HR处理。 分析上述案列，我们需要实现如下几个功能： 审批流程：TeamLeader→ProjectLeader→HR。 审批权限：每级都有自己独立的审批权限。 审批：审批动作本身。 最常见的方式 通常最容易想到的就是按C语言的方式在主程序里通过if-else的判断来实现这种逐级处理。 我们先把请假请求封装成一个类，当中有一个表示请假天数的成员变量（封装成类是为了后续需求变化考虑，因为可能请假可能不仅考虑到天数，还考虑到职位、在团队里的重要性等等）： class CLeaveRequest { public: CLeaveRequest() {} CLeaveRequest(int vLeaveDays) : m_LeaveDays(vLeaveDays) {} int getLeaveDays() const { return m_LeaveDays; } private: int m_LeaveDays; }; 我们再创建一个员工的基类（依赖倒置原则），它只有一个表示审批动作本身的函数，至于通不通过我们在主程序里通过if-else去实现： #include "LeaveRequest.h" class CEmployee{ public: virtual void approveLeaveV(const CLeaveRequest *vLeaveRequest) const = 0; }; 然后实现员工类的3个子类，它们各自有自己具体的审批动作： #include #include "Employee.h" class CTeamLeader : public CEmployee{ public: virtual void approveLeaveV(const CLeaveRequest *vLeaveRequest) const override { std::cout < "The leave request of" < vLeaveRequest->getLeaveDays() < " days has been approved by team leader." < std::endl; } };]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>责任链模式适配器模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[老张培训笔记第四课外观模式、观察者模式和命令模式]]></title>
    <url>%2F2017%2F08%2F30%2F%E8%80%81%E5%BC%A0%E5%9F%B9%E8%AE%AD%E7%AC%94%E8%AE%B0%E7%AC%AC%E5%9B%9B%E8%AF%BE%2F</url>
    <content type="text"><![CDATA[感谢老张！ 案例：房间里有一台电视和一台空调，按下遥控器的Open键后，可以同时打开空调和电视。设计程序来实现该按键的功能。 最普通的解决方案 最普通也是最容易想到的方法，就是分别建一个电视类、空调类、遥控器类，在遥控器类里调用电视类和空调类的打开方法，然后在主程序里调用遥控器类： TV.h: #pragma once #include class CTV{ public: void open(){ std::cout < "The TV is turned on." < std::endl; } };]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>外观 观察 者命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fermi Asynchronous Texture Transfer]]></title>
    <url>%2F2017%2F08%2F20%2FFermi-Asynchronous-Texture-Transfer%2F</url>
    <content type="text"><![CDATA[简介 NVIDIA Fermi 架构里存在拷贝引擎硬件，专门用于GPU到CPU之间以DMA的方式进行双向数据传输。Quadro中高端显卡会有两个拷贝引擎硬件，一个用于从GPU上下载数据到CPU，一个用于CPU上传数据到GPU。如下图所示： CPU上异步纹理传输：CPU Asynchronous Texture Transfers 使用多个PBO异步传输数据的图示如下：代码如下： GLuint pbo[2]; // The ping-pong pbo ? s unsigned int curPBO = 0; // Bind current pbo for app->pbo transfer glBindBuffer(GL_PIXEL_UNPACK_BUFFER, pbo[curPBO]); GLubyte *ptr; ptr = (GLubyte *)glMapBufferRange(GL_PIXEL_UNPACK_BUFFER_ARB, 0, size, GL_MAP_WRITE_BIT | GL_MAP_INVALIDATE_BUFFER_BIT); memcpy(ptr, pData , width * height * sizeof(GLubyte) * nComponents); glUnmapBuffer(GL_PIXEL_UNPACK_BUFFER); glBindTexture(GL_TEXTURE_2D , texId); // Bind next pbo for upload from pbo to texture object glBindBuffer(GL_PIXEL_UNPACK_BUFFER, pbo[1 - curPBO]); glTexSubImage2D(GL_TEXTURE_2D , 0, 0, 0, width , height, GL_RGBA, GL_UNSIGNED_BYTE, 0); glBindBuffer(GL_PIXEL_UNPACK_BUFFER, 0); glBindTexture(GL_TEXTURE_2D , 0); curPBO = 1 - curPBO; 注意这只是在单个渲染线程上，不同PBO的数据传输在并行执行，属于CPU异步输出。并没有用到GPU的Copy引擎。 GPU上异步纹理传输：GPU Asynchronous Texture Transfers GPU的Copy引擎硬件默认是不开启的，因为对于少量的数据传输，使用它会带来一些性能瓶颈。 为了触发Copy引擎，需要把数据传输(transfers)放在一个单独的线程里，这样GPU调度程序就会把渲染线程(render thread)发出的命令交由图形渲染引擎来完成，而数据传输线程(transfer thread)发出的命令会交由Copy引擎来并行执行。这就是GPU异步传输。图示如下： Implementation Details 多线程实现GPU异步传输时，需要为上传、渲染、下载分别建立一个单独的线程。下图是上传线程和渲染线程异步工作的图解：下图是渲染线程和下载线程异步工作的图解：值得注意的是我们是通过多张纹理数据来达到并行执行的效果，确保渲染线程在工作的同时，上传线程或下载线程会保持繁忙（busy）。 管理线程并发访问共享纹理为了管理线程到共享纹理的并发访问，需要为每个纹理创建类似signal这种同步原语。 OpenGL的绘制函数（glDraw*等）是异步的，所以函数返回时并不能保证渲染完成了，但是我们经常需要知道一些事会在什么时候完成，比如渲染线程需要知道纹理是什么时候上传完成的，它才能开始用这张纹理。这种信号交换由GL_ARB_Sync机制的同步对象（synchronization object）来负责管理，这些同步对象在不同的OpenGL上下文之间可以共享。一个上下文里创建的同步对象可以用来阻塞另一个上下文。 上传线程和渲染线程之间的同步机制如下图所示，渲染线程必须在上传线程传输完纹理数据后才能使用该纹理，渲染线程在使用某纹理的时候上传线程不能对该纹理传输数据：渲染线程和下载线程之间的同步机制如下图所示：其中 endUploadValid、endDownloadValid等用于避免线程之间出现忙等（？？？）。 Copy引擎注意事项 连接Copy引擎的OpenGL上下文也可以发送非非DMA命令，但是这些命令可能会和渲染线程分时，导致丢失并行性。如果序列化传输线程和渲染线程中的命令，可能会产生错误：“Pixeltransferis synchronizedwith 3Drendering.” Fermi的Copy引擎只允许pixel传输，而不允许vertex传输。 FBO和Copy引擎结合使用时，由于纹理附件和渲染缓存附件的验证，可能会带来一些性能瓶颈。出于这个原因，建议用glGetTexImage来下载数据，而非用glReadPixels从渲染缓存或者纹理附件里下载数据。 应该根据渲染时间和传输时间的比例来设置最佳共享纹理数，这需要很多次实验才能得出好的结果。两个时间平衡后，使用双缓冲纹理就足够了。 总结 上传数据时，在Quadro上比在GeForce上有更大的性能提升。 传输的纹理大小小于1MB时，Copy引擎带来的性能提升很小。 下载数据时，在GeForce上比在Quadro上有更大的性能提升。 对于渲染时间和传输时间平衡的应用程序，Copy引擎能够带来最大的性能提升。 参考文献：《OpenGL Insight》- Chapter29:Fermi Asynchronous Texture Transfers]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>异步传输</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Asyn Buffer Transfers]]></title>
    <url>%2F2017%2F08%2F20%2FAsyn-Buffer-Transfers%2F</url>
    <content type="text"><![CDATA[CPU和GPU之间的数据传输简介 调用OpenGL函数时，驱动程序会将其转换为一系列命令，并把这些命令添加到CPU端的命令队列中。这些命令会被GPU以异步的方式取出来执行。也就是说，OpenGL命令不一定会被立即执行，只是被放进了命令队列，实际的渲染执行都有可能在几帧以后了。 CPU和GPU之间的数据通过PCIe（PCI Express）总线来传输，是双向传输的。 CPU和GPU之间的数据传输是使用DMA机制来实现的。 pinned memory（固定内存）：固定内存也称作不可分页内存。由于不可以分页，所以操作系统不会将固定内存进行分页并交换到磁盘上，这块内存会始终驻留在物理内存中，不会被破坏或者重新定位。如果是分页的内存，CPU上的数据会先拷贝到一块不可见的pined memory（临时的页锁定内存）中，再传输拷贝到GPU中，会存在两次数据拷贝。malloc分配的是分页内存，cudaHostAlloc分配的是页锁定内存。使用pinned memory可以加速CPU和GPU之间的数据传输，性能可以提高两倍左右，但是不能滥用，因为固定内存驻留在物理内存中，如果固定内存很多，会导致系统内存被耗尽，程序无法正常运行，还会影响系统上其他应用程序的性能。用到的时候采取申请固定内存，不用的时候立即释放。 集成显卡（Integrated GPU）和CPU共享内核和内存空间，所以在CPU和GPU之间传输数据时不受限于PCIe总线的传输能力。但传输速度还是比不过对应的独立显卡（Discrete GPU）。 内存传输 CPU到GPU的数据传输函数使用glBufferData系列函数将数据从CPU传到GPU上时（即Buffer Object有可能存在于CPU，也可能存在于GPU上，由glBufferData函数的usage参数决定），会先将数据写到CPU内存（比如常用的GLfloat Verrtices[ ]）上，再由glBufferData函数将存储在CPU内存上的数据传到驱动（driver）的固定内存里，上传完之后，会立即以DMA的方式将数据从驱动的固定内存传到GPU内存上，同时glBufferData函数结束使命，函数返回。图示如下： 使用glMapBuffer函数可以得到驱动里固定内存的地址，直接将数据写到固定内存里，不用先把数据拷贝到CPU内存里，会比glBufferData函数更快。图示如下： Usage参数OpenGL可以把应用程序的数据最终存在CPU或者GPU上（存在CPU上时GPU通过PCIe总线来访问数据）。对于glBufferData和glMapBuffer函数，其usage参数可以帮助驱动程序（driver）决定最终要把数据存在哪个位置（不全由usage参数决定，驱动程序可能不会遵从usage指定的内容）。如下图所示： 隐式同步 驱动在绘制上一帧的数据（存在VBO里）时，可能应用程序已经想要开始传下一帧的数据了，如果用的同一个VBO，那么应用程序如果传下一帧数据就会破坏上一帧存在VBO里的数据，导致绘制结果不正确，所以OpenGL会存在一个隐式同步（Implict synchronization），等待驱动利用上一帧数据绘制完以后，应用程序才开始下一帧数据传输。如下图所示：这种隐式同步等待，可能会对程序程序性能造成严重损害（可能会增加好几毫秒的渲染时间）。 【注】： 绘制图形时，同时存在应用程序线程（负责发送OpenGL函数）和驱动程序线程（负责转换和处理OpenGL命令）。 应用程序线程里有调用glClear等等函数，驱动程序线程同样有glClear等等函数，这些函数是从应用程序传过来的，实际上在驱动里存储的是glClear等等函数的命令形式。 上传UpLoad 避免隐式同步的方法 缓冲对象循环链 （多缓冲） 重新分配缓存 使用glFenceSync、glClientWaitSync和glMapBufferRange函数来完全手动同步缓冲对象循环链（多缓冲）方法避免隐式同步之前会出现隐式同步，一个很重要的原因是应用程序线程和驱动程序线程使用的是同一个VBO，它们向同一块缓冲中写入和读取帧数据。所以，我们可以让它们循环使用不同的VBO来避免隐式同步：应用程序先向vbo[0]中写入帧数据，然后驱动程序在使用vbo[0]绘制的同时，应用程序向vbo[1]中传入帧数据，接下来驱动程序在使用vbo[1]绘制的同时，应用程序又向vbo[0]中写入帧数据……。如下图所示：重新分配缓存方法避免隐式同步上面是让两个线程分别操作两个不同的缓存对象，来避免隐式同步，其实还有另一种办法来保证应用线程的glSubBufferData函数和驱动线程的glDrawElements函数操作的不是同一个缓存：在应用程序调用glBufferSubData之前，先调用glBufferData函数在GPU上重新分配一块显存区域（新的VBO显存），用来接收后续glBufferSubData函数传过来的数据，原先的VBO显存不会被覆盖，依然可以为驱动线程的glDrawElements函数提供绘制图形的数据源。图示如下：驱动程序在调用glDrawElements绘制第n-1帧时，应用程序已经同时调用glBufferData函数在GPU上为VBO重新开辟了一段显存空间，然后用glBufferSubData为这块新的显存空间传输数据，但是glDrawElement还是用的原来的VBO显存在绘制，这样glDrawElements和glBufferSubData就是操作的不同的VBO缓存，就不会出现隐式同步了。【注】： 上图中左下角的memory block是指驱动程序里的固定内存，右下角VBO里的memory block是GPU显存。 glBufferData函数才会重新分配缓存空间，glBufferSubData不会。 除此之外，也可以使用glMapBufferRange函数配合 GL_MAP_INVALIDATE_BUFFER_BIT或者GL_MAP_ INVALIDATE_RANGE_BIT参数，来让VBO对应的固定内存失效，也就是对VBO和固定内存进行解绑，固定内存将对VBO不可见，这时通过映射后的指针向固定内存里写入数据，但是却不会将固定内存的数据传到VBO里，也就是不会影响glDrawElements使用的VBO显存数据，这样就可以在传数据的同时，驱动线程也并行执行glDrawElements。当使用映射指针传输完数据后，调用glUnmapBuffer函数，会重新让固定内存对VBO可见，这时才会开始把固定内存里的数据传入到VBO里： glBindBuffer(GL_ARRAY_BUFFER , my_buffer_object); void *mydata_ptr = glMapBufferRange(GL_ARRAY_BUFFER , 0, data_size, GL_MAP_WRITE_BIT | GL_MAP_INVALIDATE_BUFFER_BIT); // Fill mydata_ptr with useful data glUnmapBuffer(GL_ARRAY_BUFFER); 缺点但是上面两种方法只要和渲染操作一起同时使用，还是会造成高昂的同步代价（为什么？？？），而且使用glMapBufferRange里的这些参数标志，还会涉及到驱动器内存管理，这可能会带来10倍的性能消耗，所以不推荐使用这两种方式来避免隐式同步。可以使用接下来的异步缓存映射。 更好的方法：异步缓存映射方法避免隐式同步首先需要给glMapBufferRange函数传递 GL_MAP_UNSYNCHRONIZED_BIT标志，告诉OpenGL驱动不需要任何同步操作和重新分配内存操作，然后使用多个VBO缓存（通常3个就足够了，因为函数延迟一般不会超过两帧），每一帧使用各自的缓冲区进行数据读写和渲染。如下图所示：不过需要保证一个缓存区不会被多帧使用，比如第0帧在使用buffer[0]进行glDrawBufferRange，而第1帧也在使用buffer[0]进行glMapBufferRange。可以通过glFencSync和glClientWaitSync函数来实现：先调用glClientWaitSync函数对缓存对象对应的同步对象加锁，防止其他帧的函数也进来访问该缓存对象，使用glMapBufferRange函数取得的内存指针，写完数据后，开始绘制，绘制完后释放同步对象，这时其他帧的函数才能进来访问该缓存对象。 const int buffer_number = frame_number++ % 3; // Wait until buffer is free to use, in most cases this should not wait // because we are using three buffers in chain , glClientWaitSync // function can be used for check if the TIMEOUT is zero GLenum result = glClientWaitSync(fences[buffer_number], 0, TIMEOUT); if (result == GL_TIMEOUT_EXPIRED || result == GL_WAIT_FAILED) { // Something is wrong } glDeleteSync(fences[buffer_number]); glBindBuffer(GL_ARRAY_BUFFER , buffers[buffer_number]); void *ptr = glMapBufferRange(GL_ARRAY_BUFFER , offset, size, GL_MAP_WRITE_BIT | GL_MAP_UNSYNCHRONIZED_BIT); // Fill ptr with useful data glUnmapBuffer(GL_ARRAY_BUFFER); // Use buffer in draw operation glDrawArray(...); // Put fence into command queue fences[buffer_number] = glFenceSync(GL_SYNC_GPU_COMMANDS_COMPLETE, 0); 大多数情况下都是不需要同步的，因为我们还有第3个缓冲区，足够应用程序线程和驱动线程使用了。 其中glFenceSync函数用于发出信号，让阻塞在同步对象里的glWaitSync和glClientWaitSync命令变为非阻塞状态，返回释放的同步对象的名字；glWaitSync会导致OpenGL服务端被阻塞，直到指定的同步对象发出释放信号或者等待超时；glClientWaitSync会导致OpenGL客户端（应用程序）被阻塞，直到指定的同步对象发出释放信号或者等待超时。 下载Download 使用PBO下载数据大多数情况下我们都是从GPU上下载纹理到CPU，这时就需要用到glReadPixels和PBO了（直接glGetTexImage很慢）。先将数据渲染到纹理，再使用glReadPixels将纹理数据读入到PBO中，值得注意的是，在为PBO缓存对象分配内存空间时，即调用glBufferData时，需要指定usage参数为GL_*_READ形式，这样OpenGL就会把PBO放在驱动的固定内存里，可以直接被应用程序通过映射指针来访问。如下图所示：但是应用程序需要同步等待数据从GPU完全传输到驱动内存里以后，才可以调用glMapBuffer来访问驱动固定内存里的数据，那么怎么避免这个等待呢？ 在read和map之间做一些别的工作来避免闲置等待在调用glReadPixels函数后，做一些无关的CPU操作，等DMA数据传输完以后，再调用glMapBuffer函数。这种方法其实不实用，因为不好控制执行多少CPU操作数据才会传输完，而且这样做会增加代码的难度，难以写出高效的代码。 错帧调用map来避免闲置等待在调用glReadPixels函数的前一帧或者后两帧，再调用glMapBuffer函数。因为这时候数据通常都已经传输完了。这种方法也需要多缓冲来实现（用多缓冲来控制前一帧或者后两帧使用map来读取对应缓冲）。 信号锁明确告知数据传输完成时间点，结合多张纹理来避免闲置等待和上传时的异步缓存映射方法一样，使用信号锁。先调用glReadPixels函数，将数据从GPU传到驱动内存里，传输完后调用glFenceSync函数释放同步对象，在glMapBuffer之前，先判断同步对象是否被释放，如果被释放则说明数据已经全部从GPU传到了驱动内存里，立即开始映射数据到应用程序内存： if (rb_tail != rb_head) { const int tmp_tail = (rb_tail + 1) & RB_BUFFERS_MASK; GLenum res = glClientWaitSync(fences[tmp_tail], 0, 0); if (res == GL_ALREADY_SIGNALED || res == GL_CONDITION_SATISFIED) { rb_tail = tmp_tail; glDeleteSync(sc->_fence); glBindBuffer(GL_PIXEL_PACK_BUFFER, buffers[rb_tail ]); glMapBuffer(GL_PIXEL_PACK_BUFFER, GL_READ_ONLY); // Process data glUnmapBuffer(GL_PIXEL_PACK_BUFFER); } } const int tmp_head = (rb_head + 1) & RB_BUFFERS_MASK; if (tmp_head != rb_tail) { glReadBuffer(GL_BACK); glBindBuffer(GL_PIXEL_PACK_BUFFER, buffers[rb_head]); glReadPixels(0, 0, width , height, GL_BGRA, GL_UNSIGNED_BYTE , (void*)offset); fences[tmp_head] = glFenceSync(GL_SYNC_GPU_COMMANDS_COMPLETE, 0); //new add } else { // We are too fast } 由于有多张纹理在同时从GPU传到CPU里，所以一个被阻塞，另一个可能还在继续传输数据，这样相当于同步等待的时间也没有被浪费，被其他纹理传输利用起来了。 在AMD显卡上，glUnmapBuffer有时候是同步的，如果需要异步，需要用AMD_pinned_memory扩展。在NVIDIA显卡上，先使用glReadPixels把数据读到一个缓存（GPU上的一个临时buffer）里，再使用glCopyBufferSubData把这个缓存里的数据拷贝到CPU缓存里，速度会快两倍： glBindBuffer(GL_COPY_READ_BUFFER, source_buffer); glBindBuffer(GL_COPY_WRITE_BUFFER, dest_buffer); glCopyBufferSubData(GL_COPY_READ_BUFFER, GL_COPY_WRITE_BUFFER, source_offset , write_offset , data_size); 多线程和共享上下文 线程和上下文每一个用到OpenGL函数的额外线程都需要有自己的上下文，并且需要显式地连接到第一个上下文以便共享OpenGL对象，驱动程序会为每一个线程创建一个命令队列。如下图所示： 多线程共享上下文时会的同步问题 由于多个线程之间没有隐式同步，可能会发生一个线程正在上传数据你，而另一个线程在用这些数据，这样可能会导致用的时候只上传了部分mesh或者部分实例化数据等等。 可能由于多个线程在驱动里共享上下文的原因， 会导致每帧的渲染时长增加0.5ms左右。 多线程共享上下文并不会让数据传输和渲染并行执行。 避免多线程共享上下文建议即使用到多个线程离线上传数据或任务时，也不要共享上下文。如下图所示：这幅图中没有画出驱动线程。在单线程环境下，客户端只有一个应用程序线程，同时负责将数据从CPU传输到驱动内存的任务，以及利用这些数据进行渲染的任务。在客户端有两个线程和一个上下文的环境下，应用程序线程负责将数据传输到驱动内存，同时渲染线程会比应用程序线程滞后一帧，渲染N-1帧的数据。可以看到多线程单上下文的环境下，帧渲染时长比单线程短了很多。 补充和总结 在渲染循环中，如果在某一帧使用glEnable改变了某个状态，由于OpenGL会发生一个漫长的状态验证过程，所以可能会增加很多渲染时间。 通常情况下，建议使用单线程和多缓冲（map时设置 GL_MAP_UNSYCHRONIZED_BIT标志），因为对于提升现有程序的性能它是一个更简单有效地方式。 参考文献：《OpenGL Insight》- Chapter28:Asynchronous Buffer Transfers]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>异步传输</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[老张培训笔记第三课工厂模式和单例模式]]></title>
    <url>%2F2017%2F07%2F18%2F%E8%80%81%E5%BC%A0%E5%9F%B9%E8%AE%AD%E7%AC%94%E8%AE%B0%E7%AC%AC%E4%B8%89%E8%AF%BE%2F</url>
    <content type="text"><![CDATA[感谢老张！ 案例：暴发户有几两汽车：Benz、Audi，上不同的车都会有对应的开车行为。 简单工厂 最简单的实现方式如下： #include #include class CCar { public: virtual void driveV() = 0; }; class CBenz : public CCar{ public: virtual void driveV() override{ std::cout < "Driving Benz..." < std::endl; } }; class CAudi : public CCar { public: virtual void driveV() override { std::cout < "Driving Audi..." < std::endl; } }; class CCarFactory { public: CCar* createCar(std::string vCarName) { if ("Benz" == vCarName) return new CBenz; else if ("Audi" == vCarName) return new CAudi; else return NULL; } }; int main() { std::string CarName; std::cin >> CarName; CCarFactory CarFactory; CCar* Car = CarFactory.createCar(CarName); if(Car) Car->driveV(); return 0; }]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>工厂模式单例模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[老张培训笔记第二课面向对象设计原则]]></title>
    <url>%2F2017%2F07%2F18%2F%E8%80%81%E5%BC%A0%E5%9F%B9%E8%AE%AD%E7%AC%94%E8%AE%B0%E7%AC%AC%E4%BA%8C%E8%AF%BE%2F</url>
    <content type="text"><![CDATA[感谢老张！ 新增加代码的是否是必须的？判断标准是： 程序不会因为新增加的代码而发生连锁反应 新增加的代码不用了解源程序过多的细节 枚举就不是一个好的设计风格，因为枚举类型增加时，需要去修改原有的代码，需要去了解源程序与枚举相关的很多地方。 开闭原则：团队开发中，需求增加时，只增加自己的代码，不应该更改已有的代。即对扩展开放，对修改关闭。开闭原则是面向对象最重要的设计原则，其关键在于抽象。 案例：绘制圆和正方形。最粗暴的做法如下： #include class CCircle { public: void draw() { std::cout < "Drawing cirlce..." < std::endl; } }; class CSquare { public: void draw() { std::cout < "Drawing square..." < std::endl; } }; int main() { enum EShapeType { Circle, Square }; EShapeType shapeType[] = { Circle, Square }; for (int i = 0; i < sizeof(shapeType) / sizeof(EShapeType); i++) { switch (shapeType[i]) { case Circle: CCircle circle; circle.draw(); break; case Square: CSquare square; square.draw(); break; default: break; } } return 0; }]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>面向对象设计原则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[老张培训笔记第一课码农]]></title>
    <url>%2F2017%2F07%2F10%2F%E8%80%81%E5%BC%A0%E5%9F%B9%E8%AE%AD%E7%AC%94%E8%AE%B0%E7%AC%AC%E4%B8%80%E8%AF%BE%2F</url>
    <content type="text"><![CDATA[感谢老张！ 用设计模式去解决一些实际问题。 团队交流的重要性不亚于个人的编码能力。 若有一个简单的函数要实现几十个int型数据的加法，最粗暴的写法如下： int Add(int n) { int sum = 0; for (int i = 0; i < n; i++) { sum += i; } return sum; } 但是如果需求变成几十个float型数据相加呢，是不是需要把上面函数中的int都换为float，如果还增加了double、char等等呢，需要重复写上诉代码？ 很显然，这样做就真的是码农了，花大把时间做体力活。应该使用模板，如下： template T Add(T n) { T sum = 0; for (T i = 0; i < n; i++) { sum += i; } return sum; } 这样就可以很方便的调用Add(100)，Add(100.0f)，Add(‘!’)等等了。值得注意的是，在模板函数中声明变量时必须同时赋值来初始化，如上面程序中的T sum=0; 码农的定义：需求变化时，会有很多体力活要做。 对同一个功能，应该用更少的代码去实现。 多调试团队里其他人的代码，包括bug。 函数不能超过50行，这样函数的功能就会比较单一，方便给函数起名字，这样一来也能减少甚至达到不写注释。 在代码中应该尽量不要写注释，但注释不同于文档。注释是在说明变量代表什么，函数实现了什么功能，文档是在说明为什么这么设计，比如该函数为什么是私有的或者保护的。 在写代码中，不要ctrl+c、ctrl+v，也不要copy团队里其他人的代码，要使用别人的代码时，应该只需要调用别人预留的函数接口，而非具体的代码实现。 做起来像体力活的东西都需要改进。 用不同的设计模式来解决同一个问题。 问题示例：写日子文件。很多人的做法是仅仅实现了往文件里写东西的功能，但是没有考虑到效率问题，每收到一条log就打开文件、写文件、关闭文件。应该增加一个缓冲区，将日志信息先放到缓冲区中，每隔一段时间将缓冲区里的内容一起写入日志文件。 具体的实现细节应该隐藏在类内部，外部只需要知道类的功能是什么。 类的成员变量都应该尽量是私有的。甚至接口、虚基类里的成员变量也应该尽量私有（非保护）。为私有成员变量添加get、set函数，这样可以在get、set函数中对变量的读取、写入添加一些条件限制。 比如某个私有成员变量m_Money，只有当它的值大于1000时，才允许被读取到外界： int getMoney() { if (m_Money > 1000) return m_Money; else return -1; } 如果将m_Money直接写为公有的，那么外界就可以直接读取到该变量，但是如果增加了上面这个读取条件限制，那么就需要在每个读取该变量的地方，加上条件限制，很显然体力活又来了。这就是为何需要将成员变量写为私有的原因。 如下代码： vector getMoney() { vector array; for (int i = 0; i < 100; i++) { array.push_back(i); } return array; } 这样的函数是不够好的，因为它向外界暴露了函数内部数据的存储方式为vector，如果哪天把vector改为了List，那么外界所有调用该函数的地方可能都需要随之改变，把外界的vector改为List，体力活又来了。 如果想返回vector里的所有数据，通常get函数会接收一个输入输出参数，比如数组，来存储vector里的所有数据。当然，这样好的设计风格确实带来了数据复制时的性能开销。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>码农</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++浅层拷贝和深层拷贝]]></title>
    <url>%2F2017%2F05%2F31%2FC%2B%2B%E6%B5%85%E5%B1%82%E6%8B%B7%E8%B4%9D%E5%92%8C%E6%B7%B1%E5%B1%82%E6%8B%B7%E8%B4%9D%2F</url>
    <content type="text"><![CDATA[拷贝构造函数 什么是拷贝构造函数拷贝构造函数是一种特殊的构造函数，其形参是本类对象的引用。它的作用是：在建立一个新对象时，使用一个已经存在的对象去初始化这个新对象。例如： Point p2(p1); 在建立新对象p2时，用已经存在的对象p1去初始化新对象p2，在这个过程中就要调用拷贝构造函数。 拷贝构造函数的特点拷贝构造函数具有以下特点： 因为它也是一种构造函数，所以其函数名与类名相同，并且没有返回值类型。 只有一个参数，并且是同类对象的引用。 每个类都必须有一个拷贝构造函数。如果我们没有自定义某个类的拷贝构造函数，那么系统会自动生成一个默认的拷贝构造函数，用于复制出数据成员值完全相同的新对象。 拷贝构造函数的一般形式自定义拷贝构造函数的一般形式如下： 类名(const 类名& 对象名){ ... } 例如： class Point { private: int x, y; public: Point(int a, int b) { x = a; y = b; } Point(const Point& p) { x = 2 * p.x; y = 2 * p.y; } }; 什么时候会调用拷贝构造函数有3种情况下会调用拷贝构造函数： 用一个对象去初始化另一个对象时。如下：Point p2(p1); Point p3=p1; 类对象作为函数参数时。如下：void func(Point p){ } 调用函数func，实参传入形参时会调用拷贝构造函数来初始化形参p。 函数返回值是类对象时。如下： Point func(){ Point p1(10,20); return p1; } int main(){ Point p2; p2 = func(); return 0; } 执行语句return p1时，将会调用拷贝构造函数将p1的值复制到一个临时对象中，这个临时对象是编译系统在主程序中临时创建的，函数运行结束时对象p1消失，但临时对象将会通过语句p2=func()将它的值赋给对象p2，执行完这个语句后，临时对象的使命也就完成了，该临时对象便自动消失了。 浅层拷贝构造函数 编译器会提供默认的拷贝构造函数，但它只是把传递进来的对象的每个成员复制到新对象的成员变量中去，两个对象的变量共享内存区域，我们把这种拷贝叫做浅层拷贝。 如果浅层拷贝的两个对象共享指针变量，那么当其中一个对象释放掉该存放指针变量的内存空间时，另一个对象的该指针变量就变成了野指针（迷途指针），会报错。如下所示： #include using namespace std; class Point { private: int *x; public: Point(int a) { x = new int(); *x = a; } ~Point() { cout < "delete" < endl; delete x; x = NULL; } Point(const Point& p) { x = p.x; } int getX() { return *x; } }; int main() { Point *p1 = new Point(14); Point p2 = *p1; delete p1; cout < p2.getX() < endl; return 0; }]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>拷贝构造函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ const详解]]></title>
    <url>%2F2017%2F05%2F30%2FC%2B%2Bconst%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[被const修饰的东西（包括变量、函数、返回值等等）都强制为只读的，可以防止外界意外地改动，可以提高程序的健壮性，所以我们可能经常看到一句话：“Use const whenever you need”。 用const修饰变量 对于const int *m;，const修饰的是整型变量*m，不是指针变量m，所以*m是不可变的，m是可变的，即： const int *m; int *n; m = n; //合法，m所指向的对象是可变的 *m = 14; //不合法，m指向的对象的内容是不可变的 const int *m和int const *m是一样的。 对于int * const m;，const修饰的是指针变量m，所以m是不可变的，但*m是可变的，即： int p; int * const m = &p; int *n; m = n; //不合法，m所指向的对象是不可变的 *m = 14; //合法，m指向的对象的内容是可变的 而且int * const m是必须在定义时赋初值的，否则m将指向随机的内存地址，这个内存地址是可能会变的，即m会变，则不符合const修饰的只读属性，所以必须在定义时为其指定一个确切的地址，而且一经赋值就不能再变了。 对于const int m，const修饰的是m，m的值是不可变的，如下：int n; const int m = n; int p = m; //合法，因为p是m的复制，不共用地址，不是同一个变量，可以有不同的读写属性 int& q = m; //不合法，因为p和m共用地址，是同一个变量，但p和m却具有不同的读写属性，不合语义 在定义m时也是需要赋初值的，因为m的值是一经确定不能再改变的，它需要从一开始就知道自己的值是多少，不能后续再通过赋值语句来确定自己的值，即m = 14;是非法的。int&amp; q = m不合法是因为m是只读的，q是可读可写的，但是m和q共用一个地址，实际上是同一个变量，但却有不同的读写属性，即可以通过改变q来改变m的值，这是不符合const语义的，所以它不合法。而int p = m合法是因为p是m的复制，和m不共用地址，不是同一个变量，可以拥有不同的读写属性，改变p并不会影响到m。 【注】： 上面的const int *m可以不用赋初值，是因为const虽然修饰的是*m，*m是不可以直接赋值改变的，但是指针m指向的内容（即*m）是可以通过改变m来间接改变的：const int *k; int m = 10; int n = 20; k = &m; cout < *k < endl; k = &n; cout < *k < endl;]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>const</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《GPP》第一章 架构、性能和游戏]]></title>
    <url>%2F2017%2F05%2F25%2FGPP%E7%AC%AC%E4%B8%80%E7%AB%A0%E6%9E%B6%E6%9E%84%E6%80%A7%E8%83%BD%E5%92%8C%E6%B8%B8%E6%88%8F%2F</url>
    <content type="text"><![CDATA[软件架构 衡量一个设计好坏的方法就是看它应对变化的灵活性。 如果两块代码耦合，意味着我们必须同时了解这两块代码，如果让它们解耦，那么只需了解其一。耦合得越低，更改所波及的范围就会越小。 好架构的代价 解耦意味着我们在进行扩展时仅需理解少量代码，但同时抽象却也增加了理解代码的难度。 如果过度关注代码的设计架构，便会得到一个架构已经失控的代码库。我们会看到接口和抽象无处不在。插件系统、抽象基类、虚方法众多，还有各种的扩展点。我们将花费大量时间去找到有实际功能的代码。要避免过度设计。 性能和速度 使用接口，能够让代码可以与任何实现这些接口的类进行工作，而不是使用具体类。 模板元编程可以让我们获得抽象接口而没有任何运行时开销，在编译期间就能决定在模板实例化时调用哪个类。 性能优化总是在某些假设下进行的。 软件架构好，灵活性高，但是会降低游戏性能，一种折中的办法是保持代码的灵活性，直到设计稳定下来，然后去除一些抽象，以提高游戏性能。 坏代码中的好代码 只是为了验证游戏想法、迟早会扔掉的一些代码，在编写时不必在意设计架构。 我们需要确保那些使用一次性代码的人明白这种一次性代码看起来能够运行，但是它却不可维护，必须被重写。让boss明白原型代码只能用1次，以后要接着用就不要要求快速原型。 有一个小技巧确保我们的原型代码不会变成真正的代码，就是使用不同于我们游戏使用的语言来编写。这样的话，我们就必须用游戏使用的语言重写一遍了。 简单性 保持简单性，代码量就会变少。这意味着更改代码时，我们的脑袋里只需装载更少的代码。 但是一个好的解决方案并不是更少的实际代码量，而是对代码的升华。 Blaise Pascal曾说：“我会写一封更简短的信，但我没有足够的时间。” Antoine de Saint-Exupery（书，小王子）：“极臻完美，并非无以复加，而是简无可减。” More.. 抽象和解耦能够使我们的程序开发变得更快和更简单。但不要浪费时间来做这件事，除非我们确信存在问题的代码需要这种灵活性。 在我们的开发周期中要对性能进行思考和设计，但是要推迟那些降低灵活性的、底层的、详尽的优化，能晚则晚。 如果我们将要删除代码，那么不要浪费时间将它整理得很整洁。摇滚明星把酒店弄得很乱是因为他们知道第二天就要结账走人。 在游戏发布前的两个月并不是我们开始担心“游戏的FPS只有1帧”问题的时候。&nbsp; 参考文献：Nystrom R. Game Programming Patterns[M]. ?:Genever Benning, 2014.11.]]></content>
      <categories>
        <category>游戏设计模式</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[OpenGL27：Gamma校正]]></title>
    <url>%2F2017%2F05%2F24%2FOpenGL27Gamma%E6%A0%A1%E6%AD%A3%2F</url>
    <content type="text"><![CDATA[现在的很多监视器都是阴极射线管显示器（CRT）或者LED显示器，它们在显示颜色时并非按照线性方式工作，我们在程序中输出的颜色，最终显示到屏幕上亮度会减弱，这对于计算光照和实时渲染的图形质量有一定影响，需要我们进行Gamma校正。 Gamma校正的概念及意义 我们在自己的图形程序中认为颜色(1.0,0.0,0.0)的红色强度应该是颜色(0.5,0.0,0.0)的两倍，但是实际上显示设备对于输入的原始值，是按照2.2次幂的的指数形式（简称Gamma指数变换）进行处理的，即$C_{out}=C_{in}^{2.2}$，其中2.2是Gamma系数，不同显示器的Gamma系数值会略有不同，通常在2.0到2.4之间。所以程序中红色分量增大到了2倍，但是显示器显示出来的红色亮度并不是2倍，而是暗一些，比2倍低（因为原始颜色值都是在0到1之间的小数）。显示器所做的这种Gamma指数变换如下图所示： 图1图中间的点线是我们在图形程序中通常认定的线性颜色，即我们希望在程序中颜色分量（横轴）增加的同时显示器显示出来的亮度也会同比例增加。当显示器接收了来自程序的线性原始值后，会进行上诉的指数运算，完成Gamma变换，然后输出图中下方实线所示的非线性颜色，除了0和1这两个端点以外，其他颜色分量的亮度都会降低。 【注】：线性颜色可以通俗地理解为我们最终想要的颜色。 所以，要想最终显示器按照我们在程序中预期的中间线性颜色来输出，我们需要在显示器执行Gamma指数变换之前，先做一个Gamma指数变换的逆变换：$C_{corrected}=C_{in}^{1.0/2.2}$，这样最终输出的颜色才会是我们在程序中指定的颜色，这个逆变换称为Gamma校正（Gamma Correction），对应图1中最上面的短划线。Gamma系数取2.2进行校正在大多数显示器上效果都比较理想。例如颜色(0.5，0.0，0.0)进行Gamma校正后会变为：$(0.5,0.0,0.0)^{1/2.2}=(0.73,0.0,0.0)$，校正后的颜色接下来会被发送给显示器，由于现实器会对输入的颜色做Gamma指数变换，所以最显示出来的颜色是：$(0.73,0.0,0.0)^{2.2}={0.5,0.0,0.0}$，与我们在程序中最初想要输出的颜色一致。 下图是Gamma变换前后的效果图，可以看到Gamma变换后的亮度增大了，恢复为程序想要的正常颜色。 图2 在程序中使用Gamma校正 有两种在场景中应用Gamma校正的方式： 使用OpenGL内置的sRGB帧缓冲。使用glEnable(GL_FRAMEBUFFER_SRGB)开启sRGB帧缓冲，告诉OpenGL每个后续的绘制命令里，在颜色存储到颜色缓冲之前都先校正sRGB颜色，即OpenGL会自动使用硬件为自定义帧缓冲和默认帧缓冲执行Gamma校正。sRGB这个颜色空间大致对应于Gamma2.2。 值得注意的是，Gamma校正应该放在最后一步，即把颜色输出给默认帧缓冲的前一步。如果在最后输出给屏幕之前就进行Gamma校正，那么后续操作都将是在操作不正确的颜色值（非线性的颜色值）。例如，如果使用多个帧缓冲，同时想要在两个帧缓冲之间传递的中间结果依然是线性颜色，那么只应该给最后的那个帧缓冲应用Gamma校正。 自己在像素着色器的最后使用程序进行Gamma校正。如下代码所示：void main(){ ... float gamma=2.2; color = vec4(pow(resultColor.rgb, vec3(1.0/gamma)), 1.0f); } 该方法有个问题就是为了保持场景中所有物体都应用了Gamma校正，必须在每个像素着色器里加上该Gamma校正。解决方案是使用后处理，在后处理窗口四边形上应用Gamma校正，这样就只用做一次Gamma校正就好了。 并非任何时候都要进行Gamma校正 我们在本地资源管理器中通过看图软件打开一张图片，想要通过图形程序显示和这张图片一模一样的效果，即看图软件中图片的颜色是我们想要的最终颜色，是线性颜色。由于图片显示到屏幕上会经过Gamma指数变换，所以内存中实际存储的图片颜色数据是经过Gamma校正以后的，因为这样才能在显示器上显示我们想要的线性颜色。换句话说，绘图或者编辑图片的过程就是对内存中颜色数据进行人为的Gamma校正。 如果我们在图形程序中做了Gamma校正，那么最终图形程序在显示器上显示的就是经过两次Gamma校正和一次Gamma指数变换后的非线性颜色（对应图1中最上面的短划线），但是本地看图软件打开的图片是线性颜色，这就会造成图形程序最终显示的图片比看本地看图软件打开的图片更亮，不是我们想要的一模一样的效果，如下图所示： 图3为了解决这个问题，我们可以首先使用Gamma指数变换把sRGB纹理的纹素值变回线性空间，再继续其他光照计算等等，最后再做一次Gamma校正，然后输出给帧缓冲： float gamma=2.2; vec3 diffuseColor = pow(texture(diffuse, texCoords).rgb, vec3(gamma)); 为每个sRGB空间的纹理做这件事很麻烦，幸运的是，OpenGL为我们提供了GL_SRGB和GL_SRGB_ALPHA内部纹理格式，使用这两种内部纹理格式，OpenGL会自动将颜色校正到线性空间中。可以这样定义一个sRGB纹理： glTexImage2D(GL_TEXTURE_2D, 0, GL_SRGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, image); 值得注意的是，不是所有纹理都在sRGB空间中，比如diffuse漫反射纹理几乎都是在sRGB空间，但是specular镜面贴图和法线贴图几乎都在线性空间中，因为这样比较容易获取光照参数，如果把镜面贴图和法线贴图都存储为sRGB纹理的话，光照就废了。 Gamma校正对光照衰减的影响 光照衰减的物理公式应该是二次的，比如之前文章里介绍的二次衰减方程，简化版如下： float attenuation = 1.0 / (distance * distance); 还可以用不太标准的双曲线函数来实现光源衰减： float attenuation = 1.0 / distance; 但是有趣的是，在不使用Gamma校正时，双曲线函数比二次函数有更好的衰减效果；使用Gamma校正时，二次函数比双曲线函数有更好的衰减效果。如下图所示： 图4这是因为不应用Gamma校正时，经过显示器Gamma指数变换后二次函数衰减方程变为$(1.0/distance^2)^{2.2}$，双曲线函数变为$(1.0/distance)^{2.2}=1.0/distance^{2.2}$，这和物体公式很接近，所以不应用Gamma校正时，二次衰减方程衰减得会非常快，而双曲线函数的衰减效果比较好。 总之，Gamma校正使我们可以在线性颜色空间中进行操作，因为线性空间更符合物理世界，使大多数物理公式都可以获得较好的效果，比如真实的二次光照衰减方程。&nbsp; 参考文献：LearnOpenGL]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>Gamma校正</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL26：Blinn-Phong模型]]></title>
    <url>%2F2017%2F05%2F24%2FOpenGL26Blinn-Phong%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[Phong模型的缺陷 在《OpenGL10：光照基础Phong模型》中，我们使用了Phong模型来模拟光照效果，但是在镜面高光系数很低（比如0.5），即镜面光半径很大的时候，它的镜面反射会失效，如下图所示：可以看到，镜面区域边缘迅速减弱并截止，出现这个问题的原因是视线向量和反射光向量之间的夹角大于90度了，根据Phong模型中max(dot(reflectDir, viewDir), 0);，夹角大于90度时，镜面反射系数会被设置为0，所以一旦视线方向和反射光之间夹角大于90度，镜面光就会突然消失，变为0，产生镜面光硬边缘。但是大于90度变为0这只适用于漫反射光，而不适用于镜面光。计算漫反射光需要的夹角是入射方向和法线之间的夹角，大于90度时，入射光转到了物体背面，变为0；但是计算镜面反射光需要的夹角是视线方向和反射光方向之间的夹角，大于90度时，光线不一定转到了物体背面，如下图：所以对于镜面光，不能在夹角大于90度时令镜面光反射系数变为0。 当镜面高光系数较大时，高光比较集中，当高光突变为0时还有很强的漫反射光存在，所以人眼观察到的镜面光硬边缘不明显；但是当镜面高光系数较小时，高光半径会很大，高光在边缘处突变为0时漫反射强度很弱，镜面光成分较高，此时的镜面光硬边缘就会很明显。 Blinn-Phong模型 1977年James F. Blinn提出了Blinn-Phong模型，它是对Phong模型的改进：放弃反射光向量，改用半程向量，半程向量是入射光线向量与视线向量的和向量，再归一化之后的单位向量。如下图中的向量H：Blinn-Phong模型不再使用法线与反射向量的夹角来计算镜面光，而是使用半程向量和法线向量之间的夹角。半程向量越靠近法线向量，人眼观察到的镜面光强度越大。只要不从物体背面去看，半程向量和法线向量之间的夹角永远都小于等于90度。 Blinn-Phong模型的代码实现 Phong模型计算镜面光的代码如下： vec3 reflectDir = normalize(reflect(-lightDir, normal)); vec3 viewDir = normalize(viewPos - positionInWorld); float specularFactor = pow(max(dot(reflectDir, viewDir), 0.0), 1); vec3 specularColor = specularFactor * lightColor; Blinn-Phong模型舍弃反射光向量，使用半程向量，代码如下： vec3 viewDir = normalize(viewPos - positionInWorld); vec3 halfDir = normalize(lightDir + viewDir); float specularFactor = pow(max(dot(halfDir, normal), 0.0f), 1); vec3 specularColor = specularFactor * lightColor; 可以发现Blinn-Phong模型除了表现效果更真实以外，还有个很大的优势：不用去计算复杂的反射光向量，降低了计算量，相比Phong模型性能更高。 当镜面高光系数为0.5时，Phong模型表现效果如第一幅图。Blinn-Phong模型表现效果如下图：由于半程向量和法线向量之间的夹角通常会比视线向量和反射向量之间的夹角更小，即余弦值更大，所以相同镜面高光系数下，Blinn-Phong模型的镜面光会比Phong模型更亮，Blinn-Phong模型要达到和Phong模型一样的效果，需要增大镜面高光系数，通常是Phong模型中的镜面高光系数的2到4倍。 所有源码请看这里。 &nbsp; 参考文献：LearnOpenGL]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>Blinn-Phong</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[交流中的启迪]]></title>
    <url>%2F2017%2F05%2F23%2F%E4%BA%A4%E6%B5%81%E4%B8%AD%E7%9A%84%E5%90%AF%E8%BF%AA%2F</url>
    <content type="text"><![CDATA[求取一个物体从某点看过去的轮廓（边缘检测）物体的边缘是由很多三角面片的边组成的，某条边是不是位于轮廓上，可以通过其三角形法线与视线方向向量的点乘来计算。如下图所示：每条边会被两个三角形共享，如果视线方向与其中一个三角形的点乘是正数，与另一个三角形的点乘是负数，则共享该边的两个三角形一个能被看见一个被挡住了，说明该边就是位于轮廓上。 此方法其实和冯氏漫反射光照很像。可以在几何着色器里实现，几何着色器可以接收类型为triangles_adjacency的图元，即接收一个三角面片的三个顶点和该三角面片的三个邻接顶点，如下图所示：根据这六个点计算出三角面片和其邻接面片的法线，用上述方法即可判断该三角面片的三条边是否有位于轮廓上。邻接顶点需要在CPU上事先算好（可以先存储由边构成的三角形，再判断当前边属于哪些三角形，再取出所属的邻接三角形的邻接顶点），存入顶点数据中传给顶点着色器。交流来源：师兄王振参考文献：《边缘检测》]]></content>
      <tags>
        <tag>交流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[毕设笔记]]></title>
    <url>%2F2017%2F05%2F22%2F%E6%AF%95%E8%AE%BE%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[在投影变换的过程中，就会剔除掉所有在视见体之外的片段，它们是不会从顶点着色器进入片元着色器的。也就是说那些在视见体之外的片段不会执行片元着色器。 深度测试是在片元着色器的过程中的，即使是那些被挡住的片段也是会执行片元着色器里的内容（比如片元着色器里的所有光照计算），很明显的证明例子就是延迟着色，延迟着色的优点就是剔除掉了对那些被遮挡的片段的光照计算。虽然被遮挡的和没被遮挡的片段都会执行光照计算，但是最后留在帧缓冲里的都是没被遮挡的片段，因为开启了深度测试。 透视除法也是在片元着色器之前的。当我们在顶点着色器输出一个裁剪空间顶点位置到gl_Position时，OpenGL会自动进行一个透视除法，将裁剪空间坐标范围的-w到w转换为-1到1。这要通过将x、y、z元素除以w元素来实现。 纹理采样时，纹理坐标是在每一个纹素的中心位置采样的。比如一张1024 * 768的纹理，如果传入的纹理坐标范围是0~1，那么采样最左下角的纹理坐标应该是（1/1024*0.5，1/768*0.5），它的右边的纹理坐标应该是（1/1024*1.5，1/768*1.5）。 片段坐标gl_FragCoord也是这样。 memset函数不能对数组置0和-1以外的值。 CPU上的结构体可以有构造函数，但是GPU上着色器里的结构体内不能有任何函数。想要对着色器里的结构体初始化，只能到CPU上进行。 如果前面有用过glActiveTexture()，那么后面绑定纹理时，也必须得用该函数激活对应的纹理单元，即使这时只有一个纹理要绑定（或者说要去采样）。如果前面激活了GL_TEXTURE0，且用完纹理后解绑了，那么后面绑定时可以再激活绑定到GL_TEXTURE0上；如果没有解绑，就得绑定到其他没用过的纹理单元上。 使用完纹理后，一定要记得立即解绑，否则可能出现很诡异的结果。 shader里的着色器缓冲对象SSBO和uniform缓冲对象UBO等等，有std140或者std430的修饰时，一定要注意字节对齐。 比如下面这个着色器里的缓冲对象SSBO： struct Light{ vec3 Position; //世界坐标 vec3 Color; float radius; //光体积半径 }; layout (std430, binding = 3) buffer LightsData{ Light lights[]; }; 因为buffer里的成员是结构体，而根据std140和std430的对齐规则，结构体对齐值应该是结构体内最大成员的对齐值，所有上面结构体Light的对齐值就应该是vec4，即16字节对齐（vec3需要按vec4算）。也就是说GPU每次是按16字节一起读的，所以为了值正确，我们需要把上述结构体改为： struct Light{ vec3 Position; //世界坐标 float none; //用作16字节对齐 vec3 Color; float radius; //光体积半径 }; 或者： struct Light{ vec4 Position; //世界坐标 vec3 Color; float radius; //光体积半径 }; 如果还是原来的Light结构体的话，读vec3类型的Position时，会一次直接读走32个字节（vec4），这样就把Position后面的Color的前4个字节读走了，导致Position和Color的值都不正确。所以我们可以把Position改成vec4，或者在它后面添加一个float，来补足16字节。后面vec3类型的Color和float类型的radius正好组成16字节，可以一次读走，每个成员数据在读的时候没有被中断而分成两半，所以这样读出来的值才是正确的。 使用glTexImage2D函数生成图片后一定要设置图片的过滤方式，否则图片不会显示。 实验证明，如果不使用glClear清除深度缓冲，OpenGL默认深度值是0.0。使用该函数清除了深度缓冲之后，才会将深度值设为1.0。所以如果一直不使用glClear(GL_DEPTH_BUFFER_BIT)，而且开启了深度测试，将会黑屏，画不出来任何东西，因为深度值是0.0，每个片段都无法通过深度测试。 如果在自定义的帧缓冲里有深度测试，一定要给自定义的帧缓冲绑定深度附件（渲染缓冲或者纹理附件都可以），否则深度测试无效。傻B又惨痛的教训~~ 某个变量在shader里没有被赋值给别的变量，那么它就不会被NSight显示出正确的值。想要看出它的正确值，只有把它再赋值给另一个变量了，观察另一个变量的值是多少。如下面的程序： for(int i = 0; i < 5; i++){ ... } 在循环过程中，由于i没有被赋值给别的变量，所以NSight所显示出来的i值就一直是0，如果想看到i的值，可以加一行代码，如下： for(int i = 0; i < 5; i++){ int j = i; ... } 用NSight调试可以看到，i的值虽然一直都是0，但是j的值却会从0变到4。 这个结论不一定正确，只是经验之谈。不过却提供了一种调试的方法，当发现NSight给出的值明显不正确时（它可能给出的是0或者？？？等等），可以把它赋给另一个变量，就可以看到正确的值了。 GPU对于if-else的处理，并不像LearnOpenGL中（Deferred Shading那一节）讲得那样：为了GPU高度并行if分支和else分支都会被执行，执行完之后再回滚。做实验如下： #version 430 core out vec4 color; void main(){ if(true){ color=vec4(1,0,0,1); } else{ while(true){} } } 如果if和else分支都执行，那么程序将陷入死循环，但是实际运行结果是屏幕上会出现红色矩形（该着色器用于绘制一个矩形），说明else分支没有被执行。如果把程序改成如下，将会陷入死循环（实验的结果就是重启电脑吧！卡住了！）： #version 430 core out vec4 color; void main(){ if(true){ while(true){} color=vec4(1,0,0,1); } else{ while(true){} } } 自定义程序实现的前置深度测试：比如我们需要对一个模型进行很多很复杂的光照计算，为了不让被遮挡住的片元也去进行光照计算（因为被遮挡的片元颜色是不会显示出来的，它所进行的关照计算对最后的显示结果是多余的），我们可以采用延迟着色（Deferred Shading）或前向着色（forward shading）。延迟着色很好理解，而对于前向着色，为了不让被遮挡的片元也进行光照计算，我们也可以向延迟着色一样，把光照阶段剥离出来：先开启深度测试把模型绘制一遍，把深度值保存到深度纹理中，这样在深度纹理中的深度值就是模型最靠近摄像机的片元的深度值了（这是第一个pass）；接着我们再把模型绘制一遍，在这次绘制中，我们先在片元着色器里，判断当前片元的深度值是否大于深度纹理中对应位置的深度值，如果是则直接返回，不用再进行接下来的光照计算，否则照常进行光照计算，赋予片元光照下的颜色值： void main(){ if(gl_FragCoord.z > texture(TexForDepth, vec2(gl_FragCoord.x/1024.0f, gl_FragCoord.y/768.0f)).r ){ return; } //执行光照计算 ... } 这样一来，就只有最后会被显示到窗口上的片元才会去执行光照计算，大大减少了光照计算的次数。 但是在实际运用中，按照上诉代码来实现前置深度测试，会出现如下图所示的抖动现象：这通常是由于计算机对浮点数精度表示的不准确而造成的，我们在条件判断的时候加上一个很小的误差就能解决这个问题了： void main(){ if(gl_FragCoord.z > texture(TexForDepth, vec2(gl_FragCoord.x/1024.0f, gl_FragCoord.y/768.0f)).r + 0.00001){ return; } //执行光照计算 ... } 结果如下： GLFW的回调函数：按键回调函数、鼠标位置回调函数、鼠标滚轮回调函数等等，都是在事件触发之后才会执行的。也就是说鼠标放在窗口里不动，是不会调用鼠标位置回调函数的。 类的私有构造函数是不会被执行的。比如单例模式中的私有构造函数。 在单例模式中，返回的实例对象最好是指针类型的，如果是直接返回静态的实例对象，那么在其他地方对返回的这个实例对象的修改是不会影响到原单例类的实例对象的：单例类A： static A getInstance(){ return m_Instance; } void init(){ m_Count = 10; } 其他类B： A::getInstance().init(); 另一个类C： cout]]></content>
      <categories>
        <category>毕设</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[项目中遇到的C++特性问题]]></title>
    <url>%2F2017%2F05%2F09%2FC%2B%2B%E7%89%B9%E6%80%A7%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[多态使用基类实现多态时，是使用基类指针，而不是基类对象： class A{ virtual print(){ cout < "A"]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>c++特性</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[项目中遇到的C++编译链接错误]]></title>
    <url>%2F2017%2F05%2F09%2FC%2B%2B%E7%BC%96%E8%AF%91%E9%93%BE%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[编译时出现重定义，可参考这篇文章 链接时出现LINK1120：无法解析的外部符号，这种情况通常都是没有包含对应的库文件，或者库文件没有包含正确。库文件包括.lib和.dll。 链接过程中出现读取访问冲突，很可能是空指针造成的。如果是在调用OpenGL函数的时候出现该问题，无法访问某个地址，则很有可能是在初始化GLEW之前就调用了该函数。要知道没有初始化GLEW，有可能某些OpenGL函数是无法使用的（版本问题）。 使用静态成员变量时出现无法解析的外部符号：原因是静态成员变量必须在类外进行初始化，否则的话是不会给它们分配内存空间的。 c++对bool变量的默认值是没有规定的，根据编译器不同，可能默认是true，也可能是false，应该自己显示对bool变量赋初始值，不要让编译来决定。 如下代码： test1.h: #pragma once #include "test2.h" class A { }; test1.cpp: #include "test1.h" int n = 10; test2.h: #pragma once #include "test1.h" #include extern int n; class B { public: void draw() { std::cout < n < std::endl; } };]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>编译链接错误</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C测试笔记]]></title>
    <url>%2F2017%2F04%2F19%2FC%E6%B5%8B%E8%AF%95%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[C语言中默认没有bool类型。需要加上stdbool.h头文件以后才能使用bool类型。 符号常量（用define定义的）和变量不同，符号常量是不占内存的，只是一个临时符号，预编译后这个符号就不存在了。 变量名实际上是以一个名字代表的一个存储地址。编译链接时，编译系统会给每一个变量名分配对应的内存地址。 常变量（用const定义的）和常量不同，常变量具有变量的基本属性，有类型，占存储单元，而常量只是一个数，没有名字不占内存。 编码中常用的字符’1’、’A’等等，在内存中是以ASCII码存储的，占一个字节。字符’1’和整数1是不同的，整数1是以整数存储方式（二进制补码）存储的，占4个字节。例如：char c = '1'; printf("%d",c); char a = 1; printf("%d",a); 输出结果是49和1。 字符型char也有signed和unsigned。 表达式如下：printf("%7.2f\n",12.345678f); 输出结果如下：12.35 整数部分12前面还有两个空格，%7.2表示输出结果总共占7列（包括小数点），保留两位小数并且会有四舍五入。 c语言中没有string类型，但是却可以使用strlen、’strcpy’等字符串函数：#include int main() { char str[4] = "acd"; char str1[4]; strcpy(str1,str); printf("%d\n",strlen(str)); printf("%s",str1); return 0; } 输出结果是：3 adc 注意上面字符数组str的长度是4，这样赋值后C语言会自动在末尾添加一个\0。末尾有’\0’的字符数组才相当于字符串，才可以使用这些字符串函数。如果把str数组的长度改为3，是得不到正确结果的：char str[3] = "acd"; //不能正常使用字符串函数 char str[] = "acd"; //可以正常使用字符串函数 使用这些字符串函数时不需要加额外的头文件。 float型小数只能保证6位有效数字，double型小数只能保证15位有效数字。 printf(&quot;%-10.6f&quot;, a);是左对齐的，不足的列数在右端用空格补齐；printf(&quot;%10.6f&quot;, a);是右对齐的，不足的列数在左端用空格补齐。 指数格式输出：printf("%e\n", 123.456); 输出结果是：1.234560e+002 如果想输出‘%’，应该使用两个’%’：printf("%%"); 如果是scanf(&quot;%d%d%d&quot;, &amp;a, &amp;b, &amp;c);，则应该像这样输入1 2 3，以空格或者回车来分隔每个输入的数据。但如果是scanf(&quot;%d,%d,%d&quot;, &amp;a, &amp;b, &amp;c);，则需要像这样输入1,2,3，需要加上逗号。 C语言中求log_10 x 的函数是log10，也有log函数，不过它求的是lnx。 求最大公约数的核心思想：对于辗转相除法（欧几里德算法），核心点在于m、n和m%n的最大公约数是相等的，一直除余到0后，得到的除数或者说被除数就是最大公约数： int gcd(int m,int n){ if(mC A->C C语言变量存储类别有4种：自动的（auto）、静态的（static）、寄存器的（ register）、外部的（extern）。 静态局部变量（在函数中定义的static变量）是在编译时赋初值的，即只赋值一次，以后每次调用函数时不再重新赋初值，而是保留上一次函数调用结束后的值。如果不对静态局部变量赋初值，编译时会自动赋为0或者空字符\0，但是如果不对自动变量赋初值，它的值就会是不确定的。因为静态局部变量是存放在静态存储区的，程序执行过程中不会改变位置，而自动变量是存放在动态存储区的，在每次函数结束后都会释放存储单元，下次调用时又重新分配存储单元，而所分配的存储单元中的内容是不可知的。 寄存器变量使用register声明的变量，如下：register int i; 寄存器变量用于存储那些使用非常频繁的变量，比如在10000次循环中每次都要用到的变量。其实现在的编译系统通常都能识别使用频繁的变量，从而自动把这些变量放到寄存器里，不需要程序设计者指定。所以用register声明变量的必要性不大。 extern外部变量：其实用extern声明的外部变量是强制把变量的作用域扩大了。比如在同一个文件中，变量在后面声明的，但是在前面就想要用到这个变量，那么可以在用这个变量时，使用extern声明一下这个变量，把它的作用域扩展到此声明处。如下： int main(){ extern int A,B,C; ... } int A,B,C; int max(int a, int b){ ... } 还可以使用extern把全局变量的作用域扩展到另一个文件：比如在一个程序文件中声明了全局变量Num，在另一个程序文件里也想使用这个变量，那么可以在另一文件中用extern对Num扩大作用域，即extern Num;。在编译连接时，系统会由此知道Num有外部链接，就会从别的文件找到已定义的Num变量，并把作用域扩展到本文件。 把全局变量的作用域强制限制在本文件，可以使用static关键字声明。这样有利于不同文件独立，即使在不同文件中定义了同名的全局变量，甚至使用了extern关键字，都会互不影响。 注意对于全局变量来说，无论是否用static关键字声明，它都是存储在静态存储区的，这一点和局部变量不同： 对局部变量用static关键字声明，会把它分配在静态存储区，该变量在整个程序执行期间不释放其存储单元，知道程序结束。 对全局变量用static声明，是限制该变量的作用域只限于本文件模块（即被声明的文件中）。 【注】：全局变量是指在函数外部定义的变量，不一定是在文件开头处定义的外部变量。也就是说这里的全局变量就是外部变量。 在函数定义时用static声明，是把该函数作为静态函数，限制在本文件中使用，如果在函数定义时用extern声明，则该函数可以在其他文件中使用，在其他文件中使用时需要先用extern声明该函数，表示该函数是在其他文件中定义的。其实在C语言中可以省写extern，因为函数在本质上就是外部的。可以知道，函数原型声明其实就是扩大函数的作用域（到本文件的该函数前面区域，甚至扩大到其他文件都可以）。函数原型会通知编译系统，该函数在本文件稍后定义，或在另一文件中定义。利用函数原型扩展函数作用域最常见的例子就是#include &lt;....h&gt;，因为通常在 #include指定的头文件中包含了很多函数原型，以此来扩展函数作用域到本文件。 变量名其实就是地址的别名，可以通过变量名直接访问到对应地址中的内容；而指针是另一个变量，它存储着别的变量所对应的地址，访问时，指针变量会根据自己对应的地址去取出地址里的内容，而这个内容就是另一个变量的地址，再根据取出来的这个地址，就可以去访问另一个变量里存储的内容了。总之，通常所说的指针是一个存储着别人的地址的变量。 如果指针是字符型的，那么指针加1，是使它存储的地址值加1；如果是整型的，那么指针加1，是使它存储的地址值加4。 指针运算符*和自加运算符++是同等优先级的，所以*p++等价于*(p++)，都是先取*p，再使p加1。*(++p)是先使p加1，再取*。 对于二维数组a[m][n]来说，a表示首行（第0行）的首地址，a+1表示第1行的首地址，就是指向a[1]，和&amp;a[1]等价。注意对于二维数组来说，a[i]只是第i行的首地址，是个指针，a[i]和*(a+i)等价，a[i][j]和*(*(a+i)+j)等价。要表示二维数组中某个元素的值，应该是两层指针*。还有，&amp;a[0]与a等价，都是指向第0行的，a[0]是指向第0行第0列的；&amp;a[1]与a+1等价，都是指向第1行的。总之a、a+i等是二维指针，有两个**，a[0]等是一维指针，有1个*。如下面的程序：int a[2][2]={0}; printf("%d\n",a); printf("%d\n",*a); printf("%d\n",**a); 输出结果如下：2686720 2686720 0 可以使用指针指向的字符串来代替printf函数中的格式字符串：char* format; format = "a=%d,b=%f\n"; printf(format,a,b); 它相当于：printf("a=%d,b=%f\n",a,b); 只要改变format所指向的字符串，就可以改变输入输出的格式，这种printf称为可变格式输出函数。当然用字符数组代替上面的指针也是可以的。 函数指针：指向函数代码存储空间首地址的指针。如下： int (*p)(int,int); 这个p就是指向函数的指针变量，它可以指向函数类型为int且有两个int型参数的函数。除了用函数名来调用函数，我们还可以通过函数指针来调用函数： #include int max(int a,int b); int main() { int a=1,b=2; int(*p)(int,int); p=max; printf("max is %d\n",(*p)(a,b)); return 0; } int max(int a,int b){ return a>b?a:b; } 其实就是用函数指针*p代替了函数名max而已。 函数指针可以作为其他函数的参数，这样在不同情况下通过传入不同的实参，就能实现调用不同的函数。 int *p[4]和int (*p)[4]是不一样的，前者是指针数组（有4个指针的数组），后者是指向一维数组的指针变量。 带参数的main函数：int main(int argc, char* argv[]){ ... } main函数也是可以带有参数的，argc是argument count的缩写，表示参数个数，argv是argument vector的缩写，是一个char*指针数组，数组中的每一个元素指向命令行中的一个字符串。由于main函数是有操作系统调用的，所以它的参数也是由操作系统提供。通常在命令行状态下，我们可以通过类似DOS界面给main函数指定参数。在DOS下的命令行一般形式是：可执行文件名 参数1 参数2......参数n 它们之间用空格分开。可执行文件里应该包含main函数，且实际上应该还要包含文件路径。如果我们给出的命令行像这样：file1 China Beijing main函数像这样：int main(int argc, char* argv[]){ while(argc>1){ ++argv; printf("%s\n",argv); --argc; } return 0; } 执行程序后会输出如下：China Beijing C语言里的动态分配内存相关函数（声明在stdlib.h头文件中）： malloc函数：函数原型是：void* malloc(unsigned int size);，用于在内存的动态存储区中分配一个长度为size字节的连续空间。 calloc函数：函数原型是：void* calloc(unsigned n, unsigned size);，用于在内存的动态存储区分配n个长度为size字节的连续空间。例如：p=calloc(50,4);。 free函数：函数原型是：void free(void* p);，用于释放指针变量p所指向的动态空间。 realloc函数：函数原型是：void* realloc(void* p, unsigned int size);，用于改变指针p所指向的动态空间的大小为size字节。 约瑟夫环：n个人围成一圈，从任意某个人从1开始报数，报到第m个的人拖出去，剩下的人接着从1开始报数，报到第m个的人再拖出去，……，如此循环，问最后一个人是原来的第几个人。该问题可用数学方法解决，也可用循环链表实现。 下面的程序是正确的：int* p; p=malloc(sizeof(int)); p[2]=200; printf("%d\n",p[2]); 但是如果把第二行去掉，会报错，这是因为没有指明指针p指向哪个位置，p[2]是无意义的。 使用union声明的共用体，它里面的所有成员都是从同一个位置开始存放的（覆盖技术）。每一瞬间只能存放一个成员。 用typedef声明新类型名：typedef int Interger; //指定用Integer为类型名，作用与int相同 文件分为ASCII文件和二进制文件。比如整数10000，用ASCII码存储到文件时，占用5个字节；而以二进制形式存储到文件时，只占用4个字节。 C语言使用File* fopen(文件名，文件打开方式);来打开文件；使用int fclose(File*)来关闭文件；使用char fgetc(File*)来从文件读取一个字符，使用char fputc(char, File*)来把一个字符写入到文件。使用char* fgets(char* str, int n, File* fp)来从文件读取n-1个字符到str字符串中（末尾加’\0’）。使用int fputs(str, fp)来把字符串输出到文件。 例如，从一个文件中读取数据写入到另一个文件中： #include #include int main() { FILE *fin,*fout; char ch; fin=fopen("test1.txt","r"); if(fin==NULL){ printf("open file1 failed!\n"); } fout=fopen("test2.txt","w"); if(fout==NULL){ printf("open file2 failed\n"); } while(!feof(fin)){ ch=fgetc(fin); fputc(ch,fout); } fclose(fin); fclose(fout); return 0; } 上面是对文件以字符的形式进行输入输出，还可以格式化的方式读写文件： fprintf函数：fprintf(fout, "%d%f", i, f); fscanf函数：fscanf(fin, "%d%f", &i, &f); 由于fprintf函数在输出时要将内存中的二进制转换为字符，fscanf函数在输入时要将文件中的ASCII码字符转换为二进制在保存到内存变量中，这种转换要花费很多时间，所以我们通常使用fread和fwrite函数来代替他俩进行二进制的读写。 fread函数一次从文件中读取一个数据块，fwrite函数向文件写一个数据块。它们都是以二进制形式进行读写的。 fread函数原型：fread(buffer, size, count, fp);buffer是存储从文件读出的数据的内存起始地址，size是每个数据项的字节数，count要读取的数据项个数，fp是文件指针。 fwrite函数原型：fwrite(buffer, size, count, fp);buffer是准备写入文件的内存数据的内存起始地址，size、count、fp同上。 更改文件读写位置的相关函数： void rewind(FILE* fp)函数：强制将文件读写位置更改为文件开头。 fseek函数：函数原型是：fseek(文件指针，位移量，起始点);起始点有0、1、2三个选项，0表示文件开头，1表示当前位置，2表示文件末尾。位移量是以起始点为基准，向前移动的字节数。注意位移量数据类型是long型。例如：fseek(fp, 100L, 0); long ftell(FILE* p)函数：读出当前的文件读写位置。返回的是当前位置相对于文件开头的位移量。 牛顿迭代法求方程f(x)=0的根，实际上是从估计值x0开始，不断对fx切线方程，该切线与x轴（y=0）的交点x1会比x0更加精确（更容易使得f(x)=0），然后以x2求fx的切线，得到与x轴的交点x3…直到前后两次交点的差值满足一定的精度（小于某个值）。 long类型通常是4个字节。]]></content>
      <categories>
        <category>C语言</category>
      </categories>
      <tags>
        <tag>C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++里XXX重定义]]></title>
    <url>%2F2017%2F03%2F15%2FC%2B%2B%E9%87%8D%E5%AE%9A%E4%B9%89%2F</url>
    <content type="text"><![CDATA[有时候我们编译工程会出现重定义的编译错误，在同一个源文件里定义两个相同的变量就不说了，这是最低级的错误。我们来说一下其他可能造成重定义的原因和解决办法。 没有在头文件最前面加#pragma once：如果我们在同一个文件中包含了某个头文件两次：#include "A.h" #include "A.h" 那么在A里面定义的变量就会出现重定义的错误。 我们在某个文件中包含了A.h和B.h，但是在B.h里面也包含了A.h，那么就会造成A.h里面变量的重定义。 这种重复包含头文件，就会造成头文件被重复编译，出现重定义的编译错误。即使没有出现重定义的错误，但是这样重复编译头文件，也会使编译效率低下。一个解决办法是在头文件前面加上#pragma once，它的意思是让该头文件只编译一次。 但是如果在不同的头文件中定义了相同的类型，即使是加上了#pragma once，也会出现重定义。如下： ----A.h文件：----- #pragma once int A; //全局变量 ----B.h文件：----- #pragma once int A; //同样的全局变量 ----主程序：------ #include "A.h" #include "B.h" int main() { return 0; } 还有一种会出现重定义的可能是在映射虚拟盘的时候，可参考这篇文章。 其实避免上述重定义的最好解决办法是使用#ifndef/#define/#endif，以这样的方式来保证头文件里的相同内容只被编译一次： ----A.h文件：----- #ifndef A_H #define A_H int A; //全局变量 ... #endif // !A_H ----B.h文件：----- #ifndef A_H #define A_H int A; //同样的全局变量 ... #endif // !A_H ----主程序：------ #include "A.h" #include "B.h" int main() { return 0; } 这样int A就不会被多次编译了。要实现整个头文件只被编译一次（代替#pragma once的作用），可以这样做（把原来的整个头文件放在#define 和#endif的中间）： //#pragma once #ifndef A_H #define A_H class A { ... }; #endif // !A_H 使用#ifndef虽然比较古老，但是却有很好的稳定性和可移植性。&nbsp; 参考文献：http://www.cnblogs.com/baiyanhuang/archive/2009/09/17/1730732.htmlhttp://blog.csdn.net/abc5382334/article/details/18052757]]></content>
      <categories>
        <category>调试错误集锦</category>
      </categories>
      <tags>
        <tag>重定义错误</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL25：反走样初步]]></title>
    <url>%2F2017%2F03%2F09%2FOpenGL25%E5%8F%8D%E8%B5%B0%E6%A0%B7%E5%88%9D%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[锯齿效果 在我们的渲染中，可能会遇到模型边缘有锯齿的问题。锯齿边出现的原因是由顶点数据像素化成为片段的方式引起的。比如直线上的点是连续的，而屏幕上的像素却是离散的，用屏幕上的像素来近似表示直线段，必然会出现锯齿效果（可参考《基本光栅图形生成技术》一文中的直线扫描转换）。 下面是一个简单的立方体，可以看到它有锯齿边的效果：放大后会更明显：很明显能看到边是由像素所构成的，这种现象叫做走样（Aliasing）。有很多技术能够减少走样，产生更平滑的边缘，这些技术叫做抗锯齿技术（Anti-aliasing，也被称为反走样技术）。&nbsp; 超级采样抗锯齿技术超级采样反走样技术（Super-Sampled Anti-Aliasing，SSAA），是通过以更高的分辨率来采样图形，然后再显示在低分辨率的设备上，从而减少失真的方法。例如下图表示了增加分辨率后，绘制直线的差别：通过将高分辨率的图形，显示在低分辨率的设备上，确实能有效减轻走样现象，但是存在的弊端就是：要为这些多出来的像素，进行更多的计算，并且内存开销很大。这是一种比较传统的方法。&nbsp; 多重采样抗锯齿技术多重采样抗锯齿技术（Multi-Sampled Anti-Aliasing，MSAA）是对SSAA的改进，改进之处在于执行像素着色器的次数并没有明显增加，对边缘部分却进行了很好的反走样。多采样相对于单采样，单采样在一个像素上，以像素中心为标准，当光栅化时，如果这个中心采样点在图元内部，那么就生成这个像素对应的片段，否则如果采样点不在图元内部，那么就不生成对应片段。而多采样，是在每个像素上进行细分，在每个像素上分出更多的子采样点（sub-sample），如下图所示：当图元覆盖了像素中的子采样点时，则会执行像素着色器。像素着色器的执行不是以子采样点为单位，也就是说不管有多少个子采样点，这个像素只执行一次像素着色器。执行的结果会存储到每个被覆盖的子样本中（没有被覆盖的子样本还是保持背景色）。最终的像素颜色将取为像素里这些子采样点颜色的平均值。 例如上图中，三角形图元覆盖了某个像素中的2个采样点，那么这个像素的最终颜色由三角形覆盖的2个采样点的颜色和另外两个采样点的颜色（可能是glClearColor指定的颜色）的均值决定。 下图是单采样对应的光栅化过程：下图是多采样对应的光栅化过程：用过多采样，绘制的三角形的边缘部分，因为有了和背景颜色的混合，从而减轻了走样现象，如下图所示：开启MSAA以后，不仅颜色会多采样，深度和模板测试也同样会多采样，每个子样本都会去存储颜色值、深度值和模板值。也就是说所需要的颜色、深度和模板缓冲大小都会增加。&nbsp; 在OpenGL中使用MSAA为了在OpenGL中使用MSAA，我们需要一个更大的缓冲来存储多采样点的采样结果，称之为多样本缓冲。 我们所使用的GLFW窗口系统就给我们提供了这个多样本缓冲，来代替默认的颜色缓冲。我们需要用glfwWindowHint来设置： glfwWindowHint(GLFW_SAMPLES, 4); 它会告诉OpenGL。每个像素使用一个包含4个子样本的颜色缓冲。 接下来我们需要使用glEnable函数来开启多采样： glEnable(GL_MULTISAMPLE); 由于实际的多采样算法在OpenGL驱动光栅化里已经实现了，所以我们不需要做别的了。运行效果如下：可以看到还是有很明显的抗锯齿效果的。 直接使用glEnable开启多采样，实现反正样的源码请看这里。 离屏MSAA 有的时候需要让MSAA的效果渲染到我们自定义的帧缓冲中。 我们首先为自定义的帧缓冲创建多采样纹理，来存储多采样结果。 多采样纹理附件创建多采样纹理和普通纹理的不同之处在于，使用glTexImage2DMultisample函数来代替glTexImage2D，而且纹理目标得改为GL_TEXTURE_2D_MULTISAMPLE： glBindTexture(GL_TEXTURE_2D_MULTISAMPLE, tex); glTexImage2DMultisample(GL_TEXTURE_2D_MULTISAMPLE, samples, GL_RGB, width, height, GL_TRUE); glBindTexture(GL_TEXTURE_2D_MULTISAMPLE, 0); 第二个参数samples是我们打算让纹理拥有的样本数。最后一个参数设置为GL_TRUE，可以让图像上的每一个纹理像素使用相同的样本位置，以及同样的子样本数量。 创建好多采样纹理后，我们还是使用glFramebufferTexture2D函数来把它附加到帧缓冲上，不过纹理类型改为GL_TEXTURE_2D_MULTISAMPLE： glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D_MULTISAMPLE, tex, 0); 多采样渲染缓冲对象附件除了多采样纹理附件外，我们还可以使用渲染缓冲对象rbo。跟以前不同的是，在为渲染缓冲分配内存的时候，要将glRenderbufferStorage改为glRenderbufferStorageMultisample： glRenderbufferStorageMultisample(GL_RENDERBUFFER, 4, GL_DEPTH24_STENCIL8, width, height); 注意上面的4就是我们设置的样本数量。 渲染到多采样帧缓冲绑定我们自定义的帧缓冲以后，正常绘制就能把颜色、深度、模板等信息写入多采样帧缓冲。但是多采样缓冲有点特别，不能直接使用渲染得到的缓冲图像，比如在着色器中进行采样作后处理。 这是因为多采样图像包含了比普通图像更多的信息，我们需要压缩（或还原）图像。通常用glBlitFramebuffer函数来还原多采样帧缓冲，它会从一个帧缓冲中复制一个区域粘贴到另一个帧缓冲里，同时会将多采样缓冲还原。 glBlitFramebuffer函数把一个4屏幕坐标源区域传递到另一个也是4空间坐标的目标区域。在这之前，我们需要先设置读缓冲区（源区域）和写缓冲区（目标区域）： glBindFramebuffer(GL_READ_FRAMEBUFFER, multisampledFBO); glBindFramebuffer(GL_DRAW_FRAMEBUFFER, 0); glBlitFramebuffer(0, 0, width, height, 0, 0, width, height, GL_COLOR_BUFFER_BIT, GL_NEAREST); 编译运行后，我们将得到和之前一样的结果，边缘锯齿明显减少了：【注】： 渲染到自定义的帧缓冲时，不需要使用glfwWindowHint和开启反走样。因为在指定缓冲附件的时候，我们已经指明了使用多采样缓冲附件。 渲染到自定义帧缓冲的反走样源码（不用开启OpenGL的反走样）在这里。 多采样纹理转换为普通2D纹理 上面我们把多采样缓冲还原到默认缓冲了，可以正常渲染出MSAA效果。但是如果我们不想还原到默认缓冲，需要继续做后处理怎么办？原理其实一样的，我们就不还原到默认缓冲，而是还原到另一个自定义的帧缓冲，只是这次的帧缓冲使用正常的缓冲附件，而非多采样缓冲附件。伪代码如下： //创建多采样的fbo GLuint msFBO; ... //创建正常的fbo GLuint intermediateFBO; ... while(!glfwWindowShouldClose(window)) { ... glBindFramebuffer(msFBO); ClearFrameBuffer(); DrawScene(); // 将多采样缓冲还原到普通的自定义帧缓冲 glBindFramebuffer(GL_READ_FRAMEBUFFER, msFBO); glBindFramebuffer(GL_DRAW_FRAMEBUFFER, intermediateFBO); glBlitFramebuffer(0, 0, width, height, 0, 0, width, height, GL_COLOR_BUFFER_BIT, GL_NEAREST); // 将得到的普通自定义帧缓冲的纹理图贴到屏幕四边形上 glBindFramebuffer(GL_FRAMEBUFFER, 0); ClearFramebuffer(); glBindTexture(GL_TEXTURE_2D, screenTexture); DrawPostProcessingQuad(); ... } 如果我们实现之前在《OpenGL19：帧缓冲》中的后处理效果，比如模糊kernel，结果会像这样： 将多采样纹理转换为普通2D纹理，实现反走样的所有源码请看这里。 由于屏幕纹理重新变回了只有一个采样点的普通纹理，有些后处理，比如边缘检测（edge-detection）将会再次导致锯齿边问题。为了修正此问题，我们应该对这个屏幕纹理进行模糊处理，或者自定义抗锯齿算法。 注意开启多采样会明显降低性能，样本越多越明显，MSAA4是最常用的。 自定义反走样算法 其实也可以直接把一个多采样纹理图像传到着色器里，就是不需要先还原。这个时候我们就得将uniform采样器定义为sampler2DMS了，而不是sampler2D： uniform sampler2DMS screenTextureMS; 然后使用texelFetch函数来获取每个样本的信息（比如样本颜色）： vec4 colorSample = texelFetch(screenTextureMS, TexCoords, 3); 3是指我们想获取像素中第4个样本的信息。 获取到像素中每个样本的信息后，我们就可以自定义反走样算法，来决定如何生成最终的像素颜色。能够获取到MSAA中每个样本的颜色、深度、模板等信息，有时候还是很需要的！&nbsp; 参考文献：LearnOpenGL]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>反走样</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL24：实例化]]></title>
    <url>%2F2017%2F02%2F06%2FOpenGL24%E5%AE%9E%E4%BE%8B%E5%8C%96%2F</url>
    <content type="text"><![CDATA[假如我们有一个许多模型的场景，而这些模型的顶点数据都一样，只是进行了不同的世界空间的变换。想象一下，有一个场景中充满了草：每根草都是几个三角形组成的。最终一次渲染循环中可能有成千上万个草需要绘制。渲染多个物体的时候，代码类似下面这样： for(GLuint i = 0; i < amount_of_models_to_draw; i++) { DoSomePreparations(); //在这里绑定VAO、绑定纹理、设置uniform变量等 glDrawArrays(GL_TRIANGLES, 0, amount_of_vertices); } 像这样多次绘制同一个模型，很快会达到一个瓶颈，这是因为我们调用的glDrawArrays或glDrawElements这样的函数（Draw Call）过多。因为在使用它们绘制之前，必须做一些准备工作，比如告诉GPU从哪个缓冲读取数据，以及在哪里 找到顶点属性，所有这些命令从CPU到GPU是需要花费时间的，会使CPU到GPU的总线变慢。 如果能够一次就绘制多个模型就好了，这就是实例化。 实例化 实例化（Instancing）是一种只调用一次渲染函数却能绘制出很多物体的技术，它节省渲染物体时从CPU到GPU的通信时间，只需要做一次即可。 要使用实例化渲染，我们必须将glDrawArrays和glDrawElements各自改为glDrawArraysInstanced和glDrawElementsInstanced。它们相比各自之前的函数，只是多了一个参数，叫做实例数量，它设置我们打算渲染的实例的数量。 我们使用这个函数确实可以一次渲染很多个相同的物体，但是它们都会处在同一个位置，我们只能看到一个物体。不过GLSL为我们提供了一个内置变量gl_InstanceID，表示当前绘制的实例序号，初始值是0。我们可以利用这个当前实例序号，去索引一个位置数组，来把每个实例放在不同的位置上。 下面我们使用实例化来一次绘制100个方块。首先我们设置好方块的顶点数据： //方块的顶点数据 GLfloat quadVertices[] = { // ---位置--- ------颜色------- -0.05f, 0.05f, 1.0f, 0.0f, 0.0f, 0.05f, -0.05f, 0.0f, 1.0f, 0.0f, -0.05f, -0.05f, 0.0f, 0.0f, 1.0f, -0.05f, 0.05f, 1.0f, 0.0f, 0.0f, 0.05f, -0.05f, 0.0f, 1.0f, 0.0f, 0.05f, 0.05f, 0.0f, 1.0f, 1.0f }; 接下里是我们的顶点着色器： #version 330 core layout (location=0) in vec2 position; layout (location=1) in vec3 color; out vec3 fColor; uniform vec2 offsets[100]; void main(){ gl_Position = vec4(position + offsets[gl_InstanceID], 0.0f, 1.0f); fColor = color; } 在顶点着色器中，我们设置了一个uniform数组，它是在主程序里被赋值的，表示了100个方块的位置。它在主程序中是这样被赋值的： //100个方块的位置 vec2 quadOffsets[100]; int index = 0; for (GLfloat y = -0.9; y]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>实例化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL23：几何着色器]]></title>
    <url>%2F2017%2F02%2F05%2FOpenGL23%E5%87%A0%E4%BD%95%E7%9D%80%E8%89%B2%E5%99%A8%2F</url>
    <content type="text"><![CDATA[在顶点和片段着色器之间有一个可选的着色器，叫做几何着色器（Geometry Shader）。 几何着色器 几何着色器以一个或多个基本图形的顶点作为输入，比如一个点或者三角形。几何着色器可以将这些顶点转变为完全不同的基本图形，可以生成比原来多得多的顶点，再把这些顶点发送到下一个着色器阶段。 我们直接来看一个几何着色器的例子： #version 330 core layout (points) in; layout (line_strip, max_vertices = 2) out; void main() { gl_Position = gl_in[0].gl_Position + vec4(-0.1, 0.0, 0.0, 0.0); EmitVertex(); gl_Position = gl_in[0].gl_Position + vec4(0.1, 0.0, 0.0, 0.0); EmitVertex(); EndPrimitive(); } 在几何着色器中，我们需要声明输入的基本图形（primitive）类型，这个输入是我们从顶点着色器中接收到的。需要在in关键字前面声明一个layout标识符，括号里表示可以从一个顶点着色器接收的基本图形。可以有以下基本图形值：这是我们能够给渲染函数的几乎所有的基本图形。如果我们在主程序中选择以GL_TRIANGLES方式绘制顶点，我们就要把这里的输入修饰符设置为triangles。括号里的数字代表对应基本图形的最少顶点数。 当我们需要指定几何着色器所输出的基本图形类型时，我们就在out关键字前面加一个layout标识符。和输入layout标识符一样，输出的layout标识符也可以接受以下基本图形值： points line_strip triangle_strip 使用这三个输出修饰符，我们可以从输入的基本图形创建任何我们想要的形状。为了生成一个三角形，我们定义一个triangle_strip作为输出标识符，然后在其main函数里输出3个顶点，就能够输出一个三角形。同时，我们需要指定几何着色器能够输出的顶点数量的最大值（如果超出了这个数值，OpenGL就会忽略剩下的顶点），如上面的line_strip, max_vertices=2，表示我们将使用2个顶点输出一个line_strip。【注】： line_strip就是首位相连的线条。线条是把多个点链接起来表示出一个连续的线，它最少有两个点来组成。后一个点在前一个新渲染的点后面渲染。line_strip如下图所示：在上面的着色器里，当然不能得到上图的线条，因为输出顶点数量的最大值被我们设置为了2，只能输出一个线段。 顶点着色器的数据是通过什么传递到几何着色器的呢？GLSL为我们提供了一个内置变量gl_in，它的内部像这样： in gl_Vertex { vec4 gl_Position; float gl_PointSize; float gl_ClipDistance[]; } gl_in[]; 它被声明为一个借口块，表示从顶点着色器接收的顶点数组。其中就包含了与顶点着色器输出相似的位置向量gl_Position。要注意gl_in是一个数组，因为几何着色器一次接收一个基本图形的所有顶点来填充gl_in数组，作为它的输入。 使用来自顶点着色器的顶点数据，我们可以开始输出新的顶点数据了。这需要通过EmitVertex函数（输出一个顶点）和EndPrimitive函数（结束基本图形）来实现。&nbsp; 使用几何着色器把点转化为线这里我们用一个demo：在几个着色器里接收一些点的输入，转化为线条输出，来完整地使用一次几何着色器。 首先我们在顶点着色器里定义4个顶点的顶点数据： GLfloat pointsVertices[] = { //位置坐标 0.5f, 0.5f, 0.5f,-0.5f, -0.5f,-0.5f, -0.5f, 0.5f, }; //点的pointsVAO和数据解析 GLuint pointsVAO, pointsVBO; glGenVertexArrays(1, &pointsVAO); glBindVertexArray(pointsVAO); glGenBuffers(1, &pointsVBO); glBindBuffer(GL_ARRAY_BUFFER, pointsVBO); glBufferData(GL_ARRAY_BUFFER, sizeof(pointsVertices), &pointsVertices, GL_STATIC_DRAW); glEnableVertexAttribArray(0); glVertexAttribPointer(0, 2, GL_FLOAT, GL_FALSE, 2 * sizeof(GL_FLOAT), (GLvoid*)0); glBindVertexArray(0); 然后是我们的几何着色器（写在points.geometry）： #version 330 core layout (points) in; layout (line_strip,max_vertices=2) out; void main(){ gl_Position = gl_in[0].gl_Position + vec4(-0.1f,0.0f,0.0f,0.0f); EmitVertex(); gl_Position = gl_in[0].gl_Position + vec4(0.1f,0.0f,0.0f,0.0f); EmitVertex(); EndPrimitive(); } 在该几何着色器里，我们接收的输入是点这种基本图形的顶点，输出是线条这种基本图形，同时指定输出的图形最多由两个顶点组成。在main函数里，我们先把接收到的第一个顶点向x方向移动-0.1，把得到的新顶点用EmitVertex函数发送出去；接着再把第一个顶点向x方向移动0.1，把得到的新顶点用EmitVertex函数发送出去，两个顶点发完了，我们的线条这个基本图形到此结束。注意，由于这里几何着色器的输入基本图形是点points，所以它每次得到的来自顶点着色器的输入顶点只有1个，而不是4个，这4个顶点是分4次传到几何着色器里的；如果输入基本图形是triangles，那么几何着色器每次得到的顶点个数就是3个。 当然，不要忘了，我们的着色器类得改改了。得把几何着色器也加进来，编译后附加到着色器程序对象上： const GLchar* geometryShaderSource = GetShaderSourceFromFile(geometryPath); GLuint geometryShader; geometryShader = glCreateShader(GL_GEOMETRY_SHADER); glShaderSource(geometryShader, 1, &geometryShaderSource, NULL); glCompileShader(geometryShader); glGetShaderiv(geometryShader, GL_COMPILE_STATUS, &success); if (!success) { glGetShaderInfoLog(geometryShader, 512, NULL, infolog); cout < "geometry shader compilation failed" < infolog < endl; } glAttachShader(shaderProgram, geometryShader);]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>几何着色器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL22：高级GLSL]]></title>
    <url>%2F2017%2F01%2F25%2FOpenGL22%E9%AB%98%E7%BA%A7GLSL%2F</url>
    <content type="text"><![CDATA[本文将会讨论一些GLSL内置变量、接口块和uniform缓冲对象。&nbsp; GLSL的内置变量GLSL有几个以gl_为前缀的变量，我们可以用它们来实现对着色器的输入输出数据。其中两个我们已经接触过：gl_Position和gl_FragCoord，前一个是顶点着色器的输出向量，后一个是像素着色器的变量。接下里我们再多了解几个内置变量。 顶点着色器的内置变量我么已经了解到gl_Position是顶点着色器裁剪空间输出的位置向量，如果想让窗口上渲染出东西，必须使用它，否则我们什么都看不到。除此之外，还有几个顶点着色器的内置变量： 内置变量gl_PointSize渲染的基本图形不仅可以是我们常用的GL_TRIANGLES，还可以是GL_POINTS，顾名思义，它是渲染每一个顶点。除了在主程序中可以使用glPointSize函数来设置这个点的大小以外，我们还可以在顶点着色器里通过内置输出变量gl_Pointsize来设置点的大小。 gl_Pointsize是一个float变量。要使用它我们必须要先开启OpenGL的GL_PROGRAM_POINT_SIZE，因为在着色器中影响点的大小默认是关闭的： glEnable(GL_PROGRAM_POINT_SIZE); 现在我们来画几个点，着色器都很简单：点的顶点着色器（写在points.vertex中）： #version 330 core layout (location=0) in vec3 position; void main(){ gl_Position = vec4(position, 1.0f); gl_PointSize = position.z * 10; } 这里我们让内置变量gl_PointSize（也就是顶点大小）等于顶点z坐标的10倍。 点的像素着色器（points.fragment）： #version 330 core out vec4 color; void main(){ color= vec4(1.0f, 0.0f, 0.0f, 1.0f); } 完整源码在这里。 编译运行后的结果如下：可以看到z值越大的点越大。想象一下，每个顶点表示出来的点的大小不同，如果用在像粒子生成之类的技术里会挺有意思的。 内置变量gl_VertexID顶点着色器给我们提供了一个有趣的输入变量gl_VertexID，它是只读的。 gl_VertexID是个整型变量，它存储着我们绘制的当前顶点的ID。当进行索引渲染（indexed rendering，使用glDrawElements函数绘制）时，这个变量保存着当前绘制顶点的索引；如果用的不是索引绘制（使用glDrawArrays函数绘制），这个变量保存的是从渲染开始直到当前处理的这个顶点（当前顶点）的编号。 片段着色器的内置变量 内置变量gl_FragCoord在《OpenGL15：深度测试》中，我们已经用过gl_FragCoord了，因为它的z值表示片段的深度值。 gl_FragCoord的x和y元素是当前片段的窗口空间坐标，它的起始处（原点）是窗口的左下角。 gl_FragCoord变量的一个常用方式是与一个不同的片段计算出来的视频输出进行对比，通常在技术演示中常见。比如我们可以把物体分为两部分，某个x值左侧渲染一个输出，右侧渲染另一个输出。如下面的像素着色器： void main(){ if(gl_FragCoord.x < 400){ color = vec4(1.0f, 0.0f, 0.0f, 1.0f); } else{ color = vec4(0.0f, 1.0f, 0.0f, 1.0f); } } 我们用这个像素着色器代码绘制一个立方体，源码不再赘述了，之前的文章里有很多，编译运行后的结果如下： 内置变量gl_FrontFacing像素着色器另一个有意思的输入变量是gl_FrontFacing。在《OpenGL18：背面剔除》中，我们知道OpenGL可以根据顶点绘制顺序弄清楚一个面是正面还是背面。如果我们不使用面剔除，那么gl_FrontFacing变量能告诉我们当前片段是某个正面的一部分还是背面的一部分。 gl_FrontFacing变量是一个布尔值，如果当前片段时正面的一部分那么就是true，否则就是false。这样我们可以创建一个立方体，里面和外面使用不同的纹理： #version 330 core out vec4 color; in vec2 TexCoords; uniform sampler2D frontTexture; uniform sampler2D backTexture; void main() { if(gl_FrontFacing) color = texture(frontTexture, TexCoords); else color = texture(backTexture, TexCoords); } 编译运行后，如果我们移动摄像机到箱子的一角里，就能看到里面和外面使用的是不同的纹理：注意不要开启面剔除，否则摄像机进入箱子后，不会看到箱子的任何部分。 内置变量gl_FragDepth输入变量gl_FragCoord让我们可以读得当前片段的窗口空间坐标和深度值。但是GLSL给我们提供了一个叫做gl_FragDepth的变量，我们可以用它在着色器中设置像素的深度值（片段的窗口空间坐标是没法改变的）： gl_FragDepth = 0.0f; //现在片段的深度值被设为0 如果着色器中没有显式设置gl_FragDepth的值，它就会自动采样gl_FragCoord.z的值。 我们自己设置深度值有一个显著缺点，因为只要我们在像素着色器中对gl_FragDepth写入什么，OpenGL就会关闭所有的前置深度测试，因为在我们运行片段着色器之前，OpenGL搞不清楚像素的深度值，因为片段着色器可能会完全改变这个深度值。因此需要考虑到gl_FragDepth写入所带来的性能的下降。 然而从OpenGL4.2起，我们仍然可以对二者进行一定的调和，这需要在片段着色器的顶部使用深度条件（depth condition）来重新声明gl_FragDepth： layout (depth_) out float gl_FragDepth; condition可以使用下面的值：下面是一个在像素着色器里增加深度值得例子，不过仍可开启前置深度测试： #version 330 core layout (depth_greater) out float gl_FragDepth; out vec4 color; void main() { color = vec4(1.0f); gl_FragDepth = gl_FragCoord.z + 0.1f; } 一定要记住这个功能只能在OpenGL4.2以上版本才有。&nbsp; 接口块到目前为止，每次我们打算从顶点着色器向片段着色器发送数据，我们都会声明一个相互匹配的输出/输入变量。但是随着应用变得越来越大，我们也许会打算发送的不仅仅是变量，最好还可以包括数组和结构体等。 为了帮助我们组织这些变量，GLSL为我们提供了一些叫做接口块（Interface Blocks）的东西，好让我们能够组织这些变量。声明接口块和声明结构体比较像，只是结构使用struct关键字，而接口块使用in和out关键字来定义一个输入或输出块。示例如下： #version 330 core layout (location = 0) in vec3 position; layout (location = 1) in vec2 texCoords; uniform mat4 model; uniform mat4 view; uniform mat4 projection; out VS_OUT { vec2 TexCoords; } vs_out; void main() { gl_Position = projection * view * model * vec4(position, 1.0f); vs_out.TexCoords = texCoords; } 我们声明了一个叫做vs_out的接口块，它把我们需要发送给下个阶段着色器的所有输出变量组合起来。 然后我们还需要在像素着色器中声明一个输入接口块，快名应该是一样的，但是实例名可以不一样： #version 330 core out vec4 color; in VS_OUT { vec2 TexCoords; } fs_in; uniform sampler2D texture; void main() { color = texture(texture, fs_in.TexCoords); } 如果两个接口块的快名一致，它们对应的输入和输出就会匹配起来。&nbsp; Uniform缓冲对象UBO在之前的文章中，我们肯定有感受：箱子、地面等等不同的物体，它们使用不同的着色器，但是每种着色器里都有相同的uniform变量：观察矩阵view和投影矩阵projection。我们之前的做法是为每种着色器都设置这些uniform变量的值。既然对于每个着色器来说它们都是一样的，那为何还多次设置它们呢？ OpenGL为我们提供了一个叫做uniform缓冲对象（uniform buffer object）的工具，使我们能够声明一系列的全局uniform变量，它们会在几个着色器程序中保持一致。当使用uniform缓冲对象时相关的uniform就只需设置一次了。但是我们还是需要为每个着色器手动设置uniform块，只是不需要在主程序里为这些uniform变量重复赋值了。 如何在多个着色器之间简洁地共享变量，GLSL中可以通过uniform buffer来实现。实现思路是：在多个着色器中定义相同的uniform块（就是上面的接口块，但是使用uniform关键词），然后将这些uniform块绑定到对应的uniform缓冲对象ubo，而uniform缓冲对象中实际存储这些需要共享的变量。着色器中的uniform块和主程序中的uniform缓冲对象，是通过OpenGL的绑定点（binding points）连接起来的，它们的关系如下图所示：使用时，每个shader中定义的uniform块有一个索引，通过这个索引连接到OpenGL的绑定点x；而主程序中创建uniform缓冲对象，传递数据后，将这个UBO绑定到对应的绑定点x，这样shader中的uniform块就和主程序中的UBO连续起来了，我们在主程序中操作UBO的数据，就能够在不同着色器之间共享了。例如上图中，着色器A和着色器B中的Matrices的索引都指向绑定点0，他们共享主程序的uboMatrices这个UBO的数据。同时着色器A的Lights和着色器B的Data，分别指向不同的UBO。 下面是一个使用uniform块的着色器例子： #version 330 core layout (location = 0) in vec3 position; layout (std140) uniform Matrices { mat4 projection; mat4 view; }; uniform mat4 model; void main() { gl_Position = projection * view * model * vec4(position, 1.0); } 这里我们声明了一个叫做Matrices的uniform块，它存储两个4x4矩阵。在uniform块中的变量可以直接获取，而不用使用块名作为前缀。 但是上面的layout (std140)是什么意思呢？它的意思是说为当前的uniform块的内容使用特定的内存布局，这个声明实际上就是在设置uniform块布局（uniform block layout）。&nbsp; Uniform块布局在主程序中对UBO的实现（或者说数据填充），依赖于着色器中uniform块的内存布局。uniform块的内存布局有四种形式：shared、packed、std140、std430（GLSL4.3以上才支持），默认是shared共享内存布局。 我们先来了解一下字节对齐的概念： 字节对齐的概念字节对齐的一个经典案例就是C语言中的结构体变量，例如下面的结构体： struct StructExample { char c; int i; short s; }; 估计他占用内存大小是多少字节？如果int占用4字节，short占用2字节，char占用1字节，那么整体大小等于1+4+2=7字节吗？ 答案是否定的。在Windows平台上测试的结果是占用12个字节。这是因为结构体里的变量存在字节对齐（或者叫字节补齐）的概念。实际上上述结构体的内存布局为： struct StructExample { char c; // 0 bytes offset, 3 bytes padding int i; // 4 bytes offset short s; // 8 bytes offset, 2 bytes padding }; // End of 12 bytes 内存布局如下图所示：字节对齐的一个重要原因是为了使机器访问更迅速。例如在32位字长的机器中，每次会读取4个字节数据，所以将字节对齐到0x0000、0x0004、0x0008、0x000C等，将使读取更加迅速。否则，如果上面的结构体里，字符c后面不填充三个字节而直接紧邻int，那么int将会跨越两个字长（0x0000和0x0004，32位机中4个字节为一个字），就需要两次读取操作，影响效率。还有一些更详细的原因，可参考SO Purpose of memory alignment。 关于字节对齐，需要记住以下几个要点： 每个基本变量的起始位置，一定是自己长度的整数倍（对齐） 对齐后的总长度必须是最长元素长度的整数倍，不够的话用额外的字节补齐 复杂类型（结构体、联合等）以其中的最长成员的长度对齐。 上面的结构体中，int变量的起始地址应该是自身长度4的整数倍，为了int类型对齐，需要在char后面填充3个字节。这样一来，char、int、short总共占了10字节，但是总长度需要是最长元素int长度4的整数倍，所以需要在末尾再补上2个字节，让总长度达到12字节。 std140的字节对齐std140内存布局同样存在字节对齐的概念，可以参考官方文档获取完整描述。常用标量int、float、bool等要求4字节对齐。4字节也被作为一个基础值N，下面是几个常用的类型的字节对齐要求：例如一个复杂的uniform块定义如下： layout (std140) uniform ExampleBlock { // base alignment ---------- // aligned offset float value; // 4 // 0 vec3 vector; // 16 // 16 (必须是16的倍数，因此 4->16) mat4 matrix; // 16 // 32 (第 0 行) // 16 // 48 (第 1 行) // 16 // 64 (第 2 行) // 16 // 80 (第 3 行) float values[3]; // 16 (数组中的标量与vec4相同) //96 (values[0]) // 16 // 112 (values[1]) // 16 // 128 (values[2]) bool boolean; // 4 // 144 int integer; // 4 // 148 }; 根据std140布局规则，使用计算出来的偏移量，我们可以用glBufferSubData这样的函数来传递数据并填充缓冲。虽然不是很高效，但std140布局可以保证在每个程序中声明的这个uniform块的布局保持一致。&nbsp; 使用uniform缓冲首先我们需要使用glGenBuffers函数创建一个uniform缓冲对象，然后绑定到GL_UNIFORM_BUFFER目标上，接着需要调用glBufferData函数来给它分配足够的内存空间： //创建uniform缓冲对象 GLuint ubo; glGenBuffers(1, &ubo); glBindBuffer(GL_UNIFORM_BUFFER, ubo); glBufferData(GL_UNIFORM_BUFFER, 150, NULL, GL_STATIC_DRAW); glBindBuffer(GL_UNIFORM_BUFFER, 0); 以后当我们打算往缓冲中更新或插入数据，我们就绑定一下该缓冲对象uboExampleBlock，并使用glBufferSubData来更新它的内存。 我们可以使用glUniformBlockBinding函数来把uniform块绑定到一个指定的绑定点上。在此之前，我们需要先用glGetUniformBlockIndex函数来获取指定着色器中uniform块的索引位置： //把uniform块绑定到绑定点2 GLuint uniform_index = glGetUniformBlockIndex(cube_shader.shaderProgram, "Matrices"); glUniformBlockBinding(cube_shader.shaderProgram, uniform_index, 2); glGetUniformBlockIndex的第一个参数是着色器程序对象，第二个参数就是该着色器里的块名称。glUniformBlockBinding函数的第一个参数也是着色器程序对象，第二个参数是uniform块索引，第三个参数是绑定点。注意，我们必须对每个着色器的uniform块都要做这件事。 【注】： 从OpenGL4.2起，也可以在着色器中通过添加另一个局部标识符来存储一个uniform块的绑定点，就不用我们调用glGetUniformBlockIndex和glUniformBlockBinding了。如下所示：layout(std140, binding = 2) uniform Lights { ... }; 添加一个binding标识符就能指定了uniform块的绑定点了。 然后我们还需要把uniform缓冲对象绑定到同样的绑定点上，可以使用glBindBufferBase函数或glBindBufferRange函数来完成： glBindBufferBase(GL_UNIFORM_BUFFER, 2, uboExampleBlock); // 或者 glBindBufferRange(GL_UNIFORM_BUFFER, 2, uboExampleBlock, 0, 150); 函数glBindBufferBase的第一个参数是绑定目标，这里当然是uniform缓冲；第二个参数是绑定点，第三个参数就是uniform缓冲对象。函数glBindBufferRange多了两个参数，可以指定把一定范围内的uniform缓冲绑定到一个绑定点上。所以使用glBindBufferRange函数，能够将让一个uniform缓冲对象对应多个uniform块。 最后我们可以开始想uniform缓冲中添加数据了。可以使用glBufferSubData函数来实现。例如为了更新之前那个uniform块里的boolean变量，我们可以使用下面的代码： glBindBuffer(GL_UNIFORM_BUFFER, uboExampleBlock); GLint b = true; // GLSL中的布尔值是4个字节，因此我们将它创建为一个4字节的整数 glBufferSubData(GL_UNIFORM_BUFFER, 144, 4, &b); glBindBuffer(GL_UNIFORM_BUFFER, 0); &nbsp; Demo下面我们上一个Demo，使用uniform缓冲对象。将观察矩阵view和投影矩阵projection放到uniform块中。由于模型矩阵是频繁变化的，在不同的着色器里模型矩阵的值可能不同，所以不需要把模型矩阵model也放入uniform块中。uniform块中存储着的应该是被大多数着色器共享的uniform变量，在这些着色器里的值都应该一样才行。 我们将在窗口上绘制红、绿、蓝、黄4个立方体，它们有各自的像素着色器，共用一个顶点着色器（当然也可以是4个顶点着色器，不过它们的代码是一样的）。它们的代码很简单，可参考文末的源码汇总。 写好4个立方体各自的着色器之后，我们给它们各自创建一个着色器类对象： //定义自定义着色器类shader的对象 shader redCube_shader("cube.vertex", "redCube.fragment"); shader greenCube_shader("cube.vertex", "greenCube.fragment"); shader blueCube_shader("cube.vertex", "blueCube.fragment"); shader yellowCube_shader("cube.vertex", "yellowCube.fragment"); 接下里我们把每个着色器程序里的uniform块Matrices绑定到绑定点2上（其他绑定点也可以）： //把uniform块绑定到绑定点2 //红方块的uniform块 GLuint uniform_index = glGetUniformBlockIndex(redCube_shader.shaderProgram, "Matrices"); glUniformBlockBinding(redCube_shader.shaderProgram, uniform_index, 2); //绿方块的uniform块 uniform_index = glGetUniformBlockIndex(greenCube_shader.shaderProgram, "Matrices"); glUniformBlockBinding(greenCube_shader.shaderProgram, uniform_index, 2); //蓝方块的uniform块 uniform_index = glGetUniformBlockIndex(blueCube_shader.shaderProgram, "Matrices"); glUniformBlockBinding(blueCube_shader.shaderProgram, uniform_index, 2); //黄方块的uniform块 uniform_index = glGetUniformBlockIndex(yellowCube_shader.shaderProgram, "Matrices"); glUniformBlockBinding(yellowCube_shader.shaderProgram, uniform_index, 2); 还需要创建一个uniform缓冲对象，并且把它绑定到相同的绑定点2上： //将uniform缓冲对象绑定到相同的绑定点2 //创建uniform缓冲对象 GLuint ubo; glGenBuffers(1, &ubo); glBindBuffer(GL_UNIFORM_BUFFER, ubo); glBufferData(GL_UNIFORM_BUFFER, 150, NULL, GL_STATIC_DRAW); glBindBuffer(GL_UNIFORM_BUFFER, 0); //绑定ubo到绑定点2 glBindBufferBase(GL_UNIFORM_BUFFER, 2, ubo); 这样一来，每个着色器里的uniform块Matrices就都和这个uniform缓冲对象ubo连接在一起了。 然后我们就可以在渲染循环里给这个uniform缓冲对象填充数据了（使用glBufferSubData函数），也就是给uniform块的view矩阵和projection矩阵赋值： //为uniform缓冲对象填充数据 mat4 view = mycamera.GetViewMatrix(); mat4 projection = perspective(radians(mycamera.cameraFov), (GLfloat)WIDTH / (GLfloat)HEIGHT, 0.1f, 100.0f); glBindBuffer(GL_UNIFORM_BUFFER, ubo); glBufferSubData(GL_UNIFORM_BUFFER, 0, sizeof(mat4), value_ptr(view)); glBufferSubData(GL_UNIFORM_BUFFER, sizeof(mat4), sizeof(mat4), value_ptr(projection)); glBindBuffer(GL_UNIFORM_BUFFER, 0); 最后当然就是绘制这4个立方体： //绘制红绿蓝黄四个立方体 //红色立方体 redCube_shader.Use(); mat4 model; model = translate(model, vec3(-0.75f, 0.75f, 0.0f)); glUniformMatrix4fv(glGetUniformLocation(redCube_shader.shaderProgram, "model"), 1, GL_FALSE, value_ptr(model)); glBindVertexArray(cubeVAO); glDrawElements(GL_TRIANGLES, 36, GL_UNSIGNED_INT, 0); //绿色立方体 greenCube_shader.Use(); model = mat4(); model = translate(model, vec3(-0.75f, -0.75f, 0.0f)); glUniformMatrix4fv(glGetUniformLocation(greenCube_shader.shaderProgram, "model"), 1, GL_FALSE, value_ptr(model)); glBindVertexArray(cubeVAO); glDrawElements(GL_TRIANGLES, 36, GL_UNSIGNED_INT, 0); //蓝色立方体 blueCube_shader.Use(); model = mat4(); model = translate(model, vec3(0.75f, 0.75f, 0.0f)); glUniformMatrix4fv(glGetUniformLocation(blueCube_shader.shaderProgram, "model"), 1, GL_FALSE, value_ptr(model)); glBindVertexArray(cubeVAO); glDrawElements(GL_TRIANGLES, 36, GL_UNSIGNED_INT, 0); //黄色立方体 yellowCube_shader.Use(); model = mat4(); model = translate(model, vec3(0.75f, -0.75f, 0.0f)); glUniformMatrix4fv(glGetUniformLocation(yellowCube_shader.shaderProgram, "model"), 1, GL_FALSE, value_ptr(model)); glBindVertexArray(cubeVAO); glDrawElements(GL_TRIANGLES, 36, GL_UNSIGNED_INT, 0); 编译运行后的结果如下：所有源码请看这里。&nbsp; 使用uniform缓冲对象的好处uniform缓冲对象比单独的uniform有很多好处： 一次设置多个uniform比一次设置一个速度快。 如果打算改变一个横跨多个着色器的uniform，只需要在uniform缓冲中更改一次。 使用uniform缓冲对象让我们可以在着色器中使用更多的uniform。因为OpenGL对uniform缓冲对象最大个数比uniform最大个数大。&nbsp; shared共享内存布局同std140内存布局方式不一样，shared方式的内存布局依赖于具体实现，因此我们无法提前根据某种字节对齐规范计算出UBO中变量的位移偏量和整体大小，所以在使用shared方式时，我们需要多次利用OpenGL的函数来查询UBO的信息。如下面的部分程序所示： #version 330 core // 使用默认shared​方式的UBO uniform mixColorSettings { vec4 anotherColor; float mixValue; }; out vec4 color; void main() { color = mix(vec4(0.0, 0.0, 1.0, 1.0), anotherColor, mixValue); } // 通过查询获取uniform buffer中各个变量的索引和位移偏量 const GLchar* names[] = { "anotherColor", "mixValue" }; GLuint indices[2]; glGetUniformIndices(redShader.programId, 2, names, indices); GLint offset[2]; glGetActiveUniformsiv(redShader.programId, 2, indices, GL_UNIFORM_OFFSET, offset); // 使用获取的位移偏量更新数据 glm::vec4 anotherColor = glm::vec4(0.0f, 1.0f, 1.0f, 1.0f); GLfloat mixValue = 0.5f; glBindBuffer(GL_UNIFORM_BUFFER, colorUBOId); glBufferSubData(GL_UNIFORM_BUFFER, offset[0], sizeof(glm::vec4), glm::value_ptr(anotherColor)); glBufferSubData(GL_UNIFORM_BUFFER, offset[1], sizeof(glm::vec4), &mixValue); glBindBuffer(GL_UNIFORM_BUFFER, 0); &nbsp; 参考文献：LearnOpenGL]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>GLSL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL21：缓冲对象及其相关函数]]></title>
    <url>%2F2017%2F01%2F23%2FOpenGL21%E7%BC%93%E5%86%B2%E5%AF%B9%E8%B1%A1%E5%8F%8A%E5%85%B6%E7%9B%B8%E5%85%B3%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[缓冲对象的概念在OpenGL中，缓冲对象（buffer object）是OpenGL的绘制上下文，是GPU分配的，完成未格式化数据区域的存储，例如完成顶点数据、帧缓冲数据的存储。 缓冲对象中的数据实际上就是原始的字节流，例如我们在程序中指定顶点属性数据，然后使用glBufferData这个函数将数据从CPU传送至GPU中，这一步只完成了数据的上传，关于这份数据，OpenGL是不知道其具体格式的，因此在实际使用中还必须告诉OpenGL如何具体使用这些数据，这是通过glVertexAttribPointer这样的函数来完成的。 每个缓冲对象，必须绑定到一个具体的目标（target）后，OpenGL才知道如何具体操作这个缓冲对象，例如绑定到GL_ARRAY_BUFFER，OpenGL使用这个缓冲对象作为顶点属性数据；例如绑定到GL_ELEMENT_ARRAY_BUFFER，则OpenGL使用这个缓冲对象的数据作为索引绘图的索引数据。 缓冲对象的数据，也存在读写、复制、清除等操作，同时缓存对象在适当时候也可以使用glDeleteBuffers这类函数释放。&nbsp; 数据从CPU传递到GPU内存的函数把数据从CPU传递到GPU的函数有：glBufferData函数、glBufferSubData函数、glMapBuffer和memcpy函数。 glBufferData函数函数原型为：glBufferData(GLenum target, GLsizeiptr size, const void* data, GLenum usage) glBufferData函数可以把数据从CPU传递到GPU，并且能够在GPU上开辟一块大小等于其第二个参数的内存，然后把来自CPU的数据存储到这片内存里。如果第三个参数data传递的是NULL，那么OpenGL只会帮我们分配内存，而不会填充它。这对后面的glBufferSubData函数很有用。 glBufferSubData函数函数原型为：glBufferSubData(GLenum targrt, GLintptr offset, GLsizeiptr size, const void* data) glBufferSubData函数也可以把数据从CPU传递到GPU，但是它不会再GPU上开辟内存，所以在调用该函数之前，必须调用glBufferData函数分配好足够的内存，然后该函数才能把来自CPU的数据放到这片内存的指定位置。 glBufferData函数是从开辟的内存的起始地址开始，把所有数据一次性地填充到这片内存里，而glBufferSubData函数是从开辟的内存的offset位置开始，把数据填充到这片内存的指定位置上，只要不越界就可以（不超过开辟的内存的结束地址）。例如： glBufferSubData(GL_ARRAY_BUFFER, 24, sizeof(data), &data); // 范围： [24, 24 + sizeof(data)] glMapBuffer和memcpy函数使用glMapBuffer函数可以返回一个当前绑定缓冲的内存的地址，是一个指针，我们可以把这个返回的内存地址作为memcpy函数的参数，从而把数据传递到该内存地址所指定的位置： glBindBuffer(GL_ARRAY_BUFFER, buffer); // 获取当前绑定缓存buffer的内存地址 void* ptr = glMapBuffer(GL_ARRAY_BUFFER, GL_WRITE_ONLY); // 向缓冲中写入数据 memcpy(ptr, data, sizeof(data)); // 完成够别忘了告诉OpenGL我们不再需要它了 glUnmapBuffer(GL_ARRAY_BUFFER); 别忘了调用glUnmapBuffer函数告诉OpenGL我们已经用完指针了，需要解映射，这样这个地址指针将不再可用。 把数据直接映射到缓冲区上使用glMapBuffer很有用，因为它不用把它存储在临时内存里，可以从文件读取数据然后直接复制到缓冲的内存里。而glBufferData和glBufferSubData是需要先开辟临时内存，再存储到对应的缓冲内存里。&nbsp; 分批处理顶点数据使用glVertexAttribPointer函数可以指定缓冲中顶点数组的属性的布局（layout）。我们之前一直是把顶点属性交叉存放在顶点数组里的，比如123123123123这种交叉布局，这个时候是使用glBufferData函数来传递数据，，而且每种属性下glVertexAttribPointer函数的步长参数stride应该设置为sizeof(123)，即所有属性大小之和。注：1、2、3可能还是几个GL_FLOAT大小。 其实我们还可以把顶点属性连续放置，比如111222333这种批量方式，这时传递数据应该使用glBufferSubData函数了，使用该函数指定每种属性的起始位置和该属性的所有数据大小。示例如下： GLfloat positions[] = { ... }; GLfloat normals[] = { ... }; GLfloat tex[] = { ... }; // 填充缓冲 glBufferSubData(GL_ARRAY_BUFFER, 0, sizeof(positions), &positions); glBufferSubData(GL_ARRAY_BUFFER, sizeof(positions), sizeof(normals), &normals); glBufferSubData(GL_ARRAY_BUFFER, sizeof(positions) + sizeof(normals), sizeof(tex), &tex); 在使用glVertexAttribPointer函数解析顶点数据时，每种属性下的步长就应该是对应属性的GL_FLOAT大小了。而且偏移量应该是批量属性开始的位置，不再像是交叉属性在第一组里的偏移量： glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(GLfloat), 0); glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(GLfloat), (GLvoid*)(sizeof(positions))); glVertexAttribPointer( 2, 2, GL_FLOAT, GL_FALSE, 2 * sizeof(GLfloat), (GLvoid*)(sizeof(positions) + sizeof(normals))); 当然，选用哪种方式全凭喜好了，效率上没有多大区别。&nbsp; 复制缓冲当我们的缓冲被数据填充以后，可能打算让其他缓冲也能够分享这些数据或者打算把缓冲的内容复制到另一个缓冲里。glCopyBufferSubData函数让我们能够相对容易地把一个缓冲里的数据复制到另一个缓冲里。函数原型如下： void glCopyBufferSubData(GLenum readtarget, GLenum writetarget, GLintptr readoffset, GLintptr writeoffset, GLsizeiptr size); readtarget和writetarget是复制的来源缓冲目标和目的缓冲目标，例如我们可以从VERTEX_ARRAY_BUFFER复制到VERTEX_ELEMENT_ARRAY_BUFFER。该函数的意思就是从源目标readtarget缓冲的readoffset位置开始，复制size大小的数据到目的目标writetarget缓冲的writeoffset位置开始的内存区里。 但是如果我们的源和目的都是顶点数组缓冲(GL_VERTEX_ARRAY_BUFFER)怎么办？我们显然不能把源和目的都设置为它。为此，OpenGL 给我们设了额外的两个缓冲目标：GL_COPY_READ_BUFFER和GL_COPY_WRITE_BUFFER。这时我们可以使用下面的代码来实现两个顶点数组缓冲之间的数据复制： GLfloat vertexData[] = { ... }; glBindBuffer(GL_COPY_READ_BUFFER, vbo1); glBindBuffer(GL_COPY_WRITE_BUFFER, vbo2); glCopyBufferSubData(GL_COPY_READ_BUFFER, GL_COPY_WRITE_BUFFER, 0, 0, sizeof(vertexData)); 也可以只把目标缓冲设为GL_COPY_WRITE_BUFFER，如下代码： GLfloat vertexData[] = { ... }; glBindBuffer(GL_ARRAY_BUFFER, vbo1); glBindBuffer(GL_COPY_WRITE_BUFFER, vbo2); glCopyBufferSubData(GL_ARRAY_BUFFER, GL_COPY_WRITE_BUFFER, 0, 0, sizeof(vertexData)); 下一篇文章里我们将会讨论uniform缓冲对象，到时候我们会充分利用glBufferSubData函数。&nbsp; 参考文献：LearnOpenGL]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>缓冲对象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL20：立方体贴图]]></title>
    <url>%2F2017%2F01%2F22%2FOpenGL20%E7%AB%8B%E6%96%B9%E4%BD%93%E8%B4%B4%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[立方体贴图概念及采样方法立方体贴图包含6个2D纹理，每个2D纹理是立方体的一个面，也就是说它是一个有贴图的立方体。使用立方体贴图可以实现很多有意思的效果，比如天空盒、环境映射等等。 对于2D纹理，可以通过纹素的2D坐标来采样，那么立方体纹理怎样采样呢？它的采样方式类似下图：如果立方体的中心位于原点上，那么可以通过原点到立方体表面片段的向量来采样，如上图中的橘黄色向量。也就是说，我们可以直接使用片段的位置向量（或者说片段坐标）来进行采样，在顶点着色器里将片段的位置坐标直接赋值给输出变量纹理坐标： void main(){ gl_Position = position; TexCoords = position; } 利用(s,t,r)采样时，首先根据(s,t,r)中模最大的分量决定在哪个面采样，然后使用剩下的2个坐标在对应的面上做2D纹理采样。例如，如果(s,t,r)中s分量的模最大，且符号为正，则决定选取+x面作为采样的2D纹理，然后使用(t,r)坐标在+x面上做2D纹理采样。 这6个面在OpenGL中指定如下：这几个枚举常量其实是连续的，可以循环遍历，在OpenGL中它们定义如下： #define GL_TEXTURE_CUBE_MAP_POSITIVE_X 0x8515 #define GL_TEXTURE_CUBE_MAP_NEGATIVE_X 0x8516 #define GL_TEXTURE_CUBE_MAP_POSITIVE_Y 0x8517 #define GL_TEXTURE_CUBE_MAP_NEGATIVE_Y 0x8518 #define GL_TEXTURE_CUBE_MAP_POSITIVE_Z 0x8519 #define GL_TEXTURE_CUBE_MAP_NEGATIVE_Z 0x851A &nbsp; 创建立方体贴图既然立方体贴图有6个纹理，那么我们需要把这6张纹理都加载进来，生成一个最终的立方体纹理贴图。我们把这部分代码写入自定义类CubemapLoader的loadCubemap方法中： 首先，创建立方体贴图对象和创建普通纹理一样，只是绑定目标变成了GL_TEXTURE_CUBE_MAP： GLuint cubemap; glGenTextures(1, &cubemap); glBindTexture(GL_TEXTURE_CUBE_MAP, cubemap); 接下来我们加载立方体贴图的6张纹理： int width, height; unsigned char* image; for (int i = 0; i < facePaths.size(); i++) { image = SOIL_load_image(facePaths[i], &width, &height, 0, SOIL_LOAD_RGB); glTexImage2D(GL_TEXTURE_CUBE_MAP_POSITIVE_X + i, 0, GL_RGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, image); } 其中facePaths是函数loadCubemap的参数，指明6张纹理的路径。在使用glTexImage2D函数生成纹理时，目标应该是具体的立方体的某个面。由于立方体的每个面都有一个常数来表示，而且是连续的，所以我们就用GL_TEXTURE_CUBE_MAP_POSITIVE_X和迭代遍历i来循环遍历了。 接着需要设置立方体纹理贴图的参数，环绕方式和过滤方式设置如下： glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_WRAP_R, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_CUBE_MAP, GL_TEXTURE_MAG_FILTER, GL_LINEAR); 将立方体贴图在S、T、R方向上的环绕方式设为了GL_CLAMP_TO_EDGE，这是指明当(s,t,r)坐标没有落在哪个面，而是落在两个面之间时，采样为边缘的纹理值。 完整的CubemapLoader类可见后面的源码。&nbsp; 立方体贴图应用之天空盒我们之前的场景背景一直都是用的glClearColor，现在我们想让场景的背景是一片天空。而立方体贴图完全满足这个要求，我们在场景中绘制一个使用cubemap纹理的立方体，将这个立方体总是置于场景外围，让玩家感觉好像场景很长大，触不可及像天空一样，但是实际上他还是在一个小盒子中。我们要用到的天空盒子贴图可在这里下载。 天空盒也是一个立方体，当然也需要为它设置顶点属性，VAO以及顶点数据解析。顶点数据如下，其它的可参考后面的主程序源码： //天空盒的顶点坐标 GLfloat skyboxVertices[] = { //位置坐标 //立方体前面 1.0f, 1.0f, 1.0f, 1.0f,-1.0f, 1.0f, -1.0f,-1.0f, 1.0f, -1.0f, 1.0f, 1.0f, //立方体后面 1.0f, 1.0f,-1.0f, 1.0f,-1.0f,-1.0f, -1.0f,-1.0f,-1.0f, -1.0f, 1.0f,-1.0f, //立方体上面 1.0f, 1.0f, 1.0f, 1.0f, 1.0f,-1.0f, -1.0f, 1.0f,-1.0f, -1.0f, 1.0f, 1.0f, //立方体下面 1.0f,-1.0f, 1.0f, 1.0f,-1.0f,-1.0f, -1.0f,-1.0f,-1.0f, -1.0f,-1.0f, 1.0f, //立方体右面 1.0f, 1.0f, 1.0f, 1.0f, 1.0f,-1.0f, 1.0f,-1.0f,-1.0f, 1.0f,-1.0f, 1.0f, //立方体左面 -1.0f, 1.0f, 1.0f, -1.0f, 1.0f,-1.0f, -1.0f,-1.0f,-1.0f, -1.0f,-1.0f, 1.0f }; 这里我们让这个天空盒的坐标绝对值都取为1，好让它填充满整个窗口。 然后我们生成天空盒的立方体贴图，需要加载6个纹理： //立方体贴图的6个纹理的路径 vector facePaths; facePaths.push_back("skybox/right.jpg"); facePaths.push_back("skybox/left.jpg"); facePaths.push_back("skybox/top.jpg"); facePaths.push_back("skybox/bottom.jpg"); facePaths.push_back("skybox/back.jpg"); facePaths.push_back("skybox/front.jpg"); CubemapLoader cubemapLoader; GLuint cubemap = cubemapLoader.loadCubemap(facePaths); 要画出这个天空盒，我们还需要给它写顶点着色器（写在cubemap.vertex中）和像素着色器（写在cubemap.fragment中）： #version 330 core layout (location=0) in vec3 position; out vec3 TexCoords; uniform mat4 view; uniform mat4 projection; void main(){ gl_Position = projection * view * vec4(position,1.0f); TexCoords = position; } 天空盒子不需要从模型坐标系到世界坐标系的平移、旋转、缩放，所以这里就没有写model矩阵。其实OpenGL是会自动给乘上一个model单位矩阵的。我们还让纹理坐标直接等于片段的位置坐标，因为此时的天空盒子中心是在原点的，可以直接使用片段的位置向量作为采样向量。注意纹理坐标是3维的。 #version 330 core in vec3 TexCoords; out vec4 color; uniform samplerCube cubemap; void main(){ color = texture(cubemap,TexCoords); } 像素着色器很简单，直接让片段最终颜色等于立方体贴图采样的纹素颜色就可以。 当然，肯定还需要给天空盒子定义一个着色器类对象： shader skybox_shader("cubemap.vertex", "cubemap.fragment"); 接下来我们在渲染循环里绘制这个天空盒子。在绘制天空盒子之前，我们需要关闭面剔除，否则天空盒子不会显示，因为我们现在是正处于天空盒子内部的，如果不关闭面剔除，它的每个面都将被剔除掉；而且还要禁用深度写入，否则场景中的其他物体都会被天空盒子覆盖掉，其他物体将不能通过深度测试而被抛弃： //Draw skybox glDisable(GL_CULL_FACE); glDepthMask(GL_FALSE); 接下来就是和绘制普通立方体一样，来绘制天空盒了： skybox_shader.Use(); mat4 view = mycamera.GetViewMatrix(); mat4 projection = perspective(radians(mycamera.cameraFov), (GLfloat)WIDTH / (GLfloat)HEIGHT, 0.1f, 100.0f); glUniformMatrix4fv(glGetUniformLocation(skybox_shader.shaderProgram, "view"), 1, GL_FALSE, value_ptr(view)); glUniformMatrix4fv(glGetUniformLocation(skybox_shader.shaderProgram, "projection"), 1, GL_FALSE, value_ptr(projection)); glBindVertexArray(skyboxVAO); glBindTexture(GL_TEXTURE_CUBE_MAP, cubemap); glDrawElements(GL_TRIANGLES, 36, GL_UNSIGNED_INT, 0); glDepthMask(GL_TRUE); glEnable(GL_CULL_FACE); 后面再照常绘制其他物体就可以了。 编译运行后的结果如下：移动摄像机，会发现天空盒子也会跟着移动，给人的感觉确实就是个盒子，而不是一片浩瀚的天空。要解决这个问题，我们需要让天空盒子不会随着摄像机移动而移动。天空盒子之所以会移动，是因为在它的顶点着色器中顶点坐标乘上了观察矩阵view，这个观察矩阵是随着摄像机移动而改变的。我们可以去掉观察矩阵的平移部分，把4x4的矩阵改成3x3即可（线性代数知识）。我们在主程序中完成这个操作，然后把新的观察矩阵发送给顶点着色器： mat4 view = mat4(mat3(mycamera.GetViewMatrix())); glUniformMatrix4fv(glGetUniformLocation(skybox_shader.shaderProgram, "view"), 1, GL_FALSE, value_ptr(view)); 这样编译运行后的结果就正常了：&nbsp; 优化上面再绘制天空包围盒时，我们首先禁用了深度缓冲写入，再绘制包围盒，让它处于场景外围，这样做虽然能正常工作，缺点是如果场景中有的物体挡住了天空，按照上面的绘制方式，这部分被挡住的天空还是被绘制了，只是后来又被其他物体（比如场景中的箱子）覆盖了，这导致了不必要的着色器调用，是一种性能上的损失。 所以，绘制天空盒时，我们还是得允许深度写入。但是我们想办法让天空盒的深度最大（1.0），因为它是最外围的。如果有物体挡住了它，被遮挡住的天空盒部分将无法通过深度测试，会被丢弃。那么如何让天空盒的每一个片段的深度值都等于1.0呢？我们在天空盒的顶点着色器中做如下操作： void main(){ vec4 pos = projection * view * vec4(position,1.0f); gl_Position = pos.xyww; TexCoords = position; } 我们把顶点坐标的z值改成了w。正如我们以前就知道的，z值代表了该片段的深度值。在投影变换之后OpenGL会进行透视除法，顶点的x、y、z都会去除以w，因为我们把z值变成了w，所以透视除法的结果就是每个顶点的z值都变成了1.0。 注意这时我们应该改变一下通过深度测试的条件：应该是小于等于时通过深度测试，而不是默认的小于，否则下一次渲染循环的天空深度值因为等于1.0，和深度缓冲的深度值里一样，将会被丢弃，导致天空无法显示出来： //深度测试函数 glDepthFunc(GL_LEQUAL); 所有源码在这里。&nbsp; 环境映射我们使用立方体贴图能够渲染的不只是天空盒，可以是任何大环境，比如一个山谷、一个空间内部等等。我们可以利用这些带有场景的立方体贴图，让物体可以反射或折射周围的环境。像这样使用了环境立方体贴图的技术叫做环境贴图技术，其中最重要的是反射和折射。由于我们着重关注怎么让物体反射和折射环境，所以我们还是使用之前的天空盒，让箱子反射和折射天空。 反射反射是一个物体（或物体的，某部分）反射（Reflect）它周围环境的属性，比如物体的颜色多少有些等于它周围的环境，这要基于观察者的角度。 下图展示了如何计算反射向量，然后使用这个反射向量去立方体贴图中采样：计算反射向量的方法已经在《OpenGL10：光照基础Phong模型》 里讲过了，原理很简单，我们直接上代码： #version 330 core in vec3 Normal; in vec3 PositionInWorld; out vec4 color; uniform vec3 cameraPos; uniform samplerCube cubemap; void main(){ vec3 I = normalize(PositionInWorld - cameraPos); vec3 R = reflect(I,normalize(Normal)); color = texture(cubemap,R); } 对应的顶点着色器为： #version 330 core layout (location=0) in vec3 position; layout (location=1) in vec3 normal; out vec3 Normal; out vec3 PositionInWorld; uniform mat4 model; uniform mat4 view; uniform mat4 projection; void main(){ gl_Position = projection * view * model * vec4(position,1.0f); Normal = mat3(transpose(inverse(model))) * normal; PositionInWorld = vec3(model * vec4(position,1.0f)); } 既然要用到法线向量，那还得给立方体顶点添加法线数据： //立方体顶点的坐标、法线向量 GLfloat cubeVertices[] = { //位置坐标 //法线 //立方体前面 0.5f, 0.5f, 0.5f, 0, 0, 1, 0.5f,-0.5f, 0.5f, 0, 0, 1, -0.5f,-0.5f, 0.5f, 0, 0, 1, -0.5f, 0.5f, 0.5f, 0, 0, 1, //立方体后面 0.5f, 0.5f,-0.5f, 0, 0,-1, 0.5f,-0.5f,-0.5f, 0, 0,-1, -0.5f,-0.5f,-0.5f, 0, 0,-1, -0.5f, 0.5f,-0.5f, 0, 0,-1, //立方体上面 0.5f, 0.5f, 0.5f, 0, 1, 0, 0.5f, 0.5f,-0.5f, 0, 1, 0, -0.5f, 0.5f,-0.5f, 0, 1, 0, -0.5f, 0.5f, 0.5f, 0, 1, 0, //立方体下面 0.5f,-0.5f, 0.5f, 0,-1, 0, 0.5f,-0.5f,-0.5f, 0,-1, 0, -0.5f,-0.5f,-0.5f, 0,-1, 0, -0.5f,-0.5f, 0.5f, 0,-1, 0, //立方体右面 0.5f, 0.5f, 0.5f, 1, 0, 0, 0.5f, 0.5f,-0.5f, 1, 0, 0, 0.5f,-0.5f,-0.5f, 1, 0, 0, 0.5f,-0.5f, 0.5f, 1, 0, 0, //立方体左面 -0.5f, 0.5f, 0.5f, -1, 0, 0, -0.5f, 0.5f,-0.5f, -1, 0, 0, -0.5f,-0.5f,-0.5f, -1, 0, 0, -0.5f,-0.5f, 0.5f, -1, 0, 0 }; 当然，对应的数据解析也得作调整了，不再赘述。环境反射的所有源码在这里。 编译运行后的结果如下：可以看到我们得到了一个镜子一样的箱子，完美地反射了周围的天空盒。如果是球模型，会更明显： 折射环境映射的另一个形式是折射。如下图所示：我们可以通过折射向量R来从立方体贴图上采样。 折射可以通过GLSL的内置函数refract来计算，它需要3个参数：观察向量、法线向量、折射指数： void main(){ //折射 float ratio = 1.00/1.52; vec3 I = normalize(PositionInWorld - cameraPos); vec3 R = refract(I,normalize(Normal),ratio); color = texture(cubemap,R); } 折射指数决定了一个材质上光线扭曲的数量，每个材质都有自己的折射指数。下表是常见的折射指数：编译运行后的结果如下：环境折射的所有源码在这里。&nbsp; 动态环境贴图现在我们的环境立方体贴图还只是静态的。但是如果我们有个镜子一样的物体，它周围有多个物体，当移动摄像机或者移动镜子物体时，它所反射/折射的环境应该是变化挺大的，用静态的立方体贴图显然不够逼真。 可以使用帧缓冲为镜子物体的所有6个不同角度创建一个场景的纹理，把它们每次渲染迭代存储为一个立方体贴图。之后我们可以使用这个（动态生成的）立方体贴图来创建真实的反射和折射表面。这种方法叫做动态环境映射（Dynamic Environment Mapping），因为我们动态地创建了一个物体的以其四周为参考的立方体贴图，并把它用作环境贴图。 这种方法看起来效果很好，但是有一个缺点：我们必须为每个物体渲染场景6次，这需要非常大的开销。我们还是应该尽量使用静态的天空盒子，尽量减少动态环境贴图的使用。想要在不降低执行效率的情况下实现动态环境贴图还需要很多巧妙的技巧。&nbsp; 参考文献：LearnOpenGL]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>天空盒子</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL19：帧缓冲]]></title>
    <url>%2F2017%2F01%2F21%2FOpenGL19%E5%B8%A7%E7%BC%93%E5%86%B2%2F</url>
    <content type="text"><![CDATA[颜色缓冲、深度缓冲、模板缓冲统称帧缓冲。到目前为止，我们在使用OpenGL渲染时，最终的目的地都是默认的帧缓冲区，实际上OpenGL也允许我们创建自定义的帧缓冲区。使用自定义的帧缓冲区，可以实现镜面、离屏渲染，以及很酷的后处理效果。&nbsp; 帧缓冲FBO概念在OpenGL中，渲染管线中的顶点、纹理等经过一系列处理后，最终显示在2D屏幕上，渲染管线的最终目的地就是帧缓冲区。帧缓冲包括颜色缓冲区、深度缓冲区、模板缓冲区。默认的缓冲区由窗口系统创建，例如我们一直使用GLFW库来完成这项任务。这个默认的帧缓冲区，就是目前我们一直使用的绘图命令的作用对象， 称之为窗口系统提供的帧缓冲区。 OpenGL也允许我们手动创建一个帧缓冲区，并将渲染结果重定向到这个缓冲区。在创建时允许我们自定义帧缓冲区的一些特性，这个自定义的帧缓冲区，称之为应用程序帧缓冲区。 和默认的帧缓冲区一样，自定义的帧缓冲区也包含颜色缓冲、深度和模板缓冲，这些逻辑上的缓冲区在FBO中称之为附件（可附加的文件，Attachment），它们是可以附加到FBO的数组内存空间。 FBO中包含两种类型的附件：纹理图像、渲染缓冲（renderbuffer）对象。之所以用附加这个词，表达的是FBO可以附加多个缓冲区，而且可以灵活地在缓冲区间切换，一个重要的概念是附加点（其实就是指针）。FBO中可以包含多个颜色附加点，但只能有一个深度和模板附加点，如下图所示：从图中可以看到FBO本身并不包含任何缓冲对象，实际上是通过附加点指向实际缓冲对象的。这样FBO就可以快速地切换缓冲对象。&nbsp; 创建帧缓冲FBO和创建其他缓冲对象一样，使用glGenFramebuffers函数创建FBO如下： //创建FBO GLuint fbo; glGenFramebuffers(1, &fbo); 然后我们需要将创建的fbo绑定到目标对象（读帧缓冲/写帧缓冲/读写帧缓冲）： glBindFramebuffer(GL_FRAMEBUFFER, fbo); 绑定到目标GL_FRAMEBUFFER后，接下来所有的读、写帧缓冲操作都会影响到当前绑定的帧缓冲，并且该缓冲区可以执行读和写操作。绑定的目标还可以是GL_READ_FRAMEBUFFER，这时该帧缓冲区只能执行读操作，比如glReadPixels；目标还可以是GL_DRAW_FRAMEBUFFER，这时该帧缓冲区允许进行渲染、清空等等写入操作。大多数时候我们都用的GL_FRAMEBUFFER。 构建一个完整的帧缓冲FBO必须满足以下条件： 至少附加一个附件（或者说缓冲区，就是颜色、深度、模板缓冲等） 至少有一个颜色附件 所有的附件必须完整（预分配了内存） 每个缓冲区的采样数需要一致 从上面可以看到，我们需要为帧缓冲创建一些附件，还需要把这些附件添加到帧缓冲上。当我们做完上面的所有条件后，我们可以使用glCheckFramebufferStatus函数来检查FBO是否完整： if(glCheckFramebufferStatus(GL_FRAMEBUFFER) == GL_FRAMEBUFFER_COMPLETE) ... 后续的所有渲染操作将渲染到当前绑定的帧缓冲所附加的对应缓冲中。由于我们这里的帧缓冲是自己创建的，不是默认的帧缓冲，渲染命令对窗口的视频输出不会产生任何影响，所以称为离屏渲染（off-screen rendering）。为了让所有的渲染操作对主窗口产生影响，我们必须在最后通过绑定帧缓冲到0（即默认帧缓冲），来激活默认帧缓冲，才能才窗口上实现最终的绘制效果： glBindFramebuffer(GL_FRAMEBUFFER, 0); &nbsp; 前面提到了，我们需要把一个或多个附件附加到帧缓冲上。一个附件其实就是一个指向颜色缓冲（或深度缓冲、或模板缓冲）的指针。有两张类型的附件（缓冲区）：纹理、渲染缓冲对象。 附件：纹理当把一个纹理附加到帧缓冲上的时候，所有渲染命令会写入到该纹理上，就像它是一个普通的颜色/深度/模板缓冲一样。使用纹理的好处是，所有渲染操作的结果都会被存储为一个纹理图像，这样我们就可以在着色器中访问并使用这个渲染出来的纹理，可以实现很多特效。 创建一个用于附加到帧缓冲的纹理，和创建普通纹理差不多： //创建纹理附件 GLuint texAttachment; glGenTextures(1, &texAttachment); glBindTexture(GL_TEXTURE_2D, texAttachment); glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, NULL); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); 主要区别是： 我们把纹理大小设置为渲染窗口的大小。因为后边把这张纹理绘入到默认帧缓冲里，让这张纹理铺满整个渲染窗口，以达到和只使用默认帧缓冲一样的效果 在glTexImage2D函数中，传入NULL作为纹理的data数据。因为我们只需要分配内存，不会用加载的纹理数据去填充它，纹理填充会在渲染到帧缓冲的时候自动完成。 不用关心环绕方式和Mipmap。因为在作为帧缓冲的纹理附件时，大多数时候都不需要它们。 【注】： 如果打算渲染到一个当前渲染窗口大一点或者小一点的纹理上，需要使用glViewport函数调整当前的渲染窗口。因为最好让渲染窗口和纹理附件尺寸大小一致。 创建完纹理附件后，还需要把它附加到帧缓冲上： //将纹理附件附加到帧缓冲上 glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, texAttachment, 0); 该函数参数说明如下： 第一个参数target：我们所创建的帧缓冲类型（读/写/读写的帧缓冲）。 第二个参数attachment：指明我们所要附加的附件类型。这里我们附加的是一个颜色附件。后面那个0表示我们可以附加1个以上的颜色附件。 第三个参数textarget：指明希望附加的纹理类型 第四个参数level：指明多级渐远纹理的层级，这里设置为0就可以。 除了可以把纹理附件附加为帧缓冲的颜色缓冲外，还可以作为深度缓冲和模板缓冲。如果是要附加为深度缓冲，需要把glFramebufferTexture2D函数的第二个参数附件类型指定为GL_DEPTH_ATTACHMENT，而且用glTexImage2D函数生成纹理时，纹理格式和内部格式不再是GL_RGB了，而是GL_DEPTH_COMPONENT，这样才可以存储为深度缓冲所需要的存储格式；如果是要附加为模板缓冲，需要把附件类型指定为GL_STENCIL_ATTACHMENT，把纹理格式和内部格式指定为GL_STENCIL_INDEX。 还可以把纹理附件同时作为帧缓冲的深度缓冲和模板缓冲。这样纹理的每32位数值就包含了24位的深度信息和8位的模板信息，这时需要把附件类型指定为GL_DEPTH_STENCIL_ATTACHMENT，生成纹理时内部格式应该指定为GL_DEPTH24_STENCIL8，纹理格式应该设置为GL_DEPTH_STENCIL，如下所示： glTexImage2D( GL_TEXTURE_2D, 0, GL_DEPTH24_STENCIL8, 800, 600, 0, GL_DEPTH_STENCIL, GL_UNSIGNED_INT_24_8, NULL ); glFramebufferTexture2D(GL_FRAMEBUFFER, GL_DEPTH_STENCIL_ATTACHMENT, GL_TEXTURE_2D, texture, 0); &nbsp; 附件：渲染缓冲对象除了纹理附件，另外一种附件是渲染缓冲对象。和纹理图像一样，渲染缓冲对象也是一个缓冲，它可以是一堆字节、整数、像素或者其他东西。渲染缓冲对象的一大优点是：它以OpenGL原生渲染格式存储它的数据，因此在离屏渲染到帧缓冲的时候，这些数据就相当于被优化过的了。 渲染缓冲对象将所有渲染数据直接存储到它们的缓冲里，而不会进行针对特定纹理格式的任何转换，这样它们就成了一种可快速可写的存储介质了。然而，渲染缓冲对象是只写的，不能修改它们（就是只能写一次，后面不能再修改了）。可以用glReadPixels函数去读取。 因为它所存储的数据已经是原生格式了，在写入或把它们的数据简单地拷贝到其他缓冲的时候会非常快。所以使用渲染缓冲对象时，像切换缓冲这种操作会变得异常高速。我们在每个渲染循环末尾使用的那个glfwSwapBuffers函数，同样可以缓冲对象实现：我们简单地写入到一个渲染缓冲对象，最后交换到另一个里。渲染缓冲对象对于这种切换缓冲的操作来说很完美。 创建渲染缓冲对象创建渲染缓冲对象和创建一般的缓冲对象类似： GLuint rbo; glGenRenderbuffers(1, &rbo); 接下来需要绑定到渲染缓冲上，这样所有后续渲染操作都会影响到当前绑定的渲染缓冲对象： glBindRenderbuffer(GL_RENDERBUFFER, rbo); 大多数时候，我们不需要从深度和模板缓冲中读取数据，不需要进行采样，只要能进行深度和模板测试就可以，而渲染缓冲对象通常是只写的，所以它经常作为深度和模板附件来使用，优点是它们等于是被优化过的。 我们可以调用glRenderbufferStorage函数为rbo预分配内存空间，这里把rbo存储为24位深度缓冲和8位模板缓冲的格式： glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH24_STENCIL8, 800, 600); 【注】： 渲染缓冲对象是专门被设计用于图像的，而不是通用目的的数据缓冲。 最后需要把帧缓冲对象附件附加到帧缓冲上： glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_STENCIL_ATTACHMENT, GL_RENDERBUFFER, rbo); 在帧缓冲项目中，渲染缓冲对象可以提供一些优化，但更重要的是知道何时使用渲染缓冲对象，何时使用纹理附件。通常的规则是：如果永远都不需要从特定的缓冲中进行采样，渲染缓冲对象对特定缓冲是更明智的选择；如果需要从比如颜色或深度这样的特定缓冲中采样数据的话，最好还是使用纹理附件。&nbsp; 渲染到纹理现在我们来上个demo，把场景渲染到一个颜色纹理上（这个纹理是附加到我们创建的帧缓冲上的），然后我们把纹理绘制到一个简单的四边形上（这个四边形铺满整个屏幕）。最后输出的图像看似和没用帧缓冲一样，但是其实是直接输出到了一个单独的四边形上面。后面会看到这样做的好处。 首先，我们需要创建一个帧缓冲对象，并绑定它： //创建FBO GLuint fbo; glGenFramebuffers(1, &fbo); glBindFramebuffer(GL_FRAMEBUFFER, fbo); 接下来创建一个纹理附件，它将附加为帧缓冲的颜色缓冲： //创建纹理附件 GLuint texColorBuffer; glGenTextures(1, &texColorBuffer); glBindTexture(GL_TEXTURE_2D, texColorBuffer); glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, NULL); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); glBindTexture(GL_TEXTURE_2D, 0); //将纹理附件附加到帧缓冲上 glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, texColorBuffer, 0); 我们还想让OpenGL可以进行深度测试和模板测试，所以我们还需要向帧缓冲中添加一个深度和模板附件。由于我们只采样颜色缓冲，并不采样深度缓冲，所以深度附件可以用渲染缓冲对象来实现。 创建并绑定渲染缓冲对象，同时预分配内存空间： //创建渲染缓冲对象 GLuint rbo; glGenRenderbuffers(1, &rbo); glBindRenderbuffer(GL_RENDERBUFFER, rbo); glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH24_STENCIL8, width, height); glBindRenderbuffer(GL_RENDERBUFFER, 0); 然后需要把渲染缓冲对象附加到帧缓冲上： //将渲染缓冲对象附加到帧缓冲上 glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_STENCIL_ATTACHMENT, GL_RENDERBUFFER, rbo); 接下里我们检查一下帧缓冲是否真的做完整了，如果没有就打印一个错误消息： //检查帧缓冲是否完整 if (glCheckFramebufferStatus(GL_FRAMEBUFFER) != GL_FRAMEBUFFER_COMPLETE) { std::cout < "Framebuffer is not complete!" < std::endl; }]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>帧缓冲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL18：背面剔除]]></title>
    <url>%2F2017%2F01%2F18%2FOpenGL18%E8%83%8C%E9%9D%A2%E5%89%94%E9%99%A4%2F</url>
    <content type="text"><![CDATA[对于一个立方体，从任何一个方向最多只能看到3个面，那我们为何还需要去绘制那3个看不到的面呢？如果我们可以以某种方式丢弃它们，那我们至少会为像素着色器提高50%的性能！我们如何知道哪个面是能看到的（即正面，朝向观察者），哪个面是不能看到的（即背面，背对观察者）呢？ 【注】： 一个三角形相对于观察者只可能是正面或者背面，不可能既是正面又是背面 这里所说的正面背面都是相对于封闭形状来说的，能够看到的是正面，被挡住的是背面。 后面说到的三角形，请带入封闭形状里考虑，不然一个单独的三角形是不存在正面、背面之说的。&nbsp; 顶点绕序我们需要丢弃背对观察者的三角形片元，那如何确定一个面是否背对观察者呢？OpenGL使用顶点绕序（winding order）来解决这个问题。 顶点绕序就是当几何对象细分为三角形时，三角形顶点相对于中心的定义顺序，如下图所示：左图中的顶点绕序是顺时针的，右边是逆时针的。 默认情况下，OpenGL认为三角形的正面都是逆时针的顶点绕序，顺时针的顶点绕序都是三角形的背面，背对观察者。 我们在定义顶点属性数据时，需要从三角形的正面看过去（保证能够看到三角形），以逆时针绕序进行定义。如下图所示：右边的三角形顶点和左边的三角形顶点都是以逆时针顺序进行定义的，它们在各自的方向上都能被看到：右边的三角形从右边能够被看到，左边的三角形从左边能够被看到。但是如果现在观察点在右边，OpenGL会根据三角形顶点被定义的顺序，来计算相对于观察者来说这个顺序是逆时针还是顺时针。如果是逆时针，说明该面是正面，朝向观察者；如果是顺时针，说明该面是背面，背对观察者。根据三角形顶点的本身绕序，来计算相对于观察者的相对绕序（即相对于观察者是逆时针/顺时针），这是在光栅化阶段由OpenGL自动完成的。&nbsp; 在OpenGL中使用背面剔除首先，我们需要把立方体每个面的顶点按逆时针顺序去定义。注意，一定要从正面去看立方体的每个面，这时再去确定逆时针顺序的顶点。由于我们是用索引去绘制立方体，所以只需要按逆时针指定索引就可以了: //三角形顶点的坐标、纹理坐标 GLfloat cubeVertices[] = { //位置坐标 //纹理坐标 //立方体前面 0.5f, 0.5f, 0.5f, 1.0f,1.0f, 0.5f,-0.5f, 0.5f, 1.0f,0.0f, -0.5f,-0.5f, 0.5f, 0.0f,0.0f, -0.5f, 0.5f, 0.5f, 0.0f,1.0f, //立方体后面 0.5f, 0.5f,-0.5f, 1.0f,1.0f, 0.5f,-0.5f,-0.5f, 1.0f,0.0f, -0.5f,-0.5f,-0.5f, 0.0f,0.0f, -0.5f, 0.5f,-0.5f, 0.0f,1.0f, //立方体上面 0.5f, 0.5f, 0.5f, 1.0f,1.0f, 0.5f, 0.5f,-0.5f, 1.0f,0.0f, -0.5f, 0.5f,-0.5f, 0.0f,0.0f, -0.5f, 0.5f, 0.5f, 0.0f,1.0f, //立方体下面 0.5f,-0.5f, 0.5f, 1.0f,1.0f, 0.5f,-0.5f,-0.5f, 1.0f,0.0f, -0.5f,-0.5f,-0.5f, 0.0f,0.0f, -0.5f,-0.5f, 0.5f, 0.0f,1.0f, //立方体右面 0.5f, 0.5f, 0.5f, 1.0f,1.0f, 0.5f, 0.5f,-0.5f, 1.0f,0.0f, 0.5f,-0.5f,-0.5f, 0.0f,0.0f, 0.5f,-0.5f, 0.5f, 0.0f,1.0f, //立方体左面 -0.5f, 0.5f, 0.5f, 1.0f,1.0f, -0.5f, 0.5f,-0.5f, 1.0f,0.0f, -0.5f,-0.5f,-0.5f, 0.0f,0.0f, -0.5f,-0.5f, 0.5f, 0.0f,1.0f }; //顶点索引 GLuint cubeIndices[] = { //立方体前面 0,3,1, 1,3,2, //立方体后面 4,5,7, 5,6,7, //立方体上面 8,9,11, 9,10,11, //立方体下面 12,15,13, 13,15,14, //立方体右面 16,19,17, 17,19,18, //立方体左面 20,21,23, 21,22,23 }; 然后，我们需要开启面剔除： //开启面剔除 glEnable(GL_CULL_FACE); 编译运行后，所有不是正面朝向观察者的面都会被丢弃，尝试移动摄像机到箱子里面，会发现看不到箱子了：如果不开启背面剔除，运行的结果会是这样：目前，因为使用了背面剔除，在渲染片段上我们节约了超过50%的性能，但记住这只对像立方体这样的封闭形状有效。 所有源码在这里。&nbsp; 更多剔除 还可以剔除正面OpenGL默认是剔除背面三角形，但是也可以使用glCullFace函数来剔除正面等： glCullFace(GL_FRONT); 该函数的参数有一下三个可选项： GL_BACK：只剔除背面 GL_FRONT：只剔除正面 GL_FRONT_AND_BACK：剔除正面和背面 正面也可以是顺时针之前我们使用逆时针来代表正面，其实也可以通过glCullFace函数来设置顺时针代表正面： glFrontFace(GL_CW); 默认值是GL_CCW，表示逆时针，GL_CW表示顺时针。&nbsp; 参考文献：LearnOpenGL]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>背面剔除</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL17：混合]]></title>
    <url>%2F2017%2F01%2F17%2FOpenGL17%E6%B7%B7%E5%90%88%2F</url>
    <content type="text"><![CDATA[在OpenGL中，物体透明技术通常被叫做混合（Blending）。&nbsp; 透明透明是指物体自身颜色与它背面物体颜色不同程度的混合，而在OpenGL中就是使用混合技术来实现的，将当前要绘制的物体的颜色和颜色缓冲区中已经绘制了的物体颜色进行混合，最终决定当前物体的颜色。下图是一副全透明和半透明的窗子：物体的透明度是由片段颜色的alpha值（颜色向量的第4个元素）决定的，全透明的alpha值是0.0即透明度是100%，不透明的alpha值是1.0即透明度是0%。&nbsp; 丢弃片段来实现全透明有些纹理是纹理部分要么全透明，要么不透明，不存在半透明的部分。如下面的草纹理，它没有半透明的部分：对于这种纹理，我们可以直接丢弃全透明部分的片段，没有必要将它存储到颜色缓冲中，更没有必要使用混合技术。 首先，我们需要更改一下SOIL加载图片的方式，我们需要以RGBA的方式去加载带有alpha值的纹理（如果某些像素没有alpha值将会被设为1.0）： //加载纹理图像 unsigned char* image = SOIL_load_image(texturePath, &imageWidth, &imageHeight, 0, SOIL_LOAD_RGBA); 不要忘记还要改变OpenGL生成纹理的方式： //生成2D纹理 glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, imageWidth, imageHeight, 0, GL_RGBA, GL_UNSIGNED_BYTE, image); 绘制草的着色器很简单，仅仅是让片段颜色等于纹素颜色而已，代码如下：顶点着色器（写在grass.vertex中）： #version 330 core layout (location=0) in vec3 position; layout (location=1) in vec2 texCoords; out vec2 TexCoords; uniform mat4 model; uniform mat4 view; uniform mat4 projection; void main(){ gl_Position = projection * view * model * vec4(position,1.0f); TexCoords = vec2(texCoords.x ,1 - texCoords.y); } 像素着色器（写在grass.fragment中）： #version 330 core in vec2 TexCoords; out vec4 color; uniform sampler2D texture1; void main(){ color = texture(texture1,TexCoords); } 设置草平面的顶点属性如下： //草平面的顶点属性（位置坐标、纹理坐标） GLfloat grass_vertices[] = { //顶点位置坐标 //纹理坐标 0.5f, 0.5f, 0.0f, 1.0f,1.0f, 0.5f,-0.5f, 0.0f, 1.0f,0.0f, -0.5f, 0.5f, 0.0f, 0.0f,1.0f, 0.5f,-0.5f, 0.0f, 1.0f,0.0f, -0.5f, 0.5f, 0.0f, 0.0f,1.0f, -0.5f,-0.5f, 0.0f, 0.0f,0.0f, }; 接下来需要对它进行VAO绑定和数据解析： //草平面顶点数据的绑定和解析 GLuint grassVAO, grassVBO; glGenVertexArrays(1, &grassVAO); glBindVertexArray(grassVAO); glGenBuffers(1, &grassVBO); glBindBuffer(GL_ARRAY_BUFFER, grassVBO); glBufferData(GL_ARRAY_BUFFER, sizeof(grass_vertices), grass_vertices, GL_STATIC_DRAW); glEnableVertexAttribArray(0); glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 5 * sizeof(GL_FLOAT), (GLvoid*)0); glEnableVertexAttribArray(1); glVertexAttribPointer(1, 2, GL_FLOAT, GL_FALSE, 5 * sizeof(GL_FLOAT), (GLvoid*)(3 * sizeof(GL_FLOAT))); glBindVertexArray(0); 还需要加载草纹理： TextureLoader texLoader; GLuint grassTexture = texLoader.LoadTexture("grass.png"); 由于要绘制多株草，我们给每株草设置不同的位置： //草的位置 vector grass_location; grass_location.push_back(vec3(-1.5f, 0.0f, -0.48f)); grass_location.push_back(vec3(1.5f, 0.0f, 0.51f)); grass_location.push_back(vec3(0.0f, 0.0f, 0.7f)); grass_location.push_back(vec3(-0.3f, 0.0f, -2.3f)); grass_location.push_back(vec3(0.5f, 0.0f, -0.6f)); 为了绘制草所定义的着色器对象如下： shader grass_shader("grass.vertex", "grass.fragment"); 最后就是在渲染循环里绘制几株草了： //绘制几株草 glBindVertexArray(grassVAO); glBindTexture(GL_TEXTURE_2D, grassTexture); for (int i = 0; i < grass_location.size(); i++) { model = mat4(); model = translate(model, grass_location[i]); glUniformMatrix4fv(glGetUniformLocation(grass_shader.shaderProgram, "model"), 1, GL_FALSE, value_ptr(model)); glDrawArrays(GL_TRIANGLES, 0, 6); } glBindVertexArray(0); 编译运行后的结果如下：出现这种结果是因为OpenGL默认是不知道如何处理alpha值得，需要我们自己来设置。在像素着色器中，当片段的alpha值小于某一指定值时，就使用discard命令丢弃它。discard是GLSL为我们提供的用于丢弃片段的命令： #version 330 core in vec2 TexCoords; out vec4 color; uniform sampler2D texture1; void main(){ vec4 texColor = texture(texture1,TexCoords); if(texColor.a < 0.1) discard; color=texColor; } 编译运行后的结果如下：可以看到绘制出来的每张草纹理上方会有一个白边，这是因为我们的纹理设置得是REPEAT环绕方式，在采样纹理边缘的时候，OpenGL会在该边缘和环绕的下一张重复纹理的边缘之间插值，这里上方的白边就是草纹理的透明上边缘和下边缘（绿色）插值的结果。为了防止四周这种白边的出现，我们需要把纹理环绕方式设置为GL_CLAMP_TO_EDGE： //设置纹理s和t方向的环绕方式 glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE); 编译运行后的结果如下：草确实没有了白边，但是地面很诡异了，地面纹理边缘也被拉伸了。地面纹理和草纹理应该是不同的环绕方式，所以，我们给TextureLoader类的LoadTexture函数加一个参数，表示s和t方向上的环绕方式，函数声明如下： GLuint LoadTexture(const GLchar* texturePath, GLint wrap_st = GL_REPEAT); 在LoadTexture函数的实现中，就用这个wrap_st参数来设置纹理环绕方式： //设置纹理s和t方向的环绕方式 glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, wrap_st); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, wrap_st); 现在加载草纹理和地面纹理应该是这样： TextureLoader texLoader; GLuint grassTexture = texLoader.LoadTexture("grass.png", GL_CLAMP_TO_EDGE); GLuint planeTexture = texLoader.LoadTexture("container.jpg"); 编译运行后的结果如下：所有源码在这里。&nbsp; 混合原理上诉丢弃片段的方式，虽然可以实现全透明效果，但是不能渲染半透明图像。为了能够实现半透明，我们需要先开启混合： //开启混合 glEnable(GL_BLEND); 混合方程OpenGL是按照以下混合方程进行混合的：$$\begin{equation}Result=source*sFactor+destination*dFactor\end{equation}$$source是源颜色向量，是将要绘制的纹理的颜色向量；destination是目标颜色向量，是存储在颜色缓冲中当前位置的颜色向量。sFactor和dFactor分别是对源颜色目标颜色的影响系数。 系数着色器运行完成并且所有的测试都通过以后，混合方程才开始执行。方程中的源和目标颜色会自动被OpenGL设置，而源和目标颜色的影响因子是由我们来设置的。比如现在有以下两个方块（或者说放大了的片段）：我们希望在红色方块上绘制绿色方块。红色方块将是目标颜色（它会先进入颜色缓冲中），绿色方块将是源颜色。如果我们把源颜色影响因子设为源颜色的alpha值0.6， 把目标颜色影响因子设为剩下（1-0.6），那么混合方程将是：$$\begin{equation}Result =\begin{pmatrix}0.0 \\\ 1.0 \\\\0.0 \\\ 0.6\end{pmatrix}* 0.6 +\begin{pmatrix}1.0 \\\ 0.0 \\\\0.0 \\\ 1.0 \\\\\end{pmatrix}* (1 - 0.6)\end{equation}$$最终方块将包含60%的绿色和40的红色： 设置源和目标颜色的影响因子我们使用glBlendFunc函数来设置这两个影响因子，函数原型如下： void glBlendFunc(GLenum sfactor, GLenum dfactor) 这两个参数可以设置为下列选项：为了获得混合效果，把源颜色的alpha给源因子，1-alpha给目标因子： glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA); glBlendFunc函数是为R、G、B、A这四个分量都设置了相同的影响因子。其实我们还可以不用混合方程，直接使用glBlendFuncSeperate函数为最终颜色的每个分量设置一个值，例如： glBlendFuncSeperate(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA,GL_ONE, GL_ZERO); 混合方程不止于加我们之前给的混合方程是源颜色和目标颜色按比例相加，其实还可以是减、逆序减。这需要用到glBlendEquation函数。函数原型如下： void glBlendEquation(GLenum mode) 它的参数有以下选项： GL_FUNC_ADD：相加，这是默认的，$Result = Src + Dst$。 GL_FUNC_SUBTRACT：相减，$Result = Src - Dst$。 GL_FUNC_REVERSE_SUBTRACT：反过来相减，$Result = Dst - Src$。通常可以省略glBlendEquation函数，因为大多数时候我们需要的混合效果都是相加的，这恰好是默认的。&nbsp; 渲染半透明纹理现在我们开始用OpenGL来渲染下面这个半透明的窗子： 首先我们需要开启混合，并设置合适的混合方程： //开启混合 glEnable(GL_BLEND); //混合方程 glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA); 这里是让源颜色影响因子等于源颜色的alpha值，目标颜色的影响因子等于1-源颜色的alpha。 现在我们是用混合来绘制半透明窗子的，不需要丢弃片段了，将像素着色器改回来： #version 330 core in vec2 TexCoords; out vec4 color; uniform sampler2D texture1; void main(){ /*vec4 texColor = texture(texture1,TexCoords); if(texColor.a < 0.1) discard; color=texColor;*/ color = texture(texture1,TexCoords); } 编译运行后的结果如下：&nbsp; 但是有个很明显的问题，前面的窗子并不能透明显示后面的窗子。这是因为深度测试并不关心alpha值，所以前面的窗子就会挡住后面的窗子，即使前面的窗子是透明的，它也会把后面窗子被挡住的片段丢弃。 由远及近地绘制透明物体对于包含不透明和透明物体的场景，绘制顺序应该是： 首先绘制不透明物体 先绘制离摄像机远的透明物体，再绘制近的透明物体 如果由远及近地绘制透明物体，那么在绘制近一些的透明物体时，就会混合远处的透明物体，最终会产生正确的结果。 几个窗子的位置如下： //窗子的位置 vector window_location; window_location.push_back(vec3(-1.5f, 0.0f, -0.48f)); window_location.push_back(vec3(1.5f, 0.0f, 0.51f)); window_location.push_back(vec3(0.0f, 0.0f, 0.7f)); window_location.push_back(vec3(-0.3f, 0.0f, -2.3f)); window_location.push_back(vec3(0.5f, 0.0f, -0.6f)); 我们以窗子到摄像机的距离作为键，以窗子的位置作为键对应的值，会 建键值对数据结构map，map会自动对键进行排序，也就是map会自动排序窗子到摄像机的距离。【注】： map是STL库中的数据结构，是键值对的集合，可以用键作为下标来访问对应的值。 在渲染循环中，我们创建一个map，并且把窗子到摄像机的距离作为键，把当前窗子作为键对应的值： //把多个窗子位置存入map数据结构中，以窗子到摄像机的距离为键 map sortedWindow; for (int i = 0; i < window_location.size(); i++) { GLfloat distance = length(mycamera.cameraPos - window_location[i]); sortedWindow[distance] = window_location[i]; } 在绘制时，我们逆序遍历这个map，就能由远及近地绘制出每个窗子： //逆序访问键值对map，由远及近地绘制透明窗子 for (map::reverse_iterator it = sortedWindow.rbegin(); it != sortedWindow.rend(); ++it) { model = mat4(); model = translate(model, it->second); glUniformMatrix4fv(glGetUniformLocation(grass_shader.shaderProgram, "model"), 1, GL_FALSE, value_ptr(model)); glDrawArrays(GL_TRIANGLES, 0, 6); } reverse_iterator是逆序迭代器，it-&gt;second是键值对中的第二个元素，这里就是键对应的值，窗子的位置。 编译运行后的结果如下： 全部源码在这里。 在这个场景里，我们是按照窗子到摄像机的距离来由远及近地排序的，但是这种方法不是通用的。我们这个场景里所有的窗子都是相互平行，没有交叉折叠的，如果物体比较奇怪复杂，就需要其他排序方式了。对场景中的物体进行排序是很有难度的，完美地渲染带透明和不透明物体的场景也不那么容易，如果感兴趣可以了解一些更高级的技术，比如次序无关透明度（order independent transparency）。&nbsp; 参考文献：LearnOpenGL]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>混合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL16：模板测试]]></title>
    <url>%2F2017%2F01%2F15%2FOpenGL16%E6%A8%A1%E6%9D%BF%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[什么是模板测试当像素着色器处理完片段之后，深度测试之前，模板测试（stencil test）就开始执行了，和深度测试一样，它能丢弃一些片段：如果片段的模板值和当前模板缓冲区的对应位置上的模板值，满足指定关系，则不会被丢弃。这就是模板测试。仍然保留下来的片段将进入深度测试阶段，深度测试又会丢弃一些片段。 在渲染管线里包括很多种测试，它们的执行顺序如下图：&nbsp; 模板缓冲模板缓冲类似于颜色缓冲和深度缓冲，不过模板值通常是8位的，每个片段可以有256种不同的模板值（最大值255） 模板缓冲的作用下面举一个模板缓冲的简单例子：左边的场景在中间的模板作用下，只有对应模板值为1的片段才会被显示，不为1的片段都被丢弃了，最终呈现右图的结果。 可以看到，使用模板缓冲，我们可以根据模板值对决定是否丢弃特定的片段。&nbsp; 使用模板缓冲使用模板缓冲的步骤一般如下： 开启模板测试 绘制模板，写入模板缓冲（不写入color buffer和depth buffer） 关闭模板缓冲写入 利用模板缓冲中的值，绘制后续场景 首先我们需要开启模板测试： glEnable(GL_STENCIL_TEST); 而且像颜色缓冲和深度缓冲一样，每次渲染循环之前，需要先清空模板缓冲： glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT | GL_STENCIL_BUFFER_BIT); 同样，和深度测试的glDepthMask函数一样，模板缓冲也有一个类似的函数glStencilMask，它用于控制模板缓冲区的写入，使用位掩码的方式决定是否可以写入模板缓冲区。使用的较多的是0x00表示禁止写入，0xFF表示允许任何写入： // 0xFF == 0b11111111 //此时，模板值与它进行按位与运算结果是模板值，模板缓冲可写 glStencilMask(0xFF); // 0x00 == 0b00000000 == 0 //此时，模板值与它进行按位与运算结果是0，模板缓冲不可写 glStencilMask(0x00); 模板函数和深度测试一样，对于模板测试，我们也可以选择在什么条件下通过模板测试（使用glStencilFunc函数来完成），而且还可以选择以何种方式更新模板缓冲（比如通过模板测试后模板值不变、讲模板值变为0或者替换为另一个值等等，这使用glStencilOp函数来完成）。 glStencilFunc函数（指定模板测试通过条件）：函数原型：void glStencilFunc(GLenum func,GLint ref,GLuint mask)： 参数func：和深度测试一样，指定在什么条件通过模板测试，可用选项有：GL_NEVER、GL_LEQUAL、GL_GREATER、GL_GEQUAL、GL_EQUAL、GL_NOTEQUAL、GL_ALWAYS。 参数ref：和当前模板模板缓冲中的值stencil进行比较的指定值。 参数mask：指定一个遮罩，在比较时，分别与指定值ref和缓冲中的模板值stencil进行按位与操作，初始值为1。 【注】： 比较的方式是：如果func指定的是在GL_LESS条件下通过测试，其实是在(ref &amp; mask) &lt; (stencil &amp; mask)的条件下才通过测试；如果指定的是GL_GEQUAL，就相当于(ref &amp; mask) &gt;= (stencil &amp; mask)。 为了比较时简单直接，我们通常将mask设为0xFF： glStencilFunc(GL_EQUAL, 1, 0xFF); 表示当前模板缓冲区中值为1的部分通过模板测试，这部分片元将被保留，其余的则被丢弃。 glStencilOp函数（指定模板缓冲更新方式）：函数原型：void glStencilOp(GLenum sfail, GLenum dpfail, GLenum dppass)： 参数sfail：如果模板测试失败将采取的动作 参数dpfail：如果模板测试通过，但是深度测试失败时采取的动作 参数dppass：如果模板测试和深度测试都通过，将采取的动作 这三个参数是同一种枚举类型，每个参数都可以使用下列任何一个动作，来更新模板缓冲：&nbsp; 绘制矩形模板首先我们设置好矩形的顶点属性并解析： //模板矩形的顶点坐标 GLfloat stencilRectVertices[] = { 0.5f, 0.5f, 0.0f, 0.5f, -0.5f, 0.0f, -0.5f, 0.5f, 0.0f, -0.5f, 0.5f, 0.0f, 0.5f, -0.5f, 0.0f, -0.5f, -0.5f, 0.0f }; //模板矩形stencilRectVAO和数据解析 GLuint stencilRectVAO, stencilRectVBO; glGenVertexArrays(1, &stencilRectVAO); glBindVertexArray(stencilRectVAO); glGenBuffers(1, &stencilRectVBO); glBindBuffer(GL_ARRAY_BUFFER, stencilRectVBO); glBufferData(GL_ARRAY_BUFFER, sizeof(stencilRectVertices), &stencilRectVertices, GL_STATIC_DRAW); glEnableVertexAttribArray(0); glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(GL_FLOAT), (GLvoid*)0); glBindVertexArray(0); 画这个模板矩形，当然也需要着色器（最简单的那种着色器就可以）：模板矩形的顶点着色器（写在stencilRect.vertex中）： #version 330 core layout (location=0) in vec3 position; void main(){ gl_Position = vec4(position,1.0f); } 模板矩形的像素着色器（写在stencilRect.fragment中） #version 330 core out vec4 color; void main(){ color = vec4(1.0f); } 当然，需要开启模板缓冲： glEnable(GL_STENCIL_TEST); 在渲染循环开始的时候，清除模板缓冲区： glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT | GL_STENCIL_BUFFER_BIT); 我们将要绘制一个矩形，用它来更新模板缓冲，但是不希望这个矩形被显示出来，所以绘制矩形之前需要先用掩码禁用颜色缓冲和深度缓冲： glColorMask(GL_FALSE, GL_FALSE, GL_FALSE, GL_FALSE); glDepthMask(GL_FALSE); 然后我们使用位掩码设置允许模板缓冲区写入： glStencilMask(0xFF); 接下来我们设置将要绘制的矩形片段总是通过模板测试，而且通过测试之后，把对应模板值设为1： glStencilFunc(GL_ALWAYS, 1, 0xFF); glStencilOp(GL_KEEP, GL_KEEP, GL_REPLACE); 当矩形片段通过模板测试和深度测试后，会用函数glStencilFunc的ref参数（这里是1）来替换对应模板值。 接下来我们就可以来画这个矩形了（注意，由于禁用了颜色缓冲和深度缓冲，这个矩形不会被画到窗口上，只是被画到了模板缓冲里）： stencilRect_shader.Use(); glBindVertexArray(stencilRectVAO); glDrawArrays(GL_TRIANGLES, 0, 6); 矩形模板已经绘制好了，接下来我们开始绘制上一篇文章里的箱子和地面。 肯定需要先把禁用了的颜色缓冲和深度缓冲重新开启： glColorMask(GL_TRUE, GL_TRUE, GL_TRUE, GL_TRUE); glDepthMask(GL_TRUE); 绘制箱子和地面的时候，应该不会去改变模板缓冲中的值，所以我们禁用模板缓冲区写入： glStencilMask(0x00); 我们希望用矩形模板来绘制箱子和地面，只有被包含在矩形内的部分才被绘制出来，其余的被丢弃。由于在模板缓冲中已经被我们绘制了一个矩形（由好多1构成的一个矩形），所以绘制箱子和地面时，我们设置片段模板值等于1时才通过模板测试（模板值不会改变）： glStencilFunc(GL_EQUAL, 1, 0xFF); glStencilOp(GL_KEEP, GL_KEEP, GL_KEEP); 接下来就按照上一篇文章里的方式来绘制箱子和地面即可：编译运行后的结果如下：全部源码在这里。&nbsp; 物体轮廓outline接下来我们再使用模板测试来实现一个很有意识的效果：物体轮廓（object outline），如下图这样：给箱子添加轮廓的大致思路如下： 绘制出箱子，绘制时允许模板缓冲写入。这样就能在绘制箱子的同时，把箱子画入模板缓冲里（注意是窗口上二维显示的箱子，不是空间三维的箱子），其实就是一堆数字1。 绘制出地面，绘制时禁用模板缓冲。因为我们的模板跟地面没关系，不希望在绘制地面时受到影响。 禁用模板缓冲，绘制稍微大一点的纯色箱子（或者其他想要的边框颜色都行），同时设置模板值不等于1的片段无法通过模板测试，将会被丢弃。这样我们就能给之前的箱子绘出一个边框了。 绘制箱子因为我们要在绘制箱子的同时，把箱子模板画入模板缓冲中，所以需要先设置模板测试总是通过，并且通过后用1替换模板值，当然还需要允许模板缓冲写入： //Draw Cube，绘制箱子的同时绘制箱子模板 glStencilFunc(GL_ALWAYS, 1, 0xFF); glStencilOp(GL_KEEP, GL_KEEP, GL_REPLACE); glStencilMask(0xFF); ... 剩下的就是照常绘制箱子了，不再赘述，可参考文末的源码。 绘制地面绘制地面的时候，模板缓冲应该不受影响，所以需要先禁用模板缓冲写入： //Draw Plane，绘制地面时应禁用模板写入 glStencilMask(0x00); ... 接下里就是照常绘制地面了，不再赘述。 绘制箱子轮廓绘制箱子轮廓，其实就是绘制一个模板值不等于1的稍微大一点的箱子。需要设置模板测试通过的条件是模板值不等于1： glStencilFunc(GL_NOTEQUAL, 1, 0xFF); 而且，利用箱子模板绘制箱子轮廓时，模板缓冲不能受到影响，需要禁用模板缓冲写入： glStencilMask(0x00); 接下来就是照常绘制稍微大一点的箱子了，这里我们是绘制一个1.1倍大小的箱子，可参见文末源码。而且这个稍大的边框箱子和实际箱子不是同一套着色器，因为它们的颜色不同（实际箱子是纹理颜色，而边框箱子我们用的纯色，着色器代码也可参见文末源码）。 最后，绘制完箱子轮廓后，不要忘了重新允许模板缓冲写入： glStencilMask(0xFF); 其实，每当改变深度缓冲、模板缓冲等写入方式时，利用完了让它们恢复到最初状态是个很好的习惯，不容易出错。 编译运行后的结果如下：可以看到下轮廓和地面交界的地方，轮廓只显示了很细的一条线，这是因为下轮廓片段的深度值大于交界处地面片段的深度值，被挡住了，在深度测试时被丢弃了。解决办法是在画轮廓时关闭深度测试： glDisable(GL_DEPTH_TEST); //保证轮廓不被挡住 ... 轮廓画完了以后，不要忘了重新开启深度测试： glEnable(GL_DEPTH_TEST); 编译运行后的结果如下：&nbsp; 箱子轮廓的所有源码在这里。&nbsp; 参考文献：LearnOpenGL]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>模板测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL15：深度测试]]></title>
    <url>%2F2017%2F01%2F14%2FOpenGL15%E6%B7%B1%E5%BA%A6%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[使用深度缓冲所存储的深度值，可以确定一个片段是否被其他片段遮挡。 什么是深度测试深度缓冲区、颜色缓冲区和窗口像素是一一对应的，也就是说窗口上的每一个像素都有一个颜色值和一个深度值。颜色缓冲区存储的是像素的颜色信息，而深度缓冲区存储的是像素的深度信息。 在决定是否绘制一个片段时，首先让该片段的深度值与当前深度缓冲区对应位置上的深度值作比较，如果小于深度缓冲区中的值，则用该片段的颜色值和深度值去更新颜色缓冲区和深度缓冲区；否则，说明三维空间中该片段在对应屏幕像素后面，被挡住了，将丢弃该片段。这个过程就叫做深度测试（Depth Testing）。&nbsp; 在OpenGL中使用深度测试深度缓冲区一般由窗口管理系统（例如GLFW）来自动创建，深度值一般是16位、24位或32位，位数越高，深度的精确度越高。大多数系统的深度缓冲区都是24位。 要在OpenGL中使用深度测试，需要先开启深度测试，因为默认是关闭的： glEnable(GL_DEPTH_TEST); 而且在每一次渲染循环开始之前，还需要清除深度缓冲区，否则深度缓冲区将保留上一次进行深度测试时所写的深度值： glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); 有的时候我们需要进行深度测试，但不希望更新深度缓冲区，这时可以用glDepthMask函数将深度掩码设置为GL_FALSE来关闭深度缓冲区写入： glDepthMask(GL_FALSE); 【注】： 使用glDepthMask函数来关闭深度缓冲区写入，只在深度测试被启用的时候有效。 深度测试函数上面说片段深度值小于深度缓冲区对应深度值的时候，深度测试通过。其实也可以是其他关系，比如大于、等于等等。这就需要我们使用’glDepthFunc’函数来设置什么时候通过深度测试了，因为默认情况下是小于的时候才通过深度测试： glDepthFunc(GL_LESS); 除了小于GL_LESS以外，还有其他比较运算符：下面我们把glDepthFunc函数的参数设为GL_ALWAYS来看看效果，源码请看这里。 编译运行后的结果如下：可以看到GL_ALWAYS和我们没有启用深度测试得到了相同的效果。深度测试总是通过，所以后绘制的片段肯定会覆盖之前绘制的片段。在上面的程序中我们先绘制立方体，再绘制的地面，所以地面就把立方体遮住了。把参数设为GL_LESS后的结果如下：&nbsp; 可视化深度值深度测试是在像素着色器运行之后（也在模板测试运行之后），在屏幕空间中执行的。屏幕空间坐标与OpenGL的glViewport函数定义的视口（viewport）直接相关，可以在像素着色器中通过GLSL的内置变量gl_FragCoord来获取片段的屏幕空间坐标。gl_FragCoord的x和y元素表示片段的屏幕空间坐标（(0,0)是左下角），而它的z元素就是片段的实际深度值。 我们把地面的顶点坐标更改如下： //地面的顶点坐标、纹理坐标 GLfloat planeVertices[] = { //位置坐标 //纹理坐标 5.0f, -0.05f, 5.0f, 2.0f, 0.0f, -5.0f, -0.05f, 5.0f, 0.0f, 0.0f, -5.0f, -0.05f, -5.0f, 0.0f, 2.0f, 5.0f, -0.05f, 5.0f, 2.0f, 0.0f, -5.0f, -0.05f, -5.0f, 0.0f, 2.0f, 5.0f, -0.05f, -5.0f, 2.0f, 2.0f }; 地面在y方向上更靠近摄像机了（摄像机在y=0的位置上）。 再把像素着色器更改如下： #version 330 core in vec2 TexCoords; out vec4 color; uniform sampler2D texture1; void main(){ //color = texture(texture1,TexCoords); color = vec4(vec3(gl_FragCoord.z),1.0f); } 我们让箱子和地面不输出纹理颜色，而只是输出深度值。源码在这里。得到结果如下：可以看到地面靠近摄像机的地方有些黑色，说明深度值比较小，但是黑色部分很少。它向白色的过渡变化并不是均匀的，近的地方深度值变化很快，只远离几英寸就让暗色完全变亮了，剩余的部分大多都是亮色。 这是因为片段在屏幕空间里的深度值和它们在三维空间里的z值并不是线性关系。z很小的时候（准确的是靠近摄像机的时候），片元的深度值变化得会很快，能够很好地反映出摄像机近处物体的空间位置关系；但是当z比较大的时候，物体远离摄像机，远处的物体谁在前谁在后通常都不会太影响我们的视觉效果，这时远离摄像机的片元的深度值就不需要变化那么快了。而OpenGL的深度值恰好符合这种视觉规律：z较小时深度变化快，z较大时深度变化慢。 通常NDC坐标系下的深度值$z_n$和观察空间下的深度值$z_e$具有如下关系：$$z_n=\frac{-\frac{far+near}{far-near} \cdot z_e-\frac{2 \cdot far \cdot near}{far-near}}{-z_e}$$ 【注】： 从公式里可以看出，更准确地应该是越靠近近裁剪面，深度值变化越快。因为近裁剪面通常是0.1，相距摄像机很近，所以通常才说成越靠近摄像机深度值变化越快。 在下图中可以看到z值和对应的深度缓冲值的非线性关系（图中横轴是$z_e$，纵轴是$z_n$投影到[0,1]之后的值（NDC坐标系下的深度值$z_n$是在[-1,1]之间的））： 如果想要深入了解投影矩阵的数学意义、上面的公式是如何推导出来的、以及造成这种非线性关系的原因可以参考这篇文章。 这个非线性的深度z是在屏幕空间下的，如果我们想把它变成观察空间下的线性深度怎么办呢（因为很多时候我们都需要观察空间下的线性深度，屏幕空间下的深度对精度的要求太高了）？这时我们需要反转深度值的投影变换。屏幕空间下的深度是在[0,1]之间，首先需要将其重新映射为[-1,1]之间的NDC坐标： float NDC_Z = vScreenDepth * 2.0 - 1.0; //vScreenDepth是屏幕空间下的深度值 然后我们可以根据上面的公式反推出线性的观察空间深度值： float LinearDepth = (2.0 * u_Far * u_Near) / (u_Far + u_Near - NDC_Z * (u_Far - u_Near)); 再用如下shader代码显示出这个线性深度： uniform float u_Far = 100.0; uniform float u_Near = 0.1; float linearizeDepth(float vScreenDepth) { float NDC_Z = vScreenDepth * 2.0 - 1.0; return (2.0 * u_Far * u_Near) / (u_Far + u_Near - NDC_Z * (u_Far - u_Near)); } void main() { float Depth = linearizeDepth(gl_FragCoord.z) / u_Far; //除以u_Far是为了把观察空间下的线性深度归一化到[0,1]之间 color = vec4(vec3(Depth),1.0f); } 运行结果如下：这里面的深度值是随着离视点的距离增大而线性变化的，之所以基本上都是黑色的，是因为我们的远平面是100.0，物体相对视点都几乎在5.0以内，很靠近近平面，所以都基本上是黑的。 深度冲突z-fighting 两个平面或三角形相互接近通常会出现一种视觉失真，深度缓冲没有足够的精确度来弄清哪个形状在前，哪个形状在后（比如两个三角形实际深度是0.801和0.802，但是如果24位深度缓冲只能精确到0.80，那就无法分清这两个三角形谁在前谁在后）。结果就是两个形状持续地交换顺序，产生了诡异的差错样式。这叫做z-fighting，就像两个形状为了显示在上面而打架。 使用最开始的代码，让箱子和地面显示不同的纹理，我们把摄像机移动到箱子里面，就会看到下图所示的这种深度冲突效果（箱子的底部和地面持续地相互交换，产生了锯齿样式）：&nbsp; 减弱z-fighting深度冲突z-fighting是深度缓冲区中常见的问题，通常当物体越远的时候越严重（因为越远的地方深度变化越慢，深度值越接近，精确度低）。z-fighting至今无法完全避免，但是有些技术能够帮助我们减弱z-fighting 永远不要把物体放得彼此太近，不要让物体间的三角形重合。两个物体间留有一小段用户难以观察到的距离，可以完美地避免z-fighting。但是，这需要我们手工干涉每个物体以及仔细测试才能确保场景中的物体没有产生z-fighting。 把近平面设置得尽可能远。因为近裁剪面附近深度变化很快，精确度很高，因此尽可能让近裁剪面远一些（也就是尽可能靠近场景中的物体）的话，会使整个裁剪范围内的精确度变高一些。但是这种方式会使距离观察者较近的物体被裁剪掉，所以需要不断调整才能找到一个合适的近裁剪面参数。 使用更高位数的深度缓冲区，通常使用的深度缓冲区是24位的，但现在显卡支持32位深度值，这会让深度值得精度提高很多。但是同时也带来了一些更大的运算开销。&nbsp; 参考文献：LearnOpenGL]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>深度测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL14：模型加载]]></title>
    <url>%2F2017%2F01%2F12%2FOpenGL14%E6%A8%A1%E5%9E%8B%E5%8A%A0%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[之前我们的场景里用的全都是小方块，现在我们想要去加载一些其他模型。我们是无法像定义小方块一样，用程序去手动地指定房子、人这些复杂模型的顶点、法线和纹理坐标。这些复杂模型通常是由美工用Blender、3DS Max和Maya这些建模软件来制作的，我们要做的只是把这些已经做好的模型打入到我们的应用程序中。在建模软件导出模型文件时，会自动生成模型的所有顶点坐标、顶点法线和纹理坐标，而我们需要去解析这些导出的模型文件，并将其中的模型数据存储为OpenGL能够使用的数据。 由于导出的模型文件通常有几十种格式，为每种格式都写一种解析方式是很麻烦的。这里我们直接使用市面上一个很流行的模型加载库，叫做Assimp。&nbsp; 模型加载库AssimpAssimp是一个常用的模型加载库，全称是Open Asset Import Library。它可以导入几十种不同格式的模型文件（也可以导出部分模型格式），并且可以把不同的模型文件都转换为一个统一的数据结构，所以无论我们导入哪种格式的模型文件，都可以用同一个方式去访问我们需要的模型数据。它能读取以下格式的模型文件： Autodesk ( .fbx ) Collada ( .dae ) glTF ( .gltf, .glb ) Blender 3D ( .blend ) 3ds Max 3DS ( .3ds ) 3ds Max ASE ( .ase ) Wavefront Object ( .obj ) Industry Foundation Classes (IFC/Step) ( .ifc ) XGL ( .xgl,.zgl ) Stanford Polygon Library ( .ply ) AutoCAD DXF ( .dxf ) LightWave ( .lwo ) LightWave Scene ( .lws ) Modo ( .lxo ) Stereolithography ( .stl ) DirectX X ( .x ) AC3D ( .ac ) Milkshape 3D ( .ms3d ) TrueSpace ( .cob,.scn ) Biovision BVH ( .bvh ) CharacterStudio Motion ( .csm ) Ogre XML ( .xml ) Irrlicht Mesh ( .irrmesh ) Irrlicht Scene ( .irr ) Quake I ( .mdl ) Quake II ( .md2 ) Quake III Mesh ( .md3 ) Quake III Map/BSP ( .pk3 ) Return to Castle Wolfenstein ( .mdc ) Doom 3 ( .md5* ) Valve Model ( .smd,.vta ) Open Game Engine Exchange ( .ogex ) Unreal ( .3d ) BlitzBasic 3D ( .b3d ) Quick3D ( .q3d,.q3s ) Neutral File Format ( .nff ) Sense8 WorldToolKit ( .nff ) Object File Format ( .off ) PovRAY Raw ( .raw ) Terragen Terrain ( .ter ) 3D GameStudio (3DGS) ( .mdl ) 3D GameStudio (3DGS) Terrain ( .hmp ) Izware Nendo ( .ndo ) 还能导出几种常见格式的模型： Collada ( .dae ) Wavefront Object ( .obj ) Stereolithography ( .stl ) Stanford Polygon Library ( .ply ) Assimp生成的模型数据结构当Assimp导入一个模型文件时，它会加载整个模型文件到一个scene对象，它包含了所有被导入的模型和场景数据（一个模型文件可能包含多个模型或场景）。Assimp会为这个模型文件中的所有场景节点、模型节点都生成一个对应的数据结构，每个节点包含着存储在scene对象中的数据的索引，有的可能还包含几个子节点。下图展示了一个简化的Assimp生成的模型数据结构： 所有的模型、场景数据都包含在scene对象中，如所有的材质和Mesh。而且，场景的根节点应用也在这个scene对象中。 场景的根节点包含很多子节点和很多指向scene对象中的Mesh网格数据的引用。因为根节点的mMeshes数组才包含着实际的网格对象，其他节点的mMeshes数组的值都只是根节的mMeshes的索引。 一个mesh由顶点、边、面片组成，它包含了渲染所需的所有相关数据，比如顶点位置、法线向量、纹理坐标、面片、材质等，一个mesh是一个可绘制的独立实体，如一条手臂、一条腿。 一个mesh会包含多个面片Face。一个面片表示渲染中的一个最基本的图元（如点、线、三角面片、矩形面片）。一个面片记录了一个图元的顶点索引，通过这个索引，可以在mMeshes中寻找到对应的顶点位置数据。因为顶点和索引是分开的，所以我们很容易使用索引缓冲来进行高速渲染。 一个mesh还会包含一个材质对象，用于指定物体的一些材质属性，如颜色、纹理贴图（漫反射贴图、镜面反射贴图等）。 我们后面会用上诉的数据结构来创建我们自己的Model类和Mesh类，用于加载和保存那些导入的模型。我们不需要去渲染整个模型的所有数据，而只是去渲染这个模型所包含的所有独立的Mesh。 构建Assimp要使用Assimp模型加载库，我们需要先构建它。下载地址在这里。最好我们自己用CMake去编译Assimp库，因为Assimp官方的已编译库不能很好地在所有平台上正常运行。具体编译、构建和链接过程可以回顾《OpenGL1：OpenGL概述及环境配置》。 下面给出一些编译Assimp时可能遇到的问题： 在使用CMake进行Configure时，可能遇到如下错误：Could not locate DirecXCMake Error at cmake-modules/FindPkgMacros.cmake:110 (message):Required library DirectX not found! Install the library (including dev packages) and try again. If the library is already installed, set the missing variables manually in cmake. 这是因为你之前没有安装过DirectX SDK，那么下载安装吧！ 在安装DirectX SDK时，可能会遇到一个错误码为S1023的错误。解决步骤如下： 在命令行窗口运行下面两行命令：MsiExec.exe /passive /X{F0C3E5D1-1ADE-321E-8167-68EF0DE699A5} MsiExec.exe /passive /X{1D8E6291-B0D5-35EC-8441-6616F567A0F7} 删除掉Visual C++ 2010 Redistributable Package。如下图所示： 安装DirectX SDK 重新安装Visual C++ 2010 Redistributable Package。可以在这里下载到。注意x64系统需要安装vcredist_x86.exe和vcredist_x64.exe两个版本。 【注】： 使用默认配置构建的Assimp是一个动态库，所以我们需要把编译出来的assimpd.dll文件拷贝到我们自己的源文件所在的目录里。 如果想要让Assimp使用多线程来提高性能，可以使用Boost库来编译Assimp。在Boost安装页面，可以找到关于Boost的完整安装介绍。&nbsp; 网格类Mesh使用Assimp可以把多种不同格式的模型加载到程序中，但是一旦载入，它们就都被存储为Assimp自己的数据结构。我们需要将其转变为OpenGL可读的数据，才能用OpenGL来渲染物体。 绘制网格所需数据一个网格代表一个可绘制的实体，我们把Assimp加载的模型转变成很多个网格，分别绘出这些网格，就能绘制出整个模型。现在我们来自定义一个自己的网格类，便于转换Assimp的数据结构为OpenGL可读的数据结构。一个网格应该至少需要一组顶点，每个顶点包含一个位置向量、一个法线向量、一个纹理坐标，还需要包含顶点索引以及用纹理（漫反射贴图、镜面贴图）形式表现的材质数据。 那我们先来定义一个顶点： struct Vertex { vec3 position; vec3 normal; vec2 texCoords; }; 顶点中包含了顶点位置、法线和纹理坐标。 接着我们来定义绘制网格所需要的纹理： struct Texture { GLuint id; string samplerName; }; 纹理中包含了纹理加载后的ID，和在像素着色器（在文末有像素着色器代码，和上一篇文章几乎一样）中纹理所对应的采样器名称。 建立网格类然后，我们可以开始建立Mesh类了： class Mesh { public: vector vertices; vector indices; vector textures; float shininess; ... } 它包含了绘制网格所需的一堆顶点、顶点索引和纹理，它们都是vector类型（使用vector需要包含vector文件#include &lt;vector&gt;），还包含了计算镜面光时所需要的镜面反射系数。这些顶点位置、纹理等等都是从Assimp加载后的数据里面得到的（在后面自定义的模型加载类ModelLoader里通过参数传递到Mesh类里）。 我们可以在Mesh类的构造函数里，用传递过来的参数初始化这些顶点、纹理： Mesh(vector vertices, vector indices, vector textures, float shininess) { this->vertices = vertices; this->indices = indices; this->textures = textures; this->shininess = shininess; ... } 和之前的绘制流程一样，在绘制之前先对这些数据绑定VAO、VBO、EBO以及解析顶点数据，我们把它写在PrepareBeforeDraw函数里： GLuint VAO, VBO, EBO; //在绘制之前的绑定、发送数据、解析等准备工作 void PrepareBeforeDraw() { glGenVertexArrays(1, &VAO); glGenBuffers(1, &VBO); glGenBuffers(1, &EBO); glBindVertexArray(VAO); glBindBuffer(GL_ARRAY_BUFFER, VBO); glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, EBO); glBufferData(GL_ARRAY_BUFFER, vertices.size() * sizeof(Vertex), &vertices[0], GL_STATIC_DRAW); glBufferData(GL_ELEMENT_ARRAY_BUFFER, indices.size() * sizeof(GLuint), &indices[0], GL_STATIC_DRAW); glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, sizeof(Vertex), (GLvoid*)0); glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, sizeof(Vertex), (GLvoid*)offsetof(Vertex, normal)); glVertexAttribPointer(2, 2, GL_FLOAT, GL_FALSE, sizeof(Vertex), (GLvoid*)offsetof(Vertex, texCoords)); glEnableVertexAttribArray(0); glEnableVertexAttribArray(1); glEnableVertexAttribArray(2); glBindVertexArray(0); } 然后在构造函数里调用该函数： Mesh(vector vertices, vector indices, vector textures, float shininess) { this->vertices = vertices; this->indices = indices; this->textures = textures; this->shininess = shininess; PrepareBeforeDraw(); } 绘制网格所需的数据以及绑定解析好了，接下来就可以绘制网格了： void Draw(shader myshader) { for (GLuint i = 0; i < textures.size(); i++) { glActiveTexture(GL_TEXTURE0 + i); glBindTexture(GL_TEXTURE_2D, textures[i].id); glUniform1i(glGetUniformLocation(myshader.shaderProgram, ("material." + textures[i].samplerName).c_str()), i); } glUniform1f(glGetUniformLocation(myshader.shaderProgram, "material.shininess"), shininess); glBindVertexArray(VAO); glDrawElements(GL_TRIANGLES, indices.size(), GL_UNSIGNED_INT, 0); glBindVertexArray(0); } 先对每一张纹理激活纹理单元和设置对应的uniform采样器，再设置uniform镜面反射系数的值，最后再次绑定VAO调用glDrawElements函数就可以绘制出整个网格了。&nbsp; 模型加载类ModelLoader我们需要使用Assimp把模型文件加载到我们的程序里，再读出一些Assimp数据（比如顶点、索引、纹理等 ）传到Mesh里用以绘制（这里我们使用纳米铠甲的模型）。 加载模型文件要使用Assimp，除了编译链接好以外，还需要在我们的程序中包含以下头文件： //Assimp #include #include #include using namespace Assimp; 然后我们在自定义的LoadModel函数里使用Assimp的Importer对象的ReadFile函数，来把模型文件读取到场景对象中： const aiScene* scene; void LoadModel(string path) { //用Assimp加载模型文件到场景对象中 Importer importer; scene = importer.ReadFile(path, aiProcess_Triangulate | aiProcess_FlipUVs); if (!scene || !scene->mRootNode || scene->mFlags == AI_SCENE_FLAGS_INCOMPLETE) { cout < "Error:Assimp:" < importer.GetErrorString() < endl; return; } ... } mMeshes[i]]; meshes.push_back(ProcessMesh(aimesh)); } //递归遍历子节点 for (GLuint i = 0; i < node->mNumChildren; i++) { TraverseNode(node->mChildren[i]); } } 在每一个结点中存储的mesh，都只是场景对象scene包含的mesh的一个索引。所以需要使用形如scene-&gt;mMeshes[node-&gt;mMeshes[i]]的方式去scene中获得真正的mesh。 从aiMesh中提取数据转换为Mesh类对象函数ProcessMesh是我们的自定义函数，用于从Assimp加载的aiMesh里提取出顶点、索引、纹理等，转变为Mesh类对象。 先在ProcessMesh函数里定义我们的Mesh所需要的顶点、索引和纹理： //把Assimp的aiMesh转换为我们自定义的Mesh Mesh ProcessMesh(aiMesh* aimesh) { vector vertices; vector indices; vector textures; ... } 【注】： 这里的Vertex、Texture都是在Mesh类之前定义的结构体，所以需要先包含mesh.h：#include &quot;mesh.h&quot; 接下来我们取出aiMesh中所有顶点的位置、法线、纹理坐标等顶点属性，赋值给我们自定义的顶点结构体： //获取aiMesh中的所有顶点数据（包括顶点位置、法线向量、纹理坐标） for (GLuint i = 0; i < aimesh->mNumVertices; i++) { Vertex vertex; vertex.position = vec3(aimesh->mVertices[i].x, aimesh->mVertices[i].y, aimesh->mVertices[i].z); vertex.normal = vec3(aimesh->mNormals[i].x, aimesh->mNormals[i].y, aimesh->mNormals[i].z); if (aimesh->mTextureCoords[0]) { vertex.texCoords = vec2(aimesh->mTextureCoords[0][i].x, aimesh->mTextureCoords[0][i].y); } else { vertex.texCoords = vec2(0.0f, 0.0f); } vertices.push_back(vertex); } 【注】： Assimp允许一个模型的每个顶点有8个不同的纹理坐标，所以mTextureCoords是2维的，第一维指明是那组纹理坐标，第二维才指明是某组的哪一个纹理坐标。这里我们只关心顶点的第一组纹理坐标，所以第一维是0。 当然，每次循环完后，不要忘记把Vertex结构体变量添加到vertices里。 接着我们取出aiMesh中的所有顶点索引，这些顶点索引都保存在每一个面片中： //获取aiMesh中所有面片（这里就是三角形）的顶点索引 for (GLuint i = 0; i < aimesh->mNumFaces; i++) { aiFace aiface = aimesh->mFaces[i]; for (GLuint j = 0; j < aiface.mNumIndices; j++) { indices.push_back(aiface.mIndices[j]); } } 我们再来取出aiMesh的所有纹理，这些纹理都存储在材质中，所以需要先获取到材质： //获取aiMesh的材质的所有材质纹理 if (aimesh->mMaterialIndex >= 0) { aiMaterial* aimat = scene->mMaterials[aimesh->mMaterialIndex]; ... } 如果某个mesh没有材质，那么它的mMaterialIndex属性会小于0。 由于Mesh类里需要纹理加载和绑定后的ID，所以我们需要aiMesh的每一个纹理的存储路径。纹理的名称可以由aiMaterial对象的GetTexture函数得到： aiString str; //获取第i个漫反射纹理的名称 aimat->GetTexture(aiTextureType_DIFFUSE, i, &str); string texRelativePath = str.C_Str(); GetTexture函数的第一个参数是纹理类型，可以是漫反射纹理或者镜面纹理，第二个参数是第几个对应纹理，第三个参数用于存储纹理名称。注意第三个参数纹理名称是aiString类型的，需要使用C_Str函数转换为string类型。 只得到了纹理名称还不够，还应该有这个纹理所在的文件夹路径，这个我们可以用字符串自己指定。由于我们已经把纹理和模型文件nanosuit.obj放在同一个文件夹，而且在调用之前的LoadModel函数时，我们传入了模型文件的路径（LoadModel函数参数path），所以我们可以根据这个路径得到纹理所在的文件夹路径： string directory; directory = path.substr(0, path.find_last_of('/')); substr函数的第一个参数指明截取字符串的起始位置，第二个参数指明截取字符串的终止位置。 但是GetTexture的第二个参数该怎么指定呢？我们怎么知道有多少个漫反射纹理，i应该取为多少才不会越界。可以使用aiMaterial对象的GetTextureCount函数来获取材质中相应纹理的数量，它只有一个参数，指明是漫反射纹理还是镜面纹理： //获取aiMesh的材质的所有材质纹理 if (aimesh-&gt;mMaterialIndex &gt;= 0) { aiMaterial* aimat = scene-&gt;mMaterials[aimesh-&gt;mMaterialIndex]; //获取所有的漫反射纹理 for (GLuint i = 0; i &lt; aimat-&gt;GetTextureCount(aiTextureType_DIFFUSE); i++) { aiString str; //获取第i个漫反射纹理的名称 aimat-&gt;GetTexture(aiTextureType_DIFFUSE, i, &amp;str); string texName = str.C_Str(); //纹理名称 string texPath = directory + &#39;/&#39; + texName; //纹理路径 ... } } 纹理路径有了，接下来我们就可以用之前文章里的纹理加载类TextureLoader，来加载纹理了： //获取aiMesh的材质的所有材质纹理 if (aimesh->mMaterialIndex >= 0) { aiMaterial* aimat = scene->mMaterials[aimesh->mMaterialIndex]; //获取所有的漫反射纹理 for (GLuint i = 0; i < aimat->GetTextureCount(aiTextureType_DIFFUSE); i++) { aiString str; //获取第i个漫反射纹理的名称 aimat->GetTexture(aiTextureType_DIFFUSE, i, &str); string texName = str.C_Str(); //纹理名称 string texPath = directory + '/' + texName; //纹理路径 Texture texture; TextureLoader textureLoader; texture.id = textureLoader.LoadTexture(texPath.c_str()); texture.samplerName = "diffuse_texture" + IntToString(i); textures.push_back(texture); } } 加载后的纹理ID赋值给Texture结构体变量的id属性，同时我们给Texture结构体变量的samplerName 属性赋值，对应像素着色器中的纹理采样器名称。当然不要忘了把Texture结构体变量添加到textures中。【注】： 由于C++没有提供把字符转换为字符串的函数，所以我们自己写了一个IntToString函数来实现这个功能： //把int类型转换为string类型 string IntToString(int number) { ostringstream outs; outs < number; return outs.str(); } GetTexture(aiTextureType_SPECULAR, i, &str); string texName = str.C_Str(); //纹理名称 string texPath = directory + '/' + texName; //纹理路径 Texture texture; TextureLoader textureLoader; texture.id = textureLoader.LoadTexture(texPath.c_str()); texture.samplerName = "specular_texture" + IntToString(i); textures.push_back(texture); } 我们再指定一下mesh的镜面反射系数，用以计算镜面反射光： float shininess = 32; 最后，我们把这些顶点、索引、纹理和镜面反射系数，传递给Mesh类，Mesh类就会用它的构造函数，生成一个用于我们绘制的Mesh对象： return Mesh(vertices, indices, textures, shininess); 绘制每一个mesh万事俱备，只欠东风。在LoadModel类里，我们已经把所有aiMesh转换为可以绘制的Mesh对象了，最后要做的就是在LoadModel类里调用所有Mesh对象的Draw函数，我们把它写在LoadModel类的Draw函数里： void Draw(shader myshader) { for (GLuint i = 0; i < meshes.size(); i++) { meshes[i].Draw(myshader); } } &nbsp; 绘制模型绘制模型，只需要在主程序里定义LoadModel类对象，然后在渲染循环里调用它的Draw函数就可以了： Model mymodel("nanosuit/nanosuit.obj"); ... mymodel.Draw(lightObject); &nbsp; 重大优化之前对每一个mesh的所有材质纹理，我们都会使用TextureLoader类去加载绑定，这个加载纹理的过程是很费时的。由于不同的mesh，它们的纹理可能是相同的，所以很有可能会出现同一张纹理加载了好几次。这无疑是浪费，需要避免。 怎么判断要加载的纹理已经被加载过了呢？判断要加载的纹理路径是否和已加载的纹理的路径相同即可。所以，我们需要给Texture结构体添加一个属性texPath来标识纹理的路径： struct Texture { GLuint id; string samplerName; string texPath; }; 还需要设置一个Texture结构体数组，用来存储已经加载过的纹理： vector loadedTextures; //存储已经加载过的纹理 在加载纹理之前，我们先判断要加载的纹理路径是否有和已加载纹理的路径相同的： bool skip = false; //纹理是否已经加载过 for (int j = 0; j < loadedTextures.size(); j++) { if (texPath == loadedTextures[j].texPath) { skip = true; textures.push_back(loadedTextures[j]); break; } } 用bool变量skip来标识纹理是否已经加载过，如果要加载的纹理路径和已加载的某一纹理的路径相同，那么textures直接添加已加载的纹理即可，不用再去加载一次纹理，并且设置skip为真，标识纹理已经加载过，退出循环。 如果纹理没有被加载过，for循环里的内容就一直不会被执行，skip将为假，这时就需要去加载纹理了。加载完后不要忘了把纹理路径存储到Texture结构体变量中，并且把该结构体变量添加到已加载纹理数组loadedTextures中： if (!skip) { Texture texture; TextureLoader textureLoader; texture.id = textureLoader.LoadTexture(texPath.c_str()); texture.samplerName = "diffuse_texture" + IntToString(i); texture.texPath = texPath; textures.push_back(texture); loadedTextures.push_back(texture); } 对于镜面纹理，也是一样的优化处理，不再赘述。 所有源码到此，所有源码在这里 【注】： 主程序里去掉了对光源物体的绘制。 编译运行后的结果如下：&nbsp; 参考文献：LearnOpenGL]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>模型加载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL13：常见光源]]></title>
    <url>%2F2016%2F12%2F17%2FOpenGL13%E5%B8%B8%E8%A7%81%E5%85%89%E6%BA%90%2F</url>
    <content type="text"><![CDATA[几种常见的光源类型在前面的文章中，我们使用的其实都是一个点光源。现在我们将介绍几种常见的的光源类型： 定向光Directional Light：类似太阳光，每条光线平行，指向同一个方向 点光源Point Light：类似灯泡，向四周发光 聚光Spot Light：类似手电筒，只向某个方向照射 它们的图示如下：&nbsp; 定向光Directional Light定向光源类似于太阳，光源很远，每条光线接近于平行，所有光线都是同一个方向。定向光的方向和光源在哪个位置无关，因为无限远嘛。 由于定向光方向是一个固定值，所以在计算漫反射光时，就不需要用光源位置和片元位置来计算入射光线方向了，直接使用定向光方向这个固定值就可以（对所有片元来说入射光方向都是这个值）。我们先把定向光方向加入光源结构体里： //定向光源 struct Light{ vec3 direction; vec3 ambient; vec3 diffuse; vec3 specular; }; uniform Light light; //光源变量 对于定向光来说，就不需要定义光源位置了，因为定向光源是无限远的，而且也用不上。 当然，需要给这个定向光方向赋值： //设置定向光的方向 glUniform3f(glGetUniformLocation(lightObject.shaderProgram, "light.direction"), 1.0f, -1.0f, -1.0f); 在计算漫反射光时，入射光方向需要变一下，现在是定向光方向的反方向（因为入射光方向需要从片元到光源，而定向光方向是从光源到片元的）： vec3 lightDir=normalize(-light.direction); //光线入射方向的单位向量 为了清晰地看出定向光对所有物体都有相同的影响，我们还是画10个箱子出来： glBindVertexArray(lightObjectVAO); for (int i = 0; i < 10; i++) { mat4 lightObject_model; lightObject_model = translate(lightObject_model, cubeTranlate[i]); lightObject_model = rotate(lightObject_model, radians(105.0f), vec3(0.5f, 1.0f, 1.0f)); glUniformMatrix4fv(glGetUniformLocation(lightObject.shaderProgram, "model"), 1, GL_FALSE, value_ptr(lightObject_model)); glDrawElements(GL_TRIANGLES, 36, GL_UNSIGNED_INT, 0); } glBindVertexArray(0); 编译运行后的结果如下：在场景中移动摄像机，会感觉有一个太阳一样的光源照射在这些物体上。 下面是受光物体的像素着色器源码： #version 330 core //材质结构体 struct Material{ sampler2D diffuse; sampler2D specular; float shininess; }; //定向光源 struct Light{ //vec3 position; //定向光不再需要光源位置了，因为它是无限远的 vec3 direction; vec3 ambient; vec3 diffuse; vec3 specular; }; in vec3 Normal; in vec3 positionInWorld; in vec2 TexCoords; out vec4 color; uniform Material material; //材质变量 uniform Light light; //光源变量 uniform vec3 viewPos; //观察位置 void main(){ //计算最终的环境光 vec3 ambientColor=light.ambient * vec3(texture(material.diffuse,TexCoords)); //环境光 //计算最终的漫反射光 vec3 normal=normalize(Normal); //单位法向量 vec3 lightDir=normalize(-light.direction); //光线入射方向的单位向量 float diffuseFactor=max(dot(normal,lightDir),0.0); //漫反射系数（两个向量夹角的余弦） vec3 diffuseColor=diffuseFactor * light.diffuse * vec3(texture(material.diffuse,TexCoords)); //漫反射光 //计算最终的镜面反射光 vec3 reflectDir=normalize(reflect(-lightDir,normal)); //反射光方向 vec3 viewDir=normalize(viewPos-positionInWorld); //观察方向 float specularFactor=pow(max(dot(reflectDir,viewDir),0.0),material.shininess); //镜面反射系数 vec3 specularColor=specularFactor * light.specular * vec3(texture(material.specular,TexCoords)); //镜面反射光 color=vec4(ambientColor+diffuseColor+specularColor,1.0f); } &nbsp; 点光源Point Light点光源就是我们之前一直用的那种光源，它类似于一个灯泡在向四周发光。它需要用点光源位置和片元位置去计算入射光方向。 从前的点光源下面是点光源照射的一个例子：可以看到，离点光源越近的地方越亮，离得越远越暗。点光源的亮度随着距离增大应该是有一个衰减过程的。但是我们之前一直在用的点光源并没有考虑到这一点。下面的图片是我们用从前的点光源照射情况：可以看到离点光源（白色方块）越远的箱子并没有越暗。 点光源亮度衰减随着光线穿越距离的变远，亮度也随之降低的现象，通常称之为衰减。这种衰减不是线性的，它是开始的时候衰减得非常快，之后随着距离增加，减少的速度回慢下来。 其实衰减系数和$F_{att}$和$d$之间的关系如下：$$\begin{equation}F_{att} = \frac{1.0}{K_c + K_l * d + K_q * d^2}\end{equation}$$这里d表示片元到光源的距离，$K_c$表示常系数，值通常是1.0，它的作用是保证分母不会比1小，$K_l$是线性衰减系数，$K_q$是二次衰减系数。 下面的图展示了d在100以内的衰减趋势： 一些经验值上面公式的常系数、一次项系数、二次项系数应该取多少才有较好的效果呢？经过很多实验和经验总结，下表展示的各项值会有比较好的衰减效果：【注】： 上表中的距离d是我们想要点光源照射到的距离（球半径），比如第一行，当距离到达7的时候亮度几乎为0。 实现衰减的点光源下面我们在像素着色器中来计算这个衰减系数，实现点光源的衰减效果。 由于按公式计算衰减系数，我们需要常数项、一次项、二次项这三个系数，所以我们先把它们定义到点光源结构体中： //点光源结构体 struct Light{ vec3 position; vec3 ambient; vec3 diffuse; vec3 specular; float constant; //常数项 float linear; //一次项 float quadric; //二次项 }; uniform Light light; //光源变量 这里我们希望点光源覆盖50的距离，从表中找到对应的各项系数，在主程序中把它们赋值给点光源结构体的相应变量： //设置点光源衰减公式的常数项、一次项、二次项 glUniform1f(glGetUniformLocation(lightObject.shaderProgram, "light.constant"), 1.0f); glUniform1f(glGetUniformLocation(lightObject.shaderProgram, "light.linear"), 0.09f); glUniform1f(glGetUniformLocation(lightObject.shaderProgram, "light.quadric"), 0.032); 有了衰减公式中的这些系数，还需要片元到点光源的距离，我们就能在像素着色器中计算出衰减系数了。我们可以使用GLSL的内置函数length来计算片元到点光源的距离： float distance=length(light.position-positionInWorld); 然后使用距离和这些系数来计算衰减系数： float attenuation=1.0f/(light.constant+light.linear*distance+light.quadric*distance*distance); 最后，需要让点光源的每种成分光都执行这种衰减，即乘上衰减系数： //点光源的每种成分光都执行衰减 ambientColor*=attenuation; diffuseColor*=attenuation; specularColor*=attenuation; 编译运行后的结果如下：可以看到离点光源远的物体明显越来越暗了。 全部源码实现衰减的点光源的全部源码在这里。&nbsp; 聚光Spot Light 聚光计算原理聚光类似手电筒发出的光，只在一个指定的范围内发散，如下图所示：聚光灯可以由3个参数确定： SpotDir：聚光灯的灯轴方向，即图中的红线 LightPos：聚光灯的位置 Cutoff：聚光灯的张角，即图中的$\phi$ 我们要做的就是：判断片元是不是在聚光灯照射的范围内。比如图中圈出来的那个片元，聚光灯到该片元的方向是那条黑线，和红线灯轴的夹角（称为偏轴角）为$\theta$，如果$\theta \lt \phi$，则片元在聚光范围内，应该受到光照；否则，片元落在聚光范围外，将得不到光照。 实现聚光聚光灯可以由灯轴方向、灯位置、张角来确定，需要把它们添加到像素着色器的聚光灯结构体中： //聚光灯结构体 struct Light{ vec3 position; //聚光灯位置 vec3 lightAxis; //灯轴方向 float cutOff; //张角 float constant; //常数项 float linear; //一次项 float quadric; //二次项 vec3 ambient; vec3 diffuse; vec3 specular; }; uniform Light light; //光源变量 `` 聚光也有随着距离衰减的效果，所以我们保留了点光源的参数和相应计算。 接下来需要对新添加的这三个元素赋值：` ```c++ //设置聚光灯的位置、灯轴、张角 glUniform3f(glGetUniformLocation(lightObject.shaderProgram, "light.position"), mycamera.cameraPos.x, mycamera.cameraPos.y, mycamera.cameraPos.z); glUniform3f(glGetUniformLocation(lightObject.shaderProgram, "light.lightAxis"), mycamera.cameraToTarget.x, mycamera.cameraToTarget.y, mycamera.cameraToTarget.z); glUniform1f(glGetUniformLocation(lightObject.shaderProgram, "light.cutOff"), cos(radians(12.5f))); 因为在游戏中，很多时候聚光都用在主角身上，所以我们把聚光灯的位置设为了摄像机的位置，灯轴设为了摄像机照射的方向（从摄像机指向目标的向量），张角这里我们设为了12.5度的余弦值，因为后面用点乘计算出来的片元偏轴角是余弦值，所以我们这里张角也用余弦值，否则用acos转化为弧度的话计算代价是很高昂的。【注】： 在特殊需要下，聚光灯也可以在其他位置，其他朝向，可以自定义 有了聚光灯的这三个值，我们就可以在像素着色器中，计算片元的偏轴角了： //计算聚光灯下片元的偏轴角（余弦值） float theta=dot(normalize(positionInWorld-light.position),normalize(light.lightAxis)); 然后让片元的偏轴角$\theta$余弦值和聚光灯的张角$\phi$余弦值作比较，如果大于，则说明片元在聚光范围内，执行跟点光源一样的光照计算；否则该片元就显示黑色，表示没有受到光照： //计算聚光灯下片元的偏轴角（余弦值） float theta=dot(normalize(positionInWorld-light.position),normalize(light.lightAxis)); if(theta > light.cutOff){ //执行和点光源一样的光照计算 } else{ //片元在聚光范围外呈现黑色 color=vec4(0.0f,0.0f,0.0f,1.0f); } 编译运行后的结果如下：当然，片元超出聚光范围后不一定只能是黑色，也可以是其他颜色，看我们怎么设置了。如果片元超出聚光范围后，呈现环境光颜色： else{ //片元在聚光范围外时使用环境光，使其不至于完全黑暗 color=vec4(light.ambient*vec3(texture(material.diffuse,TexCoords)),1.0f); } 那么显示结果会是下面这样： 软化边缘上面的聚光灯看起来有点假，因为聚光边缘有个硬边。在像素着色器的逻辑中，片元一旦操作聚光范围，它就会理解黑下来，变成环境光，却没有任何平滑减弱的过度。真实的聚光在它的边界应该是慢慢向外减弱的。 为了实现聚光在边缘的平滑减弱，我们给聚光灯定义一个内张角$\phi$和外张角$\gamma$：内张角还是原来的张角，外张角比内张角稍大： //聚光灯结构体 struct Light{ vec3 position; //聚光灯位置 vec3 lightAxis; //灯轴方向 float inCutOff; //内张角 float outCutOff; //外张角 ... } glUniform1f(glGetUniformLocation(lightObject.shaderProgram, "light.inCutOff"), cos(radians(12.5f))); glUniform1f(glGetUniformLocation(lightObject.shaderProgram, "light.outCutOff"), cos(radians(17.5f))); 在内张角里的片元还是像上面一样，执行和点光源一样的光照计算；处在内张角和外张角之间的片元，亮度$I$在内张角余弦外张角余弦之间线性插值：$$\begin{equation}I = \frac{\theta - \gamma}{\phi - \gamma}\end{equation}$$如果片元在内张角里面，这个值会大于1，我们把它截断为1；如果片元在外张角外面，这个值会小于0，我们把它截断为0： //计算聚光灯下片元的偏轴角（余弦值） float theta=dot(normalize(positionInWorld-light.position),normalize(light.lightAxis)); //计算片元在聚光灯下的光强 float intensity=clamp((theta-light.outCutOff)/(light.inCutOff-light.outCutOff),0.0,1.0); 这样一来，乘以光照计算出来的颜色值后，在内张角里面的片元会正常执行光照，在外张角外面的片元会显示黑色，在内外张角之间的片元会插值变暗（不再需要if-else了，如果想要在外张角外显示其他颜色，那还是需要的）： //聚光的每种成分光都执行衰减和亮度插值 ambientColor*=attenuation*intensity; diffuseColor*=attenuation*intensity; specularColor*=attenuation*intensity; color=vec4(ambientColor+diffuseColor+specularColor,1.0f); 编译运行后的结果如下：使用聚光的全部源码在这里。&nbsp; 多个光源为了简介、提高代码重用率，我们把各种光源的计算分别写成一个函数：对定向光的计算写在CalcDirLight函数中，对点光源的计算写在CalcPointLight函数中，对聚光的计算写在CalcSpotLight函数中。这三个函数的代码和原来的几乎一样，只不过是拿出来放到了函数里而已。 当我们要使用多个光源时，就可以直接使用这几个光源函数了，一般都是下面这种使用结构： out vec4 color; #define NUM_POINT_LIGHTS 4 void main(){ //添加定向光计算结果到输出颜色里 vec3 result = CalcDirLight(); //添加点光源计算结果到输出颜色里 for(int i=0; i]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>常见光源</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL12：光照贴图Lighting Maps]]></title>
    <url>%2F2016%2F12%2F14%2FOpenGL12%E5%85%89%E7%85%A7%E8%B4%B4%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[为何需要光照贴图在上一篇文章《OpenGL11：材质》中，我们给整个立方体定义了一个材质，但是显示世界的物体往往不是同一种材料构成的，物体上的不同部分可能需要不同的材质。例如汽车的车身喷漆了往往很光亮，而轮胎的橡胶部分则比较暗淡。为了更好地模拟现实中物体接收光照的效果，我们应该为物体的不同部分指定不同的材质属性，而不是整个物体共用一个材质属性。 要让不同的部分对应不同的材质属性，如果不同材质的部分比较多，要精确定义很多材质是很麻烦的。其实为不同部分对应不同的材质属性，有点类似于不同的像素根据纹理坐标获取不同的纹素，这里我们我们的解决方案类似，也是使用一张纹理的纹素来作为物体上对应位置的材质属性（环境属性、漫反射属性、镜面反射属性，这些属性都是vec3类型的颜色）。对应光照下的材质属性的这种纹理叫做光照贴图lighting maps。我们这里主要介绍漫反射贴图diffuse map和镜面反射贴图specular maps（当然除此之外还有其他类型的光照贴图）。【注】： 材质的环境属性和漫反射属性通常都是相等的，都是一个颜色，所以就都使用漫反射贴图了，一般不再需要环境贴图了。&nbsp; 漫反射贴图diffuse map我们使用漫反射贴图的纹素颜色来代替材质的环境属性和漫反射属性。 首先，我们加载下面一张图片，它是一个由一圈钢边的木箱：需要用到《OpenGL5：纹理》一文中的纹理加载类，所以先创建和包含相应的头文件： #include "TextureLoader.h" 接着使用该类的LoadTexture函数加载木箱图片： TextureLoader textureLoader; GLuint diffuseMap = textureLoader.LoadTexture("container2.png"); 为了合理使用这张纹理，我们的顶点属性里面也应该加上纹理坐标属性： //立方体各面顶点的坐标、法线、纹理坐标 GLfloat vertices[] = { //位置坐标 //法线 //纹理坐标 //立方体前面 0.5f, 0.5f, 0.5f, 0, 0, 1, 1.0f, 1.0f, 0.5f,-0.5f, 0.5f, 0, 0, 1, 1.0f, 0.0f, -0.5f,-0.5f, 0.5f, 0, 0, 1, 0.0f, 0.0f, -0.5f, 0.5f, 0.5f, 0, 0, 1, 0.0f, 1.0f, //立方体后 0.5f, 0.5f,-0.5f, 0, 0,-1, 1.0f, 1.0f, 0.5f,-0.5f,-0.5f, 0, 0,-1, 1.0f, 0.0f, -0.5f,-0.5f,-0.5f, 0, 0,-1, 0.0f, 0.0f, -0.5f, 0.5f,-0.5f, 0, 0,-1, 0.0f, 1.0f, //立方体上面 0.5f, 0.5f, 0.5f, 0, 1, 0, 1.0f, 1.0f, 0.5f, 0.5f,-0.5f, 0, 1, 0, 1.0f, 0.0f, -0.5f, 0.5f,-0.5f, 0, 1, 0, 0.0f, 0.0f, -0.5f, 0.5f, 0.5f, 0, 1, 0, 0.0f, 1.0f, //立方体下面 0.5f,-0.5f, 0.5f, 0,-1, 0, 1.0f, 1.0f, 0.5f,-0.5f,-0.5f, 0,-1, 0, 1.0f, 0.0f, -0.5f,-0.5f,-0.5f, 0,-1, 0, 0.0f, 0.0f, -0.5f,-0.5f, 0.5f, 0,-1, 0, 0.0f, 1.0f, //立方体右面 0.5f, 0.5f, 0.5f, 1, 0, 0, 1.0f, 1.0f, 0.5f, 0.5f,-0.5f, 1, 0, 0, 1.0f, 0.0f, 0.5f,-0.5f,-0.5f, 1, 0, 0, 0.0f, 0.0f, 0.5f,-0.5f, 0.5f, 1, 0, 0, 0.0f, 1.0f, //立方体左面 -0.5f, 0.5f, 0.5f, -1, 0, 0, 1.0f, 1.0f, -0.5f, 0.5f,-0.5f, -1, 0, 0, 1.0f, 0.0f, -0.5f,-0.5f,-0.5f, -1, 0, 0, 0.0f, 0.0f, -0.5f,-0.5f, 0.5f, -1, 0, 0, 0.0f, 1.0f }; 当然，这下对顶点属性的解析也应该更新一下了： glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 8 * sizeof(GLfloat), (GLvoid*)0); glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, 8 * sizeof(GLfloat), (GLvoid*)(3 * sizeof(GLfloat))); glVertexAttribPointer(2, 2, GL_FLOAT, GL_FALSE, 8 * sizeof(GLfloat), (GLvoid*)(6 * sizeof(GLfloat))); glEnableVertexAttribArray(0); glEnableVertexAttribArray(1); glEnableVertexAttribArray(2); 还需要在受光物体的顶点着色器中增加输入变量，用来接收纹理坐标，还要把它输出到像素着色器： layout (location=2) in vec2 texCoords; //顶点纹理坐标属性的位置值为2 out vec2 TexCoords; void main(){ ... TexCoords=texCoords; } 像素着色器要设置一个输入变量，来接收来自顶点着色器的纹理坐标： in vec2 TexCoords; 既然是用纹素颜色来代替材质的环境属性和漫反射属性，那么： //材质结构体 struct Material{ sampler2D diffuse; vec3 specular; float shininess; }; 和读取纹素颜色一样，我们需要把diffuse设置为一个采样器，用于根据纹理坐标，从纹理中提取纹素颜色。材质的环境属性和漫反射属性通常是等值的，所以这里就省略环境属性的采样器了。 需要在主函数中，对这个采样器赋值： //设置材质的环境属性和漫反射属性（都来自漫反射贴图，这里设置的是采样器/纹理单元的值） glUniform1i(glGetUniformLocation(lightObject.shaderProgram, "material.diffuse"), 0); 接下来就是使用纹素颜色来更新环境光和漫反射光的计算了： //计算最终的环境光 vec3 ambientColor=light.ambient * vec3(texture(material.diffuse,TexCoords)); //环境光 //计算最终的漫反射光 vec3 normal=normalize(Normal); //单位法向量 vec3 lightDir=normalize(light.position-positionInWorld); //光线入射方向的单位向量 float diffuseFactor=max(dot(normal,lightDir),0.0); //漫反射系数（两个向量夹角的余弦） vec3 diffuseColor=diffuseFactor * light.diffuse * vec3(texture(material.diffuse,TexCoords)); //漫反射光 最后，需要激活相应纹理单元和绑定纹理，再进行渲染： //激活纹理单元 glActiveTexture(GL_TEXTURE0); glBindTexture(GL_TEXTURE_2D, diffuseMap); glBindVertexArray(lightObjectVAO); glDrawElements(GL_TRIANGLES, 36, GL_UNSIGNED_INT, 0); glBindVertexArray(0); 编译运行后的结果如下：&nbsp; 镜面贴图speculate map上面的物体是一个带钢边的木箱，木箱部分应该是没有高光的（或者高光很弱）才对。也就是说一个物体的不同部分可能有不同的镜面反射效果。和不同部分有不同漫反射效果类似，我们使用一张镜面贴图来表示对应不同部分的不同镜面反射效果，即用镜面贴图的纹素来代替材质的镜面反射属性。通常在镜面贴图中，镜面反射强度大的用接近白色的颜色表示，反射强度小的用接近黑色的颜色表示。使用ps或gimp之类的工具，通过将图片进行裁剪，将某部分调整成黑白图样，并调整亮度/对比度，可以很容易吧一个diffuse贴图处理成specular贴图。我们这里给准备上面的箱子使用的镜面贴图如下：木箱子部分不镜面反射，只有钢边部分才有镜面光。 使用这张镜面贴图的过程和上面漫反射贴图类似，简单走一下： 首先加载镜面贴图： GLuint specularMap = textureLoader.LoadTexture("container2_specular.png"); 然后在受光物体的像素着色器中，把材质的镜面属性改为采样器类型： //材质结构体 struct Material{ sampler2D diffuse; sampler2D specular; float shininess; }; 需要对specular采样器赋值： //设置材质的镜面反射属性（来自镜面贴图） glUniform1i(glGetUniformLocation(lightObject.shaderProgram, "material.specular"), 1); 在像素着色器中更新对镜面光的计算： vec3 specularColor=specularFactor * light.specular * vec3(texture(material.specular,TexCoords)); //镜面反射光 最后，在主程序渲染前激活相应纹理单元并绑定： //激活纹理单元0并绑定 glActiveTexture(GL_TEXTURE0); glBindTexture(GL_TEXTURE_2D, diffuseMap); //激活纹理单元1并绑定 glActiveTexture(GL_TEXTURE1); glBindTexture(GL_TEXTURE_2D, specularMap); glBindVertexArray(lightObjectVAO); glDrawElements(GL_TRIANGLES, 36, GL_UNSIGNED_INT, 0); glBindVertexArray(0); 编译运行后的结果如下：可以看到这个箱子明显真实多了！&nbsp; 使用漫反射光照贴图和镜面贴图的所有源码在这里。 其余代码不变，和《OpenGL10：光照基础Phong模型》一样。&nbsp; 参考文献：LearnOpenGL]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>光照贴图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL11材质]]></title>
    <url>%2F2016%2F12%2F12%2FOpenGL11%E6%9D%90%E8%B4%A8%2F</url>
    <content type="text"><![CDATA[材质概述在真实世界里，每个物体会对光产生不同的反应。钢看起来比陶瓷花瓶更闪闪发光，木头箱子肯定不会像钢箱子那样对光产生很强的反射。每个物体对镜面高光也有不同的反应。有些物体不会散射（scatter）很多光却会反射（reflect）很多光，结果看起来就有一个较小的高光点（highlight）；有些物体散射了很多，它们就会产生一个半径更大的高光（这其实就是镜面高光系数的体现）。如果我们想要模拟不同物体接受光照后的效果，就需要考虑物体的材质属性， 利用材质属性模拟出不同的效果。材质就是不同光属性组成的一个结构体。最终用材质颜色来代替《OpenGL10》中的物体本身颜色objectColor。&nbsp; 定义材质结构体在OpenGL10中，我们使用了冯氏光照模型来模拟复杂的光照，它有三种元素：环境光颜色、漫反射光颜色、镜面反射光颜色，我们这里再加上镜面高光系数，一起作为材质的属性，在像素着色器中组成材质结构体： //材质结构体 struct Material{ vec3 ambient; vec3 diffuse; vec3 specular; float shininess; }; 其中ambientColor材质属性定义了在环境光照下这个物体反射的是什么颜色，通常这个值和物体本身颜色相同；diffuseColor材质属性定义了在漫反射光照下物体的颜色；specularColor材质属性定义了在镜面光照下的反射颜色；shininess材质属性定义了镜面高光系数。 这些属性指定了物体在不同光照下的颜色效果，用这些颜色来代替物体本身的颜色。让物体在环境光、漫反射光、镜面光下有不同的颜色，不同的颜色组合，就有了不同的材质。 当然，要使用这个材质结构体，我们还要定义一个结构变量： uniform Material material; //材质变量 定义为uniform变量后，我们就可以在主程序中设置这个材质的各个属性值。&nbsp; 为材质赋值我们可以在主程序中为这个uniform变量material赋值，不过在glGetUniformLocation函数中，填写uniform变量名称时需要带上结构体变量名字作为前缀： //设置材质的环境属性 GLint matAmbientLoc = glGetUniformLocation(lightObject.shaderProgram, "material.ambient"); glUniform3f(matAmbientLoc, 1.0f, 0.5f, 0.31f); //设置材质的漫反射属性 GLint matDiffuseLoc = glGetUniformLocation(lightObject.shaderProgram, "material.diffuse"); glUniform3f(matDiffuseLoc, 1.0f, 0.5f, 0.31f); //设置材质的镜面反射属性 GLint matSpecularLoc = glGetUniformLocation(lightObject.shaderProgram, "material.specular"); glUniform3f(matSpecularLoc, 0.5f, 0.5f, 0.5f); //设置材质的镜面高光系数属性 GLint matShininessLoc = glGetUniformLocation(lightObject.shaderProgram, "material.shininess"); glUniform1f(matShininessLoc, 32.0f); 这里我们把ambient和diffuse属性都设置为我们想要让物体所呈现的颜色（物体本身颜色是珊瑚红，这里也设置为珊瑚红）；由于我们不希望specular镜面反射属性对这个物体产生过于强烈的影响，所以设置成了（0.5f,0.5f,0.5f）；把镜面高光系数shininess依旧设置为32。&nbsp; 更新三光的计算方式我们已经使用材质颜色来代替物体本身颜色了，所以我们需要更新环境光、漫反射光、镜面光的计算方式。 对于环境光，我们使用材质的环境光属性乘上光源颜色，就是片元最终的环境光颜色了： //计算最终的环境光 vec3 ambientColor=lightColor*material.ambient; //环境光 对于漫反射光，我们依旧需要先计算出漫反射系数，漫反射系数、光源颜色和材质的漫反射属性的乘积，就是最终的漫反射光颜色： //计算最终的漫反射光 vec3 normal=normalize(Normal); //单位法向量 vec3 lightDir=normalize(lightPos-positionInWorld); //光线入射方向的单位向量 float diffuseFactor=max(dot(normal,lightDir),0.0); //漫反射系数（两个向量夹角的余弦） vec3 diffuseColor=diffuseFactor*lightColor*material.diffuse; //漫反射光 对于镜面光，依旧需要先计算出镜面反射系数，镜面反射系数、光源颜色和材质的镜面反射属性的乘积，就是最终的镜面反射光颜色： //计算最终的镜面反射光 vec3 reflectDir=normalize(reflect(-lightDir,normal)); //反射光方向 vec3 viewDir=normalize(viewPos-positionInWorld); //观察方向 float specularFactor=pow(max(dot(reflectDir,viewDir),0.0),material.shininess); //镜面反射系数 vec3 specularColor=specularFactor*lightColor*material.diffuse; //镜面反射光 编译运行后的结果如下：有点太亮了~~~&nbsp; 分解光源颜色上面的物体太亮了。主要是因为物体的环境属性、漫反射属性、镜面反射属性都是直接乘以光源颜色，但是我们的这个光源是环境光、漫反射光和镜面光组合在一起的，应该是环境光只对材质的环境属性起作用，不应该对材质的漫反射属性起作用。光源的成分和材质的属性应该是一一对应的。 所以，直接乘以光源颜色是不对的，会造成物体太亮。我们应该把光源颜色分解为环境光颜色、漫反射光颜色和镜面反射光颜色。和材质一样，我们也使用结构体来实现： //光源 struct Light{ vec3 position; vec3 ambient; vec3 diffuse; vec3 specular; }; 当然，同样需要定义一个光源结构体变量： uniform Light light; //光源变量 接下里需要为光源结构体的这几个属性赋值了： //设置光源的位置 GLint lightPosLoc = glGetUniformLocation(lightObject.shaderProgram, "light.position"); glUniform3f(lightPosLoc, lightPos.x, lightPos.y, lightPos.z); //设置光源的环境光成分 GLint lightAmbientLoc = glGetUniformLocation(lightObject.shaderProgram, "light.ambient"); glUniform3f(lightAmbientLoc, 0.2f, 0.2f, 0.2f); //设置光源的漫反射光成分 GLint lightDiffuseLoc = glGetUniformLocation(lightObject.shaderProgram, "light.diffuse"); glUniform3f(lightDiffuseLoc, 0.5f, 0.5f, 0.5f); //设置光源的镜面反射光成分 GLint lightSpecularLoc = glGetUniformLocation(lightObject.shaderProgram, "light.specular"); glUniform3f(lightSpecularLoc, 1.0f, 1.0f, 1.0f); 环境光ambient通常设置为一个比较低的亮度，因为我们不希望环境色太过显眼；漫反射光是我们想要的光源颜色，通常是白色，这里我们把这个光调暗一点，看起来会更自然，设置为（0.5,0.5,0.5）；镜面反射光颜色通常被设置为（1.0f,1.0f,1.0f）的全强度发光。 最后我们需要再次更新三光的计算方式，把原来的光源颜色替换成对应的光源分量： void main(){ //计算最终的环境光 vec3 ambientColor=light.ambient*material.ambient; //环境光 //计算最终的漫反射光 vec3 normal=normalize(Normal); //单位法向量 vec3 lightDir=normalize(light.position-positionInWorld); //光线入射方向的单位向量 float diffuseFactor=max(dot(normal,lightDir),0.0); //漫反射系数（两个向量夹角的余弦） vec3 diffuseColor=diffuseFactor*light.diffuse*material.diffuse; //漫反射光 //计算最终的镜面反射光 vec3 reflectDir=normalize(reflect(-lightDir,normal)); //反射光方向 vec3 viewDir=normalize(viewPos-positionInWorld); //观察方向 float specularFactor=pow(max(dot(reflectDir,viewDir),0.0),material.shininess); //镜面反射系数 vec3 specularColor=specularFactor*light.specular*material.specular; //镜面反射光 color=vec4(ambientColor+diffuseColor+specularColor,1.0f); } 编译运行后的结果如下：&nbsp; 不同的光源颜色上面我们给光源的各个成分赋了一个固定的颜色，现在我们把颜色变一变，让它随着时间不停变换。由于镜面反射光通常都设为白色（1.0f,1.0f,1.0f），所以我们这里只改变环境光和漫反射光： //随着时间变化的环境光 vec3 ambientColor(0.2f, 0.2f, 0.2f); ambientColor *= vec3(sin(glfwGetTime()* 2), sin(glfwGetTime()*0.7), sin(glfwGetTime()*1.3)); //随着时间变化的漫反射光 vec3 diffuseColor(0.5f, 0.5f, 0.5f); diffuseColor *= ambientColor; //设置光源的环境光成分 GLint lightAmbientLoc = glGetUniformLocation(lightObject.shaderProgram, "light.ambient"); glUniform3f(lightAmbientLoc, ambientColor.x, ambientColor.y, ambientColor.z); //设置光源的漫反射光成分 GLint lightDiffuseLoc = glGetUniformLocation(lightObject.shaderProgram, "light.diffuse"); glUniform3f(lightDiffuseLoc, diffuseColor.x, diffuseColor.y, diffuseColor.z); //设置光源的镜面反射光成分 GLint lightSpecularLoc = glGetUniformLocation(lightObject.shaderProgram, "light.specular"); glUniform3f(lightSpecularLoc, 1.0f, 1.0f, 1.0f); 注意这里环境光和漫反射光的三个颜色分量随时间变换的快慢应该不要一致，上面是分别给glfwGetTime函数乘以了2、0.7、1.3。如果不这样做的话，三个颜色分量步调就会一直，只能看到原有的颜色变暗了，没有明显的颜色跨度。&nbsp; 到此，所有源码在这里。 编译运行后的结果类似如下： &nbsp; 参考文献：LearnOpenGL]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>材质</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL10：光照基础Phong模型]]></title>
    <url>%2F2016%2F12%2F12%2FOpenGL10%E5%85%89%E7%85%A7%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[要模拟现实的光照是很困难的，例如实际光照中，一束光可以经过场景中若干物体反射后，照射到目标物体上，也可以是直接照射到目标物体上。其中经过其他物体反射后再次照射到目标物体上，这是一个递归的过程，将会无比复杂。因此实际模拟光照过程中，总是采用近似模型去接近实现光照。&nbsp; Phong模型冯氏光照模型（Phong Lighting Model）就是其中很经典的一个光照模型，它由三部分光照组成：环境光+漫反射光+镜面光。如下图所示： 环境光（ambient lighting）：环境光是场景中光源给定或者全局给定的一个光照常量，它一般很小，主要是为了模拟即使场景中没有光照时，也不是全黑的效果。场景中总有一点环境光，不至于使场景全部黑暗。例如远处的月亮、来自远处的光。 漫反射光：模拟一个发光物对另一个物体的方向性影响。比如面向光源的一面会比其他面更亮。它是Phong模型最显著的组成部分。 镜面光：模拟的是物体表面光滑时反射的高亮的光，效果就是光泽物体表面上出现的两点。镜面光反应的通常是光的颜色，而不是物体的颜色。&nbsp; 环境光Ambient Lighting一个物体受到的光照可能是光源直射的，也可能是经过物体反射过来的，总之环境光来源有很多。如果我们同时考虑直射光线和非直射光线，这种情况下的算法叫做全局光照算法。可想而知，这种算法肯定是及其复杂而且昂贵的。 这里我们使用一种简化的的全局照明模型来表示环境光：将环境光颜色设定为一个恒定值，加到片元的最终颜色里。 实现起来很简单，用恒定环境光的颜色乘以一个很小的环境因子常量，再乘以受光物体本身的颜色，就是最终在环境光影响下的物体片元颜色： #version 330 core out vec4 color; uniform vec3 lightColor; uniform vec3 objectColor; void main(){ //环境因子 float ambientStrength=0.3f; //环境光 vec3 ambientColor=ambientStrength*lightColor; color=vec4(ambientColor*objectColor,1.0f); } 其余程序不变，编译运行后的结果如下：可以看到冯氏光照的环境光已经应用到受光物体上了，这个物体变得暗了一下，因为环境光弱了嘛！&nbsp; 漫反射光Diffuse Lighting从文首的环境光照图可以看到，环境光本身不提供明显的光照效果，但是漫反射光会对物体产生显著的视觉影响。漫反射光使物体上与光线排布越近的片段越能从光源处获得更多的亮度。漫反射光强度与光线入射方向和物体表面的法向量之间的夹角$\theta$有关。当$\theta =0$时，光线垂直照射物体表面，这时获得的光照强度最大；当$\theta =90$时，光线与物体表面平行，此时光线照射不到物体，物体获得的光照强度最小；当$\theta &gt;90$后，物体表面转到转到光线背面了，此时物体表面接受不到光照。 所以，我们可以用光线入射方向的单位向量和单位法向量的点乘，来表示光对片元颜色的影响程度。其实也就是用两个向量之间的夹角余弦值，因为两个向量都需要标准化，取的是单位向量。 添加法向量法向量是垂直于顶点表面的（单位）向量。由于顶点自身并没有表面（它只是空间中一个独立的点），所以我们利用顶点周围的顶点来计算出这个顶点的表面。我们可以使用叉乘来为立方体所有顶点计算出发现。但是由于3D立方体不是一个复杂的形状，所以我们可以简单的把法线数据手工添加到顶点数据中： //立方体各面顶点的坐标、法线 GLfloat vertices[] = { //位置坐标 //法线 //立方体前面 0.5f, 0.5f, 0.5f, 0, 0, 1, 0.5f,-0.5f, 0.5f, 0, 0, 1, -0.5f,-0.5f, 0.5f, 0, 0, 1, -0.5f, 0.5f, 0.5f, 0, 0, 1, //立方体后 0.5f, 0.5f,-0.5f, 0, 0,-1, 0.5f,-0.5f,-0.5f, 0, 0,-1, -0.5f,-0.5f,-0.5f, 0, 0,-1, -0.5f, 0.5f,-0.5f, 0, 0,-1, //立方体上面 0.5f, 0.5f, 0.5f, 0, 1, 0, 0.5f, 0.5f,-0.5f, 0, 1, 0, -0.5f, 0.5f,-0.5f, 0, 1, 0, -0.5f, 0.5f, 0.5f, 0, 1, 0, //立方体下面 0.5f,-0.5f, 0.5f, 0,-1, 0, 0.5f,-0.5f,-0.5f, 0,-1, 0, -0.5f,-0.5f,-0.5f, 0,-1, 0, -0.5f,-0.5f, 0.5f, 0,-1, 0, //立方体右面 0.5f, 0.5f, 0.5f, 1, 0, 0, 0.5f, 0.5f,-0.5f, 1, 0, 0, 0.5f,-0.5f,-0.5f, 1, 0, 0, 0.5f,-0.5f, 0.5f, 1, 0, 0, //立方体左面 -0.5f, 0.5f, 0.5f, -1, 0, 0, -0.5f, 0.5f,-0.5f, -1, 0, 0, -0.5f,-0.5f,-0.5f, -1, 0, 0, -0.5f,-0.5f, 0.5f, -1, 0, 0 }; 我们要把法线数据传递给顶点着色器，所以顶点着色器要增加一个法线属性： //顶点着色器 #version 330 core layout (location=0) in vec3 position; //顶点位置属性的位置值为0 layout (location=1) in vec3 normal; //顶点法线属性的位置值为1 ... 当然，顶点数据变了，对顶点数据的解析也应该做出调整。由于光源颜色不受影响，所以法线数据对它无用，在光源的VAO中不必解析法线数据，只是把顶点位置属性解析的步长变为6个GLfloat就行： glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 6 * sizeof(GLfloat), (GLvoid*)0); 对于受光物体，除此之外还需要解析法线数据： glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 6 * sizeof(GLfloat), (GLvoid*)0); glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, 6 * sizeof(GLfloat), (GLvoid*)(3 * sizeof(GLfloat))); 顶点着色器接收并调整法线数据在顶点着色器中需要增加法线输入变量和法线输出变量（传递给像素着色器）： layout (location=1) in vec3 normal; //顶点法线属性的位置值为1 out vec3 Normal; 传进顶点着色器的法线数据是在主程序顶点数据中定义的，它们是局部坐标（模型坐标），但是我们的片元到光源的方向向量却是世界坐标，所以我们需要在顶点着色器中将输入的法线向量转化为世界坐标。 但是却不是简单的用模型矩阵乘以法线向量就可以，如Normal=model*normal;，因为当模型矩阵执行了不等比缩放时，法向量就不一定垂直于表面了，如下图所示：为了修复这个问题，我们需要先把模型矩阵求逆矩阵，再转置，取左上角三行三列的矩阵部分，来和法向量相乘： Normal=mat3(transpose(inverse(model)))*normal; 顶点着色器的全部源码见后面。 在像素着色器中计算漫反射光现在每个顶点有了正确的法向量，但是我们还需要从片元指向光源的向量，所以还需要光源的位置坐标和顶点的世界坐标。 光源的位置坐标可以从主程序用uniform变量传到像素着色器：在像素着色器中定义光源位置uniform变量： uniform vec3 lightPos; //光源位置 然后在主程序中给该uniform变量赋值： //设置uniform变量光源位置lightPos GLint lightPosLoc = glGetUniformLocation(lightObject.shaderProgram, "lightPos"); glUniform3f(lightPosLoc, lightPos.x, lightPos.y, lightPos.z); 我们还需要顶点的世界坐标，可以在顶点着色器中让输入的顶点坐标乘以模型矩阵，就变成了顶点的世界坐标了，把结果输出到像素着色器就可以了。 现在顶点着色器中定义输出变量，用于把顶点的世界坐标传递给像素着色器： out vec3 positionInWorld; 然后在顶点着色器的main函数中，计算出顶点的世界坐标： positionInWorld=vec3(model*vec4(position,1.0f)); 当然还需要在像素着色器中定义一个同名输入变量，来接收顶点的世界坐标： in vec3 positionInWorld; 在像素着色器中已经有了光源世界坐标、顶点世界坐标，我们可以用它们来计算从片元到光源的单位方向向量： vec3 lightDir=normalize(lightPos-positionInWorld); //光线入射方向的单位向量 当然，法向量也需要标准化，变成单位向量，再用法向量刚才的光线入射方向的单位向量点乘，就可以得到漫反射光的强度（就是两个向量夹角的余弦）： //计算漫反射光 vec3 normal=normalize(Normal); //单位法向量 float diffuseFactor=max(dot(normal,lightDir),0.0); //漫反射光系数（两个向量夹角的余弦） 用漫反射光强度乘以光源颜色，就能得到漫反射光颜色了。再加上之前的环境光后，乘以片元本身的颜色，就能得到最终的片元颜色了： color=vec4((ambientColor+diffuseColor)*objectColor,1.0f); 到此，Phong模型中的环境光和漫反射光都搞定了。所有源码在这里。 &nbsp; 镜面反射光Specular Lighting和环境光一样，镜面反射光也要依据光的入射向量和法向量，但是镜面光还会依据观察方向，例如玩家是从什么方向看着这个片元的： 当镜面反射光和观察方向夹角$\theta$越小时，人眼观察到的镜面光成分越明显。镜面反射系数定义为：$specFactor=\cos (\theta)^s$。其中s是镜面高光系数 ，它的值一般为2的整数幂，值越大高光部分越集中。下图是不同高光系数下的高光效果： 求反射光线的方向向量为了计算出夹角$\theta$，我们需要先求出反射光线方向。可以使用reflect函数求出： vec3 reflectDir=normalize(reflect(-lightDir,normal)); //反射光方向 该函数的第一个参数是从光源到片元的光线入射方向，所以需要把lightDir取反，因为之前求漫反射光的时候它是从片元指向光源的；第二个参数是法向量。当然求得的反射关系方向也需要标准化。 计算观察方向然后我们需要求出观察方向，我们这里在像素着色器中设置一个uniform变量来表示观察位置： uniform vec3 viewPos; //观察位置 然后在主程序中把摄像机的位置赋值给该uniform变量： //设置uniform变量观察位置viewPos GLint viewPosLoc = glGetUniformLocation(lightObject.shaderProgram, "viewPos"); glUniform3f(viewPosLoc, mycamera.cameraPos.x, mycamera.cameraPos.y, mycamera.cameraPos.z); 我们再用观察位置减去顶点的世界坐标，就能得到观察方向了： vec3 viewDir=normalize(viewPos-positionInWorld); //观察方 计算镜面反射系数有了观察方向和反射光方向，我们就可以用向量点乘求出夹角$\theta$了，从而求出镜面反射系数： float specularFactor=pow(max(dot(reflectDir,viewDir),0.0),32); //镜面反射系数 这里为了不让镜面成分过于显眼，我们把镜面高光系数设置为32。 接下来我们还需要设置一个镜面反射强度，我们给镜面高光一个中等亮度颜色，设为0.5： float specularStrength=0.5f; //镜面反射强度 用这个镜面反射强度乘以镜面高光系数再乘以光源颜色，就能得到镜面反射光颜色了： vec3 specularColor=specularStrength*specularFactor*lightColor; //镜面反射光 加入镜面反射光最后，我们需要加上Phong模型的最后一个成分：镜面反射光： color=vec4((ambientColor+diffuseColor+specularColor)*objectColor,1.0f); 环境光、漫反射光和镜面反射光的和构成了最终的光照颜色，再乘上物体本身的颜色，就是受光物体最终的输出颜色了。&nbsp; 到此，我们为Phong光照模型计算了全部光照元素。全部源码在这里。 编译运行后的结果如下：&nbsp; per-vertex和per-fragment实现光照的对比我们上面的光照计算是在像素着色器中进行的，这种是基于片元计算的，称为Phong Shading（冯氏光照）。但是早期的光照着色器，开发者是在顶点着色器中实现这些光照的，这是基于顶点计算的，称为Gouraud Shading。因为顶点相比片元来说，顶点要少得多，光照的计算频率会更低，所以会更高效。然而，如果在顶点着色器中计算冯氏光照，那么除了顶点以外的其他片元，都只是根据顶点颜色插值得到自己的颜色，这种插值后的光照显得不是很真实，没有冯氏关照的那种平滑的光照效果：基于顶点这是的Gouraud Shading想要获得更平滑的效果，就得使用更多的顶点来加以完善，下面的图分别显示了少量顶点和大量顶点的基于顶点的关照计算效果：&nbsp; 参考文献：LearnOpenGL]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>冯氏光照</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL9：光照场景]]></title>
    <url>%2F2016%2F12%2F10%2FOpenGL9%E5%85%89%E7%85%A7%E5%9C%BA%E6%99%AF%2F</url>
    <content type="text"><![CDATA[我们先来看看物体颜色颜色是怎么形成的。&nbsp; 光照颜色和物体颜色计算机中的颜色主要是由三基色（RGB）来表示的，用有限种颜色来模拟现实世界中（无限）的颜色，因为现实世界中能被人眼区分的颜色只有有限种，差别太小的颜色人眼是看不出来的。如果想了解屏幕颜色是如何形成的，可以参考《》 OpenGL中颜色用一个vec3向量来表示： vec3 ourColor(1.0f,0.5f,0.31f); 在光学物理中，我们知道：我们看到的物体的颜色，其实是物体自身颜色和光源颜色相互作用（或者说相乘）的结果。比如物体本身是绿色，如果用白光去照它，那么物体会反射绿光，吸收其他色光，所以我们看到的物体颜色就是绿色；但是如果物体颜色是绿色，用红光去照它，那么物体就会把红色光全部吸收，没有反射光，所以我们看到的物体颜色就是黑色。 所以，物体颜色可以定义为这个物体从一个光源反射各个颜色分量的多少。 比如光源颜色是深橄榄绿色，物体颜色是珊瑚红，那么最后被人眼看到的物体颜色是： vec3 lightColor(0.33f, 0.42f, 0.18f); //深橄榄绿色 vec3 objectColor(1.0f, 0.5f, 0.31f); //珊瑚红 vec3 result = lightColor * toyColor; // = (0.33f, 0.21f, 0.06f); &nbsp; 下面我们来创建一个最基本的光照场景。 创建一个光照场景我们需要在场景中创建一个光源，设置为白色；还需要一个受光物体（被光源照射的物体）。光源和受光物体我们都用前面文章里的立方体来表示。 我们这里立方体的顶点数据只有顶点坐标，暂时不要颜色和纹理坐标属性了。顶点数据见后面的完整代码。 由于后面的文章里，我们还需要继续使用这个光照场景，后面会频繁地对物体顶点数据做一些改变，但是我们并不想因此影响到灯，所以我们光源和受光物体应该当做两个不同的立方体来绘制，不像前面文章里的10个物体都可以绑定一个VAO来绘制。我们这里给光源和受光物体分别创建一个VAO： //光源VAO GLuint lightSourceVAO, VBO, EBO; glGenVertexArrays(1, &lightSourceVAO); glGenBuffers(1, &VBO); glGenBuffers(1, &EBO); glBindVertexArray(lightSourceVAO); glBindBuffer(GL_ARRAY_BUFFER, VBO); glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, EBO); glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW); glBufferData(GL_ELEMENT_ARRAY_BUFFER, sizeof(indices), indices, GL_STATIC_DRAW); glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(GLfloat), (GLvoid*)0); glEnableVertexAttribArray(0); glBindVertexArray(0); //受光物体VAO GLuint lightObjectVAO; glGenVertexArrays(1, &lightObjectVAO); glBindVertexArray(lightObjectVAO); glBindBuffer(GL_ARRAY_BUFFER, VBO); glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, EBO); glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(GLfloat), (GLvoid*)0); glEnableVertexAttribArray(0); glBindVertexArray(0); 由于受光立方体的顶点数据和此时光源立方体的顶点数据相同，所以在受光物体的VAO中可以直接使用光源立方体的VBO和EBO，直接绑定即可，不用再使用glBufferData函数把数据发送到显存。 接下里我们需要给光源和受光物体分别设置顶点着色器和像素着色器（因为这是两个渲染效果不同的物体，不能使用同一套着色器）：光源的顶点着色器和受光物体的顶点着色器都是如下： //顶点着色器 #version 330 core layout (location=0) in vec3 position; //顶点位置变量的属性位置值为0 //模型矩阵 uniform mat4 model; //观察矩阵 uniform mat4 view; //投影矩阵 uniform mat4 projection; void main(){ gl_Position=projection * view * model * vec4(position,1.0f); } 光源的像素着色器代码如下（光源颜色始终是白色）： #version 330 core out vec4 color; void main(){ color=vec4(1.0f,1.0f,1.0f,1.0f); } 受光物体的像素着色器代码如下： #version 330 core out vec4 color; uniform vec3 lightColor; uniform vec3 objectColor; void main(){ color=vec4(lightColor*objectColor,1.0f); } 受光物体的像素着色器里有两个uniform变量，用于从主程序里接收光源颜色和物体本身颜色，输出颜色是这两个颜色的乘积。 在主程序里，我们给这两个uniform变量赋值： GLint lightColorLoc = glGetUniformLocation(lightObject.shaderProgram, "lightColor"); GLint objectColorLoc = glGetUniformLocation(lightObject.shaderProgram, "objectColor"); glUniform3f(lightColorLoc, 1.0f, 1.0f, 1.0f); glUniform3f(objectColorLoc, 1.0f, 0.5f, 0.31f); 上面lightObject是受光物体的着色器类对象。 我们还需要把这两个物体放在不同位置上。对于光源我们先给它设置一个全局变量，表示光源位置： //光源位置 vec3 lightPos(1.0f, 0.0f, -3.0f); 接着在模型矩阵中设置光源所处的位置，旋转角度和缩放系数： //模型矩阵 mat4 lightSource_model; lightSource_model = translate(lightSource_model, lightPos); lightSource_model = rotate(lightSource_model, radians(15.0f), vec3(0.5f, 1.0f, 1.0f)); lightSource_model = scale(lightSource_model, vec3(0.5f)); 当然，受光物体的模型矩阵也需要做一些类似变换： mat4 lightObject_model; lightObject_model = translate(lightObject_model, vec3(-1, 0, 0)); 接下来就是需要给两个物体设置观察矩阵和投影矩阵了，它俩在同一场景里，观察矩阵和投影矩阵应该是一样的： //观察矩阵 mat4 view = mycamera.GetViewMatrix(); //投影矩阵 mat4 projection = perspective(radians(mycamera.cameraFov), (GLfloat)WIDTH / (GLfloat)HEIGHT, 0.1f, 100.0f); 当然，不要忘了把模型、观察、投影矩阵赋值给相应的uniform变量（两个物体的像素着色器里都有这些uniform变量，都需要赋值）。 最后就是渲染出光源物体和受光物体了，需要分别绑定各自的VAO：光源的绑定和渲染： //绑定VAO，完成顶点输入初始化 glBindVertexArray(lightSourceVAO); //绘图 glDrawElements(GL_TRIANGLES, 36, GL_UNSIGNED_INT, 0); //解绑VAO glBindVertexArray(0); 受光物体的绑定和渲染： glBindVertexArray(lightObjectVAO); glDrawElements(GL_TRIANGLES, 36, GL_UNSIGNED_INT, 0); glBindVertexArray(0); 注意，它俩需要分别在各自的program.use激活着色器程序对象之后。&nbsp; 到此，我们就构建完这个最基本的光照场景了。全部源码在这里。 编译运行后，结果如下：&nbsp; 参考文献：LearnOpenGL]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>光照场景</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL8：摄像机]]></title>
    <url>%2F2016%2F12%2F08%2FOpenGL8%E6%91%84%E5%83%8F%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[OpenGL本身没有摄像机的概念，是我们虚构的，我们通过把场景往反方向移动的方式来模拟出摄像机，产生一种我们在移动的感觉。&nbsp; 摄像机坐标系（观察坐标系）摄像机默认位置是在世界空间原点，通过观察矩阵把所有的世界坐标转化为相对于摄像机位置与方向的观察坐标。但是通过观察矩阵，摄像机不一定要在原点，也是可以移动的，这就有了我们在游戏中用键盘鼠标手柄等移动视角的效果。 观察矩阵就是把世界坐标系通过矩阵变换转化为观察坐标系。那么观察坐标系是怎么构成的呢？ 观察坐标系的组成需要有4个要素构成： 摄像机的世界坐标，用来作为观察坐标系的原点，对应下面第一幅图中的摄像机位置。 //摄像机位置 vec3 cameraPos = vec3(0.0, 0.0, 3.0f); 观察坐标系的+z轴。通常用摄像机照射的目标位置到指向摄像机位置的向量来表示，对应下面第二幅图中的蓝色轴。 //摄像机目标位置 vec3 cameraTarget = vec3(0.0f, 0.0f, 0.0f); //摄像机+z轴（从目标位置指向摄像机） vec3 targetToCamera = normalize(cameraPos - cameraTarget); 观察坐标系的+x轴。需要先有一个上向量，指明摄像机的正上方。再用上向量和+z轴做叉乘，得到+x轴，对应下面第三幅图（灰色的是上向量，红色的是+x轴）： //摄像机上向量 vec3 upVector = vec3(0.0f, 1.0f, 0.0f); //摄像机+x轴（上向量和+z轴的叉乘） vec3 cameraRight = normalize(cross(upVector, targetToCamera)); 观察坐标系的+y轴。由+z轴和+x轴做叉乘得到，对应下面第四幅图中的绿色轴： //摄像机+y轴（+z轴和+x轴的叉乘） vec3 cameraUp = normalize(cross(targetToCamera, cameraRight)); 有了原点、x、y、z轴，我们就可以构建摄像机坐标系（观察坐标系）了。&nbsp; 世界坐标系转化到观察坐标系怎么把世界坐标系转到到观察坐标系呢？先上一个线性代数中的定理（证明可参考相关线性代数教材）： 线性变换可以通过基及变换后的基唯一确定，且通过计算线性变换后基的值可以得到线性变换对应的矩阵A。 直接计算变换矩阵在上面已经得到，在世界空间中，观察坐标系的原点：$（P_x，P_y，P_z）$，x基向量（+x轴）：$（X_x，X_y，X_z）$，y基向量（+y轴）：$（Y_x，Y_y，Y_z）$，z基向量（+z轴）：$（Z_x，Z_y，Z_z）$。上诉得到的是世界坐标系下的观察坐标系，由于都是右手坐标系，所以可以由线性变换得到。由定理可知，线性变换矩阵为：$$[Camera]_{world}=\begin{pmatrix}X_x &amp; Y_x &amp; Z_x &amp; P_x\\\\X_y &amp; Y_y &amp; Z_y &amp; P_y \\\\X_z &amp; Y_z &amp; Z_z &amp; P_z \\\\0 &amp; 0 &amp; 0 &amp; 1\end{pmatrix}$$但是，上面得到的是世界坐标系下的观察坐标系，但我们要的是观察坐标系下的世界坐标系，所以观察矩阵应该是上述矩阵的逆矩阵：$$view=[World]_{camera}=[Camera]_{world}^{-1}$$这个矩阵代表了观察坐标系的世界坐标系，再乘以点P在世界坐标系下的位置向量，就可以得到该点在观察坐标下的位置向量。 由旋转平移得到变换矩阵由于世界坐标系和观察坐标系都是右手坐标系，所以世界坐标系可以通过直接旋转（线性变换）、平移（仿射变换）到观察坐标系。先由世界坐标系在原点旋转，再平移过去，和观察坐标系重合。旋转矩阵R为：$$R=\begin{pmatrix}X_x &amp; Y_x &amp; Z_x &amp; 0\\\\X_y &amp; Y_y &amp; Z_y &amp; 0 \\\\X_z &amp; Y_z &amp; Z_z &amp; 0 \\\\0 &amp; 0 &amp; 0 &amp; 1\end{pmatrix}$$平移矩阵T为：$$T=\begin{pmatrix}0 &amp; 0 &amp; 0 &amp; P_x \\\\0 &amp; 0 &amp; 0 &amp; P_y \\\\0 &amp; 0 &amp; 0 &amp; P_z \\\\0 &amp; 0 &amp; 0 &amp; 1\end{pmatrix}$$T*R就是从世界坐标系旋转平移到观察坐标系，但是和前一种方法一样，得到的依旧是世界坐标系下的观察坐标系，而我们需要的是观察坐标系下的世界坐标系。所以观察矩阵$view=(T*R)^{-1}=R^{-1}*T^{-1}$，因为此时的R矩阵是正交矩阵，正交矩阵的逆矩阵就是其转置矩阵，所以$view=R^T*T^{-1}$。又因为：$$R^T=\begin{pmatrix}X_x &amp; X_y &amp; X_z &amp; 0 \\\\Y_x &amp; Y_y &amp; Y_z &amp; 0 \\\\Z_x &amp; Z_y &amp; Z_z &amp; 0 \\\\0 &amp; 0 &amp; 0 &amp; 1\end{pmatrix}$$ $$T^{-1}=\begin{pmatrix}1 &amp; 0 &amp; 0 &amp; -P_x \\\\0 &amp; 1 &amp; 0 &amp; -P_y \\\\0 &amp; 0 &amp; 1 &amp; -P_z \\\\0 &amp; 0 &amp; 0 &amp; 1\end{pmatrix}$$所以：$$view=R^T*T^{-1}=\begin{pmatrix}X_x &amp; X_y &amp; X_z &amp; 0 \\\\Y_x &amp; Y_y &amp; Y_z &amp; 0 \\\\Z_x &amp; Z_y &amp; Z_z &amp; 0 \\\\0 &amp; 0 &amp; 0 &amp; 1\end{pmatrix}*\begin{pmatrix}1 &amp; 0 &amp; 0 &amp; -P_x \\\\0 &amp; 1 &amp; 0 &amp; -P_y \\\\0 &amp; 0 &amp; 1 &amp; -P_z \\\\0 &amp; 0 &amp; 0 &amp; 1\end{pmatrix}$$ 通过具体例子或者证明，都可以很得到这两种方法得到的view矩阵最终是相等的。&nbsp; LookAt矩阵上面两种方法得到的view矩阵也叫作LookAt矩阵，它会创建一个看着（look at）给定目标的观察矩阵，可以很高效地把世界坐标转化为观察坐标。 当然，我们可以自己用代码定义和实现这个LookAt矩阵，把它封装成一个函数，专门用于求看着给定目标的观察矩阵。不过GLM已经给我们实现好了，它为我们提供了一个lookAt函数： //观察矩阵 mat4 view = lookAt(vec3(0.0f, 0.0f, 3.0f), vec3(0.0f, 0.0f, 0.0f), vec3(0.0f, 1.0f, 0.0f)); lookAt函数的第一个参数是摄像机的位置；第二个参数是目标的位置；第三个参数是摄像机的上向量。因为有这个三个参数就足以计算并构建出观察坐标系了（+z轴是目标指向摄像机，+x轴是上向量和+z轴的叉乘，+y轴是+z轴和+x轴的叉乘）。通过该函数就能构建出一个观察矩阵，以创建观察坐标系。 下面上个demo，通过改变lookAt函数的第一个参数摄像机的位置，让它围绕目标转圈： //观察矩阵 GLfloat radius = 10.0f; GLfloat cameraX = radius*sin(glfwGetTime()); GLfloat cameraZ = radius*cos(glfwGetTime()); mat4 view = lookAt(vec3(cameraX, 0.0f, cameraZ), vec3(0.0f, 0.0f, 0.0f), vec3(0.0f, 1.0f, 0.0f)); 所有源码在这里。 编译运行后，结果类似如下： 可以看到随着时间流逝，摄像机在围绕场景（准确说是世界坐标原点）转动了。&nbsp; 上向量上面的lookAt观察矩阵中以及观察坐标系构建中，有一个很诡异的上向量，它通常赋值为（0.0f,1.0f,0.0f）。 为何不直接将这个上向量作为观察坐标系的y轴呢？这是因为上向量不一定和+z轴正交，而我们需要得到正交的坐标系。所以就需要用上向量和+z轴叉乘得到正交的+x轴，再有+z轴+x轴叉乘才能得到正交的+y轴。 上向量指定了相机的头顶方向。对于相机而言，指定了相机位置、相机目标位置后，虽然相机的位置不变、指向不变，但还是可以通过改变这个上向量而影响成像的。这类似于你眼睛的位置不变，看的方向不变，但还是可以通过转动脑袋来改变哪个方向是向上，这个上向量就好比头顶的方向。其实上向量方向不同时，叉乘后得到的x轴、y轴也会发生相应变化，观察坐标系都变了，肯定会影响成像结果。 下面三张图片分别是上向量为（0,1,0）、（1,0,0）、（0,-1,0）的成像结果：&nbsp; 用键盘移动摄像机当我们按下A、S、W、D时，摄像机会向前后左右移动，所以我们需要先给出或计算出摄像机前、右这两个方向（即-z轴和+x轴）： //摄像机位置 vec3 cameraPos = vec3(0.0f, 0.0f, 3.0f); //上向量 vec3 upVector = vec3(0.0f, 1.0f, 0.0f); //摄像机照射方向（观察坐标系-z轴） vec3 cameraFront = normalize(vec3(0, 0, -1)); //摄像机+x轴方向（观察坐标系+x轴） vec3 cameraRight = normalize(cross(upVector, -cameraFront)); 摄像机上方向就是摄像机前面的方向就是摄像机照射的方向，是观察坐标系的-z轴，也就是从摄像机指向目标位置；摄像机右方向就是观察坐标系的+x轴，是上向量和+z轴的叉乘。 接下来就是响应按键了。最初在响应键盘的ESC键时，创建了一个key_callback回调函数来关闭窗口，现在我们还是在这个函数里响应其它按键： //按键回调函数 void key_callback(GLFWwindow* window, int key, int scancode, int action, int mode) { if (key == GLFW_KEY_ESCAPE&&action == GLFW_PRESS) { glfwSetWindowShouldClose(window, GL_TRUE); } //响应键盘按键来移动摄像机 float cameraSpeed = 0.05f; if (key == GLFW_KEY_W) { cameraPos += cameraSpeed * vec3(cameraFront.x, 0, cameraFront.z); } if (key == GLFW_KEY_S) { cameraPos -= cameraSpeed * vec3(cameraFront.x, 0, cameraFront.z); } if (key == GLFW_KEY_D) { cameraPos += cameraSpeed * cameraRight; } if (key == GLFW_KEY_A) { cameraPos -= cameraSpeed * cameraRight; } } 每当有按键按下时，OpenGL就会自动调用该函数。 接下来我们在使用lookAt函数构造观察矩阵时，传入的第二个参数目标位置，应该是摄像机位置加上摄像机照射方向向量（注意摄像机其实最关心的是它的照射方向，目标位置可以是照射方向上的任意一点，所以我们这里就直接加上了照射方向向量来得到目标位置）： //观察矩阵 mat4 view = lookAt(cameraPos, cameraPos + cameraFront, upVector); 到此，我们就能通过WSAD键控制摄像机移动了。所有源码在这里。 编译运行后的结果类似如下： 但是这个摄像机不能同时朝两个方向移动（对角线移动），而且按下一个按键时，它会先顿一下才开始移动。这是因为大多数事件输入系统一次只能处理一个键盘输入。 解决方案是我们在回调函数中只存储哪个按键被按下/释放的状态信息，记录到bool数组中（true表示按下）。在渲染循环中我们读取这些值，检查哪个按键是激活的，然后做出相应反应。 由于GLFW_KRY_W等本身就是int类型的，所以我们可以用它们作为bool数组下标，对应相应的按键状态信息。为了能够存储更多的按键信息，我们定义bool数组（全局变量）如下： //存储按键状态（按下/释放）的数组 bool keys[1024]; 然后在key_callbak函数中设置被按下/释放的按键为true/false： //按键回调函数 void key_callback(GLFWwindow* window, int key, int scancode, int action, int mode) { if (key == GLFW_KEY_ESCAPE&&action == GLFW_PRESS) { glfwSetWindowShouldClose(window, GL_TRUE); } //响应键盘按键来设置相应按键状态 if (action == GLFW_PRESS) { keys[key] = GL_TRUE; } else if(action==GLFW_RELEASE){ keys[key] = GL_FALSE; } } 然后在渲染循环里读取按键状态，并做出相应反应。我们把这部分功能封装到do_movement函数中： //根据按键状态移动摄像机 void do_movement() { GLfloat cameraSpeed = 5.0f*deltaTime; if (keys[GLFW_KEY_W]) { cameraPos += cameraSpeed * vec3(cameraFront.x, 0, cameraFront.z); } if (keys[GLFW_KEY_S]) { cameraPos -= cameraSpeed * vec3(cameraFront.x, 0, cameraFront.z); } if (keys[GLFW_KEY_D]) { cameraPos += cameraSpeed*cameraRight; } if (keys[GLFW_KEY_A]) { cameraPos -= cameraSpeed*cameraRight; } } 最后就是在渲染循环中调用do_movement函数了： while (!glfwWindowShouldClose(window)) { ... do_movement(); ... } 编译运行后会发现，可以同时向多个方向移动了，并且按下按钮时也会立刻移动了，操作灵活了很多。&nbsp; 平衡不同处理器的移动速度上面的摄像机移动速度是个常量，但是实际情况下根据处理器的能力不同，有些人可能会比其他人每秒绘制更多帧，也就是以更高的频率调用do_movement函数，结果就是，由于处理器性能不同，有些人可能移动很快，而有些人会移动很慢。尤其是在网游中，这是很不公平的，我们需要确保在所有硬件上的移动速度都一样。 图形程序和游戏通常会跟踪一个时间差(deltaTime)变量，它储存了渲染上一帧所用的时间。我们把所有速度都去乘以deltaTime值。结果就是，如果我们的deltaTime很大，就意味着上一帧的渲染花费了更多时间，所以这一帧的速度需要变得更高，来平衡渲染所花去的时间。这样一来，渲染时间长的移动速度较快，渲染时间短的移动速度较慢，单位时间内的移动速度就都差不多了，这样每个用户的体验就都一样了。 首先设置两个全局变量来计算deltaTime值： //当前帧与上一帧的时间差 GLfloat deltaTime = 0.0f; //上一帧开始的时间 GLfloat lastTime = 0.0f; 在每一帧（一帧可以看做一次渲染循环）开始时计算出deltaTime： //渲染循环（游戏循环） while (!glfwWindowShouldClose(window)) { //计算deltaTime GLfloat currentTime = glfwGetTime(); deltaTime = currentTime - lastTime; lastTime = currentTime; ... } 现在我们有了deltaTime，在计算速度的时候可以将其考虑进去了： //根据按键状态移动摄像机 void do_movement() { GLfloat cameraSpeed = 5.0f*deltaTime; ... } 编译运行后的结果类似如下： &nbsp; 用鼠标移动摄像机视角 现在我们要开始用鼠标来移动摄像机了。 先来点基础数学知识。旋转共3个欧拉角：俯仰角（pitch）、偏航角（yaw）、滚转角（roll）。下面的图片展示了它们的含义：俯仰角pitch是描述我们往上或往下看的角；偏航角yaw是描述我们往左或往右看的角；滚转角roll是描述我们如何翻滚摄像机的角（通常在太空飞船的摄像机中使用）。 大多数摄像机系统都支持往上下左右看，除非特殊情况一般不考虑滚转角，我们这里只关心俯仰角和偏航角。旋转摄像机的视角其实就是旋转摄像机的照射方向（也就是摄像机指向目标的向量cameraToTarget），摄像机的照射方向正好可以用俯仰角和偏航角来表示。为了计算简单，我们以摄像机所在位置为原点（计算结果后加上摄像机位置就是实际位置了），有如下图示：其中摄像机方向就是从原点发出的那条黄色线，它的俯仰角设为pitch，偏航角设为yaw。设这条向量的长度为1，那么该向量坐标应该是（cos(pitch)*cos(yaw),sin(pitch),cos(pitch)*sin(yaw)）。由于摄像机在旋转过程中，摄像机到目标的距离应该是不变的，所以用该向量乘以这个恒定距离，就是摄像机指向目标的向量的实际坐标，再加上摄像机位置，就能得到旋转过程中目标的实际位置。把目标实际位置传参给lookAt函数，就能实现摄像机旋转了。 但是俯仰角pitch和偏航角yaw怎么得到呢？我们把俯仰角和偏航角的初始值都设为0，用前后两帧鼠标位置的x差值作为偏航角的增量，y差值作为俯仰角的增量。这样就能从一开始得到每一帧里摄像机的俯仰角和偏航角了。 下面我们来实现这个功能： 设置鼠标位置回调函数首先为了让GLFW监听鼠标移动事件，我们需要注册鼠标位置回调函数（和键盘回调函数类似）： //注册鼠标位置回调函数 glfwSetCursorPosCallback(window, cursor_callback); 鼠标位置回调函数原型如下： void cursor_callback(GLFWwindow* window, double xpos, double ypos); xpos和ypos代表当前鼠标的位置，当我们用GLFW注册了鼠标位置回调函数后，鼠标一移动该函数就会被调用。 计算鼠标位移量接下来我们在鼠标位置回调函数cursor_callback中计算出前后两帧的位移量：需要先声明两个全局变量用以计算位移量： //上一帧鼠标位置 GLfloat lastCursorX = WIDTH / 2; GLfloat lastCursorY = HEIGHT / 2; 然后在回调函数中利用这两个全局变量进行计算： GLfloat sensitivity = 0.03f; void cursor_callback(GLFWwindow* window, double xpos, double ypos) { //计算前后两帧的鼠标位移量 GLfloat xOffset = (xpos - lastCursorX)*sensitivity; GLfloat yOffset = (lastCursorY - ypos)*sensitivity; lastCursorX = xpos; lastCursorY = ypos; ... } 由于鼠标位移量每次太大了，不可能直接作为摄像机度数的增量，不然摄像机移动太快了。所以需要给位移量乘以sensitivity灵敏度值。要注意的是鼠标坐标原点在窗口左上角，当我们把鼠标从下往上拉时，我们应该是希望俯仰角增大。但是由于鼠标坐标原点在窗口左上角，+x轴向右，+y轴向下，所以鼠标如果从下往上，xpos - lastCursorY的值会是负数，导致俯仰角不断变小。这与我们期待的相反。应该是正数才对，改成lastCursorY - ypos才合适。 由于lastCursorX和lastCursorY的初始值设在窗口中央，当我们的鼠标第一次从窗口外进入窗口内时，xOffset和xOffset就会很大，摄像机镜头就会突然旋转很大角度。为了避免这种突变，我们改动如下： //鼠标位置回调函数 bool firstCursor = true; void cursor_callback(GLFWwindow* window, double xpos, double ypos) { if (firstCursor) { lastCursorX = xpos; lastCursorY = ypos; firstCursor = false; } //计算前后两帧的鼠标位移量 GLfloat sensitivity = 0.03f; GLfloat xOffset = (xpos - lastCursorX) * sensitivity; GLfloat yOffset = (lastCursorY - ypos) * sensitivity; lastCursorX = xpos; lastCursorY = ypos; ... } 增加了一个firstCursor变量来判断鼠标是否是第一次进入窗口（隐藏鼠标开启的情况下），如果是，就让lastCursorX和lastCursorY等于当前的鼠标位置值，从而避免了镜头突变。 计算偏航角和俯仰角接下来就可以用鼠标x位移量和y位移量来作为摄像机偏航角和俯仰角的增量了。在此之前我们需要声明两个全局变量表示偏航角和俯仰角，但是它们的初始值不是随意指定的。 摄像机俯仰角和偏航角的初始值，与摄像机照射方向（即cameraDirection）的初始值有关，因为需要满足之前推导出的照射方向向量公式：（cos(pitch)*cos(yaw),sin(pitch),cos(pitch)*sin(yaw)）。根据cameraDirection的初始值和该公式，可以求出俯仰角pitch和偏航角yaw的初始值： //摄像机俯仰角（弧度） GLfloat Pitch = asin(cameraFront.y); //摄像机偏航角（弧度） //GLfloat Yaw = asin(sqrt((1 - cameraFront.y * cameraFront.y))); GLfloat Yaw = asin(cameraFront.z / cos(Pitch)); 如上，偏航角的求法有两种，一种是根绝三角函数公式，另一种是直接根据向量公式做除法。注意，求出来的是弧度，不是度数。 有了初始值，接下来就需要在鼠标位置回调函数求每一帧的俯仰角pitch和偏航角yaw了（就是累加鼠标位移量）： //计算偏航角和俯仰角（弧度） Yaw += radians(xOffset); Pitch += radians(yOffset); 摄像机的俯仰角还需要有一些限制，不能让用户看到高于89度和低于-89度的地方，因为在90度和-90度时，视角会发生逆转。所以俯仰角需要在-89度到89度之间： //俯仰角限制在-89度~89度之间 if (Pitch > radians(89.0f)) { Pitch = radians(89.0f); } else if (Pitch < radians(-89.0f)) { Pitch = radians(89.0f); } 偏航角不需要限制了，因为我们希望用户能够在水平面上360转圈看。 计算摄像机到目标的向量然后就是求出，摄像机旋转之后新的摄像机照射方向（即-z轴）（该照射方向向量从一开始就一直是归一化的）： //摄像机到目标的向量 cameraFront.x = cos(Pitch) * cos(Yaw); cameraFront.y = sin(Pitch); cameraFront.z = cos(Pitch) * sin(Yaw); cameraFront = normalize(cameraFront); cameraRight = normalize(cross(upVector, -cameraFront)); 传参给lookAt函数最后，我们需要把求出来的，旋转中的摄像机到目标的向量，传参给lookAt函数，让它和摄像机位置相加，得到旋转中的目标位置，作为lookAt函数的第二个参数： //观察矩阵 mat4 view = lookAt(cameraPos, cameraPos + cameraFront, upVector); 到此，摄像机可以旋转了，源码在缩放后面一起给出。&nbsp; 用鼠标滚轮缩放摄像机视角我们再来实现一个用鼠标滚轮缩放摄像机视角的功能。 摄像机视角是由投影矩阵perspective函数的第一个参数fov（视野，field of view）来指定的。我们通常在指定的视野大小在45度。这个视野指定了我们可以看到场景中多大的范围。当视野变小时，场景投影出来的空间就会减小，更小的投影空间变换到固定尺寸的窗口上，会产生放大了的感觉。 需要先设置一个摄像机视野的全局变量： //摄像机视野 GLfloat fov = 45.0f; 同鼠标位置和按键一样，我们先注册一个鼠标滚轮回调函数： //注册鼠标滚轮回调函数 glfwSetScrollCallback(window, scroll_callback); 接着我们需要在鼠标滚轮回调函数中，把鼠标滚轮y值的偏移量作为视野的增量，来计算视野值，并且把视野值限制在1到45度之间： //鼠标滚轮回调函数 void scroll_callback(GLFWwindow* window, double xoffset, double yoffset) { if (fov >= 1.0f&& fov]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>OpenGL摄像机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL7：坐标系统]]></title>
    <url>%2F2016%2F12%2F05%2FOpenGL7%E5%9D%90%E6%A0%87%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[OpenGL希望每次顶点着色器运行后，我们所有可见的顶点都化为标准化设备坐标（NDC，normalized device coordinate）。也就是说，每个顶点的x、y、z坐标都应该在-1.0到1.0之间，超出这个坐标范围的顶点都将不可见。我们通常会自己设定一个可见的坐标范围，之后再顶点着色器中将这些坐标变换为标准化设备坐标，然后将这些标准化设备坐标传入光栅器（Rasterizer），把它们变换为屏幕上的二维坐标/像素。&nbsp; 坐标转化过程 坐标转化过程中的坐标系统物体的顶点在最终化为屏幕坐标之前，还会被变换到多个坐标系统。这是因为，在中间的那些特定的坐标系统里，一些操作或运算更加方便和容易。其实这个过程类似现实世界的物体被我们看到的过程：最开始由物体出发，物体上可能有各种细节需要去研究，这时候是在局部空间（或称物体空间）；接着这个物体肯定是和我们身处在一个世界里，它身边可能还有其他物体，这时候是在世界空间；但是并不是世界里所有的物体都能被我们看到，只有在我们眼睛前方的物体，才能被我们看到，脑后的东西肯定看不到了，我们眼睛视角前方的世界范围都是观察空间（或称视觉空间）；但是受视力限制，在我们眼睛前方的世界（观察空间）不是都能看得到，我们只能看到目力所能及的观察空间，眼睛前方的视觉范围就是裁剪空间，即使在我们眼睛前方，但太近或者太远不在我们的视力范围内也是看不到的，处在裁剪空间里的物体会通过反射光投影到我们的视网膜上（根据是点光线/点光源还是平行光线/太阳光，可以分为透视投影和正交投影）；在视网膜上的投影最终会转换为我们脑海中的事物，在我们脑海中形成一个世界，这就是屏幕空间。 总之，一个顶点在被转换为屏幕像素之前需要经历5个坐标系统： 局部空间（Local Space，或称物体空间Object Space） 世界空间（World Space） 观察空间（View Space，或称视觉空间Eye Space） 裁剪空间（Clip Space） 屏幕空间（Screen Space） 坐标转化过程中的变换矩阵流程图如下：为了将坐标从一个坐标系转化到另一个坐标系，我们需要用到几个变换矩阵，最重要的是模型矩阵（Model）、观察矩阵（View）、投影矩阵（Projection）。我们的顶点坐标起始于局部空间，在这里它们称为局部坐标；通过模型矩阵的平移旋转缩放之后，物体被放在世界里的不同位置上，变成世界坐标；接下来会把世界坐标通过观察矩阵转化为观察坐标，使得每个坐标都是从摄像机或者说观察者的角度进行观察的；接着在观察坐标会通过投影矩阵转化为裁剪坐标，只有那些在-1.0到1.0之间的裁剪坐标，才会被裁剪出来有机会出现在屏幕上；最后，需要把裁剪坐标通过视口变换（Viewport Transform）转化为屏幕坐标，视口变换将位于-1.0到1.0范围内的坐标变换到由glViewport函数所定义的坐标范围内。最后变换出来的坐标将会送到光栅器，将其转化为像素。 我们之所以将顶点转化到各个不同的空间，是因为有些操作在特定的坐标系统中才有意义且更方便。例如，当需要对物体内部进行修改时，在局部空间中来操作会更方便；当需要对一个物体做出相对于其他物体的操作时，在世界空间中会更方便，等等。当然，也可以定义一个直接从局部坐标转化到裁剪坐标的变换矩阵，但是那样会失去很多灵活性。图中左边的过程包括模型变换、观察变换、投影变换，这些变换由用户根据需要自行指定，这些变换都在顶点着色器中完成；而图中右边的过程包括透视除法、视口变换，都是由OpenGL自动执行的，在顶点着色器处理后的阶段执行。&nbsp; 接下里我们更详细地讨论各个坐标系统和变换矩阵。 局部空间局部空间是指物体所在的坐标空间，即对象最开始所在的地方。比如在建模软件（如3Dmax）中创建了一个立方体，在建模软件里的这个立方体的所有顶点都是在局部空间里。&nbsp; 世界空间如果将我们在建模软件中创建的所有的物体，导入到我们的程序当中，它们可能会全挤在世界的原点（0,0,0）上，这可能并不是我们想要的结果。我们想要为每一个物体定义一个位置。让它们放在世界中的不同位置上。世界坐标就是顶点在（游戏）世界里的坐标。&nbsp; 模型变换物体的坐标从局部空间转化到世界空间，是由模型矩阵来实现的。模型矩阵是一种变换矩阵，其实说白了就是《OpenGL6：坐标变换》一文中的变换矩阵，它通过对物体进行平移、旋转、缩放来将物体放在世界的不同位置或朝向上。可以想象现在在建模软件里创建了一个茶壶，但是它在局部空间中太大了，我们先将它缩小，把它位移到大世界里，然后围绕着旋转一下，以搭配附近的茶壶：下图是在模型空间中定义的茶壶模型：茶壶通过模型变换，转化到世界坐标系中：&nbsp; 观察空间观察空间经常被人们称之为OpenGL的摄像机（所以也称摄像机空间Camera Space或视觉空间Eye Space）。观察空间是将世界坐标转化为用户眼睛前方空间的坐标而产生的结果，在观察空间里的物体只是留待我们去观察的，不一定能被我们看到，得在我们视觉范围内才行。 OpenGL中的相机默认位于原点，指向-Z轴，通常不移动相机（因为OpenGL中实际上没有摄像机，是虚构的），而是以相反的方式来调整场景中的物体，从而达到相同的效果。例如一个物体中心位于原点，照相机也位于初始位置原点，方向指向-Z轴。为了对物体的+Z面成像，一种方式是将照相机向+Z方向后退，仍指向-Z轴；另一种方式是照相机不动，让物体沿着-Z方向移动。OpenGL采用第二种方式。【注】： 其实无论是眼睛还是摄像机，都是假想的概念，是为了便于计算而引入的，并不真实存在。 OpenGL观察空间（或者说OpenGL的照相机）采用的是右手坐标系。想象屏幕处于三个轴的中心，则z轴穿过你的屏幕指向你。坐标系画起来如下：之所以叫做右手坐标系，看下图：可以看到大拇指指向正x轴方向，食指指向正y轴方向，中指指向正z轴方向，正好符合右手坐标系（如果用左手来做这个动作，会发现z轴的方向是相反的，这个叫做左手坐标系，它被DirectX广泛使用）。【注】： OpenGL提供给用户的是右手坐标系，即局部坐标系、世界坐标系、观察坐标系等是一个右手坐标系，但是标准化设备坐标系中OpenGL使用的实际上是左手坐标系，因为投影矩阵交换了左右手。&nbsp; 观察变换观察变换是把世界坐标变化到观察坐标。 在世界坐标系中指定相机的位置、指向的目标位置（相机朝向）以及相机的正上方向（viewUp）（第三个方向轴可以由前两个方向叉乘得到）可以构造出一个观察坐标系，在通过观察矩阵，就可以将物体坐标从世界坐标系转化到观察坐标系。 观察矩阵是一系列平移和旋转的组合，用于平移/旋转场景从而使得特定的对象被变换到摄像机的前方。 观察变化前后图示如下：&nbsp; 裁剪空间在一个顶点着色器运行的最后，OpenGL期望所有要显示的顶点的观察坐标都落在一个特定的范围内，任何在这个范围之外的点都不会显示，会被裁剪掉。这个范围就是裁剪空间，通常是一个视见体（简单说就是一个观察空间里的一个棱台）。 根据投影方式不同，裁剪空间（视见体）可分为以下两种：&nbsp; 投影变换投影变换将顶点坐标从观察空间变化到裁剪空间。为了实现投影变换，我们需要定义一个投影矩阵（Projection Matrix），它会把观察坐标变换为裁剪坐标。所有在视见体内的坐标被映射为裁剪坐标后，其x、y、z坐标分量的值都会在-w和w（第四个坐标分量）之间。而在视见体外的点的坐标分量不都会在-w到w之间，所以会被裁剪掉。比如投影矩阵指定的范围时-1000到1000，那么坐标（1250,500,700）将是不可见的，因为他的x坐标超出了范围，最后它被转化为了一个大于w的裁剪坐标分量，所以被裁剪掉了。【注】： 如果是像三角形这种基本图元，如果它的一部分超出了裁剪范围，则OpenGL会重新构建这个三角形为一个或多个三角形，让它在裁剪范围内的那部分能够显示出来。 投影方式不同，就会有不同的投影矩阵。 正交投影正交投影的投影线相互平行，且正交与投影面。它的视见体是一个立方体：需要指定这个视见体的宽、高、近平面和远平面，任何在视见体之外的坐标都会被裁减掉。在视见体内部的所有坐标都会被映射为标准化设备坐标。 使用glm命名空间里的ortho函数来创建一个正交投影矩阵： mat4 proj = ortho(0.0f, 800.0f, 0.0f, 600.0f, 0.1f, 100.0f); 前两个参数指定了视见体的最左和最右值，第三四个参数指定了视见体的最上下和最上值，第五六个参数指定了近平面和远平面的距离。这个投影矩阵会将处于这些x、y、z值范围内的坐标变换为标准化设备坐标。【注】： 正交投影下顶点的w坐标值是1 透视投影透视投影的投影线汇于一点，会造成近大远小的透视效果：透视投影的视见体是一个四棱台：需要指定这个视见体的视野、宽高比、近平面和远平面，任何在视见体之外的坐标都会被裁减掉。在视见体内部的所有坐标都会被映射为标准化设备坐标。 使用glm命名空间里的perspective函数来创建一个透视投影矩阵： mat4 proj = perspective(radians(45.0f), (float)width/(float)height, 0.1f, 100.0f); 该函数的第一个参数指定了视野fov（field of view）的值，并以此设置了观察空间的大小（如果想要一个真实的观察效果，它的值通常是45.0f，如果想要一个末日风格的结果可以把它设得稍大点）；第二个参数指定了视口的宽高比，由视口的宽除以高所得；第三四个参数指定了近平面和远平面的距离。所有在近平面和远平面内且处于视见体内的顶点都会被渲染。【注】： 如果把透视矩阵的近平面值设置得太大（比如10.0f），OpenGL会将靠近摄像机的坐标（在0.0f到10.0f之间）都裁减掉，这会导致一个我们在游戏中很熟悉的视觉效果：在太过靠近一个物体的时候，视线会直接穿过去。 除此之外，透视投影矩阵还修改了每个顶点坐标的w值，离观察者越远的顶点啊坐标w分量越大，从而使得在做透视除法后，产生近大远小的效果。 透视除法注意透视除法不在投影变换的范畴内，它是在投影变换之后，由OpenGL自动进行透视除法和裁剪。投影变换后的坐标范围是在-w到w之间，做完透视除法之后坐标范围在-1.0到1.0之间，变为标准化设备坐标NDC。 一旦坐标处在裁剪空间之后，透视除法就会被应用到裁剪空间坐标上：$$out =\begin{pmatrix}x /w \\\ y / w \\\ z / w\end{pmatrix}$$顶点坐标的每个分量都会除以它的w分量，透视投影时距离观察者越远顶点坐标就会越小。这也是w分量非常重要的另一个原因，它能帮助我们进行透视投影。当使用正交投影时，虽然也要进行透视除法，但是正交投影的所有顶点w分量都是1，因此除以w分量之后不会有透视效果。 正交投影主要用于二维渲染以及一些建筑或工程的程序，因为这些场景中更希望顶点不会被透视所干扰。透视投影看起来更真实。 透视投影和正交投影效果如下：&nbsp; 总之，模型矩阵针对物体在世界里的位置角度，观察矩阵针对场景移动（或者反方向摄像机移动，因为场景移动用反方向模拟了摄像机移动效果），投影矩阵针对视见体。&nbsp; Demo来一个demo，把《OpenGL5：纹理》一文中的纹理通过模型、观察、投影矩阵，变成向后旋转45度下的透视效果，如下： 创建模型、观察、投影矩阵首先，我们创建一个模型矩阵。这个模型矩阵包含了平移、旋转、缩放操作，它们会在顶点着色器中被应用到所有物体顶点上，以变换它们到全局的世界空间。这里我们让纹理平面绕着x轴旋转55度，让它看起来就像放在地上一样： //模型矩阵 mat4 model; model = rotate(model, radians(-45.0f), vec3(1.0f, 0.0f, 0.0f)); 接着我们创建一个观察矩阵。因为纹理平面默认是处在世界原点（0,0,0）的，而摄像机也是处在世界原点的，这时候摄像机照不到纹理平面，为了让纹理平面可见，我们让场景向负z轴方向移动（因为一般要让摄像机处在原点不动）： //观察矩阵 mat4 view; view = translate(view, vec3(0.0f, 0.0f, -3.0f)); 然后在创建一个投影矩阵。我们使用透视投影： //投影矩阵 mat4 projection; projection = perspective(radians(45.0f), (GLfloat)WIDTH / (GLfloat)HEIGHT, 0.1f, 100.0f); 更改顶点着色器因为要用这三个变换矩阵去影响顶点坐标，所以我们需要先更改一下着色器，让着色器有接收这三个矩阵的变量： //顶点着色器 #version 330 core layout (location=0) in vec3 position; //顶点位置变量的属性位置值为0 layout (location=1) in vec3 color; //顶点颜色变量的属性位置值为1 layout (location=2) in vec2 texCoord; //顶点纹理坐标的属性位置值为2 out vec3 ourColor; out vec2 TexCoord; //模型矩阵 uniform mat4 model; //观察矩阵 uniform mat4 view; //投影矩阵 uniform mat4 projection; void main(){ gl_Position=projection * view * model * vec4(position,1.0f); ourColor=color; TexCoord=vec2(texCoord.x,1-texCoord.y); } 设置了3个uniform变量，用于从主程序接收3个变换矩阵。然后在顶点着色器的main函数里，内置变量gl_Position的值是几个变换矩阵与顶点坐标向量的乘积。注意这里矩阵运算的顺序是相反的（我们需要从右往左阅读三个矩阵的乘法）。 把变换矩阵传递给顶点着色器我们使用给uniform变量赋值的方法，从主程序把变换矩阵传递给着色器： GLint modelLocation = glGetUniformLocation(myshader.shaderProgram, "model"); glUniformMatrix4fv(modelLocation, 1, GL_FALSE, value_ptr(model)); GLint viewLocation = glGetUniformLocation(myshader.shaderProgram, "view"); glUniformMatrix4fv(viewLocation, 1, GL_FALSE, value_ptr(view)); GLint projectionLocation = glGetUniformLocation(myshader.shaderProgram, "projection"); glUniformMatrix4fv(projectionLocation, 1, GL_FALSE, value_ptr(projection)); 全部源码在这里。&nbsp; 3D箱子我们的顶点坐标都是3D的，但是到目前为止，我们还是在使用一个2D平面。因为我们只渲染了一个平面，下面我们尝试渲染一个立方体箱子。 说到立方体，很容易想到应该设置8个顶点，但是我们的立方体每个面上都会有一张纹理，一个顶点紧邻着三个面，也就是说要让一个顶点表示3个纹理的顶点纹素，这是不可能的，因为一个顶点只对应着一个纹理坐标。所以我们需要把每个面上的纹理分开来画。一个面有4个顶点，6个面就应该设置24个顶点。每个顶点都会出现3次，但只是顶点坐标相同，对应的纹理坐标是不同的： GLfloat vertices[] = { //位置坐标 //颜色 //纹理坐标 //立方体前面 0.5f, 0.5f, 0.5f, 1.0f,0.0f,0.0f, 1.0f,1.0f, 0.5f,-0.5f, 0.5f, 0.0f,1.0f,0.0f, 1.0f,0.0f, -0.5f,-0.5f, 0.5f, 0.0f,0.0f,1.0f, 0.0f,0.0f, -0.5f, 0.5f, 0.5f, 1.0f,1.0f,0.0f, 0.0f,1.0f, //立方体后面 0.5f, 0.5f,-0.5f, 1.0f,0.0f,0.0f, 1.0f,1.0f, 0.5f,-0.5f,-0.5f, 0.0f,1.0f,0.0f, 1.0f,0.0f, -0.5f,-0.5f,-0.5f, 0.0f,0.0f,1.0f, 0.0f,0.0f, -0.5f, 0.5f,-0.5f, 1.0f,1.0f,0.0f, 0.0f,1.0f, //立方体上面 0.5f, 0.5f, 0.5f, 1.0f,0.0f,0.0f, 1.0f,1.0f, 0.5f, 0.5f,-0.5f, 0.0f,1.0f,0.0f, 1.0f,0.0f, -0.5f, 0.5f,-0.5f, 0.0f,0.0f,1.0f, 0.0f,0.0f, -0.5f, 0.5f, 0.5f, 1.0f,1.0f,0.0f, 0.0f,1.0f, //立方体下面 0.5f,-0.5f, 0.5f, 1.0f,0.0f,0.0f, 1.0f,1.0f, 0.5f,-0.5f,-0.5f, 0.0f,1.0f,0.0f, 1.0f,0.0f, -0.5f,-0.5f,-0.5f, 0.0f,0.0f,1.0f, 0.0f,0.0f, -0.5f,-0.5f, 0.5f, 1.0f,1.0f,0.0f, 0.0f,1.0f, //立方体右面 0.5f, 0.5f, 0.5f, 1.0f,0.0f,0.0f, 1.0f,1.0f, 0.5f, 0.5f,-0.5f, 0.0f,1.0f,0.0f, 1.0f,0.0f, 0.5f,-0.5f,-0.5f, 0.0f,0.0f,1.0f, 0.0f,0.0f, 0.5f,-0.5f, 0.5f, 1.0f,1.0f,0.0f, 0.0f,1.0f, //立方体左面 -0.5f, 0.5f, 0.5f, 1.0f,0.0f,0.0f, 1.0f,1.0f, -0.5f, 0.5f,-0.5f, 0.0f,1.0f,0.0f, 1.0f,0.0f, -0.5f,-0.5f,-0.5f, 0.0f,0.0f,1.0f, 0.0f,0.0f, -0.5f,-0.5f, 0.5f, 1.0f,1.0f,0.0f, 0.0f,1.0f }; 当然接下来需要对每个面指定索引了： //顶点索引 GLuint indices[] = { //立方体前面 0,1,3, 1,2,3, //立方体后面 4,5,7, 5,6,7, //立方体上面 8,9,11, 9,10,11, //立方体下面 12,13,15, 13,14,15, //立方体右面 16,17,19, 17,18,19, //立方体左面 20,21,23, 21,22,23 }; 【注】： 也可以不用索引，直接画组成立方体的每个三角形，这样6个面，每个面2个三角形，每个三角形3个顶点，那就应该是36个顶点了。 为了有趣点，我们让立方体随着时间旋转： //模型矩阵 mat4 model; model = rotate(model, (GLfloat)glfwGetTime()*radians(55.0f), vec3(0.5f, 1.0f, 0.0f)); 最后使用glDrawElements函数来绘制立方体，这次需要根据36个顶点索引来绘制36个顶点： //绘图 glDrawElements(GL_TRIANGLES, 36, GL_UNSIGNED_INT, 0); 编译运行后应该得到类似下面的效果： 但是这个立方体有点怪，有些面本应该被挡住的，却绘制在了这个立方体的其他面之上。这是因为OpenGL是一个三角形一个三角形来绘制我们的立方体的，后绘制的三角形会覆盖之前绘制的，它并不会到某个三角形被遮挡了不该绘制。 幸运的是，OpenGL把每个像素的深度信息（通常是像素的z坐标值）存储在了一个叫做Z缓冲（Z-buffer）的缓冲中，它允许OpenGL决定何时覆盖一个像素而何时不覆盖。&nbsp; Z缓冲OpenGL存储窗口上所有像素的深度信息于一个Z缓冲（Z-buffer）中，也称深度缓冲（Depth Buffer）。GLFW会自动为我们生成这样一个缓冲（就像它有一个颜色缓冲来存储图像的颜色）。当一个片元（还没绘制到窗口上的像素）准备输出它的颜色时，OpenGL会将它的深度值（z值）和相应坐标上的z缓冲进行比较，如果当前的片元在窗口像素之后（片元深度值小于窗口像素深度值，它们都是负数，越大的离摄像机越近），它将会被丢弃，否则将会覆盖。这个过程称为深度测试（Depth Testing），它是由OpenGL自动完成的。 我们首先需要用glEnable函数告诉OpenGL，我们想要开启深度测试，因为它默认是关闭的： glEnable(GL_DEPTH_TEST); glEnable和glDisable函数允许我们启用或禁用某个OpenGL功能。这个功能会一直保持启用/禁用状态，直到另一个调用来禁用/启用它。所以上面的那行代码就不用写到渲染循环里面了，因为一开启后就会一直开启，直到显式关闭。 接着还需要在每次渲染循环之前清除深度缓冲，否则前一帧的深度信息仍然保存在缓冲中。就像清除颜色缓冲一样，我们可以通过在glClear函数中指定GL_DEPTH_BUFFER_BIT位来清除深度缓冲： glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); 添加上面的代码，编译运行后的结果类似如下： &nbsp; 到此，所有源码在这里。&nbsp; 多个立方体因为要创建的10个立方体长得一样的，只是位置方向不同而已。所以我们只需要调用glDrawElements函数10次，并且每一次调用时给顶点着色器传递不同的模型矩阵就可以： vec3 cubeTranlate[] = { vec3(0.0f, 0.0f, 0.0f), vec3(2.0f, 5.0f, -15.0f), vec3(-1.5f, -2.2f, -2.5f), vec3(-3.8f, -2.0f, -12.3f), vec3(2.4f, -0.4f, -3.5f), vec3(-1.7f, 3.0f, -7.5f), vec3(1.3f, -2.0f, -2.5f), vec3(1.5f, 2.0f, -2.5f), vec3(1.5f, 0.2f, -1.5f), vec3(-1.3f, 1.0f, -1.5f) }; //绑定VAO，完成顶点输入初始化 glBindVertexArray(VAO); for (int i = 0; i < 10; i++) { mat4 model; model = translate(model, cubeTranlate[i]); model = rotate(model, (GLfloat)glfwGetTime()*radians(50.0f), vec3(0.5f, 1.0f, 1.0f)); glUniformMatrix4fv(modelLocation, 1, GL_FALSE, value_ptr(model)); //绘图 glDrawElements(GL_TRIANGLES, 36, GL_UNSIGNED_INT, 0); } //解绑VAO glBindVertexArray(0); 这样就能在不同位置上显示10个立方体了，而且它们都在转。 所有源码在这里。 编译运行后结果如下： &nbsp; 参考文献：LearnOpenGL]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>OpenGL坐标系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL6坐标变换]]></title>
    <url>%2F2016%2F12%2F02%2FOpenGL6%E5%9D%90%E6%A0%87%E5%8F%98%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[在本文将会介绍利用矩阵来对图形进行坐标变化，如平移、旋转、缩放。下面先简单介绍一些数学知识，更详细的可以参考[《几何变换》]一文。&nbsp; 向量向量的乘积分为点乘和叉乘。 向量点乘两个向量的点乘等于它们的模和夹角余弦值的乘积：$$\vec x \cdot \vec y = || \vec x || \cdot ||\vec y|| \cdot \cos \theta$$当两个向量的夹角$\theta$是90度时，余弦值就为0，那么点乘结果就是0,；如果两个向量的夹角是0度，余弦值就为1，那么点乘结果就是两个向量模的乘积。所以，使用点乘可以很容易测试两个向量是否正交或平行。 上面的公式是点乘的一般数学计算，是根据向量模长和夹角来计算的。除此之外，还可以通过向量的坐标来计算，也就是向量的矩阵运算。举例如下：$$\begin{pmatrix}\color{red}{0.6} \\\ -\color{green}{0.8} \\\ \color{blue}0\end{pmatrix}\cdot\begin{pmatrix}\color{red}0 \\\\\color{green}1 \\\ \color{blue}0\end{pmatrix}= (\color{red}{0.6} * \color{red}0) + (-\color{green}{0.8} * \color{green}1) + (\color{blue}0 * \color{blue}0) = -0.8$$点乘在计算光照的时候会非常有用。 向量叉乘向量的叉乘只在3D空间中有定义，它需要两个不平行的向量作为输入，生成一个正交于两个输入向量的第三个向量。如下图所示：向量叉乘只有一种计算方法，公式如下：$$\begin{pmatrix}\color{red}{A_{x}} \\\ \color{green}{A_{y}} \\\ \color{blue}{A_{z}}\end{pmatrix}\times\begin{pmatrix}\color{red}{B_{x}} \\\ \color{green}{B_{y}} \\\ \color{blue}{B_{z}}\end{pmatrix}=\begin{pmatrix}\color{green}{A_{y}} \cdot \color{blue}{B_{z}} - \color{blue}{A_{z}} \cdot \color{green}{B_{y}} \\\ \color{blue}{A_{z}} \cdot \color{red}{B_{x}} - \color{red}{A_{x}} \cdot \color{blue}{B_{z}} \\\ \color{red}{A_{x}} \cdot \color{green}{B_{y}} - \color{green}{A_{y}} \cdot \color{red}{B_{x}}\end{pmatrix}$$ 矩阵向量其实就是矩阵列数为1的特例。但是矩阵乘法只有点乘，没有叉乘。 矩阵点乘直接看例子吧：$$\begin{bmatrix}\color{red}4 &amp; \color{red}2 &amp; \color{red}0 \\\ \color{green}0 &amp; \color{green}8 &amp; \color{green}1 \\\\\color{blue}0 &amp; \color{blue}1 &amp; \color{blue}0\end{bmatrix}\cdot\begin{bmatrix}\color{red}4 &amp; \color{green}2 &amp; \color{blue}1 \\\ \color{red}2 &amp; \color{green}0 &amp; \color{blue}4 \\\ \color{red}9 &amp; \color{green}4 &amp; \color{blue}2\end{bmatrix}=\begin{bmatrix} \color{red}4 \cdot \color{red}4 + \color{red}2 \cdot \color{red}2 + \color{red}0 \cdot \color{red}9 &amp; \color{red}4 \cdot \color{green}2 + \color{red}2 \cdot \color{green}0 + \color{red}0 \cdot \color{green}4 &amp; \color{red}4 \cdot \color{blue}1 + \color{red}2 \cdot \color{blue}4 + \color{red}0 \cdot \color{blue}2 \\\\\color{green}0 \cdot \color{red}4 + \color{green}8 \cdot \color{red}2 + \color{green}1 \cdot \color{red}9 &amp; \color{green}0 \cdot \color{green}2 + \color{green}8 \cdot \color{green}0 + \color{green}1 \cdot \color{green}4 &amp; \color{green}0 \cdot \color{blue}1 + \color{green}8 \cdot \color{blue}4 + \color{green}1 \cdot \color{blue}2 \\\\\color{blue}0 \cdot \color{red}4 + \color{blue}1 \cdot \color{red}2 + \color{blue}0 \cdot \color{red}9 &amp; \color{blue}0 \cdot \color{green}2 + \color{blue}1 \cdot \color{green}0 + \color{blue}0 \cdot \color{green}4 &amp; \color{blue}0 \cdot \color{blue}1 + \color{blue}1 \cdot \color{blue}4 + \color{blue}0 \cdot \color{blue}2\end{bmatrix}=\begin{bmatrix}20 &amp; 8 &amp; 12 \\\ 25 &amp; 4 &amp; 34 \\\ 2 &amp; 0 &amp; 4\end{bmatrix}$$矩阵相乘不满足交换律。 单位矩阵单位矩阵是主对角线元素为1，其他元素全为0的矩阵：$$\begin{bmatrix}\color{red}1 &amp; \color{red}0 &amp; \color{red}0 &amp; \color{red}0 \\\\\color{green}0 &amp; \color{green}1 &amp; \color{green}0 &amp; \color{green}0 \\\ \color{blue}0 &amp; \color{blue}0 &amp; \color{blue}1 &amp; \color{blue}0 \\\\\color{purple}0 &amp; \color{purple}0 &amp; \color{purple}0 &amp; \color{purple}1\end{bmatrix}\cdot\begin{bmatrix}1 \\\\2 \\\ 3 \\\ 4\end{bmatrix}=\begin{bmatrix}\color{red}1 \cdot 1 \\\ \color{green}1 \cdot 2 \\\ \color{blue}1 \cdot 3 \\\ \color{purple}1 \cdot 4\end{bmatrix}=\begin{bmatrix}1 \\\ 2 \\\ 3 \\\ 4\end{bmatrix}$$上面是一个单位矩阵和另外一个向量的点乘，可以看到结果还是那个向量，没有发生变换。一个没有变换的变换矩阵有何用？其实单位矩阵是其他变换矩阵的起点，后面会看到其他变换矩阵和单位矩阵很像。&nbsp; 平移变换平移是把一个向量从一个位置平移到另一个位置。在数学上其实就是在原始向量的基础上乘了一个位移矩阵（齐次坐标下的矩阵，关于齐次坐标也可以参考前面链接的那篇文章）：$$\begin{bmatrix}\color{red}1 &amp; \color{red}0 &amp; \color{red}0 &amp; \color{red}{T_x} \\\\\color{green}0 &amp; \color{green}1 &amp; \color{green}0 &amp; \color{green}{T_y} \\\ \color{blue}0 &amp; \color{blue}0 &amp; \color{blue}1 &amp; \color{blue}{T_z} \\\ \color{purple}0 &amp; \color{purple}0 &amp; \color{purple}0 &amp; \color{purple}1\end{bmatrix}\cdot\begin{pmatrix}x \\\ y \\\ z \\\ 1\end{pmatrix}=\begin{pmatrix}x + \color{red}{T_x} \\\ y + \color{green}{T_y} \\\ z + \color{blue}{T_z} \\\ 1\end{pmatrix}$$那个4x4的矩阵就是我们的位移矩阵，在x、y、z方向上的位移量分别是$T_x、T_y、T_z$。&nbsp; 旋转变换在3D空间中旋转需要定义一个角和一个旋转轴。图形会沿着给定的旋转轴旋转指定角度。 对于不同的旋转轴，有不同的旋转矩阵： 沿x轴旋转：$$\begin{pmatrix}\color{red}1 &amp; \color{red}0 &amp; \color{red}0 &amp; \color{red}0 \\\\\color{green}0 &amp; \color{green}{\cos \theta} &amp; - \color{green}{\sin \theta} &amp; \color{green}0 \\\ \color{blue}0 &amp; \color{blue}{\sin \theta} &amp; \color{blue}{\cos \theta} &amp; \color{blue}0 \\\ \color{purple}0 &amp; \color{purple}0 &amp; \color{purple}0 &amp; \color{purple}1\end{pmatrix}\cdot\begin{pmatrix}x \\\ y \\\ z \\\ 1\end{pmatrix}=\begin{pmatrix}x \\\ \color{green}{\cos \theta} \cdot y - \color{green}{\sin \theta} \cdot z \\\ \color{blue}{\sin \theta} \cdot y + \color{blue}{\cos \theta} \cdot z \\\ 1\end{pmatrix}$$ 沿y轴旋转：$$\begin{pmatrix}\color{red}{\cos \theta} &amp; \color{red}0 &amp; \color{red}{\sin \theta} &amp; \color{red}0 \\\ \color{green}0 &amp; \color{green}1 &amp; \color{green}0 &amp; \color{green}0 \\\ -\color{blue}{\sin \theta} &amp; \color{blue}0 &amp; \color{blue}{\cos \theta} &amp; \color{blue}0 \\\ \color{purple}0 &amp; \color{purple}0 &amp; \color{purple}0 &amp; \color{purple}1\end{pmatrix}\cdot\begin{pmatrix}x \\\ y \\\ z \\\ 1\end{pmatrix}=\begin{pmatrix}\color{red}{\cos \theta} \cdot x + \color{red}{\sin \theta} \cdot z \\\ y \\\ -\color{blue}{\sin \theta} \cdot x + \color{blue}{\cos \theta} \cdot z \\\ 1\end{pmatrix}$$ 沿z轴旋转：$$\begin{bmatrix}\color{red}{\cos \theta} &amp; - \color{red}{\sin \theta} &amp; \color{red}0 &amp; \color{red}0 \\\ \color{green}{\sin \theta} &amp; \color{green}{\cos \theta} &amp; \color{green}0 &amp; \color{green}0 \\\ \color{blue}0 &amp; \color{blue}0 &amp; \color{blue}1 &amp; \color{blue}0 \\\ \color{purple}0 &amp; \color{purple}0 &amp; \color{purple}0 &amp; \color{purple}1\end{bmatrix}\cdot\begin{pmatrix}x \\\ y \\\ z \\\ 1\end{pmatrix}=\begin{pmatrix}\color{red}{\cos \theta} \cdot x - \color{red}{\sin \theta} \cdot y \\\ \color{green}{\sin \theta} \cdot x + \color{green}{\cos \theta} \cdot y \\\ z \ 1\end{pmatrix}$$【注】： 当把多个旋转矩阵结合起来时，比如先沿着x轴旋转再沿着y轴旋转，这可能会导致万向节死锁（Gimbal Lock，当两个旋转轴位于同一平面时，图形/物体就不能再旋转到任意位置了，有些方向怎么也旋转不过去）。关于万向节死锁可以参考下面这个视频：避免万向节死锁的真正解决方案是使用四元素，它不仅安全，而且计算更加友好（之后的文章会讲）。&nbsp; 缩放变换对一个向量进行缩放变换就是对向量的长度进行缩放，而保持它的方向不变：$$\begin{bmatrix}\color{red}{S_1} &amp; \color{red}0 &amp; \color{red}0 &amp; \color{red}0 \\\ \color{green}0 &amp; \color{green}{S_2} &amp; \color{green}0 &amp; \color{green}0 \\\ \color{blue}0 &amp; \color{blue}0 &amp; \color{blue}{S_3} &amp; \color{blue}0 \\\ \color{purple}0 &amp; \color{purple}0 &amp; \color{purple}0 &amp; \color{purple}1\end{bmatrix}\cdot\begin{pmatrix}x \\\ y \\\ z \\\ 1\end{pmatrix}=\begin{pmatrix}\color{red}{S_1} \cdot x \\\ \color{green}{S_2} \cdot y \\\ \color{blue}{S_3} \cdot z \\\ 1\end{pmatrix}$$&nbsp; 下面来看看在OpenGL中怎么用代码实现这些坐标变换。 GLM由于高版本的OpenGL没有自带任何的矩阵和向量知识，低版本中的glTranslate、glRotate、glScale等等都不能再用了。所以现在我们使用GLM，它是专门为OpenGL量身定制的数学库，易于使用。 GLM（OpenGL Mathematics），是一个只有头文件的库，也就是我们只需包含对应的头文件就可以使用了（包含整个glm文件夹，方法参考《OpenGL1：OpenGL概述及环境配置》一文），不用链接和编译。 坐标变换头文件我们需要的GLM的大多数功能基本上都在下面3个头文件里： //GLM #include #include #include using namespace glm; 定义变换矩阵接下来需要定义坐标变换矩阵，使用mat4类型： //定义变换矩阵（单位矩阵） mat4 transform; 按这种方式定义好的变换矩阵，初始值一般都是单位矩阵。 坐标变换（平移旋转缩放）我们先对上一篇文章中的纹理，进行旋转变换： //随着时间绕z轴旋转 transform = rotate(transform, (GLfloat)glfwGetTime()*1.0f, vec3(0.0f, 0.0f, 1.0f)); 使用glm命名空间里的rotate函数，第一个参数是旋转之前的变换矩阵；第二个参数是旋转角度（弧度值），这里旋转角度随着时间不断增加，图形将会一直旋转；第三个参数是旋转轴。 接下来对图形进行变换： //平移（0.5，-0.5，0） transform = translate(transform, vec3(0.5f, -0.5f, 0.0f)); 使用glm命名空间里的translate函数，第一个参数是平移之前的变换矩阵（准备拿去平移的矩阵）；第二个参数是位移向量，指定了平移的方向和距离。 发送变换矩阵给着色器变换矩阵已经搞定了，但是怎么把矩阵传递给着色器呢？我们使用uniform变量来实现：在顶点着色器里定义一个mat4类型的uniform变量： //顶点着色器 #version 330 core layout (location=0) in vec3 position; //顶点位置变量的属性位置值为0 layout (location=1) in vec3 color; //顶点颜色变量的属性位置值为1 layout (location=2) in vec2 texCoord; //顶点纹理坐标的属性位置值为2 out vec3 ourColor; out vec2 TexCoord; //坐标变换矩阵 uniform mat4 transform; void main(){ gl_Position=transform*vec4(position,1.0f); ourColor=color; TexCoord=vec2(texCoord.x,1-texCoord.y); } 在顶点着色器的main函数里，让内置变量gl_Position的值等于变换矩阵和顶点坐标向量的乘积，这样就能把图形顶点进行坐标变换了（注意变换矩阵必须左乘顶点坐标向量）。 接下里就需要在主函数里对这个mat4类型的uniform变量赋值了： //获取uniform全局变量transform（变换矩阵）的位置 GLint transformLoc = glGetUniformLocation(myshader.shaderProgram, "transform"); //给uniform变量（变换矩阵）赋矩阵值 glUniformMatrix4fv(transformLoc, 1, GL_FALSE, value_ptr(transform)); 首先获取到这个mat4类型的uniform变量的位置，再使用glUniformMatrix4fv函数对它赋值，该函数的第一个参数是获取到的uniform变量的位置；第二个参数是要传递多少个矩阵，这里是1；第三个参数指明是否要对矩阵进行转置（交换矩阵的行和列），OpenGL通常使用列主序的矩阵布局，而GLM的矩阵默认就是列朱旭，所以不需要转置矩阵，我们填GL_FALSE。最后一个参数是真正的矩阵数据，但是GLM矩阵并不是OpenGL所希望接受的数据形式，所以需要先用GLM自带的函数value_ptr来进行转换。&nbsp; 到此，关于坐标变换的所有源码在这里。 编译运行后，效果类似如下： 【注】： translate、rotate等函数，单独作用的时候它们都是以原点（窗口中心）为基准的，即相对于原点进行平移、旋转。 越靠近渲染函数glDrawElements的变换越先执行，所以上诉渲染循环中应该是先指定旋转变换，再指定平移变换。&nbsp; 参考文献：LearnOpenGL]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>OpenGL坐标变换</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL5：纹理]]></title>
    <url>%2F2016%2F11%2F29%2FOpenGL5%E7%BA%B9%E7%90%86%2F</url>
    <content type="text"><![CDATA[在前面的文章中，我们画过矩形，画过彩色三角形。那么能不能画出现实生活中的图片呢？比如画一面砖墙，画一朵花。这样的图形无疑看起来更真实。但是这些更真实的图形也无疑很复杂，因为它们的每个像素颜色之间并没有什么明显的规律，如果要去画的话，就得一个像素一个像素的去画，要我们自己去指定大量的顶点颜色，这个开销太庞大了~~~&nbsp; 纹理概述幸运的是，还有另一种方式。我们可以先照一张砖墙的照片，让GPU自动提取这张照片上的像素，然后画到屏幕上。这张用于GPU提取像素颜色的照片，就叫做纹理。纹理通常是一个2D图片（也有1D和3D的纹理）。可以想象纹理是一张绘有砖块的纸，无缝折叠贴合到我们的3D房子上，这样我们的房子看起来就像有砖墙外表了。这样我们就不用去一个一个地去指定纹理中每个纹素（纹理中的像素）的颜色了，只需要指定怎样把纹理贴到我们的模型（比如一个三角形、矩形甚至3D房子）上。举个例子：为了把这张木箱纹理贴到图中红色三角形上，我们需要指定三角形的顶点对应纹理的那个位置。这个位置我们叫做纹理坐标，表示纹素在纹理上的位置，通常坐标值在0.0到1.0之间，原点通常在纹理左下角。我们把三角形左下角顶点对应纹理坐标（0,0），把三角形右下角顶点对应纹理坐标（1,0），把三角形上中顶点对应纹理坐标（0.5,1.0）。我们只要给顶点着色器传递这三个顶点纹理坐标就行了，接下来它们会被传到像素着色器中，GPU会根据三角形顶点纹理坐标，去为三角形内部点进行插值（根据内部点坐标和顶点坐标的关系，去纹理中找相应纹素颜色）。使用纹理坐标获取纹理颜色叫做采样。 这么说来，纹理坐标也应该是三角形顶点的一个属性，所以我们定义如下： //三角形顶点的坐标、颜色、纹理坐标 GLfloat vertices[] = { //位置坐标 //颜色 //纹理坐标 0.5f, 0.5f, 0.0f, 1.0f,0.0f,0.0f, 1.0f,1.0f, 0.5f, -0.5f,0.0f, 0.0f,1.0f,0.0f, 1.0f,0.0f, -0.5f,-0.5f,0.0f, 0.0f,0.0f,1.0f, 0.0f,0.0f, -0.5f,0.5f, 0.0f, 1.0f,1.0f,0.0f, 0.0f,1.0f }; &nbsp; 告诉OpenGL如何解析顶点数据由于顶点数据中增加了纹理坐标，我们需要重新设置OpenGL如何解析顶点数据： //告诉OpenGL如何解析显存中的顶点位置属性数据 glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 8 * sizeof(GLfloat), (GLvoid*)0); //打开顶点位置属性数组 glEnableVertexAttribArray(0); //告诉OpenGL如何解析显存中的顶点颜色属性数据 glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, 8 * sizeof(GLfloat), (GLvoid*)(3 * sizeof(GLfloat))); //打开顶点颜色属性数组 glEnableVertexAttribArray(1); //告诉OpenGL如何解析显存中的顶点纹理坐标属性数据 glVertexAttribPointer(2, 2, GL_FLOAT, GL_FALSE, 8 * sizeof(GLfloat), (GLvoid*)(6 * sizeof(GLfloat))); //打开顶点纹理坐标属性数组 glEnableVertexAttribArray(2); 每个顶点属性的步长都变成了8*sizeof(GLfloat)，起始偏移量（最后一个参数）也发生了变化。顶点纹理坐标属性对应顶点着色器中的location为2。&nbsp; 创建纹理和绑定对象和创建顶点数组对象VAO等一样，使用纹理前，我们需要创建和绑定纹理对象： GLuint texture; //生成纹理对象texture glGenTextures(1, &texture); //给纹理对象绑定目标（2D纹理） glBindTexture(GL_TEXTURE_2D, texture); 我们使用的是2D纹理，所以纹理目标是GL_TEXTURE_2D。&nbsp; 加载纹理创建和绑定完纹理对象之后，我们把纹理从文件中加载进来。 纹理图像可能被存储为各种各样的格式，每种都有自己的数据结构和排列方式，那么我们如何才能把这些图像加载到应用中呢？一个解决方案是选一个需要的文件格式，比如png，然后自己写一个图像加载器，把图像转化为字节序列。但是如果要支持更多文件格式呢？就得为每种希望支持的格式写加载器了。 另一种解决方案就是借前人之树乘凉：使用一个支持多种流行格式的图像加载库来解决这个问题。比如我们要用的SOIL库（文末还介绍了另一种加载库）。 简易OpenGL图像库SOILSOIL是简易OpenGL图像库（Simple OpenGL Image Library）的缩写，它支持大多数流行的图像格式。可以从这里下载。下载完成后用VS打开\projects\VC8目录下的SOIL.sln，生成解决方案后，从debug文件夹里取得SOIL.lib文件，将它添加到我们自己建的Libs文件夹里，再把src文件夹下的所有.h头文件添加到我们自己建的Includes文件夹里，并且在自己的VS项目中链接上SOIL.lib（具体过程和《OpenGL1：OpenGL概述及环境配置》一文中构建GLFW类似）。 当然，在我们的源文件中还需要包含SOIL.h头文件：#include &lt;SOIL.h&gt; 使用SOIL加载图片下面我们加载一张木箱图片。首先使用SOIL库的SOIL_load_image函数把木箱图片数据加载到内存： int iamgeWidth, iamgeHeight; unsigned char* image = SOIL_load_image("container.jpg", &iamgeWidth, &iamgeHeight, 0, SOIL_LOAD_RGB); 函数SOIL_load_image的第一个参数是需要加载的图片路径；然后需要两个int指针作为第二个和第三个参数，函数会分别返回图片的宽度和高度到其中；第4个参数指定图片的通道数量，这里设为0即可；最后一个参数告诉SOIL如何来加载图片，由于我们只关注图片的RGB值，所以设为SOIL_LOAD_RGB。函数返回一个很大的char（或者说byte）数组。&nbsp; 生成纹理图像数据已经有了，存储在image数组中，下面我们利用这些图形数据来在GPU上生成一张纹理： glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, iamgeWidth, iamgeHeight, 0, GL_RGB, GL_UNSIGNED_BYTE, image); 函数glTexImage2D的参数都表示什么？ 第一个参数是纹理绑定的目标GL_TEXTURE_2D 第二个参数是纹理的多级渐远纹理（后面会讲）级别，这里我们设置为0，也就是原始纹理 第三个参数告诉OpenGL我们希望把纹理存储为何种格式。我们的图形只有RGB值，所以我们也把纹理存储为RGB 第四个和第五个参数设置最终的纹理宽度和高度。我们之前加载图像的时候读取到了图像的宽度和高度，现在刚好用上 第6个参数总是设为0（历史遗留问题） 第7个参数指定源图的格式 第8个参数指定源图的数据类型 最后一个参数是真正的图形数据 当调用函数glTexImage2D时，当前绑定的纹理对象就会被附加上纹理图像。 使用完图像内存数据后，释放所占用的内存是个好习惯： SOIL_free_image_data(image); &nbsp; 接下来还需要对纹理进行一系列的配置，先来看对纹理环绕方式的配置。 纹理环绕方式纹理坐标的范围通常是（0,0）到（1,1），那如果我们把纹理坐标设置在这个范围之外会发生什么？OpenGL默认是重复这个纹理图像（即忽略纹理坐标的整数部分，只有小数部分有效），除此之外，OpenGL还提供了几种环绕方式（Wrapping）： GL_REPEAT：重复纹理图像。这是默认的。 GL_MIRRORED_REPEAT：镜像重复纹理图像。 GL_CLAMP_TO_EDGE：纹理坐标会被约束在0到1之间，超出部分会重复纹理边缘，产生一种边缘被拉伸的效果。 GL_CLAMP_TO_BORDER：超出坐标为用户指定的边缘颜色。 当纹理坐标不在0到1之间时，每个选项都有不同的视觉输出效果：可以使用glTextParameteri函数来设置纹理的环绕方式： glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT); 第一个参数指定了纹理对象所绑定的目标；第二个参数指定需要配置的选项和应用的纹理轴，因为我们打算配置的是纹理环绕方式wrap，并且需要配置S和T方向（纹理中的s、t、r轴等价于通常的x、y、z轴）的环绕方式。最后一个参数指定环绕方式，这里我们指定的都是重复纹理图像这种方式。 【注】： 如果我们选择GL_CLAMP_TO_BORDER这种纹理环绕方式，就还需要再指定一个边缘颜色。这时就需要再使用glTexParameterfv函数了： glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_BORDER); GLfloat borderColor[] = { 1.0f,1.0f,0.0f,1.0f }; glTexParameterfv(GL_TEXTURE_2D, GL_TEXTURE_BORDER_COLOR, borderColor); 函数glTexParameterfv的第一个参数依旧是纹理对象绑定的目标；因为要设置边缘颜色，所以第二个参数变成了GL_TEXTURE_BORDER_COLOR；第三个参数是表示颜色的一个float数组。&nbsp; 接下来我们看看对纹理过滤方式的配置 纹理过滤当使用顶点坐标映射相应纹素时，由于是根据位置关系进行插值计算的，所以得到的内部点的纹理坐标不一定是整数，比如说如果纹素位置（即纹理坐标）为（152.34,255,38）该怎么办呢？这种情况称为纹理过滤。 纹理过滤有很多种方法，这里只讨论最重要的两种：GL_NEAREST（最邻近滤波）和GL_LINEAR（线性滤波） 最邻近滤波最邻近滤波是选择中心点距离浮点数纹理坐标最近的那个纹素。图示如下：因为图中红色纹素离纹理坐标最近，所以选择该红色作为最终的输出纹素。 最邻近滤波容易导致走样误差，明显有像素块的感觉。 线性滤波线性滤波是使用纹理坐标附近的一组纹素的加权平均值（插值）来确定最终的纹素值。这个权值就是纹素中心到这个纹理坐标的距离，距离越近的纹素对最终的纹素值贡献越大。如下图所示： 最邻近滤波和线性滤波的对比效果如下：GL_NEAREST产生了颗粒状的图案，能够清晰地看到纹素，而GK_LINEAR能够产生更平滑的图案，很难看出单个的纹素。GL_LINEAR可以产生更真实的输出，不过GL_NEAREST却可以产生出8-bit风格（像素风），也有很多人喜欢。 还有一些其它的滤波方式，比如三线性滤波（Trilinear Filtering）等。 纹素放大缩小时滤波除了对纹理坐标取整时需要用到滤波以外，在纹素到像素时的放大和缩小时，也可能要用到滤波。 什么是纹素到像素的放大、缩小？ 一个纹素最终对应屏幕上的多个像素，称为放大（magnification） 一个纹素最终对应屏幕上的一个像素，这时不需要滤波 一个纹素最终对应少于一个像素，称为缩小 放大和缩小图示如下： 我们可以使用glTexParameteri函数在图像放大滤波和缩小滤波选项时设置纹理滤波： glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); 第二个参数是放大滤波或者缩小滤波，第三个参数指定滤波方式。&nbsp; 多级渐远纹理mipmap一个物体，当它距离我们比较近时，需要很多像素去表现它；而当距离我们很远时，会看不大清楚，只有很少的像素需要被绘制，这时再从该物体对应的纹理中去找几个纹素来表现它，是很难的。因为它需要跨过纹理很大部分只拾取一个纹素，而且最终拾取出来的纹素凑在一起可能就面目全非了。更何况对于很远的物体去使用高分辨率的纹理无疑是浪费内存。 OpenGL使用多级渐远纹理Mipmap来解决这个问题。mipmap其实就是一系列纹理图像，后一个纹理图像只有前一个纹理图像的一半大小。在观察者的距离在不同的距离范围时使用不同级别的mipmap。mipmap的另一个加分点是它的性能非常好。mipmap图示如下： mipmap滤波在渲染中切换不同级别的mipmap时，会产生一些很明显的边界。对纹素的滤波也可以用到这里，来消除这些很生硬的边界。由于mipmap其实也相当于是把纹理缩小，所以它的滤滤波也是通过glTexParameteri函数在缩小滤波GL_TEXTURE_MIN_FILTER选项时来实现： glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST_MIPMAP_LINEAR); 函数的第三个参数就是要设置的mipmap滤波方式，它有一下几种选项（“mipmap”之后是mipmap滤波方式，之前是纹素滤波方式）： GL_NEAREST_MIPMAP_NEAREST：使用最接近像素大小的mipmap，纹理内部使用最邻近滤波 GL_LINEAR_MIPMAP_NEAREST：使用最接近像素大小的mipmap，纹理内部使用线性滤波 GL_NEAREST_MIPMAP_LINEAR：在两个最接近像素大小的mipmap中做线性插值，纹理内部使用最邻近滤波 GL_LINEAR_MIPMAP_LINEAR：在两个最接近像素大小的mipmap中线性插值，纹理内部使用线性滤波 设置好mipmap的滤波之后，就可以来创建mipmap了。 创建mipmap手工为每个纹理图像创建一系列mipmap挺麻烦的，不过OpenGL有一个glGenerateMipmaps函数，在创建完一个纹理后调用它，OpenGL就会自动建立该纹理的一系列mipmap了： glGenerateMipmap(GL_TEXTURE_2D); 【注】： 如果不需要mipmap，那关于mipmap这里的操作可以不要。&nbsp; 解绑纹理对象设置完纹理参数后，需要和别的对象一样，使用完之后解绑纹理对象： glBindTexture(GL_TEXTURE_2D, 0); &nbsp; 更改顶点着色器 //顶点着色器 #version 330 core layout (location=0) in vec3 position; //顶点位置变量的属性位置值为0 layout (location=1) in vec3 color; //顶点颜色变量的属性位置值为1 layout (location=2) in vec2 texCoord; //顶点纹理坐标的属性位置值为2 out vec3 ourColor; out vec2 TexCoord; void main(){ gl_Position=vec4(position,1.0f); ourColor=color; TexCoord=texCoord; } 顶点着色器需要增加一个纹理坐标的输入变量，由于只有s、t坐标，所以是vec2类型；还需要增加一个输出变量，用于输出纹理坐标给像素着色器。在main函数内把输入纹理坐标赋值给输出纹理坐标。&nbsp; 更改像素着色器 //像素着色器 #version 330 core in vec3 ourColor; in vec2 TexCoord; out vec4 color; uniform sampler2D ourTexture; void main(){ color = vec4(ourColor,1.0f) * texture(ourTexture,TexCoord); } 像素着色器需要增加一个纹理坐标的输入变量；只有纹理坐标还不足以在像素着色器中输出对应纹素的颜色，我们还需要一个采样器（设置为uniform变量），让它结合纹理坐标、顶点坐标、纹理图像，进行插值获得每一个像素颜色。使用texture函数来使用采样器，第一个参数是我们设置的采用器，第二个参数是纹理坐标。 在main函数内最终的输出颜色我们设置为顶点颜色和纹理颜色的混合。&nbsp; 渲染时绑定纹理对象设置完了纹理和相应的着色器，最后要做的就是在渲染循环里绑定纹理对象，这样才能渲染出纹理（这和绑定VAO是一个道理）。 //绑定纹理 glBindTexture(GL_TEXTURE_2D, texture); &nbsp; 自此，所有源码在这里。 编译运行后，结果如下：&nbsp; 使用多个纹理 载入第二张图片载入第二张图片和第一张类似： GLuint texture1; //生成纹理对象texture1 glGenTextures(1, &texture1); //给纹理对象绑定目标（2D纹理） glBindTexture(GL_TEXTURE_2D, texture1); int iamgeWidth, iamgeHeight; //加载纹理图像 unsigned char* image = SOIL_load_image("container.jpg", &iamgeWidth, &iamgeHeight, 0, SOIL_LOAD_RGB); //生成2D纹理 glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, iamgeWidth, iamgeHeight, 0, GL_RGB, GL_UNSIGNED_BYTE, image); //释放纹理数据内存 SOIL_free_image_data(image); //设置纹理s和t方向的环绕方式 glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT); //设置纹理放大和缩写时的过滤方式（纹素过滤、mipmap边界过滤） glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); //生成多级渐远纹理 glGenerateMipmap(GL_TEXTURE_2D); //解绑纹理对象 glBindTexture(GL_TEXTURE_2D, 0); GLuint texture2; //生成纹理对象texture2 glGenTextures(1, &texture2); //给纹理对象绑定目标（2D纹理） glBindTexture(GL_TEXTURE_2D, texture2); //加载纹理图像 image = SOIL_load_image("awesomeface.png", &iamgeWidth, &iamgeHeight, 0, SOIL_LOAD_RGB); //生成2D纹理 glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, iamgeWidth, iamgeHeight, 0, GL_RGB, GL_UNSIGNED_BYTE, image); //释放纹理数据内存 SOIL_free_image_data(image); //设置纹理s和t方向的环绕方式 glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_LINEAR); //设置纹理放大和缩写时的过滤方式（纹素过滤、mipmap边界过滤） glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); //生成多级渐远纹理 glGenerateMipmap(GL_TEXTURE_2D); //解绑纹理对象 glBindTexture(GL_TEXTURE_2D, 0); 更改像素着色器使用多个纹理，我们就需要在像素着色器中使用多个采样器： //像素着色器 #version 330 core in vec3 ourColor; in vec2 TexCoord; out vec4 color; //纹理采样器1 uniform sampler2D ourTexture1; //纹理采样器2 uniform sampler2D ourTexture2; void main(){ color = vec4(ourColor,1.0f) * mix(texture(ourTexture1,TexCoord),texture(ourTexture2,TexCoord),0.41); } 在main函数中使用mix函数来混合两个纹理，第一个参数是纹理1的纹素颜色，第二个参数是纹理2的纹素颜色，第3个参数是纹素2在最终输出颜色中所占的权重，代码中是59%的纹素1，41%的纹素2。 渲染中激活纹理单元并设置相应采样器我们可以看到我们的采样器是被uniform声明的，但是很奇怪的是之前的源程序中，渲染时并没有对uniform全局变量ourTexture赋值，但是依旧有效并没有报错。这是因为我们的ourTexture变量是个采样器，通过多个采样器我们可以使用多个纹理。 每个纹理都有一个位置值，称为纹理单元（有点像多个纹理叠加时的图层）。而对于纹理处在哪一层，即纹理单元是多少，就是通过使用glUniform1i函数来给采样器赋值，从而确定纹理单元值。但是默认情况下，当只使用一个纹理时，纹理单元GL_TEXTURE0总是被激活的，也就是这个采样器（或者说纹理单元）总是对应0（0图层），所以不需要显式使用glUniform1i函数去为采样器赋值。 但是有多个纹理时，就没有默认了，需要显式为每个采样器指定一个整数值，对应被激活的图层（被激活的纹理单元）： //激活纹理单元 glActiveTexture(GL_TEXTURE0); //获取uniform变量位置 GLint uniformLocation1 = glGetUniformLocation(myshader.shaderProgram, "ourTexture1"); //设置采样器的值（对应纹理单元值） glUniform1i(uniformLocation1, 0); //绑定纹理对象 glBindTexture(GL_TEXTURE_2D, texture1); glActiveTexture(GL_TEXTURE1); GLint uniformLocation2 = glGetUniformLocation(myshader.shaderProgram, "ourTexture2"); glUniform1i(uniformLocation2, 1); glBindTexture(GL_TEXTURE_2D, texture2); 在给采样器赋值之前，我们需要先激活纹理单元，活着说激活纹理图层，再给采样器赋以相应的被激活的纹理单元值，这样采样器才能读出纹素颜色。【注】： 如果采样器值对应的纹理单元没有被激活，是无法读出纹素的。因为默认纹理单元0是激活的，所以在只渲染一个纹理时，就不用去激活纹理单元并设置采样器值，默认就是用采样器0去纹理单元0（图层0）采集纹素颜色。 设置完采样器的值后，接下来就需要绑定纹理对象，好把相应纹理放在刚刚激活的纹理单元（图层）上。 OpenGL至少保证有16个纹理单元可供使用，也就是说可以激活从GL_TEXTURE0到GL_TEXTURE15。它们都是按顺序定义的，所以GL_TEXTURE8=GL_TEXTURE0+8，这在当我们需要循环一些纹理单元时会很有用。 其余代码和之前的源程序一样，编译运行的结果如下： 翻转图片可以看到第二张纹理上下颠倒了！这是因为OpenGL要求y轴0.0在图片底部，但是通常图片y轴0.0在图片顶部。有一些图片加载器比如DevIL在加载的时候有选项重载y原点，但是SOIL没有。所以，为了修复这个小问题，有两个选择： 改变顶点的纹理坐标属性，翻转y值（用1减去y坐标） 更改顶点着色器中对输出纹理坐标的赋值，也是用1减去y坐标：//顶点着色器 #version 330 core layout (location=0) in vec3 position; //顶点位置变量的属性位置值为0 layout (location=1) in vec3 color; //顶点颜色变量的属性位置值为1 layout (location=2) in vec2 texCoord; //顶点纹理坐标的属性位置值为2 out vec3 ourColor; out vec2 TexCoord; void main(){ gl_Position=vec4(position,1.0f); ourColor=color; TexCoord=vec2(texCoord.x,1-texCoord.y); } 编译运行后的结果如下：&nbsp; 到此，使用两张纹理的全部源程序在这里。&nbsp; 纹理加载类我们把上面主程序中加载纹理的部分单独封装成一个类：纹理加载类的头文件： #pragma once #define GLEW_STATIC #include #include #include class TextureLoader { public: GLuint LoadTexture(GLchar* texturePath); }; 纹理加载类的源文件： #include "TextureLoader.h" GLuint TextureLoader::LoadTexture(GLchar* texturePath) { GLuint texture; //生成纹理对象texture glGenTextures(1, &texture); //给纹理对象绑定目标（2D纹理） glBindTexture(GL_TEXTURE_2D, texture); int imageWidth, imageHeight; //加载纹理图像 unsigned char* image = SOIL_load_image(texturePath, &imageWidth, &imageHeight, 0, SOIL_LOAD_RGB); //生成2D纹理 glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, imageWidth, imageHeight, 0, GL_RGB, GL_UNSIGNED_BYTE, image); //释放纹理数据内存 SOIL_free_image_data(image); //设置纹理s和t方向的环绕方式 glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT); //设置纹理放大和缩写时的过滤方式（纹素过滤、mipmap边界过滤） glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); //生成多级渐远纹理 glGenerateMipmap(GL_TEXTURE_2D); //解绑纹理对象 glBindTexture(GL_TEXTURE_2D, 0); return texture; } 主程序可以直接使用该类的LoadTexture函数直接加载图片了。全部源码在这里。&nbsp; 参考文献：LearnOpenGL]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>纹理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++的输入输出]]></title>
    <url>%2F2016%2F11%2F25%2FC%2B%2B%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%2F</url>
    <content type="text"><![CDATA[C++输入输出系统的优势C语言本身有自己的输入输出方式，作为升级版的C++为何还要建立一个输入输出系统呢？原因如下： C++的输入输出系统是类型安全的，也就是说它可以自动识别输出数据的类型，如cout &lt;&lt; 5;会自动识别出要输出的数据是字符串类型，但是如果用C的话就得写成printf(&quot;%d&quot;,5);。因为C++可以自动识别类型，所以可以有效防止格式控制符与输出数据的类型不一致的错误。 C++可以通过重载运算符&lt;&lt;和&gt;&gt;，让用户能够自定义输入和输出的形式，并且可以像预定义（C++已经定义好的\自带的）的一样有效方便。 C++输入输出的书写形式简单清晰，程序代码会有更好的可读性。 【注】： 在C++中也可以使用C的printf和scanf函数。&nbsp; C++的输入输出流C++的输入输出是以字节流的形式实现的。在输入操作中，字节流从输入设备（如键盘、磁盘、网络连接等）流向内存；输出操作中，字节流从内存流向输出设备（如显示器、打印机、网络连接等）。可以看到输入输出是相对于内存的，流向内存的称为输入，从内存流出的称为输出。 C++编译系统给了一个用于输入输出的库：iostream类库。这个类库中包含了很多头文件，很多用于输入输出操作的类的声明都放在这些头文件中。&nbsp; C++用于输入输出的常用头文件 iostream：主要用于基本的输入输出操作。使用cin、cout对标准设备进行IO（输入输出）时，须包含此头文件。 fstream： 用于文件的IO操作。使用文件流对象对磁盘文件进行读写，须包含此头文件。 sstream：用于字符串流的IO操作。使用字符串流对象对内存字符串空间的IO操作，须包含此头文件。 iomanip：用于输入输出时的格式控制。在使用setw、fixed等大多数操作符进行格式控制时，须包含此头文件。 【注】： 用于字符串流IO的还有strstream头文件。strstream头文件是基于C类型字符串char*类型编写的，返回的是char*类型的字符串；而sstream是基于std::string编写的，返回的是string类型的字符串。&nbsp; C++用于输入输出的流类C++的iostream类库中当然还有很多用于输入输出的类，它们的声明都包含在上诉头文件中。常用的流类有如下：其中，ios类是所有输入输出类的抽象基类，类istream和ostream单一继承ios类，而类iostream多重继承于类istream和ostream。&nbsp; C++预定义的流对象用上诉的流类定义的对象称为流对象。C++有几个已经定义好的流对象，也就是C++自带的： cin：它是istream类的派生类istream_withassign的对象，与标准输入设备（比如键盘）相联系。 cout：它是ostream类的派生类ostream_withassign的对象，与标准输出设备（比如显示器）相联系。 cerr：它也是ostream类的派生类ostream_withassign的对象，与标准错误输出设备（比如显示器）相联系。 clog：它也是ostream类的派生类ostream_withassign的对象，也是与标准错误输出设备（比如显示器）相联系。 【注】： 可以看到cerr和clog都用来输出错误信息。区别是cerr不经过缓冲区，直接向显示器输出相关信息，所以发送给它的任何内容都立即输出；而clog中的信息存放在缓冲区中，缓冲区满后或遇上endl后才向显示器输出。&nbsp; 基本输入输出流的成员函数众所周知，C++的基本输入输出可以用&lt;&lt;（输出运算符\插入运算符）和&gt;&gt;（输入运算符\提取运算符）来实现。除此之外，还可以使用类istream和类ostream对象的一些成员函数来实现字符的输入输出： put函数put函数用于输出一个字符，形如：cout.put(&#39;A&#39;);。 它的参数可以是一个字符，也可以是字符的ASCII码，如cout.put(65);也会在屏幕上显示字符A。 get函数get函数用于读入一个字符，赋给指定的字符。形如：char ch;cin.get(ch);。get函数会把从标准输入设备（键盘）上输入的字符赋值给字符类型变量ch。 cin.get函数与&gt;&gt;有一点不同，get函数可以读入空白字符，而&gt;&gt;默认情况下是不接收空白字符的。 getline函数getline函数用于读取n-1个字符，赋给指定的字符数组，然后插入一个字符串结束标志’\n’。形如：char line[20];cin.getline(line,20,&#39;t&#39;);。如果在读取n-1个字符之前遇到指定的终止字符（比如第三个参数t），则会提前结束读取。 使用cin&lt;&lt;读取数据默认以空白字符（包括空格、tab键、回车键）作为终止字符，而cin.getline是可以读取空格的。 ignore函数ignore函数用于跳过输入的n个字符，或者在遇到指定字符时停止跳过。形如: char* str=new char(); cin.ignore(3,'z'); cin.getline(str,6,'a'); cout&lt;&lt;str&lt;&lt;endl; 如果输入bcdefghi，ignore函数会跳过头3个字符bcd，getline函数把后面的efghi这5个字符存储到str中，最后在屏幕上输出的就是efghi。 如果输入bzdefga，ignore函数在跳过3个字符之前遇到了指定的终止字符z，getline函数继续读取字符，在读取6-1个字符之前遇到了指定的终止字符a，最后输出defg。&nbsp; 重载&gt;&gt;和&lt;&lt;我们可以重载输入运算符&gt;&gt;和输出运算符&lt;&lt;，来达到我们想要的输出方式。 重载输出运算符&lt;&lt;重载的格式如下： ostream &amp;operator&lt;&lt;(ostream &amp;out, class_name&amp; obj) { out &lt;&lt; obj.item1; out &lt;&lt; obj.item2; out &lt;&lt; obj.itemn; return out; } 其中class_name是我们自定义的类名，函数内部可以根据需要输出我们想输出的内容。以后使用&lt;&lt;对象名就可以一次性输出你想输出的全部内容。举例如下： #include "stdafx.h" #include&lt;iostream> using namespace std; class Coord { public: int x, y; Coord(int i = 0, int j = 0) { x = i; y = j; } }; //重载输出运算符&lt;&lt; ostream &amp;operator&lt;&lt;(ostream &amp;out, Coord&amp; obj) { out &lt;&lt; obj.x &lt;&lt; "," &lt;&lt; obj.y; return out; } int main() { Coord a(11, 22); cout &lt;&lt; a &lt;&lt; endl; return 0; } 输出的结果如下： 11,22 重载输入运算符&gt;&gt;重载的格式如下： istream &amp;operator>>(istream &amp;in, class_name&amp; obj) { in >> obj.item1; in >> obj.item2; in >> obj.itemn; return in; } 其中class_name是我们自定义的类名，函数内部可以根据需要输入我们需要的内容。以后使用&gt;&gt;对象名就可以一次性输入需要的全部内容。举例如下： #include "stdafx.h" #include&lt;iostream> using namespace std; class Coord { public: int x, y; Coord(int i = 0, int j = 0) { x = i; y = j; } }; istream &amp;operator>>(istream &amp;in, Coord&amp; obj) { in >> obj.x; in >> obj.y; return in; } int main() { Coord a; cin >> a; cout &lt;&lt; a.x &lt;&lt; "," &lt;&lt; a.y &lt;&lt; endl; return 0; } 如果输入如下： 11 22 那么会有如下输出结果： 11,22 【注】： 上述两个重载代码虽然简单易懂，但是在工程设计上确实有点糟糕啊~-~！&nbsp; 对于文件的输入输出请参考《C++文件的输入输出》，对于字符串流的输入输出这篇文章也有简单介绍。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++IO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL4：着色器]]></title>
    <url>%2F2016%2F11%2F25%2FOpenGL4%E7%9D%80%E8%89%B2%E5%99%A8%2F</url>
    <content type="text"><![CDATA[在上一篇文章中，我们已经知道了简单的着色器和它们的使用方法，本文再详细地来看看着色器。着色器是运行在GPU上的小程序，是一种相当独立的程序，它们不能相互通信，只能通过输入和输出的方式进行沟通：在链接程序对象的时候，上一个阶段着色器的输出变量，和下一阶段的同名同类型输入变量，会链接到一起。&nbsp; GLSL概述在OpenGL中着色器是用GLSL语言来编写的，它是为图形计算量身定制的，尤其是向量和矩阵运算。 着色器的开头总是要声明GLSL的版本，用于匹配对应的OpenGL版本。接着是输入变量和输出变量、uniform和main函数。和大多数程序一样，着色器的入口点也是main函数，在main函数中我们处理所有的输入变量，并且用输出变量输出结果。 着色器一般都形如： #version version_number in type in_variable_name; in type in_variable_name; out type out_variable_name; uniform type uniform_name; int main() { //处理输入并进行一些图形操作 ... //输出处理的结果到输出变量 out_variable_name=... } 对于顶点着色器，每个输入变量也叫顶点属性（vertex attribute）。由于硬件有限，我们能够声明的顶点属性是有上限的。不同的硬件上限可能不同，想知道你的电脑最多能支持多少个顶点属性的话，可以查询一下： GLint maxVertexAttribs; glGetIntegerv(GL_MAX_VERTEX_ATTRIBS, &amp;maxVertexAttribs); cout &lt;&lt; maxVertexAttribs &lt;&lt; endl; 通常情况下至少会返回16个，大部分情况够用了。OpenGL也确保至少16个包含4分量的顶点属性可用。&nbsp; GLSL中的向量前面提到GLSL对向量提供了特别支持，下面来看一下。GLSL中的向量是一个可以包含有1、2、3或4个分量的容器，分量的类型可以是基础类型中的任意一个。根据分量类型和支持的分量个数，有如下几种向量（n代表分量数量）： vecn：包含n个float分量的默认向量 bvecn：包含n个bool分量的向量 ivecn：包含n个int分量的向量 uven：包含n个unsigned int分量的向量 dvecn：包含n个double分量的向量 除此之外，GLSL还允许对颜色使用rgba向量，对纹理使用stpq向量。 GLSL所支持的向量有很灵活的分量组成方式，叫做重组（swizzling）。重组允许像这样的语法： vec2 someVec; vec4 differentVec = someVec.xyxx; vec3 anotherVec = differentVec.zyw; vec4 otherVec = someVec.xxxx + anotherVec.yxzy; 可以利用向量现有的分量重组成其它个数的向量。 当然向量（或其分量）还可以作为另一个向量的构造参数： vec2 vect = vec2(0.5f, 0.7f); vec4 result = vec4(vect, 0.0f, 0.0f); vec4 otherResult = vec4(result.xyz, 1.0f); &nbsp; 输入与输出每个着色器都应当有输入和输出，这样才能进行数据交流和传递嘛！GLSL定义了in和out关键字来实现输入输出。 但是在顶点着色器中稍微有点不同，顶点着色器作为渲染管线上的第一个着色器，它的输入是从顶点数据中直接接收输入。为了定义顶点数据该如何管理，我们使用location这一元素指定输入变量（在用glVertexAttribPointer函数解析缓冲中的顶点数据时会用到），这样我们才可以在CPU上配置顶点属性。此外，顶点着色器还需要为它的输入提供一个额外的layout标识，这样我们才能把location链接到顶点数据，形如：layout(location=0)。【注】： 也可以不用layout(location=0)，而通过在OpenGL代码中使用glGetAttribLocation函数查询属性位置值（location），只是工作量大了些。 还有渲染管线上的最后一个着色器——像素着色器，也有点不同。它需要有一个vec4颜色输出变量，因为像素着色器需要生产一个最终输出的颜色。如果在像素着色器中没有定义输出颜色，OpenGL会把物体渲染为白色（或黑色）。 如果我们打算从一个着色器向另一个着色器发送数据，我们必须在发送方着色器中声明一个输出，在接收方着色器声明一个同名输入。当名字和类型都一样的时候，OpenGL就会把两个变量链接到一起，它们之间就可以发送数据了（这是在链接程序对象时完成的）。 接下来上个demo，让顶点着色器为像素着色器决定颜色：顶点着色器： //顶点着色器 const GLchar* vertexShaderSource = "#version 330 core\n" "layout (location=0) in vec3 position;\n" "out vec4 vertexColor;\n" "void main(){\n" "gl_Position=vec4(position.x,position.y,position.z,1.0f);\n" "vertexColor=vec4(0.5,0.0f,0.0f,1.0f);\n" "}\0"; 像素着色器： //像素着色器 const GLchar* fragmentShaderSource = "#version 330 core\n" "in vec4 vertexColor;\n" "out vec4 color;\n" "void main(){\n" "color=vertexColor;\n" "}\0"; 可以看到我们在顶点着色器中声明了一个vertexColor变量作为输出，并且在顶点着色器的main函数中为这个输出变量赋了值；然后在像素着色器中声明了一个同名同类型的输入变量，并在其main函数中令输出变量color等于该输入变量。当链接程序对象后，像素着色器的vertexColor就和顶点着色器的vertexColor链接在一起了，因为我们在顶点着色器中设置的是深红色的，所以在像素着色器中输出的结果也是深红色的：我们完成了顶点着色器向像素着色器发送数据！&nbsp; 全局变量uniform上面我们完成了一个着色器向另一个着色器发送数据，那么能不能从应用程序向像素着色器发送一个颜色呢？我们可以使用全局变量unifrom来实现。 uniform是一种从CPU中的应用向GPU中的着色器发送数据的方式。但是uniform和顶点属性不同，uniform变量是全局的，在每个着色器程序都是独一无二的，可以在渲染管线的任意一个阶段访问。而且uniform变量会一直保存它们的数据，直到它们被重置或更新。 一般我们都是在着色器代码中声明uniform变量，形如uniform vec4 ourColor。 下面上一个demo，我们通过uniform变量来设置三角形颜色。 像素着色器： //像素着色器 const GLchar* fragmentShaderSource = "#version 330 core\n" "out vec4 color;\n" "uniform vec4 ourColor;\n" "void main(){\n" "color=ourColor;\n" "}\0"; 我们在像素着色器中声明了一个uniform变量ourColor，并且把像素着色器的输出颜色设置为uniform变量的值。 下面我们到应用程序里，去给这个在像素着色器中声明的uniform变量赋值。首先需要找到这个uniform变量在着色器程序对象中的位置，我们使用glGetUniformLocation函数来完成。然后就可以使用glUniform4f函数来给uniform变量赋值了： //激活着色器程序对象 glUseProgram(shaderProgram); //找到uniform变量在着色器程序对象中的位置 GLint ourColorLocation = glGetUniformLocation(shaderProgram, "ourColor"); //给uniform变量赋值 glUniform4f(ourColorLocation, 0.0f, 1.0f, 0.0f, 1.0f); glGetUniformLocation函数第一个参数是链接后的着色器程序对象，第二个参数是我们要查找的uniform变量，返回GLint类型变量，代表找到的位置值。glUniform4f函数的第一参数是uniform变量的位置值，接下来几个参数就是R、G、B、A了。【注】： 查询uniform变量位置和给uniform变量赋值在glUseProgram前后都可以。 因为OpenGL的核心库是C库，所以它的函数不支持重载，在函数参数不同时就需要为其定义新的函数。glUniform函数就是一个例子。这个函数用后缀标识设定的uniform类型，可能的后缀有： f：函数需要1个float作为uniform变量的值 i：函数需要1个int作为uniform变量的值 ui：函数需要1个uint作为uniform变量的值 3f：函数需要3个float作为uniform变量的值 fv：函数需要一个float向量/数组作为uniform变量的值 上面我们找到了在着色器程序对象中uniform变量ourColor的位置，并给它赋值为绿色（0,1,0,1），在渲染后就会在窗口上出现一个绿色的三角形。 现在我们把效果做的再灵动点：让三角形的颜色随着时间不断变化。想一想其实很简单吧，只需要把上面程序中的绿色改为随时间变化的颜色就可以了： // 更新颜色 GLfloat timeValue = glfwGetTime(); GLfloat greenValue = sin(timeValue) / 2 + 0.5; //给uniform变量赋值 glUniform4f(ourColorLocation, 0.0f, greenValue, 0.0f, 1.0f); //激活着色器程序对象 glUseProgram(shaderProgram); glfwGetTime函数会获取运行的秒数，然后使用sin函数让颜色值在0到1之间变化，把结果存储到greenValue变量里。再使用这个不断变化（每一次循环greenValue的值都会改变）的变量去给uniform变量赋值，这样像素着色器输出的颜色值也就是在随着时间不断变化了。 所有源码在这里。 编译运行后的结果如下： &nbsp; 多个顶点属性可以看到上面的三角形内部点都是相同的颜色，或者三角形的每个顶点都是相同的颜色，这是因为三个顶点都是使用像素着色器中的输出颜色来绘制的，那三角形的这三个顶点肯定同色了，而在使用GL_TRIANGLES方式进行绘制时，三角形内部点的颜色是由三个顶点的颜色值插值计算得到，由于三个顶点同色，插值后的结果当然还是和顶点一样的颜色，所以整个三角形中的所有点就都是一个颜色。归根结底就是因为三角形的三个顶点同色造成的，现在如果我们想要三角形中点不同色，那就需要给这三个顶点赋不同的颜色值了。也就是每个顶点现在应该要有两种顶点属性：顶点位置坐标、顶点颜色： //三角形顶点的坐标和颜色 GLfloat vertices[] = { //位置坐标 //颜色 -0.5f,-0.5f,0.0f, 1.0f,0.0f,0.0f, 0.5f, -0.5f,0.0f, 0.0f,1.0f,0.0f, 0.0f, 0.5f, 0.0f, 0.0f,0.0f,1.0f }; 输入的顶点数据变了，顶点属性也增加了，所以我们还需要使用glVertexAttribPointer函数重新解析顶点数据： //告诉OpenGL如何解析显存中的顶点位置属性数据 glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 6 * sizeof(GLfloat), (GLvoid*)0); //打开顶点位置属性数组 glEnableVertexAttribArray(0); //告诉OpenGL如何解析显存中的顶点颜色属性数据 glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, 6 * sizeof(GLfloat), (GLvoid*)(3 * sizeof(GLfloat))); //打开顶点颜色属性数组 glEnableVertexAttribArray(1); 对于顶点位置坐标属性，它的location为0，由三个float组成，不需要规范化，因为从位置属性开始每隔6个float数据（3个位置坐标、3个颜色），才会再次回到位置属性，所以步长是6*sizeof(GLfloat)，第一个位置属性在缓冲中的偏移量是0；对于顶点颜色属性，它的location为1，由三个float组成，不需要规范化，颜色属性也是6个float数据一个轮回，所以步长也是6*sizeof(GLfloat)，第一个颜色属性是在3个float坐标分量（x、y、z）之后才开始的，所以偏移量是(GLvoid*)(3*sizeof(GLfloat))。 然后需要在顶点着色器中增加一个颜色输入属性，然后把颜色输出（以便传递给像素着色器）： //顶点着色器 const GLchar* vertexShaderSource = "#version 330 core\n" "layout (location=0) in vec3 position;\n" //位置变量的属性位置值为0 "layout (location=1) in vec3 color;\n" //颜色变量的属性位置值为1 "out vec3 ourColor;\n" "void main(){\n" "gl_Position=vec4(position,1.0f);\n" "ourColor=color;\n" "}\0"; 接着在像素着色器接收颜色，并把它赋值给输出颜色变量： //像素着色器 const GLchar* fragmentShaderSource = "#version 330 core\n" "in vec3 ourColor;\n" "out vec4 color;\n" "void main(){\n" "color=vec4(ourColor,1.0f);\n" "}\0"; 这样我们就能给三角形三个顶点赋不同的颜色值了，并且三角形内部的点会由三个顶点颜色插值得到。 全部源码在这里。 编译运行后的结果如下：&nbsp; 自定义着色器类从上面的程序里可以看到，主函数main太庞杂了，我们希望减轻main函数的负担，把有关着色器的内容拿出来，单独封装成一个类，用于读取、编译、管理着色器，也便于程序理解和移植。 前面是直接把着色器代码写到字符串里，很不方便，IDE也没法检查是否有语法错误。所以我们选择把着色器代码单独写在另一个文件里，要用的时候从文件里读出来。读文件的代码如下： //从指定路径的文件中读取着色器源码 const GLchar* shader::GetShaderSourceFromFile(const GLchar* shaderPath) { //以二进制方式打开指定路径的文件 ifstream fin(shaderPath, ios::binary); //检测是否成功打开文件 if (!fin) { cout &lt;&lt; "Cannot open input file" &lt;&lt; endl; exit(1); } //将读指针设置到文件尾 fin.seekg(0, ios::end); //读出当前文件位置，以获取文件长度 int length = fin.tellg(); //定义长度为length+1的字符串来存储文件内容 char* shaderSource = new char[length + 1]; //重新将读指针设置到文件头 fin.seekg(0, ios::beg); //读出整个文件 fin.read(shaderSource, length); //给字符串末尾加上字符串结束符'\0' shaderSource[length] = '\0'; fin.close(); return shaderSource; } 这里把读文件写在一个名为GetShaderSourceFromFile的函数里，函数返回的就是从文件里读出的着色器代码。注释很详细，就不再赘述了，关于C++的文件IO可以参考《C++文件的输入输出》。 其余的代码和之前差不多，只是关于着色器的都转移到了类里而已，全部源码在这里：&nbsp; 参考文献：LearnOpenGL]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>着色器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++文件的输入输出]]></title>
    <url>%2F2016%2F11%2F24%2FC%2B%2B%E6%96%87%E4%BB%B6IO%2F</url>
    <content type="text"><![CDATA[计算机领域的文件，其实是指存放在外部介质上的数据的集合。 如果想查找存放在外部介质上的数据，必须先按文件名找到所指定的文件，然后再从该文件中读取数据；而要把数据存储在外部介质上，必须先建立一个文件（以文件名标识），才能向它存入数据。&nbsp; 文本文件和二进制文件C++按照数据的组织形式，把文件分为文本文件和二进制文件。 文本文件文本文件又称ASCII文件，它的每个字节存放一个ASCII码，代表一个字符。 比如，对于一个整数10000，它如果按照文本形式输出到磁盘上，因为有5个数字，每个字符占一个字节，所以需要5个字节来保存这个整数。用文本形式输出时，一个字节对应一个字符，这便于对字符进行逐个处理，也便于输出字符，但是占用的存储空间较大。 二进制文件二进制文件是把内存中的数据，按照其在内存中的存储形式原样写到磁盘上存放。 比如，对于一个整数10000，它在内存中只需要两个字节就能存储10000的二进制形式，它如果按照二进制形式输出到磁盘上，当然还是在磁盘上占用两个字节就能表示出10000的二进制。用二进制形式输出数据，可以节省存储空间和转换时间，但是一个字节不能对应一个字符，无法直接以字符形式输出。对于需要暂时保存在外存上，以后又需要输入到内存的中间结果数据，常用二进制形式保存。&nbsp; C++进行文件输入输出的基本过程在C++中，无论对文本文件还是二进制文件，要进行文件的输入输出，必须首先创建一个流对象，然后将这个流对象与文件相关联，即打开文件，此时才能进行读写操作，读写操作完成后再关闭这个文件。 创建流对象 → 打开文件 → 读写操作 → 关闭文件。&nbsp; 创建流对象建立流的过程其实就是定义流类的对象。因为与文件IO有关的类fstream、ifstream和ofstream都包含在头文件fstream，所以首先需要在程序中包含此头文件：#include &lt;fstream&gt;。 接下来使用流类来定义流对象，例如： ifstream in; ofstream out; fstream both; 分别定义了输入流对象in、输出流对象out、输入输出流对象both。 其实常用的cin和cout也是流对象，只是已经在头文件iostream中事先定义好了，我们不需要再去自己定义了。&nbsp; 打开文件打开文件有两种方式：使用3个文件流类的成员函数open打开文件、在定义流对象时同时打开文件。 使用成员函数open打开文件一般形式是：文件流对象.open(文件名,打开方式); 其中文件名可以是相对路径也可以是绝对路径。 打开方式有如下选项： ios::app：打开一个输出文件，用于将数据添加到文件尾部。文件位置指针自动移到文件尾部。 ios::ate：打开一个现存文件，文件位置指针自动移到文件尾部，但数据可以写入文件中任何地方。 ios::in：打开一个文件，用于输入数据，即从文件读出数据到内存。 ios::nocreate：打开一个文件，若文件不存在，则打开失败（通常用open函数打开文件时，如果不存在则创建该文件）。 ios::noreplace：打开一个文件，若文件存在，则打开失败，不存在则新建文件。 ios::out：打开一个文件，用于输出数据，即从内存写入数据到文件。 ios::trunc：打开一个文件，若文件存在，则删除其中全部数据；若文件不存在，则新建文件。 ios::binary：以二进制方式打开一个文件，默认情况下是以文本方式打开文件。 对于ifstream对象，文件打开方式默认为ios::in；对于ofstream对象，文件打开方式默认为ios::out。 当一个文件需要多种方式打开时，可以用操作符“|”把几种方式连接在一起。例如，打开一个用于输入和输出的二进制文件： fstream mystream; mystream.open("test.dat",ios::in|ios::out|ios::binary); 定义流对象同时打开文件可以在定义文件流对象时指定文件路径，来同时打开文件。形如： ofstream out("test.dat"); 由于这种方式没有指定打开方式，所以使用的是默认打开方式，依旧是：ifstream对象为ios::in打开方式，ofstream对象为ios::out打开方式。所以上面的打开文件代码相当于： ofstream out; out.open("test.dat"); 检测打开文件是否成功执行打开文件操作后，还需要检测打开文件是否成功，如果打开失败，与文件相联系的流对象（比如上面的out）的值将是0。检测代码形如： if(!out){ cout&lt;&lt;"Cannot open file!"&lt;&lt;endl; //其它处理 ... } &nbsp; 文件读写文件打开以后，就可以进行文件读写了。但是由于数据组织方式不同，文本文件和二进制文件的读写是不一样的（二进制文件在打开时还需要显式指定ios::binary打开方式，默认是以文本方式打开）。 文本文件的读写其实和cin、cout一样，使用流对象&gt;&gt;把数据从文件输入到内存，使用流对象&lt;&lt;把数据从内存输出到文件。 下面上个demo，先建立一个输出文件，向它写入数据，然后关闭文件，在按输入方式打开它，并读取信息，保存到变量中，在屏幕上显示出来： #include "stdafx.h" #include &lt;iostream> #include &lt;fstream> using namespace std; int main() { //定义输出流对象，同时打开文件 ofstream fout("test.dat"); //检测文件是否打开成功 if (!fout) { cout &lt;&lt; "Cannot open output file!" &lt;&lt; endl; } //把一个字符串写到磁盘文件test.dat中 fout &lt;&lt; "hello!\n"; //把一个十进制整数和一个十六进制整数写到test.dat中 fout &lt;&lt; 100 &lt;&lt; ' ' &lt;&lt; hex &lt;&lt; 100 &lt;&lt; endl; //关闭文件 fout.close(); //定义输入流对象，同时打开文件 ifstream fin("test.dat"); if (!fin) { cout &lt;&lt; "Cannot open input file!" &lt;&lt; endl; } char* s=new char(); int i; int j; //从磁盘文件test.dat中读取一个字符串赋给s，读取一个整数赋给i fin >> s >> i >> j; //在屏幕上显示 cout &lt;&lt; s &lt;&lt; endl &lt;&lt; i &lt;&lt; endl &lt;&lt; j &lt;&lt; endl; fin.close(); return 0; } 编译运行后，会在该源文件同路径下，创建出一个test.dat文件，文件中内容如下： hello! 100 64 并且在屏幕上会输出如下结果： hello! 100 64 64是100的二进制。 二进制文件的读写二进制文件的读写不再是使用&gt;&gt;或&lt;&lt;，而是使用类istream和类ostream的成员函数来进行读写。 根据每次读写的数据量不同，二进制文件的读写有两种方式：一种是使用成员函数get和put；另一种是使用成员函数read和write。 使用get和put函数读写二进制文件：get函数是类istream的成员函数，put函数是类ostream的成员函数，它们每次都只是读写一个字节（字符）。 上个demo体会一下，将a到z的26个英文字母写入二进制文件，而后从该文件中读出并在屏幕上显示出来： #include "stdafx.h" #include &lt;iostream> #include &lt;fstream> using namespace std; int main() { ofstream outb("binary.dat", ios::binary); if (!outb) { cout &lt;&lt; "Cannot open output file!" &lt;&lt; endl; exit(1); //退出程序，和abort()作用一样 } char ch = 'a'; for (int i = 0; i &lt; 26; i++) { //输出字符到磁盘文件binary.dat中 outb.put(ch); ch++; } outb.close(); ifstream inb("binary.dat", ios::binary); if (!inb) { cout &lt;&lt; "Cannot open input file" &lt;&lt; endl; abort(); } while (inb.get(ch)) { //从磁盘文件中读取字符赋给ch cout &lt;&lt; ch; } inb.close(); return 0; } 编译运行后，会在该源文件同路径下，创建出一个binary.dat，文件内容是26个小写英文字符对应的二进制（用记事本等工具打开后二进制会转为字符，所以用记事本打开看到的不是二进制，而是26个英文字母），并且屏幕上回输出如下结果： abcdefghijklmnopqrstuvwxyz 使用read和write函数读写二进制文件： read函数是类istream的成员函数，形如inb .read(char* buf,int len);。用于从与输入文件流对象inb向关联的磁盘文件中，读取len个字节（或遇到EOF提前结束），并把它们存放在字符指针buf所指的一段内存空间内。如果在len个字节（字符）前被读出前，就到达了文件尾，则read函数停止执行。 write函数是类ostream的成员函数，形如outb.write(const char* buf,int len); 。用于将字符指针buf所给出地址开始的len个字节的内容，不加转换地写到与输出文件流对象outb相关联的磁盘文件中。 再上个demo体会一下，将课程结构体以二进制形式一次性存放到磁盘文件中： #include "stdafx.h" #include &lt;iostream> #include &lt;fstream> using namespace std; //课程结构体 struct Course { char courseName[20]; int score; }; int main() { //课程结构体实例 Course course = { "computer",100 }; ofstream outb("binary2.dat", ios::binary); if (!outb) { cout &lt;&lt; "Cannot open output file!" &lt;&lt; endl; exit(1); } //将课程结构体实例写入磁盘文件binary2.dat中 outb.write((char*)&amp;course, sizeof(course)); outb.close(); //课程结构体实例，用于存储从文件中读取的数据 Course inCourse; ifstream inb("binary2.dat", ios::binary); if (!inb) { cout &lt;&lt; "Cannot open input file!" &lt;&lt; endl; exit(1); } //从磁盘文件binary2中读取数据存入inCourse结构体实例中 inb.read((char*)&amp;inCourse, sizeof(inCourse)); cout &lt;&lt; "courseName:" &lt;&lt; inCourse.courseName &lt;&lt; ' ' &lt;&lt; "score:" &lt;&lt; inCourse.score &lt;&lt; endl; inb.close(); return 0; } 编译运行后，在源文件同路径下回创建出一个binary2.dat文件，用记事本打开结果如下： computer d 因为用记事本打开时会自动将二进制转换为字符，而数字100对应的二进制正好是字母d的ASCII码，所以数字100转变成了字母d。并且屏幕上会出现如下结果： courseName:computer score:100 检测读文件是否结束在文件结束的地方有一个标志位，记为EOF（end of file）。采用文件流方式读文件时，使用成员函数eof可以检测到这个结束符： ifstream in; ... if(!in.eof()){ ... } 函数eof如果返回值为0，未达到文件尾；如果返回值非0，表示到达文件尾。 其实前面在使用get函数读文件时： while (inb.get(ch)) { //从磁盘文件中读取字符赋给ch cout &lt;&lt; ch; } get函数在读取字符的同时，也通过返回值是否为0，判断是否到达文件尾。 二进制文件的随机读写文本文件一般是顺序读写的，但二进制文件还支持从任意位置开始读写，即随机读写。主要是靠设置读指针和写指针的位置来实现。 类istream提供了3个成员函数来设置读指针位置（下面的g是get的缩写）： tellg()：返回读指针的当前位置 seekg(long position)：将读指针设置到指定的position位置（以字节为单位） seekg(long offset,int way)：以参照位置way为基准移动offset个字节 参照位置有如下选项： ios::beg：文件开头位置 ios::cur：当前文件指针位置 ios::end：文件末尾位置 例如inf.seekg(-50,ios::cur);，表示使读指针以当前位置为基准向前（文件开头方向）移动50个字节。 类ostream也提供了3个成员函数来设置写指针位置（下面的p是put的缩写）： tellp()：返回当前写指针的位置 seekp(long position)：将写指针设置到指定的position位置（以字节为单位） seekp(long offset,int way)：以参考位置way为基准移动offset个字节 参照位置选项与上面的相同，不赘述了。 把读指针位置设置为文件尾ios::end，再使用tellg函数可以获得整个文件的长度： fin.seekg(0, ios::end); int length = fin.tellg(); 知道了整个文件的长度，再使用read函数就可以一次性读出整个文件。上个demo，现在已经有一个binary.dat文件，文件内容如下： abcdefghijklmnopqrstuvwxyz ABC 实现代码如下： #include "stdafx.h" #include&lt;iostream> #include&lt;fstream> using namespace std; int main() { ifstream fin("binary.dat", ios::binary); //设置读指针到文件尾 fin.seekg(0, ios::end); //读出当前读指针的位置，从而得到文件长度 int length = fin.tellg(); //新建字符串str存储文件内容。 //需要在读出所有内容后给字符串加'\0'，所以长度设为length+1 char* str = new char[length + 1]; //把读指针重新设到文件头 fin.seekg(0, ios::beg); //一次性读出整个文件 fin.read(str, length); //给str加上字符串结束符'\0' str[length] = '\0'; cout &lt;&lt; str &lt;&lt; endl; fin.close(); } 编译运行后，在屏幕上的输出结果如下： abcdefghijklmnopqrstuvwxyz ABC 【注】： 成员函数get、put、read、write函数不仅可以用于二进制文件，也可以用于文本文件 当要将文件完整读入时，最好使用二进制方式打开ios::binary，因为如果以文本文件方式打开的话，文件流会把一些非字符的数据过滤掉，我们将读取不到那些内容。&nbsp; 关闭文件输入输出操作完成后，应该将文件关闭，否则可能丢失数据。所谓关闭，其实是将所打开的磁盘文件与流对象断开联系，关闭后流对象就不能再对该文件进行输入输出操作了。使用close成员函数实现，形如： in.close(); out.close(); inb.close(); outb.close(); &nbsp; C++字符串流的输入输出C++字符串流的输入输出与文件IO类似。文件IO是内存和磁盘文件之间传递数据，而字符串流IO是内存和字符串流之间传递数据。 字符串流IO主要由三个类来实现： istringstream类：从字符串流向内存输入数据 ostringstream类：从内存向字符串流输出数据 stringstream类：既可以向字符串流读数据也可以写数据 【注】： string字符串其实也是内存 它们都包含在sstream.h头文件中。 也是通过字符串流对象配合&gt;&gt;和&lt;&lt;运算符来进行IO操作： string line=&quot;ourStr&quot;; istringstream ins(line); string str; ins&gt;&gt;str; string line; ostringstream outs; outs&lt;&lt;&quot;ourStr&quot;; cout&lt;&lt;outs.str()&lt;&lt;endl;]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>文件IO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL3：着色器画三角形]]></title>
    <url>%2F2016%2F11%2F19%2FOpenGL3%E7%9D%80%E8%89%B2%E5%99%A8%E7%94%BB%E4%B8%89%E8%A7%92%E5%BD%A2%2F</url>
    <content type="text"><![CDATA[在高版本的OpenGL中绘制图形，这个过程主要是由OpenGL的图形输送管道来完成的。&nbsp; 图形输送管道图形输送管段（pipeline，管线）接收一组3D坐标，然后把它们转变为屏幕上的有色2D像素。图形输送管道可以被划分为几个阶段，每个阶段的输出都是下一个阶段的输入。所有这些阶段都是高度专门化的，它们能够简单地并行执行。由于它们的可并行执行的特征，当今大多数显卡都有成千上万的小处理核心，在GPU上为管线上的每个阶段运行各自的小程序，从而在图形输送管道中快速处理这些它的以及几何运算。这些小程序就叫做着色器（如今CPU最多只有8核，而GPU却有很多很多简单的核，可以大量并行执行那些不是很复杂的计算，比如绘制图形所用的几何运算。关于GPU可以参考这下面这个视频）。 有些着色器允许开发者自己配置，用我们自己写的着色器替换默认存在的。这样我们就可以更细致地控制输送管道的特定部分了。因为它们运行在GPU上，所以会节约宝贵的CPU时间。着色器是用OpenGL着色器语言GLSL（OpenGL Shading Language）写的。 图形输送管道的每个阶段如下（蓝色部分代表的是我们可以自定义的着色器）：如你所见，图形输送管道包含很多部分，从最初的顶点数据转变为最终的有色像素。 现在我们用数组的形式传递3个3D坐标作为图形输送管道的输入，它们用来表示一个三角形，这个数组叫做这个三角形的顶点数据（Vertex Data）。除此之外，简单的顶点数据还通常包括顶点的颜色值。 【注】： 为了让OpenGL知道我们的坐标和颜色值到底构成了什么，OpenGL需要我们去给出提示，希望这些数据所表示的是什么类型，是一些列的点？一些列的三角形？还是一条线？做出的这些提示叫做基本图形（primitives）。任何一个绘制命令的调用都必须把基本图形类型传递给OpenGL。这是基本图形类型中的几个：GL_POINTS（点）、GL_TRIANGLES（三角形）、GL_LINE_STRIP（连续折线）。 下面简单介绍一下图形输送管道的每个部分： 顶点着色器（vertex shader）阶段把一个单独的顶点作为输入。主要目的是把3D坐标转换为另一种3D坐标（后续文章会与解释），同时允许我们队顶点属性进行一些基本处理。顶点着色器阶段会把表示基本图形的所有顶点输出到基本图形组装阶段，作为它的输入。 基本图形组装（primitive assembly）阶段把所有输入的点作组装为特定的基本图形的形状（本文例子是一个三角形）。基本图形组装阶段的输出会传递给几何着色器。 几何着色器（geometry shader）可以通过产生新顶点构造出新的（或是其他的）基本图形，来生成其他形状。 细分着色器（tessellation shader）可以把给定的基本图形细分成更多小基本图形。这样我们就能在物体更接近玩家的时候通过创建更多的三角形，用这种方式创建出更平滑的视觉效果。 像素化（rasterization，也叫光栅化） 阶段会把基本图形映射为屏幕上相应的像素，生成供像素着色器使用的fragment。并且在像素着色器允许之前，会执行裁剪（clipping）。裁剪会丢弃超出视图以外的那些像素，来提升执行效率。 【注】： OpenGL中的一个fragment是OpenGL渲染一个独立像素所需的所有数据。其实就是带有一些额外信息的像素，由于带有额外信息，OpenGL就没有给它取名叫像素。 像素着色器的主要目的是计算一个像素的最终颜色，这也是OpenGL高级效果最终产生的地方。通常，像素着色器包含用来计算像素最终颜色的3D场景的一些数据（比如关照、阴影、关的颜色等等）。在所有颜色值确定后，最终它会传到下一个alpha测试和混合（blending）阶段。 alpha测试和混合阶段检测像素的深度值和stencil值，来检查一个像素是否被遮挡了，从而做出取舍（即如果被遮住了就不画这个像素了）。还会查看alpha值（透明度）和物体之间的混合。所以即使在像素着色器中计算出来了一个像素将要输出的颜色，最后的像素颜色在渲染多个三角形的时候也可能会再发生变化，因为有遮挡和alpha混合存在。 应该说这个图形输送管道还是挺复杂的，包含很多要配置的部分。但是大多数场合，我们必须做的只是顶点和像素着色器。几何着色器和细分着色器是可选的，通常使用默认的着色器就行了。&nbsp; 在开始绘制之前，我们必须给OpenGL输入一些顶点数据。 顶点输入OpenGL是一个3D图形库，所以我们在OpenGL中指定的坐标都是3D的，即包括x、y、z坐标。因为我们想要渲染一个三角形，所以我们需要指定三角形的3个顶点的3D坐标。为了简单起见，这里我们直接使用标准化设备坐标（x、y、z都在-1到1之间），存储在GLfloat数组中： //三角形顶点坐标 GLfloat vertices[] = { -0.5f,-0.5f,0.0f, 0.5f,-0.5f,0.0f, 0.0f,0.5f,0.0f }; 由于我们要画的是一个2D的三角形，所以就把3个顶点的z坐标都设为0了，即每个顶点的深度（depth）都是一样的，看上去就像是2D的。 【注】： 标准化设备坐标会通过glViewport函数提供的数据，进行视口变换，最后转换为屏幕空间坐标。这通常都是在顶点着色器中进行的，这些屏幕空间坐标最终会作为像素属性输入到像素着色器。 现在有了这样的顶点数据，我们需要把它输入发送给GPU，从而进入顶点着色器阶段。 在发送顶点数据之间，我们需要建立一个顶点数组对象VAO（vertex array object），用于记录顶点数据的存储和如何使用的细节信息。后面我们会告示OpenGL这些顶点数据是怎么存储的以及GPU应该怎么读出来，当我们需要用相同的顶点数据画多个三角形时，就不用每次都去指定这些顶点数据的存储方式和使用方式了，很节省效率： //生成顶点数组对象VAO，记录数据的存储和如何使用的细节信息 GLuint VAO; glGenVertexArrays(1, &amp;VAO); 由于CPU把数据发送到显卡相对较慢，但是GPU中顶点着色器却能很快获得顶点。如果从CPU一个顶点一个顶点地发送到显卡，无疑会造成GPU等待，浪费资源。所以我们希望把多个顶点数据一起从CPU发送到显存，这里我们使用顶点缓存对象VBO（vertex buffer object）来实际负责这些顶点数据的存储（包括存储空间和存储过程），它会在GPU内存上存储大批顶点： //生顶点缓冲对象VBO，负责实际数据的存储 GLuint VBO; glGenBuffers(1, &amp;VBO); 正如《OpenGL1：OpenGL概述及环境配置》一文里“OpenGL中的对象”中所诉，接下来要做的就是给顶点数组对象绑定目标（顶点数组）： //给顶点数组对象绑定目标(顶点数组，不需要参数) glBindVertexArray(VAO); 再给顶点缓冲对象绑定目标（数组内存）： //给顶点缓冲对象绑定目标（数组内存） glBindBuffer(GL_ARRAY_BUFFER, VBO); 已经在显卡上开辟好存储这些顶点的空间了，接下来我们需要顶点数据复制到显存缓冲中： //把顶点数据复制到显卡的缓冲内存中 glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW); glBufferData函数用来把用户定义的数据复制到当前绑定缓冲里。它的第一个参数是我们希望复制到上面的缓冲类型，这里是数组缓冲这种类型GL_ARRAY_BUFFER；第二个参数是我们希望传递给缓冲的数据大小（字节）；第三个参数是我们希望发送的真实数据；第四个参数指定了我们希望显卡如何管理给定的数据，有三种形式： GL_STATIC_DRAW：数据不会或几乎不会改变。 GL_DYNAMIC_DRAW：数据会被改变很多。 GL_STREAM_DRAW：数据每次绘制时都会改变 我们要画的三角形的位置数据不会改变，每次渲染调用时都保持原样，所以它使用的类型最好是GL_STATIC_DRAW。如果一个缓冲中的数据将频繁被改变，那么使用的类型就是GL_DYNAMIC_DRAW或GL_STREAM_DRAW，因为这样能确保图形卡把数据放在高速写入的内存部分。&nbsp; 告诉OpenGL如何读取顶点数据到现在我们只是把一堆顶点数据放到了显存的缓冲区中了，但是显卡并不知道这些顶点数据是怎么存放的，该连续多少个字节的数据才表示一个顶点坐标？不知道这些信息就无法用OpenGL函数一个一个地分开读出顶点数据。 下面我们使用 glVertexAttribPointer函数来告知OpenGL如何识别解析显存缓冲中的顶点数据： //告诉OpenGL如何识别显存中的顶点数据 glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(GLfloat), (GLvoid*)0); 它的第一个参数指定我们要配置哪一个顶点属性。因为我们在后面的顶点着色器中使用了layout (location=0)来定义顶点属性的位置值为0，所以这里要把这个参数设为0。 第二个参数指定每个属性数据由几个分量组成。因为在本例中，顶点着色器中就一个坐标属性，由3个float组成，所以这个参数设为3（这个参数的值只能是1、2、3、4中的一个）。 第三个参数指定属性分量的数据类型。由于本例中每个顶点位置由3个float组成，所以该参数设为float。 第四个参数指定是否希望数据被规格化。如果设置为GL_TRUE，所有有符号型数据会被映射到-1到1之间，无符号型数据会被映射到0到1之间。这里我们把它设为GL_FLASE。 第五个参数叫做步长，表示相同属性每隔多少字节出现一次。当顶点属性紧密排列时，可以填0，由OpenGL代替我们计算出该值。本例中每隔3*sizeof(GLfloat)字节属性就会重复出现了，即又是x、y、z了。 最后一个参数表示当前绑定到GL_ARRAY_BUFFER缓冲对象的缓冲区中，顶点对应属性的第一个分量距离缓冲起点的偏移量，以字节为单位计算。因为最后一个参数的类型是GLvoid*，而我们的顶点数据就是从数据起点开始的，所以这里设为（GLvoid*）0。 现在已经告诉OpenGL应该怎么从缓冲中解析顶点数据了，接着需要使用glEnableVertexAttribArray函数打开顶点属性数组，让这些顶点数据可以用于渲染图形。 //打开顶点属性数组 glEnableVertexAttribArray(0); 当然，最后不要忘了解绑VBO和VAO。解绑了之后才能让它们脱离具体的目标，从而再去复用，绑定别的目标： //解绑VBO glBindBuffer(GL_ARRAY_BUFFER, 0); //解绑VAO glBindVertexArray(0); &nbsp; 顶点着色器源码顶点着色器是几个着色器中的一个，它是可编程的。现代OpenGL需要我们至少设置一个顶点着色器和一个像素着色器。 我们需要做的第一件事是用着色器语言GLSL写顶点着色器，然后编译这个着色器，这样我们就可以在接下来的程序中使用这个顶点着色器了。下面是一个非常基础的顶点着色器源码： //顶点着色器 const GLchar* vertexShaderSource = "#version 330 core\n" "layout (location=0) in vec3 position;\n" "void main(){\n" "gl_Position=vec4(position.x,position.y,position.z,1.0);\n" "}\0"; 在引号中的就是我们的顶点着色器源码，现在把它存储在一个字符串中，方便后面用着色器名字直接使用着色器。每个着色器都起始于一个版本声明，这是因为要让高版本的GLSL和OpenGL相匹配（GLSL330对应OpenGL3.3）。我们同样在后面显示地表示我们会用core profile功能。 然后就是在顶点着色器中使用in关键字声明所有的输入属性。因为现在我们只关心位置数据（position），所以我们使用in vec3 position，同时需要指定属性的索引，即layout (location = 0)，何在一起就是layout (location=0) in vec3 position;。 接下来在着色器的main函数（注意是着色器的main函数）中，我们设置顶点着色器的输出，gl_Position为内置变量（以gl前缀开头的变量一般都表示内置变量），表示顶点输出位置。我们必须把输入的位置数据赋值给预定义的gl_Position（该变量是vec4类型）： void main(){ gl_Position = vec4(position.x, position.y, position.z, 1.0); } gl_Position会作为顶点着色器的输出发送到图形输送管道的下一阶段。在后续文章会解释vec4的第4个参数为什么是1.0f。 【注】： 向量：在GLSL中一个向量最多可以有4个元素：x、y、z、w。但是z元素不是用作表达空间位置的，而是用在透视除法上。后续文章会介绍到。 这个顶点着色器应该是能想到的最简单的了，因为我们直接输入的就是标准化设备坐标，在顶点着色器里面什么都没有处理就把输入数据输出了。但是在真是应用里输入数据通常都没有在标准化设备坐标中，所以在顶点着色器中通常都需要把它们转化为标准化设备坐标，放进OpenGL的可视区域内。&nbsp; 编译着色器上面我们已经写了一个顶点着色器源码，但是为了让OpenGL能够使用它，我们必须在运行时动态编译它的源码。 通常的流程都是：创建着色器对象 → 把着色器源码附加到着色器对象 → 编译着色器 → 检测编译是否成功。 创建着色器对象使用glCreateShader函数创建着色器，参数是着色器类型： //创建顶点着色器对象 GLuint vertexShader = glCreateShader(GL_VERTEX_SHADER); 附加着色器源码到着色器对象使用glShaderSource函数把着色器源码添加到新创建的着色器对象上： //把着色器源码附加到着色器对象 glShaderSource(vertexShader, 1, &amp;vertexShaderSource, NULL); 第一个参数是着色器对象；第二个参数指定了源码中有多少个字符串，这里只有一个；第三个参数是顶点着色器真正的源码；第四个参数可以设置为NULL，表示每个字符串都没有终止，直到遇到’\0’。 编译着色器使用glCompileShader函数来编译着色器，参数是着色器对象： //编译顶点着色器 glCompileShader(vertexShader); 检测编译是否成功 //检测编译是否成功 GLint success; //编译结果 GLchar infoLog[512]; //错误信息 glGetShaderiv(vertexShader, GL_COMPILE_STATUS, &amp;success); if (!success) { glGetShaderInfoLog(vertexShader, 512, NULL, infoLog); std::cout &lt;&lt; "ERROR::SHADER::VERTEX::COMPILATION_FAILED\n" &lt;&lt; infoLog &lt;&lt; std::endl; } 首先定义一个整型success来表示是否成功编译，还需要一个存储错误消息的容器infoLog（如果有错误的话），然后用glGetShaderiv函数来检查是否编译成功了。如果编译失败，用glGetShaderInfoLog函数来获取错误信息，然后打印它。 函数glGetShaderInfoLog的第一个参数是编译失败的着色器，第二个参数是存储错误信息的数组大小，第三个参数是返回的错误信息字符串的长度，如果不需要可以为NULL，第四个参数是存储错误信息的字符数组。&nbsp; 像素着色器源码像素着色器是最终我们打算创建的用于渲染三角形的着色器。像素着色器的全部，都是用来计算像素的最后颜色输出。为了简单点，我们的像素着色器只输出橘黄色（每个颜色的强度都是在0到1之间的浮点数，三种颜色可以调配处1600万中不同颜色，颜色值的第4个参数表示alpha透明度）： //像素着色器 const GLchar* fragmentShaderSource = "#version 330 core\n" "out vec4 color;\n" "void main(){\n" "color=vec4(1.0,0.5f,0.2f,1.0f);\n" "}\0"; 像素着色器只需要一个输出变量，这个变量是一个表示最终输出颜色的vec4向量。可以用out关键字来声明输出变量，命名为color，即out vec4 color;。然后在像素着色器的main函数中给输出变量color指定橘黄色，透明度为1（不透明），即color = vec4(1.0f, 0.5f, 0.2f, 1.0f);。&nbsp; 编译像素着色器编译像素着色器的过程与顶点着色器一致，如下： //创建像素着色器对象 GLuint fragmentShader = glCreateShader(GL_FRAGMENT_SHADER); //把像素着色器源码附加到像素着色器对象 glShaderSource(fragmentShader, 1, &amp;fragmentShaderSource, NULL); //编译像素着色器源码 glCompileShader(fragmentShader); //检测是否编译成功 glGetShaderiv(fragmentShader, GL_COMPILE_STATUS, &amp;success); if (!success) { glGetShaderInfoLog(fragmentShader, 512, NULL, infoLog); std::cout &lt;&lt; "ERROR::SHADER::FRAGMENT::COMPILATION_FAILED\n" &lt;&lt; infoLog &lt;&lt; std::endl; } &nbsp; 顶点着色器和像素着色器都已经编译了，剩下的事情就是把两个着色器对象链接到一个着色器程序中，它是用来渲染的。 着色器程序着色器程序对象（shader program object）是多个着色器最后链接的版本。如果要使用刚才编译好的着色器我们必须把它们链接为一个着色器程序对象，然后当渲染物体的时候激活这个着色器程序，才能进行利用着色器进行渲染。 把着色器链接为一个程序就等于把每个着色器的输出链接到下一个着色器的输入。当然，如果你的输出和输入不匹配，那么将得到一个链接错误。 创建着色器程序对象首先需要使用glCreateShader函数创建着色器程序对象： //创建着色器程序对象 GLuint shaderProgram = glCreateProgram(); 附加链接然后需要把着色器附加到着色器程序对象上，然后链接起来： //把着色器附加到着色器程序对象上，然后链接起来 glAttachShader(shaderProgram, vertexShader); glAttachShader(shaderProgram, fragmentShader); glLinkProgram(shaderProgram); 检测是否链接成功接下来是需要检测一下链接是否成功，和检测是否成功编译类似： //检查是否链接成功 glGetProgramiv(shaderProgram, GL_LINK_STATUS, &amp;success); if (!success) { glGetProgramInfoLog(shaderProgram, 512, NULL, infoLog); std::cout &lt;&lt; "ERROR::PROGRAM::LINKING_FAILED\n" &lt;&lt; std::endl; } 删除着色器对象最后是删除着色器对象，因为它们已经被成功链接到着色器程序对象了，不再需要着色器对象了，应该释放它们： //删除着色器对象 glDeleteShader(vertexShader); glDeleteShader(fragmentShader); &nbsp; 在游戏循环中渲染三角形在顶点输入、顶点着色器、像素着色器、着色器程序对象等过程都完成后，迎来了最终的三角形渲染。 OpenGL的glDrawArrays函数为我们提供了绘制物体的能力，它使用当前激活的着色器、前面定义的顶点属性和顶点数组对象VAO来绘制基本图形。 所以我们需要先激活着色器程序对象，再绑定VAO完成顶点输入初始化，接着使用glDrawArrays函数来画三角形，最后解绑VAO： //激活着色器程序对象 glUseProgram(shaderProgram); //绑定VAO，完成顶点输入初始化 glBindVertexArray(VAO); //绘图 glDrawArrays(GL_TRIANGLES, 0, 3); //解绑VAO glBindVertexArray(0); glDrawArrays函数的第一个参数是我们打算绘制的OpenGL基本图形的类型，这里是三角形GL_TRIANGLES；第二个参数是我们打算绘制的那个顶点数组的起始位置的索引；最后一个参数是我们打算绘制多少个顶点。 当然，在退出渲染后，不要忘了清除掉顶点数组对象VAO和顶点缓冲对象VBO： //删除VAO、VBO glDeleteVertexArrays(1, &amp;VAO); glDeleteBuffers(1, &amp;VBO); &nbsp; 到此为止，我们已经完成了一个三角形的绘制，全部源码在这里。编译运行后的结果如下：&nbsp; 下面我们再来看一个，画矩形该怎么画？我们可以绘制两个三角形来组成一个矩形，事实上OpenGL主要就是绘制三角形，我们看到的很多复杂图形，包括3D图形，都是很多个小的三角形拼凑起来的。 画两个三角形的时候，如果直接用顶点去画，将需要2个三角形6个顶点： GLfloat vertices[] = { // 第一个三角形 0.5f, 0.5f, 0.0f, // 右上角 0.5f, -0.5f, 0.0f, // 右下角 -0.5f, 0.5f, 0.0f, // 左上角 // 第二个三角形 0.5f, -0.5f, 0.0f, // 右下角 -0.5f, -0.5f, 0.0f, // 左下角 -0.5f, 0.5f, 0.0f // 左上角 }; 但是这两个三角形其实有两个顶点是重合的，指定了右下角和左上角的顶点两次！一个矩形应该只有4个顶点而不是6个，这样就产生了50%的额外开销。如果我们有一个模型是大量的三角形拼凑起来的，这将会产生更大的浪费。最好的解决方案当然是每个顶点只存储一次，而在绘制的时候只需要指定打算绘制的那个顶点的索引就可以了。&nbsp; 用索引缓冲对象绘制矩形恰巧的是，OpenGL提供了用索引缓冲进行绘制的工作方式。用索引缓冲对象EBO（elements buffer object）是一个像VBO一样的缓冲，专门存储索引，OpenGL调用这些顶点的索引来绘制。 索引数组首先我们需要定义一个浮点型数组，来存储矩形的四个顶点坐标；再定义一个整型数组，来存储组成矩形的两个三角形的顶点索引： //三角形顶点坐标 GLfloat vertices[] = { 0.5f,0.5f,0.0f, 0.5f,-0.5f,0.0f, -0.5f,-0.5f,0.0f, -0.5f,0.5f,0.0f }; //顶点索引 GLuint indices[] = { 0,1,3, //第一个三角形 1,2,3 //第二个三角形 }; 索引缓冲对象接下来就是在主函数中生成索引缓冲对象EBO，负责索引数据的存储： //生成索引缓冲对象EBO，负责索引数据的存储 GLuint EBO; glGenBuffers(1, &amp;EBO); 和VBO一样，接着需要给EBO绑定目标：索引数组内存： //给索引缓冲对象绑定目标（索引数组缓冲） glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, EBO); 然后就是把索引数据复制到显卡的索引数组缓冲中了： //把索引数据复制到显卡的缓冲内存中 glBufferData(GL_ELEMENT_ARRAY_BUFFER, sizeof(indices), indices, GL_STATIC_DRAW); 【注】： 对EBO的操作还是应该在VAO绑定和解绑之间的，因为需要让VAO记录下来EBO的存储过程和细节。这样在用索引进行绘制时，还是只需要绑定VAO即可，不用再去对EBO进行一些列的绑定、复制数据等操作。 更改绘制方式因为现在是改用索引缓冲进行渲染了，所以需要把glDrawArrays函数改为glDrawElements函数： //绘图 glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0); 第一个参数指定了绘制模式；第二个参数是我们打算绘制的顶点数；第三个参数是索引的类型；最后一个参数指定索引被存储的位置（或者说是起始索引在EBO中的偏移量；如果没有使用EBO但是还想使用索引进行绘制，这里可以传递一个索引数组）。 渲染后删除EBO当然，绘制完后不要忘了删除索引缓冲对象EBO： glDeleteBuffers(1, &amp;EBO); &nbsp; 到此，我们已经绘制了一个由两个三角形组成的矩形，全部源码在这里。编译运行后的结果如下：&nbsp; 参考文献：LearnOpenGL]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>着色器画三角形</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL2：创建一个窗口]]></title>
    <url>%2F2016%2F11%2F16%2FOpenGL2%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%AA%97%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[在上一篇《OpenGL1：OpenGL概述及环境配置》中，已经说过接下来的OpenGL项目，我们将使用GLFW和GLEW相结合的方式。 头文件既然要使用GLFW和GLEW中的函数，那在我们的源文件里肯定要包含它俩的头文件： //GLEW #define GLEW_STATIC #include&lt;GL/glew.h> //GLFW #include&lt;GLFW/glfw3.h> 初始化并配置GLFW加入了头文件还不够，接下来还需要在main函数中初始化并配置GLFW： int main() { //初始化GLFW glfwInit(); //GLFW配置 glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3); //主版本号 glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3); //次版本号 glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE); // 核心开发模式 glfwWindowHint(GLFW_RESIZABLE, GL_FALSE); //窗口尺寸不可变 return 0; } 在main函数中我们首先使用glfwInit来初始化GLFW，然后可以使用glfwWindowHint来配置GLFW。glfwWindowHint的第一个参数是将要配置的选项，可以从一个枚举中选择可用的选项，这些选项带有GLFW_前缀；第二个参数是一个整数，代表我们为选项所设置的值。可用的选项和对应的值可以在GLFW文档中找到。 因为我用的是OpenGL3.3版本，所以把主版本和次版本都设为3，这会保证如果一个用户没有特定的OpenGL版本，GLFW就会运行失败。开发模式我们尽量用core-proflie核心模式，而且要求用户不可以调整窗口大小。显式地告诉GLFW我们希望是用core-profile，如果我们调用了一个OpenGL的遗留函数将会产生invalid operation错误，当我们意外地使用了不该使用的旧函数时它是一个很好的提醒。&nbsp; 创建窗口对象接下来就是创建窗口对象，有了这个窗口对象后，很多GLFW函数才会有意义： //创建能够使用GLFW函数的窗口对象（指针） GLFWwindow* window = glfwCreateWindow(800, 600, "LearnOpenGL", nullptr, nullptr); if (window == NULL) { std::cout &lt;&lt; "Failed to create GLFW window" &lt;&lt; std::endl; glfwTerminate(); return -1; } 函数glfwCreateWIndow需要窗口的宽度和高度作为它的头两个参数，第三个参数是窗口的名字，后两个参数（显示器、共享资源）可以忽略。该函数返回已创建的FLFWwindow对象的指针，在后面的其他GLFW操作会需要它。&nbsp; 设置窗口环境因为每一个窗口都必须有OpenGL或者OpenGL ES的上下文（环境），如果不给窗口指定环境，将会产生GLFW_NO_WINDIW_CONTEXT错误。这里我们使用glfwMakeContextCurrent函数指定窗口环境是当前线程的主环境： //创建窗口环境 glfwMakeContextCurrent(window); &nbsp; 初始化GLEW后面要做的就是用OpenGL函数进行渲染了。不过在之前的文章里，我们已经知道GLEW管理着OpenGL的函数指针，所以需要在调用任何OpenGL函数之前初始化GLEW： //初始化GLEW glewExperimental = GL_TRUE; //保证使用现代技术管理OpenGL机能 if (glewInit() != GLEW_OK) { std::cout &lt;&lt; "Failed to initialize GLEW" &lt;&lt; std::endl; return -1; } 注意，在初始化GLEW前我们把glewExperimental变量设置为GL_TRUE。这样可以保证GLEW使用更多的现代技术来管理OpenGL机能。如果不这么设置，它就会使用默认的GL_FALSE，这样当使用core profile时有可能会出问题。&nbsp; 设置渲染窗口在开始渲染前，需要告诉OpenGL渲染窗口的大小和位置： //设置渲染窗口位置大小 glViewport(0, 0, 800, 600); 前两个参数设置了渲染窗口的左下角位置，后两个参数是渲染窗口的宽度和高度。这里指定的是和GLFW窗口是一样大的。不过我们可以吧这个渲染窗口设置得比GLFW窗口尺寸小，这样OpenGL的渲染都会在一个更小的窗口（区域）进行显示，我们可以在OpenGL的渲染窗口viewport之外显示其他的元素。 【注】： OpenGL中处理的坐标其实是在-1到1之间，原点在显示区域正中间，比如一个被加工的点位置是（-0.5,0.5）（标准化设备坐标），通过glViewport后会把这种2D坐标映射为屏幕上的坐标（200,450）。&nbsp; 渲染循环（游戏循环）因为我们不希望程序在会在一个图像之后立即退出，然后关闭窗口，这会造成渲染的结果在屏幕上一闪而过。我们想让程序持续地绘制图像，监听用户输入知道程序被明确告知停止。为了达到这个目的，我们必须建立一个while循环，每次while循环都重新绘制（渲染）一次，直到被告知结束渲染。由于程序始终处于while循环，不会自动退出（除非循环条件不满足，即被告知结束渲染），所以渲染结果也会一直于窗口上，不会一闪而过。下面的代码是一个非常简单的游戏循环（渲染循环）： //渲染循环（游戏循环） while (!glfwWindowShouldClose(window)) { glfwPollEvents(); //检测是否有事件被触发（按键按下、鼠标移动） glfwSwapBuffers(window); //交换屏幕缓存 } glfwWindowShouldClose函数从开始便检验每一次循环迭代中GLFW窗口是否已经得到关闭提示。如果得到这样的提示，函数就会返回true，导致游戏循环终止。 glfwPollEvents函数检验是否有任何时间被触发（比如键盘输入、鼠标移动等事件），如果有就可以调用相应函数进行处理（可以通过回调函数进行设置）。而且经常都是在循环迭代前调用事件处理函数。 glfwSwapBuffers函数会交换颜色缓冲（颜色缓冲是一个GLFW窗口为每一个像素存储颜色数值的大缓存，它是在这次迭代中绘制的，也作为输出显示在屏幕上）。 【注】： 双缓冲（Double Buffer）：当一个应用以单缓冲方式绘制的时候，图像可能会产生闪烁的问题。这是因为最后的图像输出不是被立即绘制出来的，而是一个像素一个像素绘制出来的，通常是以从左到右从上到下这样的方式。由于这些图像不是立即呈现在用户面前，而是一步一步地生成结果，这就会产生很多不真实感。为了规避这些问题，窗口应用使用双缓冲的方式进行渲染。前缓冲包含最终的输出图像，它被显示在屏幕上，与此同时，所有的渲染命令绘制后缓冲。所有的渲染命令执行结束后，我们就把后缓冲交换到前缓冲，这样图像就会立即显示到用户面前了，前面提到的闪烁问题就被解决了。&nbsp; 渲染我们需要把所有的渲染命令都放在渲染循环里，因为我们打算每个循环迭代都执行所有的渲染命令。通常把渲染命令放在检查事件和交换缓冲之间： //渲染循环（游戏循环） while (!glfwWindowShouldClose(window)) { glfwPollEvents(); //检测是否有事件被触发（按键按下、鼠标移动） ... //这里是渲染命令 glfwSwapBuffers(window); //交换屏幕缓存 } 这里我们使用一个最简单的渲染命令：用指定的颜色清空屏幕。因为每个渲染迭代开始时，我们都需要清理屏幕，否则只能一直看到前一个迭代的结果： glClearColor(0.2f, 0.3f, 0.3f, 1.0f); glClear(GL_COLOR_BUFFER_BIT); 使用glClearColor函数来设置清空屏幕用的颜色。使用glClear函数清理屏幕的颜色缓冲，在这个函数中我们以缓冲位（BUFFER_BIT）指定我们希望清理哪个缓冲。可以用的位可以是GL_COLOR_BUFFER_BIT、GL_DEPTH_BUFFER_BIT和GL_STENCIL_BUFFER_BIT。因为我们现在关心的只是颜色值，所以我们只清空颜色缓冲。&nbsp; 响应输入之前的while循环是会一直运行下去的，因为没有被告知停止循环。现在我们希望在GLFW中有些控制输入的方式，当用户按下某个按键后结束渲染循环。我们可以使用GLFW的回调函数做到这点。其中有一个GLFW回调函数是KeyCallback函数，它在用户使用键盘交互的时候会被GLFW自动调用。该回调函数的原型是： void (* GLFWkeyfun)(GLFWwindow* window, int key, int scancode, int action, int mode); 按键输入回调函数的参数是一个GLFWwindow对象指针，一个代表按下按键的整型数字，按键扫描码，一个表示按键是被按下、释放还是按住的整型数字，一个代表某个标识的整数告诉你shift、control、alt或super按键是否被同时按下。每当用户按下一个按钮，GLFW都会自动调用这个函数，为该函数填充合适的参数。我们给这个按键输入回调函数随便起个名字吧，叫key_callback： void key_callback(GLFWwindow* window,int key,int scancode,int action,int mode) { if (key == GLFW_KEY_ESCAPE&amp;&amp;action == GLFW_PRESS) { glfwSetWindowShouldClose(window, GL_TRUE); } } 在我们（新创建）的key_callback函数中，我们检查被按下的按键是否是ESC键，如果是的话，就用glfwSetWindowShouldClose设置它的WindowShouldClose属性为true来关闭GLFW窗口。下一个主while循环条件不满足，则渲染循环就结束了。 还有最后一点，在使用回调函数之前，是需要先注册的，也就是得给我们的这个按键回调函数声明一下并起个名字： //注册回调函数 glfwSetKeyCallback(window, key_callback); 【注】： 除了按键回调函数外，还有许多GLFW回调函数可供于给注册我们自己的函数。 要在创建窗口之后，渲染循环之前注册回调函数。 &nbsp; 释放资源退出渲染循环后，在程序结束之前，应该释放掉由GLFW分配的资源。使用glfwTerminate函数来完成： //结束CLFW，释放由GLFW分配的资源 glfwTerminate(); 这样会清理所有资源，并正确地退出程序。&nbsp; 到此为止的所有源码在这里。编译运行后的结果是一个黑蓝绿色的窗口：按下esc键后，窗口关闭程序结束退出。&nbsp; 参考文献：LearnOpenGL]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>OpenGL窗口</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[添加数学公式mathjax]]></title>
    <url>%2F2016%2F11%2F10%2F%E6%B7%BB%E5%8A%A0%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8Fmathjax%2F</url>
    <content type="text"><![CDATA[配置方法 在Hexo\themes\transparent\layout_partial路径下新建文件mathjax.ejs（transparent是我的主题名）。打开文件写入如下代码： &lt;!-- mathjax config similar to math.stackexchange --> &lt;script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } }); &lt;/script> &lt;script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: { skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'] } }); &lt;/script> &lt;script type="text/x-mathjax-config"> MathJax.Hub.Queue(function() { var all = MathJax.Hub.getAllJax(), i; for(i=0; i &lt; all.length; i += 1) { all[i].SourceElement().parentNode.className += ' has-jax'; } }); &lt;/script> &lt;script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> &lt;/script> 打开iHexo\themes\transparent\layout_partial目录下的after_footer.ejs文件，在末尾写入如下代码：&lt;%- partial('mathjax') %> 新建一片md文章（hexo new &quot;新文章&quot;），写入如下代码：## 公式 $$J\_\alpha(x)=\sum _{m=0}^\infty \frac{(-1)^ m}{m! \, \Gamma (m + \alpha + 1)}{\left({\frac{x}{2}}\right)}^{2 m + \alpha }$$ 部署完后，打开自己的网站查看公式是否成功显示。我的显示效果如下： 关于mathjax的更多介绍和语法参见《Mathjax简介及其语法》。]]></content>
      <categories>
        <category>博客配置</category>
      </categories>
      <tags>
        <tag>mathjax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基本光栅图形生成技术]]></title>
    <url>%2F2016%2F11%2F06%2F%E5%9F%BA%E6%9C%AC%E5%85%89%E6%A0%85%E5%9B%BE%E5%BD%A2%E7%94%9F%E4%BA%A7%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[先来回顾一下图形显示的过程。&nbsp; 图形显示的过程可以看到，视频控制器是从帧缓存中读出数据不为0的单元进行显示。但是，正如图中所示，对于三角形，我们一般存储的都只是三个顶点的坐标，那么怎么根据这三个顶点的坐标得到对应的帧缓存数据呢？其实这就是图形的生成过程，从参数形式转换为点阵形式，便于光栅扫描生成相应的图形（参数形式和点阵形式可参考《图形学概述》一文中的计算机图形表示方法）。 由参数形式到点阵形式的转换就称为扫描转换。&nbsp; 从上面可以看到，图形信息是存储在帧缓存中的，其实光栅图形显示的缓存机制并不是图示的那样简单。下面来看一下： 光栅图形生成时的缓存机制 单缓存：其实光栅图形显示时的帧缓存采用两种方式：单缓存、双缓存。采用单缓存时，是在帧缓存填满之后，再由视频控制器驱动电子枪扫描形成一幅图形，接着才能再去生成下一幅图形的帧缓存（否则会覆盖破环图形数据）。这样帧缓存数据（图形点阵形式）的生成和在屏幕上扫描显示图形就是串行的。这样会降低图形的显示速率。 双缓存：现在大多采用的是双缓存，即有两个帧缓存，一幅图形在帧缓存2生成点阵数据后，再交给帧缓存1，视频控制器就可以根据帧缓存1来驱动电子枪扫描形成图形。与此同时，下一幅图形就可以在帧缓存2中再生成点阵数据。这样一来，不会覆盖破环要显示的图形数据（因为它已经转储到帧缓存1了），达到了帧缓存图形数据生成和在屏幕上扫描显示图形并行的效果。大大提高了图形显示的速率。 如下图所示：&nbsp; 下面我们先来看个简单的：直线段是怎么通过扫描转换画出来的？ 扫描转换线画图元直线段我们知道，屏幕上其实是一个一个的像素，如下图所示：想要让像素全部恰好落在直线上是很难的，我们只能去选择距离直线最近的像素点，然后用它们来近似地画出直线段（像素点是很小的，稍微不在直线上一点，肉眼是看不出来的，所以我们看到的还是一条“很直”的直线段）。 那么我们扫描转换画直线段的方法是啥呢（假设我们要画的直线段宽度是一个像素点，斜率在[0,1]之间（即0~45度））？主要有三种方法：直线方程法、DDA、中点算法。都是为了一个一个地找出直线附近的像素点。 扫描转换直线段：直线方程法 基本思想：直接根据直线的几何方程确定直线段路径上的像素位置。x坐标的值从左端点x遍历到右端点x，对应y坐标通过直线方程算出来。描点时如果发现y坐标不是整数值，需要取为离它最近的整数（如3.4取为3，3.5取为4，程序上用了一个小技巧实现：(int)(y+0.5)）。 具体代码如下： //直线段的直线方程画法。直线方程式：y=mx+b void Equation(int x0,int y0,int x1,int y1,int red,int green,int blue){ glBegin(GL_POINTS); glColor3ub(red,green,blue); //计算斜率m float m=float(y1-y0)/(x1-x0); //计算b float b=y0-m*x0; for(int x=x0;x&lt;=x1;x++){ int y=m*x+b; glVertex2d(x,int(y+0.5)); } glEnd(); } 用到的主要运算有：浮点运算、乘法、除法、取整、加法。 有计算机基础的朋友应该知道，乘除法、浮点运算的开销是很大的。画个线就这么惨，有没有开销小一点的方法呢？请看下面。 扫描转换直线段：数字差分分析法DDA（Digital Differential Analyzer）DDA算法不再直接按照直线方程求像素点，而是打上了直线斜率的主意。在直线方程法中，是根据每个点的横坐标，按直线方程求出对应的纵坐标。这是把直线上的每个点作离散处理的，忽略了直线上点的纵坐标其实是有联系的：相邻点的纵坐标正好差一个斜率。所以纵坐标不用根据方程求解了，直接从上一个点的纵坐标加一个斜率值即可。具体描述如下： 基本思想：纵坐标每次加一个斜率值。x坐标的值从左端点x遍历到右端点x，对应y坐标每次加一个斜率。描点时如果发现y坐标不是整数值，需要取为离它最近的整数（如3.4取为3，3.5取为4，程序上用了一个小技巧实现：(int)(y+0.5)）【注】：只是在描点的时候描在最近的整数点上，即(int)(y+0.5)，而不能把y值变为最近的整数值，即y=int(y+0.5)是不对的。因为每次描点都应该是在其纵坐标的真实值上，进行取整描点；如果是y=int(y+0.5)这样把纵坐标作了近似处理，那么下一个点加斜率值之后，算出来的纵坐标就不是它的真实纵坐标了。 具体代码如下： //直线段的DDA画法。直线方程式：y=mx+b void LineDDA(int x0,int y0,int x1,int y1,int red,int green,int blue){ glBegin(GL_POINTS); glColor3ub(red,green,blue); //计算斜率m float m=float(y1-y0)/(x1-x0); for(int x=x0,y=y0; x&lt;=x1; x++){ glVertex2d(x,int(y+0.5)); //四舍五入取整 y+=m; } glEnd(); } 用到的主要运算有：浮点运算、除法、加法、取整。 看出来了吧，DDA比直线方程法少了乘法运算，加快了画线速度，但是还不够好，因为还存在浮点运算和取整运算。想要更好的算法，请看下面。 扫描转换直线段：中点算法在DDA中还是存在对浮点数的取整运算，因为要描出在y方向上离直线最近的像素点。能不能不通过取整运算，直接知道哪个像素点在y方向上离直线最近呢？画个图找点灵感（直线段斜率0~45度）：图1和图2最左下角的黑点是当前已经确定的离直线最近的像素点。如果是图1这种情况，邻近的右上方（因为直线斜率0~45度）中点（图1的绿色点）在直线上方，则此时离直线最近的点应该是中点正下方的蓝色点；如果是图2这种情况，邻近的右上方中点（图2的绿色点）在直线下方，则此时离直线最近的点应该是中点正上方的蓝色点。 采用这种分类的方法（邻近的中点在直线上方还是下方），确实可以不再需要取整运算了，因为每种分类下应该取哪个整数点是确定的，通过简单的加法就能算出来（如果是图1的情况，则下一个应该描的像素点是x+1，y不变；如果是图2的情况，则下一个应该描的像素点是x+1，y+1）。问题又来了，怎么知道邻近的中点在直线上方还是下方呢？很简单，学过中学数学的朋友都知道，把中点坐标代入直线方程，如果算出来的结果0，则在直线上方。 but，把中点坐标代入直线方程？这不又要算浮点数乘法了嘛~~~。回顾在直线方程法中，之所以会出现乘法，是因为把直线上的点作离散处理的，忽略了各个点之间的联系。这里也是这个原因，因为这些中点坐标也是有联系的。如果是图1的情况，则下一个中点应该是图1中的黄色点（即相比上一个中点x+1，y不变）；如果是图2的情况，则下一个中点应该是图2中的黄色点（即相比上一个中点x+1，y+1）。直线方程是ax+by+c=0，设把中点坐标代入直线方程得到的表达式是：$d=F(M)=ax+by+c$。如果是图1的情况，因为下一个中点相比上一个中点x+1，y不变，代入直线方程很容易得到，下一个中点$d_{i+1}$和上一个中点$d_i$的联系是：$d_{i+1}=d_i+a$；如果是图2的情况，因为下一个中点相比上一个中点x+1、y+1，代入直线方程很容易得到，下一个中点$d_{i+1}$和上一个中点$d_i$的联系是：$d_{i+1}=d_i+a+b$。而图1的情况其实就是$d_{i+1} \le 0$，图2的情况其实就是$d_{i+1}\gt 0$，所以得到如下方程组：$$d_{i+1}=\begin{cases}d_i+a,&amp; d_i \gt 0 \\\\d_i+a+b,&amp; d_i \le 0 \\\\\end{cases}$$那么最初的$d_0$是多少呢？看看$d_0$的表达式$d_0=F(M)=F(x_0+1,y_0+0.5)=F(x_0,y_0)+a+0.5b$，因为点$(x_0,y_0)$在直线上，所以$d_0=a+0.5b$。但是这里又出现了浮点数0.5，能不能把它转化成整数？其实我们一直关注的都是d是大于0还是小于0，2d和d的正负性是一样的，所以我们可以给上诉方程组等号两边同时乘以2，把所有的系数都变成整数：$$\begin{array}{l}2d_0=2a+b \\\\2d_{i+1}=\begin{cases}2d_i+2a,&amp; 2d_i \gt 0 \\\\2d_i+2a+2b,&amp; 2d_i \le 0 \\\\\end{cases}\end{array}$$再把$2d_i$换成$x_i$，即$x_i=2d_i$。于是方程组变成如下：$$\begin{array}{l}x_0=2a+b \\\\x_{i+1}=\begin{cases}x_i+2a,&amp; x_i \gt 0 \\\\x_i+2a+2b,&amp; x_i \le 0 \\\\\end{cases}\end{array}$$既然可以换成$x_i$，那么当然也可以换成$d_i$啊！所以方程组还可以是下面这样：$$\begin{array}{l}d_0=2a+b \\\\d_{i+1}=\begin{cases}d_i+2a,&amp; d_i \gt 0 \\\\d_i+2a+2b,&amp; d_i \le 0 \\\\\end{cases}\end{array}$$而描点坐标的方程组也可以表示如下：$$\begin{array}{l}x_{i+1}=x_i+1 \\\\y_{i+1}=\begin{cases}y_i,&amp; d_i \gt 0 \\\\y_i+1,&amp; d_i \le 0 \\\\\end{cases}\end{array}$$【注】：参数表示下直线段两端点坐标为($x_0,y_0$)，($x_1,y_1$)。则ax+by+c=0中的$a=y_0-y_1$、$b=x_1-x_0$。且方程组中诸如2a是可以写成a+a的。 从上述方程组中可以看出中点算法下的直线段扫描转换就只剩下整数加法运算了，效率得到了很大的提升。 总结一下： 基本思想：中点算法中只存在整数加法运算。在分类情况下（下一格中点在直线上方还是下方），下一个像素点坐标可以直接通过上一个点坐标做加法得到；同时下一个中点代入方程值也可以在分类情况下，直接通过上一个中点代入方程值做加法得到。【注】：上面只是研究了直线斜率0~45度的情况，其实其它斜率也是同样的研究方法。不再赘述，结论如下： 具体代码如下： //直线段的中点算法。直线方程ax+by+c=0 void MidPointLine(int x0,int y0,int x1,int y1,int red,int green,int blue){ glBegin(GL_POINTS); glColor3ub(red,green,blue); //初始化线段方程中的a、b int a=y0-y1; int b=x1-x0; //中点公式当中的d=d+dPlusPart1 int dPlusPart1; int dPlusPart2; int d; int y=y0; int x=x0; //计算斜率 float k=float(y1-y0)/(x1-x0); int type=0; if(k>=0&amp;&amp;k&lt;=1) type=1; else if(k>1) type=2; else if(k>=-1&amp;&amp;k&lt;0) type=3; else type=4; switch(type){ //斜率大于0小于1 case 1: dPlusPart1=a+a; dPlusPart2=a+a+b+b; d=a+a+b; for(;x&lt;x1;x++){ glVertex2d(x,y); if(d&lt;0){ y++; d+=dPlusPart2; } else{ d+=dPlusPart1; } } break; //斜率大于1 case 2: d=a+b+b; dPlusPart1=a+a+b+b; dPlusPart2=b+b; for(;y&lt;y1;y++){ glVertex2d(x,y); if(d>0){ x++; d+=dPlusPart1; } else{ d+=dPlusPart2; } } break; //斜率大于-1小于0 case 3: d=a+a-b; dPlusPart1=a+a-b-b; dPlusPart2=a+a; for(;x&lt;x1;x++){ glVertex2d(x,y); if(d>0){ y--; d+=dPlusPart1; } else{ d+=dPlusPart2; } } break; //斜率小于-1 case 4: d=a-b-b; dPlusPart1=a+a-b-b; dPlusPart2=-b-b; for(;x&lt;x1;x++){ glVertex2d(x,y); if(d>0){ y--; d+=dPlusPart1; } else{ d+=dPlusPart2; } } break; default: break; } glEnd(); } 用到的主要运算有：整数加法。 为了方便理解，举例如下： 再来看个稍微复杂点的：圆弧是怎么通过扫描转换画出来的？ 扫描转换线画图元圆弧扫描转换圆弧也是把圆弧的参数方程转换为一个一个的像素点。不过对于圆这种东西，已经对称得不能再对称了，不利用它的对称性不浪费嘛~-~。利用圆的对称性，我们只需要画出1/8圆弧（一般研究逆时针45~90度的圆弧）就可以了，剩下的7/8都可以通过x对称或y对称得到。既然说到了对称，那肯定是要把圆心放在原点才好对称啊！那如果要画的圆心不再原点怎么办？平移到原点呗（平移会在《图形几何变换》一文中讲到）。那如何扫描转换这段圆弧呢？主要有三种方法：方程法、中点算法、多边形逼近法。 扫描转换圆弧：方程法和直线扫描转换方程法原理一致，把(x,y)一个一个算出来。根据圆方程不同，大致分为以下两种方式： 这方法不说了，效率很着急！ 扫描转换圆弧：中点算法和直线段扫描转换的中点算法原理一致。先画个图找点思路：哪个点离圆弧最近呢？如果是图中黑色圆弧的情况，即中点M在圆弧外面，则M的竖直方向上，离圆弧最近的点是正下方的SE点；如果是图中红色圆弧的情况，即中点M在圆弧里面，则离圆弧最近的点是正上方的E点。而中点在圆弧外面其实就是中点代入圆方程值d大于0，中点在里面就是中点代入方程值d小于0。那么圆弧是不是和直线段一样，中点代入方程值d也可以由上一个值加一个常量得到呢？ 答案是当然的。看上图（圆方程：$x^2+y^2-R^2=0$）如果是红色圆弧的情况，那么下一个中点坐标x+1，y不变，即d增量是$2x_M+1$，但是这里$x_M$是中点的坐标，应该把它换算成圆弧上点的坐标（因为中点算法的目的就是避开中点坐标，并没有求出中点坐标具体是多少，而只是关注中点代入方程的结果值。也就是说在整个过程里中点坐标$(x_M,y_M)$是多少不得而知，所以就得把它换算成$x_i$，即上一个圆弧上点的坐标，这个我们是知道的。具体可以参考程序进行理解），如果点P的坐标是(x,y)，那么$x_M=x+1$，所以d的增量是2x+3；如果是黑色圆弧的情况，那么下一个中点坐标x+1，y-1，即d增量是$2x_M-2y_M+2$，同样的道理，$x_M=x+1，y_M=y-0.5$，所以d的增量是2x-2y+5。那么d的初始值$d_0$是多少呢？因为$d_0=(x_0+1)^2+(y_0-0.5)^2-R^2$且点($x_0,y_0$)=(0,R)，所以$d_0=1.25-R$。整理一下，有如下方程式：$$\begin{array}{l}x_{i+1}=x_i+1 \\\\y_{i+1}=\begin{cases}y_i,&amp; d \le 0 \\\\y_i-1,&amp; d \gt 0 \\\\\end{cases} \\\\d_{i+1}=\begin{cases}d_i+2x_i+3,&amp; d_i \le 0 \\\\d_i+2x_i-2y_i+5,&amp; d_i \gt 0 \\\\\end{cases} \\\\d_0=1.25-R \\\\\end{array}$$但是很可恨啊，上面存在1.25这个浮点数，所以仿照前文直线段的中点算法中对浮点数的处理，可以把上诉有关d的方程都在等号两端乘以4，转换为整数。再令$a_i=4d_i$，再令$d_i=a_i$，得到如下方程组：$$\begin{array}{l}x_{i+1}=x_i+1 \\\\y_{i+1}=\begin{cases}y_i,&amp; d \le 0 \\\\y_i-1,&amp; d \gt 0 \\\\\end{cases} \\\\d_{i+1}=\begin{cases}d_i+8x_i+12,&amp; d_i \le 0 \\\\d_i+8x_i-8y_i+20,&amp; d_i \gt 0 \\\\\end{cases} \\\\d_0=5-4R \\\\\end{array}$$but，上面又出现了$8x_i$这些乘法，不过由于这是像素点的坐标，相邻点之间具有很明显的常量联系，所以可以仿照上面的原理，把它们转化为加法。令$E_i=8x_i+12，SE_i=8x_i-8y_i+20$，与$d_i$同样的推理过程（不再赘述），会得到如下方程组：$$\begin{array}{l}x_{i+1}=x_i+1 \\\\y_{i+1}=\begin{cases}y_i,&amp; d \le 0 \\\\y_i-1,&amp; d \gt 0 \\\\\end{cases} \\\\d_{i+1}=\begin{cases}d_i+E_i,&amp; d_i \le 0 \\\\d_i+SE_i,&amp; d_i \gt 0 \\\\\end{cases} \\\\E_i=8x_i+12 \\\\SE_i=8x_i-8y_i+20 \\\\E_{i+1}=E_i+8 \\\\SE_{i+1}=\begin{cases}SE_i+8,&amp; d_i \le 0 \\\\SE_i+16,&amp; d_i \gt 0 \\\ \end{cases} \\\\d_0=5-4R \\\\E_0=8x_0+12=12 \\\\SE_0=8x_0-8y_0+20=20-8R \\\\\end{array}$$ 总结一下： 基本思想：圆弧扫描转换的中点算法也只存在整数加法运算。在分类情况下（下一格中点在圆弧里面还是外面），下一个像素点坐标可以直接通过上一个点坐标做加法得到；同时下一个中点代入方程值也可以在分类情况下，直接通过上一个中点代入方程值做加法得到。【注】：上面只是研究了逆时针45度到90度的圆弧，其他圆弧可以通过坐标对称得到。 具体代码如下：//圆弧的中点算法 void MidPointCircle(int R,int red,int green,int blue,int centre_x=0,int centre_y=0){ glBegin(GL_POINTS); glColor3f(red,green,blue); //初始化中点算法的d,即d int d=5-4*R; int x=0; int y=R; //初始化E和SE int E=12; int SE=20-8*R; //定义八分之一圆弧x的最大值 float xMax=R*1.414/2; for(;x&lt;=xMax;x++){ glVertex2d(x+centre_x,y+centre_x); glVertex2d(-x+centre_x,y+centre_x); glVertex2d(x+centre_x,-y+centre_x); glVertex2d(-x+centre_x,-y+centre_x); glVertex2d(y+centre_x,x+centre_x); glVertex2d(-y+centre_x,x+centre_x); glVertex2d(y+centre_x,-x+centre_x); glVertex2d(-y+centre_x,-x+centre_x); if(d&lt;=0){ d+=E; E+=8; SE+=8; } else{ y--; d+=SE; E+=8; SE+=16; } } glEnd(); } 扫描转换圆弧：多边形逼近法平时生活学习中，我们都知道正多边形边数越多，就会越像一个圆。多边形逼近法就是源自于此：根据已知的圆半径（圆心在原点），求出多边形的各个顶点，再依次连起来就像一个圆了。 那么根据什么规则来求多边形顶点呢？主要有两种，一种是把多边形作为圆的内接正多边形，另一种是把多边形作为与圆等面积且圆心重合的正多边形。如下图所示： 内接正多边形逼近法：点$P_i$的坐标如下：$$\begin{array}{l}x_i=R \cos \theta_i \\\\y_i=R \sin \theta_i \\\\\end{array}$$点$P_{i+1}$的坐标如下：$$\begin{array}{l}x_{i+1}=R \cos (\theta_i+\alpha) \\\\y_{i+1}=R \sin (\theta_i+\alpha) \\\\\end{array}$$用三角变化可以得到如下矩阵方程式：$$\begin{array}{c c c c}\begin{pmatrix}x_{i+1} \\\\y_{i+1} \\\\\end{pmatrix}&amp;=&amp;\begin{pmatrix}\cos \alpha &amp; -\sin \alpha \\\\\sin \alpha &amp; \cos \alpha \\\\\end{pmatrix}&amp;\begin{pmatrix}x_i \\\\y_i \\\\\end{pmatrix}\end{array}$$其中，$\alpha$是正多边形对应的圆心角，是一个常数（为什么是常数后文会讲到）。所以$\sin \alpha，\cos \alpha$只需要在开始时计算一次，之后的每一个顶点坐标都只需要4次乘法即可。 那么圆心角到底是多少呢？也就是正多边形多少条边合适？当然是边数越多越好，越像圆。但是计算机计算能力有限，不可能边数搞得特别特别大，而且在实际问题中经常也不需要那么圆，有时候可能稍微像圆一点就可以，有时候可能需要再圆一点。到底要多圆就根据实际问题能够接受的多大的误差而定了。我们经常用最大逼近误差d来表示这个能接受的最大误差。 最大逼近误差d是什么玩意？词穷了，我也不知道咋描述能简单通俗易懂，所以直接看图吧！d就是边中点到另一点（其半径与圆弧交点）的距离。也就是说这个d通常是已知的，那么圆心角就能算出来了（计算过程不再赘述了~），即$\alpha=2\arccos(R-d)/R$。总结一下： 基本思想：根据最大逼近误差d求出圆心角，再由圆心角和半径求出多边形各顶点的坐标，把各顶点依次连接起来（使用OpenGl画多边形的方法），就成了一个近似圆。 具体代码如下： //圆弧的正内接多边形逼近法 void CircleIn(float MaxError,float R,int red,int green,int blue,int centre_x=0,int centre_y=0){ glBegin(GL_LINE_LOOP); glColor3f(red,green,blue); //初始化正内接多边形对应圆心角 float alpha=2*acos((R-MaxError)/R); //初始化边数，即顶点个数 int n=2*3.14/alpha; float cosAlpha=cos(alpha); float sinAlpha=sin(alpha); float x=0; float y=R; float xTemp; float yTemp; for(int i=0;i&lt;n;i++){ glVertex2d(x+centre_x,y+centre_y); xTemp=x; yTemp=y; x=cosAlpha*xTemp-sinAlpha*yTemp; y=sinAlpha*xTemp+cosAlpha*yTemp; } glEnd(); } 等面积正多边形逼近法：在圆内接正多边形逼近法中，正多边形是内接于圆的，总感觉上面画出来的正多边形比圆要小，毕竟是内接嘛~那么有没有和圆差不多大的？减少一点这种差距。那干脆找一个面积和圆一样大，且圆心重合的正多边形把，这就是等面积正多边形逼近法（参见前面的“等面积多边形”一图）。 由于圆面积和正多边形面积相等，所以相同圆心角对应的扇形（圆的一部分）和三角形（正多边形的一部分）面积应该相等，如下图所示：图中的扇形ODCE和三角形$OP_iP_{i+1}$面积应该相等，再结合给定（在圆的参数方程中给定的）的圆半径R和最大逼近误差d，可以算出圆心角$\alpha$和正多边形半径$OP_i$的长度。知道了正多边形的圆心角和半径长度，自然就能算出正多边形个顶点的坐标了（求法和内接正多边形一致）。 基本原理和具体代码和内接正多边形逼近法类似，不再赘述了。 【注】：可以看出，中点算法是基本线画图元的高效扫面转换算法，因为算法中只用到了整数加法运算，但中点算法是有条件的：所要画的图元必须具有正负划分性，像在直线上方就是正，下方就是负；在圆外面就是正，里面就是负。像Bezier曲线这种可以自交没有正负划分性的曲线，是无法用中点算法画出来的。&nbsp; 上面研究的都是直线、圆弧这些线画图元，那么那些填充图元（包括边界和其内部的图形）又是怎么画出来的呢？主要有两种方法：扫描转换（参数→点阵）、填充（点阵→点阵）。先来看个最简单的：扫描转换矩形。&nbsp; 扫描转换填充图元矩形既然是扫描转换，那填充图元——矩形的参数形式提供了哪些参数呢？有两个：左下角坐标、右上角坐标。这足以定义一个填充的矩形了。 扫描转换时，只需要从左下角开始向右（x增大）、向上（y增大）一个一个描像素点，知道右上脚为止。代码就是x和y增大的两重循环，这里不再赘述了。&nbsp; 矩形可以这么画，但是其它多边形呢？当然要另寻他法了~~~那矩形也是多边形，为何不归为多边形画法，而要单独分出来呢？这是因为矩形的画法相当简单，没有必要去用其他多边形的那些复杂画法，而且矩形在计算机中相当常见，所以需要把这简单的单独分出来，不能把简单的搞复杂了~-~。下面来看看除了矩形以外的其他多边形是怎么画出来的。 扫描转换填充图元多边形扫描转换多边形其实就是把多边形的顶点表示形式转换成点阵表示形式。在介绍画法之前，先来看看几个问题： 共享边界如何处理？如下图：那个共享边界应该属于哪个矩形？介于此，对共享边界有个处理原则：左闭右开、下闭上开。所以上图那个共享边界应该是属于黑色矩形。 在扫描转换中，经常会提到多边形的凹凸性。所以做个解释（只考虑简单多边形，即不会自交）： 凸多边形：所有内角小于180度。 凹多边形：存在内角大于180度。 那么如何区分多边形的凹凸性呢？主要有两种方法： 顶点同侧异侧法：对于多边形的每条边，所有顶点都在这条边所在直线的同侧，则是凸多边形；如果存在异侧的，就是凹多边形。 向量叉积法：沿顺时针或逆时针，把每条边看作一个向量，如果所有相邻边向量叉积同号，则是凸多边形，否则是凹多边形。 说了这么多，到底怎么扫描转换多边形呢？主要有三种方法： 逐点判断法、扫描线算法、种子填充法。 扫描转换填充多边形：逐点判断法逐点判断法就是在绘图窗口内，一个一个地去判断像素是否位于多边形内，若是，则用指定颜色绘制该像素。 那么如何判断一个像素是否位于多边形内呢？第一感觉可能是用数学计算来判断，好吧，那先来一个粗暴的。这里主要介绍射线法。来画个图找点灵感：从上图会发现一个规律：从像素点作一条水平向右的射线，如果与多边形的交点个数是偶数，则该像素点位于多边形外边，如果交点个数是奇数，则该像素点位于多边形里面。 是吗？反例来了~如下图：~居然有出格的~那给个规定： 如果射线与边重合，则视为无数个交点，这时直接判断像素点是否在边上。 如果交点为顶点，以此顶点为端点的两条边在射线同侧，则视为两个交点；如果在射线异侧，则视为1个交点。 这样应该是没有反例了~根据上诉规律，即可判断一个像素点是否在多边形内。However，交点怎么求？用射线去和多边形的所有边通过方程求交点~不言而喻，射线法的效率低、花费大。 射线法为何效率低？主要是它忽略了多边形内部点的连续性，把它们离散处理了。当一个点在多边形内部时，通常它周围的点也会在多边形内部，这就是这里点的连续性。 扫描转换填充多边形：扫描线算法同样，画个图找点灵感：图中的水平虚线就是一条一条的扫描线（一般扫描线都是平行于x轴的，图中每条扫面线之间画的比较远，而实际扫描时扫描线都是以像素为单位，也就是y方向上每个像素都会有一条水平扫描线穿过），我们需要画出图中的多边形。 一条一条来看吧~。y=1的扫描线与多边形交于两点（水平线不参与交点计算）：P1(5，1)、P2(7，1)；y=2的扫描线也与多边形交于两点：(4，2)、(8.25，2)；……而且多边形在这些扫描线上要填充的像素点，也恰好是在扫面与多边形的两个交点之间。比如在y=1时，就把交点P1、P2之间的所有像素点描出来；在y=2时，就把交点(4，2)、(8.25，2)之间的所有像素点描出来…….直到y=7的扫描线时，我们应该已经画出了如下填充图形（不要纠结扫描线宽度，当做扫描线宽度为一个像素来理解就可以了）：但是当y=7时，扫描线与多边形有3个交点，当y=7.5时，扫描线又与多边形有4个交点（扫描线当然不会是小数，不过整数扫描线与多边形有4个交点的情况确实存在，只是这幅图找不出来，所以用7.5冒充了~-~），而且应该填充的像素点在头两个交点之间和后两个交点之间。结合之前只有两个交点的情况，好像有一个规律：把交点两两配对后，要填充的像素就在每一对交点之间。但是y=7却只有3个交点，无法两两配对，回想前面射线法是把顶点P5当做两个交点来看的，正好抄过来用一下，规定：两条边都在扫描线同一侧的顶点看作两个交点。这样y=7也可以两两配对了，扫描线一直上升到y=8甚至y=11时都可以实现交点两两配对。 扫描线从y=1上升到y=11，把配对的交点之间的像素点描上颜色，就画出了这个不规则的填充多边形。这就是扫描线转换多边形。 but同样的，我们要来看看它的效率怎么样。在两个交点之间填充像素点好说，因为扫描线是水平的，两交点的y值肯定相等，只需要让x坐标从左交点一直增大到右交点即可。但是交点怎么办？扫描线虽然是水平的，都是x=？的水平直线，那把它代入多边形边的直线方程求交？显然这又增加了一堆乘除法运算，效率很低。那有没有效率好点的求交点算法？恩~用方程求点，前面我们是不是看到过，扫描转换直线的第一个方法就是方程法，因为每个点都有一堆计算，所以放弃了方程法，效率太低，改为研究DDA算法了。那么这里能不能借用DDA的思想？其实原理是一致的，之前求扫描线与多边形的交点，忽略了扫描线上升时，多条扫描线与同一条边的交点之间其实是有联系的（因为在同一条直线上嘛）：同一条边上相邻交点的y值差1，x值正好差一个斜率的倒数。比如y=1时与边e0的交点P1（5,1）和y=2时与边e0的交点（4,2），第二个交点比第一个交点y+1（因为扫描线上升了一个像素），而第二个交点比第一个交点x-1（因为边e0的斜率为-1）；再比如y=1时与边e2的交点P2（7,1）和y=2时与边e2的交点（8.25,2），第二个交点比第一个交点y+1（因为扫描线上升了一个像素），而第二个交点比第一个交点x+1.25（因为边e2的斜率倒数是1.25）。 这样一来，我们只需要知道多边形中每条边的斜率倒数和其下端点x坐标就行，因为在同一条边上的其他交点都可以通过该边的下端点x坐标和斜率倒数做加法求出来。比如知道了边e0的和边e2的斜率倒数和其下端点坐标P1、P2，那后面边e0在y=2、3、4时的交点都可以求出来了，边e2在y=2、3、4、5时的交点也可以求出来了。但是到了y=4时，边e0变成了边e6；到y=5时，边e2也变成了边e3；到y=7时，又增加了边e5和边e4；到y=8时，边e5、e6都没了；到y=11时，仅剩的边e4和e3也没了，一条边也没了。在这过程中，有些边会加进来，有些边会删除，那什么时候加边？什么时候删除边？在回顾一下上面的过程，我们就会发现当扫描线上升到边的下端点时（扫描线y值达到了边下端点的y值），该边就会加进来配对；当扫描线上升到边的上端点时（扫描线y值达到了边上端点的y值），该边就会被删除，退出配对。所以除了边的斜率和其下端点x坐标，还需要下端点的y坐标、上端点的y坐标。 有这么多边，自然在数据结构中应该设置一个容器来存储这些边（包括边的下端点x坐标、上端点y坐标和斜率倒数，这些是已知的参数，由用户输入），那用什么容器来存储呢？第一反应当然是用数组去存储所有边，当扫描线y=1时，去遍历这个边数组，看哪条边下端点y=1就把该边加入配对队伍里，看哪条边上端点y=1就把该边从配对队伍里剔除。这个配对队伍和存储所有边的数组是同一个容器吗？当然不是~否则剔除之后到哪去遍历所有边，所以还需要另一个容器来存储那些需要去配对的边（给需要去配对的起个名字吧，叫：活性边）。那应该用什么容器来存储这些活性边呢？由于需要频繁插入、删除，而且扫描过程中，活性边容器中有多少边是不确定的，可能一会多一会少，用固定大小的数组无疑很浪费空间，而且不易于插入删除，鉴于此，存储活性边的容器选链表比较合适（可参考《数据结构与算法之链表》）一文。 那链表中的活性边如何配对呢？看看上图，比如在y=7.5的扫描线，此时的活性边是e6、e5、e4、e3，应该是e6和e5配对、e4和e3配对，放到图中刚好是从左至右两两配对。从左至右？这不就是x从小到大嘛！e6在e5左边，可见应该是下端点x小的在左边，即活性边按照下端点x坐标从小到大排序；but边e5和e4下端点x相等，e5在e4左边，可见当下端点x相等时，按照上端点x从小到大排序。 故活性边链表中的边，应该是按照下端点x值由小到大排序的，如果下端点x值相等再按照上端点x值由小到大排序（边表中每条链表里的边都是按上端点x值由小到大排序的，所以从边表里依次插入到活性边表后，下端点x值相等的边肯定是按照上端点x值由小到大排序的，所以边结构体中也就不需要上端点x坐标这个数据成员了，可参考代码进行理解）。不管怎么说，这些活性边需要按x值排序，那么采用哪种排序算法呢？因为多边形的活性边数据量不是很大，没有必要采用那些改进排序，用简单排序就好；而这些活性边应该是随着扫描线上升，动态地从链表中加入或删除，并不是一开始就全部在链表中的，所以采用冒泡排序和选择排序都不大适合，而且在简单排序中插入排序效率是最高的，所以这里对活性边的排序应该选择插入排序（关于排序可参考《数据结构与算法之简单排序》和《数据结构与算法之改进排序》）。活性边表AEL（Active Edge List）中的结点存储着边的相关信息，即边的斜率（用于求同一条边上下一个交点坐标）、当前扫描线与边的交点的x坐标（初始值为其下端点x坐标，由边表复制而来，用于求同一条边上下一个交点坐标）、上端点y坐标（用于从活性边表中删除不再参与配对的边）。活性边表结构如下图：结点中的4个数据成员依次是：上端点y坐标、当前交点的x坐标、斜率倒数、指向下一个结点的指针 存储活性边的容器选定为采用插入排序的链表了，再回过头来看看最初存储所有边的容器数组，难道扫描线每上升一次都要去遍历整个数组，找出哪些边该插入哪些边该删除~~~看图中，y=7时，应该把哪些边加入活性边表中？很显然是e5和e4，这是我们根据规律肉眼看出来的。那有没有办法当y=7时，计算机也能直接知道应该加入哪些边？把y=7时应该加入的边事先列出来存储在某一个地方不就好了么~-~就好像今天是星期天，我们应该上哪些课？通常我们是直接去查课表（课表中只有星期几和这天该上的课，不包括诸如8点到10点这些具体时间），因为课表里存储着星期几和该上哪些课。我们这里的y=？（y=几）也就相当于星期几，我们需要另一个类似课表的容器去存储y=？时应该加入活性边表的边。想想如果你要存储上面的课表，你会选用哪种容器。第一反应肯定还是最简单的数组，用数组的下标表示星期几，数组的内容表示当天应该上哪些课。但是每天上的课都不是一样多的啊，数组的内容应该取为多大才好？下标为0的数组元素可以存储2个课程结构体（因为可能想要知道课名、上课老师…等等相关内容，课程就对于多边形的边，需要知道边的斜率、下端点x坐标、上端点y坐标等），还是5个课程结构体，还是其他个数的课程结构体？这显然是不确定的，如果把数组元素内容大小设为最大长度（如一天最多上10节课），这无疑会浪费很多存储空间（可能某一天要上10节课，但另一天一节课也不上，不就浪费了10个存储空间~），所以定容的数组是不适合的，每个数组元素应该采用不定长的链表。注意是每个数组元素，就是说一周有7天是固定的，可以用大小为7的数组来表示这7天，但是每一个数组元素（每一天）能装下的课程数量是不定的，需要用链表来表示。也就是说每一个数组元素应该装一个不定长的链表，但是数组元素的容量是固定的，比如int a[7]，每个数组元素只能存放4个字节，总不能把一整条链表都装到数组元素里去吧！但是既然是链表，我们可以在数组元素里装一个指向链表第一个结点的指针啊，指针的大小是固定的（常见的是4个字节）。 这样，就解决了存储所有边应该用哪种容器：用一个大小等于扫描线条数（其实大小这里可以改进，毕竟不是每一条扫描线都有边会加入到活性边表中去，只存储那些需要加边的扫描线也是可以的）的数组表示扫描线的y=几，每个数组元素里存储着一个指向链表的指针；这个链表中存储着y=？时应该加入活性边表中的边。如下图所示（ET表示边表（Edge Table），即我们这个容器的名字）：如此，当扫描线上升到某个y值时，就可以直接从边表ET中读出需要加入活性边表AET的边。 边表中链表结点是什么样呢？链表中存储着应该加入活性边表的边，也就是这些链表中的每一个结点就表示了多边形的一个边，所以这些结点应该存储着边的相关信息，即边的斜率（用于求同一条边上下一个交点坐标）、其下端点x坐标（用于求同一条边上下一个交点坐标）、上端点y坐标（用于从），而且每条链表中存储的边（即结点）对应到图中都应该是从左到右排序的，即每条链表中的结点是按照边上端点x值由小到大排序的（这种顺序是在建立边表时人为就排好的，一般不需要再使用排序算法让计算机去排序）。因为边表中每一条链表中存储的边，都是按上端点x有序排列的，所以依次复制插入到活性边表后，下端点相同的边也就按照上端点x值由小到大排序好了。省去了到活性边表中按照上端点x再排一次，节省了很多花费。 弄清了边表中结点的数据成员和链接次序后，对图中多边形建立的完整边表如下： 回顾多边形扫描过程结合需要建立的数据结构，扫描线算法总结如下： 建立边表ET 将扫描线纵坐标y的初始值置为ET中非空元素的最小序号，如图中，y=1 置活性边表AEL为空（初始化活性边表头结点） 执行下列步骤直到ET和AET都为空4.1. 如果ET中的第y类非空，则将其中的所有边取出并复制插入到AEL中4.2. 如果有新边要插入AEL，则对AEL各边进行插入排序4.3. 对AEL中的边两两配对（第1个和第2个为一对，第3个和第4个为一对……），将每队边中x坐标按规则取整，获得有效的填充区段，再填充4.4. 将当前扫描线纵坐标y值加14.5. 将AEL中满足y=ymax（扫描线达到了某边上端点）的边删去（每条边是被看作下闭上开的，即下端点属于该边，但上端点不属于该边）4.6. 对AEL中剩下的每条边的x加斜率倒数delta，即x=x+delta 【注】：由于边的斜率倒数可能是小数，如e2的斜率倒数是1.25，所以每次算出来的交点是一个小数，但是描点的时候只能是整数值，所以4.3中，描点时需要对配对的交点的x坐标取整（这样也能在填充时减少浮点数的出现），取整规则是：让取整后的交点坐标都落在多边形内。即配对的交点中，左边的交点向右取整（通常采用int(…)+1），右边的交点向左取整（通常采用int(…)）。 用扫描线算法来扫描转换多边形的具体代码如下（代码里的多边形坐标比前面多边形图中扩大了10倍）： #include&lt;iostream> #include&lt;math.h> #include&lt;gl/glut.h> using namespace std; const int infinity=65535; //表示一个不可能的数 //建立边表ET中的链表结点（边结点）数据结构 class ETListNode{ public: float xBottom; //边的下端点x坐标 float delta; //边的斜率倒数 int yTop; //边的上端点y坐标 ETListNode* nextEdge; //指向下一个链表结点的指针 ETListNode(){ xBottom=infinity; delta=infinity; yTop=infinity; nextEdge=NULL; } }; //建立边表ET中的数组元素的结构 class ETArray{ public: ETListNode* ToETList; //指向链表的指针 ETArray(){ ToETList=NULL; } }; //边表 class ET{ public: ETArray etArray[110]; ETListNode edges[6]; ET(){ edges[0].yTop=40; edges[0].xBottom=50; edges[0].delta=-1; edges[1].yTop=50; edges[1].xBottom=70; edges[1].delta=5.0/4; edges[2].yTop=80; edges[2].xBottom=20; edges[2].delta=0; edges[3].yTop=110; edges[3].xBottom=120; edges[3].delta=0; edges[4].yTop=80; edges[4].xBottom=70; edges[4].delta=-5; edges[5].yTop=110; edges[5].xBottom=70; edges[5].delta=5.0/4; edges[0].nextEdge=&amp;edges[1]; edges[4].nextEdge=&amp;edges[5]; etArray[10].ToETList=&amp;edges[0]; etArray[40].ToETList=&amp;edges[2]; etArray[50].ToETList=&amp;edges[3]; etArray[70].ToETList=&amp;edges[4]; } }; //建立活性边表AET的结点结构 class AETListNode{ public: float xIntersection; //当前扫描线与活性边的交点的x坐标 float delta; //边的斜率倒数 int yTop; //边的上端点y坐标 AETListNode* nextEdge; //指向下一个链表结点的指针 AETListNode(){ xIntersection=infinity; delta=infinity; yTop=infinity; nextEdge=NULL; } }; //活性边表 class AET{ public: AETListNode* first; //活性边表头结点 AET(){ first=new AETListNode(); //初始化头结点 } }; //扫描线算法画多边形 void Scan(){ ET et; AET aet; bool etEmpty=false; bool aetEmpty=false; int y=0; //扫描线y值 while(et.etArray[y].ToETList==NULL){ y++; } while(y&lt;110){ ETListNode* currentETNode=et.etArray[y].ToETList; while(currentETNode!=NULL){ AETListNode* tempAETNode=new AETListNode(); tempAETNode->yTop=currentETNode->yTop; tempAETNode->xIntersection=currentETNode->xBottom; tempAETNode->delta=currentETNode->delta; AETListNode* currentAETNode=aet.first; while(currentAETNode->nextEdge!=NULL &amp;&amp; tempAETNode->xIntersection>=currentAETNode->nextEdge->xIntersection){ currentAETNode=currentAETNode->nextEdge; } //插入新边（新结点） tempAETNode->nextEdge=currentAETNode->nextEdge; currentAETNode->nextEdge=tempAETNode; currentETNode=currentETNode->nextEdge; } AETListNode* currentAETNode=aet.first; for(int i=1;currentAETNode->nextEdge!=NULL;i++){ currentAETNode=currentAETNode->nextEdge; if(i%2==1 ){ int xStart=int(currentAETNode->xIntersection)+1; int xEnd=int(currentAETNode->nextEdge->xIntersection); for(int x=xStart;x&lt;=xEnd;x++){ glVertex2d(x,y); } } } y++; currentAETNode=aet.first; while(currentAETNode->nextEdge!=NULL){ if(currentAETNode->nextEdge->yTop==y){ currentAETNode->nextEdge=currentAETNode->nextEdge->nextEdge; } else{ currentAETNode=currentAETNode->nextEdge; currentAETNode->xIntersection+=currentAETNode->delta; } } } } void Draw(){ gluOrtho2D(0,700,0,600); glClearColor(1,1,0,0); glClear(GL_COLOR_BUFFER_BIT); glBegin(GL_POINTS); glColor3ub(255,0,0); Scan(); glEnd(); glFlush(); } void mydisplay(){ Draw(); } int main(){ glutInitWindowSize(400,600); glutCreateWindow("扫描转换多边形"); glutDisplayFunc(mydisplay); glutMainLoop(); return 0; } &nbsp; 在扫描线算法中用到了交点（相邻扫描线与多边形某一条边的交点）之间的连续性，即同一条边上相邻交点是有固定代数联系的。也就是说扫描线算法是从多边形的轮廓下手的，先找出多边形轮廓上的点，再去填充这些轮廓点之间的像素点。那么能不能直接从多边形内部的点下手呢？毕竟多边形内部的点连续性更明显啊：多边形内部的点通常它周围的点都会在多边形里。下面的这个算法就是利用了这点。 扫描转换填充多边形：种子填充法种子填充法是利用了多边形内部点的连续性。有两种填充方式： 边界填充：首先用一种颜色（取名边界色）画出多边形轮廓，再从多边形内部任意一点开始，查看它的周围像素点（一般是上下左右）是否是边界色或者已填充色，如果都不是，则说明该点是多边形内部且暂时没有被描色的点，接下来给该点描色即可。一般采用递归的方式，让每个已描色的点都去重复上诉过程。 内点填充：依然是首先用一种不同于背景色的颜色，画出多边形轮廓，再从多边形内部任意一点开始，查看它的周围像素点（一般是上下左右）是否是背景色，如果是则说明该点是多边形内部且暂时没有被描色的点，接下来用一种不同于背景色的颜色给该点描色即可。同样采用递归的方式，让每个以描色的点都去重复上诉过程。 使用内点填充画五角星的代码如下： #include&lt;math.h> #include&lt;gl/glut.h> #include&lt;iostream> using namespace std; #define PI 3.14 //读像素颜色 unsigned char* GetPixel(float x,float y){ unsigned char* color=new unsigned char[3]; glReadPixels(x,y,1,1,GL_RGB,GL_BYTE,color); //调用opengl函数读取像素颜色 return color; } //写像素颜色 void SetPixel(float x,float y,int* BoundaryColor){ glBegin(GL_POINTS); glColor3ub(BoundaryColor[0],BoundaryColor[1],BoundaryColor[2]); glVertex2f(x,y); glEnd(); glFlush(); } //内点填充（递归） //参数BoundaryColor为边界色或者填充色，二者等色 void FloodFill(float x,float y,int* BoundaryColor){ unsigned char* color=GetPixel(x,y); //像素颜色是否等于原背景色:绿色，如果是则填为边界色 if(color[0]==0&amp;&amp;color[1]==127&amp;&amp;color[2]==0){ SetPixel(x,y,BoundaryColor); FloodFill(x,y+1,BoundaryColor); FloodFill(x,y-1,BoundaryColor); FloodFill(x+1,y,BoundaryColor); FloodFill(x-1,y,BoundaryColor); } } //填充五角星 void FillPentagram(){ int* BoundaryColor=new int[3]; //设置边界色/已填充色 BoundaryColor[0]=255; BoundaryColor[1]=0; BoundaryColor[2]=0; glColor3ub(BoundaryColor[0],BoundaryColor[1],BoundaryColor[2]); //指定一个种子坐标 float x0=0; float y0=10; float theta; for(int i=0;i&lt;10;i++){ //旋转种子点，每次36度 theta=0.2*PI*i; float x=cos(theta)*x0-sin(theta)*y0+300; float y=sin(theta)*x0+cos(theta)*y0+300; if(i%2==0){ BoundaryColor[0]=255; } else{ BoundaryColor[0]=127; } FloodFill(x,y,BoundaryColor); } } //画五角星轮廓 void DrawPentagramOutline(){ float R=100; //五角星外圆半径 float r=R*0.415f; //五角星内圆半径 float point[10][2]; float point_original[1][2]; point_original[0][0]=300; point_original[0][1]=300; glBegin(GL_LINE_LOOP); glColor3ub(255,0,0); for(int i=0;i&lt;10;i++){ if(i%2==0){ point[i][0]=r*cos(0.2*i*PI); point[i][1]=r*sin(0.2*i*PI); } else{ point[i][0]=R*cos(0.2*i*PI); point[i][1]=R*sin(0.2*i*PI); } } for(i=0;i&lt;10;i++){ glVertex2d(point_original[0][0]+point[i][0],point_original[0][1]+point[i][1]); } glEnd(); glBegin(GL_LINES); glColor3ub(255,0,0); for(i=0;i&lt;10;i++){ glVertex2d(point_original[0][0]+point[i][0],point_original[0][1]+point[i][1]); glVertex2d(point_original[0][0],point_original[0][1]); } glEnd(); glFlush(); } void mydisplay(){ glClearColor(0,1,0,0); glClear(GL_COLOR_BUFFER_BIT); glMatrixMode(GL_PROJECTION); glLoadIdentity(); gluOrtho2D(0,500,0,600); DrawPentagramOutline(); FillPentagram(); } void main(){ glutInitWindowSize(500,600); glutCreateWindow("种子填充"); glutDisplayFunc(mydisplay); glutMainLoop(); } 效果如下： 可以看出，无论哪种方法，其实都需要先画出多边形轮廓的点阵信息，再根据屏幕上像素点的颜色来进行填充，所以其实是点阵到点阵的转换，已经不是严格意义上的扫描转换了。但是那些事先的轮廓点阵信息一般都是由参数形式转换而来，所以才把种子填充勉强地归为扫描转换。&nbsp; 到此，已经介绍完了画基本填充图元的扫描转换法。下面是另一个画法：填充法。 画填充图形：填充法扫描转换法是把图形的参数形式转换为点阵形式，再进行显示。但是并不是每一幅图形都能用参数表示出来啊~~比如相机照出来的照片，要用参数这种数学形式表示出照片这种复杂图形估计有点难度！那就没有参数形式，只有点阵形式了，比如要在计算机上显示一幅照片，就得需要这幅照片的点阵形式，这幅照片的点阵形式是什么？当然是每一个像素点的颜色啊，所以如果知道图形每一个像素点的颜色值，则交给计算机按颜色值逐像素点描色，即可在电脑上画出这张照片。 所以填充法就是：按照事先知道的图形像素点颜色值，在计算机上逐点描色，从而画出图形。 至于怎么事先知道一幅图形的所有像素点颜色值，就得靠其它方法了，比如数码摄像机会通过电子传感器把光学影像转换成电子数据，再传输给计算机。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Mathjax简介及其语法]]></title>
    <url>%2F2016%2F10%2F27%2FMathjax%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Mathjax简介Mathjax是一款运行在浏览器中的开源数学符号渲染引擎，使用Mathjax可以方便地在浏览器中显示数学公式，不需要使用图片。目前，Mathjax可以解析LateX、MathML和ASCIIMathML的标记语言。几乎支持所有的主流浏览器。&nbsp; Mathjax语法 Mathjax公式排版方式Mathjax公式排版有两种方式：inline和displayed。inline方式是把公式内嵌（使用$...$），例如$f(x)=3 \times x$，$f(x)=3 \times x$这是一个inline公式；而displayed是公式独立成段（使用$$...$$），例如$$f(x)=3 \times x$$，$$f(x)=3 \times x$$是一个displayed公式。 右键点击公式，可查看公式代码、设置显示效果和渲染模式（点击打开的公式代码没有包含\$，自己在写公式时加上即可）。两个独立成段的displayed公式之间必须以空行分开，否则显示不出来。即应该是下面这样： \$\$...\$\$ \$\$...\$\$ 公式中的希腊字母 公式中的上标下标上标使用^，下标使用_。例如x_i^2是：$x_i^2$。【注】： 10^10得到的是$10^10$，而10^{10}才是$10^{10}$。 x^5^6会报错，因为有二义性，必须使用大括号来加以界定，如：{x^5}^6：${x^5}^6$ 或者x^{5^6}：$x^{5^6}$。 公式中的括号 小括号与方括号：小括号还是原始的()，方括号也是原始的[]。如(2+3)[4+4]：$(2+3)[4+4]$ 大括号：{}由于被用来界定分组（如上文中的10^{10}），所以大括号需要用{和}来表示，也可以使用\lbrace和\rbrace来表示。如{a*b}：${a*b}$，\lbrace a*b \rbrace：$\lbrace a*b \rbrace$。 尖括号：使用\langle和\rangle表示。如\langle x \rangle：$\langle x \rangle$。 向上取整：使用\lceil和\rceil表示。如\lceil x \rceil：$\lceil x \rceil$。 向下取整：使用\lfloor和\rfloor表示。如\lfloor x \rfloor：$\lfloor x \rfloor$。 不可见括号：使用.表示。 【注】：这些括号都是不会随着公式大小进行缩放的。如果需要括号大小自适应公式大小，可以在相应的左括号前面加上/left，右括号前面加上/right。如下所示：$$\lbrace \sum_{i=0}^n i^2 \rbrace \tag{1}$$ $$\left\lbrace \sum_{i=0}^n i^2 \right\rbrace \tag{2}$$ 公式2的括号就是经过缩放的（右键点击公式能看到公式源码）。 公式中的求和与积分求和符号使用\sum来表示，用下标_来表示求和下限，用上标^来表示求和上限。如\sum_1^n：$\sum_1^n$。 积分符号使用\int来表示，同样用上下标表示积分的上下限。如\int_1^\infty：$\int_1^\infty$。 与此类似的符号还有：二重积分\iint：$\iint$，连乘\prod：$\prod$，并\bigcup：$\bigcup$，交\bigcap：$\bigcap$。 公式中的分数分数有两种表示方式： 使用\frac ab来表示，\frac作用于其后的两个组a、b，结果为$\frac ab$。如果分子或分母不是单个字符，使用{}进行分组即可（也就是用大括号括起来）。 使用a \over b来分隔分子分母。如a+1 \over b+1：$a+1 \over b+1$。 公式中的根号根号使用\sqrt[]{}来表示。如\sqrt[4]{\frac xy}：$\sqrt[4]{\frac xy}$。 公式中的三角函数使用\sin来表示正弦函数，如$\sin x$。其他三角函数类似。 公式中的特殊符号 求极限符号：使用\lim_{x \to y}表示。如$\lim_{1 \to \infty}$。 比较运算符： 小于$\lt$：\lt。 大于$gt$：\gt 小于等于$\le$：\le。 大于等于$\ge$：\ge。 可以在这些运算符前面加上\not，如\not \gt：$\not \gt$。 常见计算运算符： 加$+$：直接在公式中使用+即可。 减$-$：直接在公式中使用-即可。 乘$\times$：\times。 除$\div$：\div。 加减$\pm$：\pm。 减加$\mp$：\mp。 点乘$\cdot$：\cdot。如x \cdot y：$x \cdot y$。 集合运算符： 并$\cup$：\cup 交$\cap$：\cap 舍$\setminus$：\setminus 包含于$\subset$：\subset 真包含于$\subseteq$：\subseteq 非真包含于$\subsetneq$：\subsetneq 包含$\supset$：\supset 属于$\in$：\in 不属于$\notin$：\notin 空集$\varnothing$：\varnothing 排列使用$n+1 \choose 2k$：使用a \choose y或者\binom ab来表示。 箭头：\to：$\to$，\rightarrow：$\rightarrow$，\leftarrow：$\leftarrow$，\Rightarrow：$\Rightarrow$，\Leftarrow：$\Leftarrow$，\mapsto：$\mapsto$。 逻辑运算符：\land：$\land$， \lor：$\lor$， \lnot：$\lnot$， \forall：$\forall$，\exists：$\exists$，\top：$\top$，\bot：$\bot$，\vdash：$\vdash$， \vDash：$\vDash$。 模运算符：\pmod。如b \pmod n：$b pmod n$。 省略号：\cdots位置居中：$\cdots$；\ldots位置稍低：$\ldots$。 \star：$\star$，\ast：$\ast$，\oplus：$\oplus$，\circ：$\circ$，\bullet：$\bullet$，\approx：$\approx$，\sim：$\sim$，\cong：$\cong$，\equiv：$\equiv$，\prec：$\prec$，\infty：$\infty$，\nabla：$\nabla$，\partial：$\partial$。 【注】：使用Detexify，可以在它的网页上画出你想要的符号，Detexify会给出相似的符号及其公式代码。但是不能保证它给出的符号可以在Mathjax中使用，可以参考supported-latex-commands确定MathJax是否支持此符号。 公式中的空格因为Mathjax通过内部策略自己管理公式内部的空间，因此a b的显示结果依然是：$a b$。想要在ab之间加入间隙，可以使用\,、\;、\quad、\qquad等，间隙依次增加，如$a\,b$、$a\;b$、$a \quad b$、$a \qquad b$。 公式中的顶部符号对于单字符\hat：$\hat x$，多字符\widehat：$\widehat {xy}$。类似的还有：\overline：$\overline {xyz}$、\vec：$\vec x$、\overrightarrow：$\overrightarrow x$、\dot：$\dot x$、\ddot：$\ddot x$。 公式中的表格使用$$\begin{array}{列样式}...\end{array}$$这样的样式来创建表格。 列样式可以是c（居中）、l（左对齐）、r（右对齐）。 每行之间使用\\\\来分隔（本来是\\，但是在markdown中第一个\被解释为转义字符，所以需要\\\\），每列之间使用&amp;来分隔。 在列样式中写入|可表示一条竖线，在每行前面加上\hline可在本行前加入一条直线。 例如： $$ \begin{array}{|c|l|c|r|} \hline n &amp; Left &amp; Center &amp; Right \\\\ \hline 1 &amp; 0.24 &amp; 1 &amp; 125 \\\\ \hline 2 &amp; -1 &amp; 189 &amp; -8 \\\\ \hline 3 &amp; -20 &amp; 2000 &amp; 1+10i \\\\ \hline \end{array} $$ 效果：$$\begin{array}{|c|l|c|r|}\hlinen &amp; Left &amp; Center &amp; Right \\\\\hline1 &amp; 0.24 &amp; 1 &amp; 125 \\\\\hline2 &amp; -1 &amp; 189 &amp; -8 \\\\\hline3 &amp; -20 &amp; 2000 &amp; 1+10i \\\\\hline\end{array}$$ 公式中的矩阵使用$$\begin{matrix}...\end{matrix}$$这样的形式来表示矩阵。矩阵的每行之间依然使用\\\\来分隔，列之间依然使用&amp;来分隔。例如： $$ \begin{matrix} 1 &amp; x &amp; x^2 \\\\ 1 &amp; y &amp; y^2 \\\\ 1 &amp; z &amp; z^2 \\\\ \end{matrix} $$ 效果：$$\begin{matrix}1 &amp; x &amp; x^2 \\\\1 &amp; y &amp; y^2 \\\\1 &amp; z &amp; z^2 \\\\\end{matrix}$$ 给矩阵加括号： 可以用前文中提到的括号再配以\left和\right。 也可以使用特殊的matrix，即替换\begin{matrix}...\end{matrix}中的matrix为pmatrix、bmatrix、Bmatrix、vmatrix、Vmatrix。如pmatrix：$\begin{pmatrix} 1 &amp; 2 \\\ 3 &amp; 4\\\ \end{pmatrix}$、bmatrix：&amp;\begin{bmatrix} 1 &amp; 2 \\\ 3 &amp; 4\\\ \end{bmatrix}$、Bmatrix：$\begin{Bmatrix} 1 &amp; 2 \\\ 3 &amp; 4\\\ \end{Bmatrix}$、vmatrix：$\begin{vmatrix} 1 &amp; 2 \\\ 3 &amp; 4\\\ \end{vmatrix}$、Vmatrix：$\begin{Vmatrix} 1 &amp; 2 \\\ 3 &amp; 4\\\ \end{Vmatrix}$。 矩阵中的省略元素：可以使用\cdots：$\cdots$、\ddots：$\ddots$、\vdots：$\vdots$来表示矩阵中的省略元素。例如：$$\begin{pmatrix}1 &amp; a_1 &amp; a_1^2 &amp; \cdots &amp; a_1^n \\\\1 &amp; a_2 &amp; a_2^2 &amp; \cdots &amp; a_2^n \\\\\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\\\1 &amp; a_m &amp; a_m^2 &amp; \cdots &amp; a_m^n \\\\\end{pmatrix}$$ 增广矩阵的表示：增广矩阵需要使用前面的array来实现，而matrix办不到了。例如：$$ \left [ \begin{array}{cc|c} 1 &amp; 2 &amp; 3 \\\\ 4 &amp; 5 &amp; 6 \\\\ \end{array} \right ] $$ 效果：$$\left [\begin{array}{cc|c}1 &amp; 2 &amp; 3 \\\\4 &amp; 5 &amp; 6 \\\\\end{array}\right ]$$公式对齐有时候可能需要一系列的公式中等号对齐，例如：$$\begin{align}\sqrt{37} &amp; = \sqrt{\frac{73^2-1}{12^2}} \\\\&amp; = \sqrt{\frac{73^2}{12^2}\cdot\frac{73^2-1}{73^2}} \\\ &amp; = \sqrt{\frac{73^2}{12^2}}\sqrt{\frac{73^2-1}{73^2}} \\\\&amp; = \frac{73}{12}\sqrt{1 - \frac{1}{73^2}} \\\ &amp; \approx \frac{73}{12}\left(1 - \frac{1}{2\cdot73^2}\right)\end{align}$$这需要使用形如\begin{align}...\end{align}的格式，其中需要使用&amp;来指明需要对齐的位置（右键可查看上诉公式的代码）。分类表达式可使用形如\begin{cases}...\end{cases}的格式。其中使用\来分类，可使用&amp;指明需要对齐的位置。例如：$$f(n) =\begin{cases}n/2, &amp; \text{if $n$ is even} \\\\3n+1, &amp; \text{if $n$ is odd} \\\\\end{cases}$$方程组 可以使用\begin{array}...\end{array}与\left{ ... \right.，配合表示方程组。例如：$$\left\{\begin{array}{c}a_1x+b_1y+c_1z=d_1 \\\ a_2x+b_2y+c_2z=d_2 \\\ a_3x+b_3y+c_3z=d_3 \\\\\end{array}\right.$$ 也可以使用\begin{cases}...\end{cases}。例如：$$\begin{cases}a_1x+b_1y+c_1z=d_1 \\\ a_2x+b_2y+c_2z=d_2 \\\ a_3x+b_3y+c_3z=d_3 \\\\\end{cases}$$ &nbsp; 【注】：本文主要参考《Mathjax与LaTex公式简介》一文，更多详细内容请参考此文。]]></content>
      <categories>
        <category>博客配置</category>
      </categories>
      <tags>
        <tag>Mathjax语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机图形显示系统]]></title>
    <url>%2F2016%2F10%2F19%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E6%98%BE%E7%A4%BA%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[在揭开计算机图形显示系统的面纱之前，我们先来看看我们再熟悉不过的显示器吧。 显示器如今的显示器大致分为两类（按器件的发光性质）： 阴极射线管CRT（Cathode Ray Cube）：优点：亮度高、对比度好、色彩鲜艳缺点：体积大、笨重 平板型显示器：液晶、等离子优点：器件薄，适合携带缺点：亮度和对比度相对较低、色彩不够鲜艳，价格偏高 两种显示器如下图所示： 接下来分别看看这两种显示器。 CRT（Cathode Ray Cube）显示器 CRT是怎么显示图形的呢？CRT是一种真空器件，利用内部电磁场产生高速的、经过聚集的电子束，偏转到屏幕的不同位置，轰击屏幕表面的荧光材料，从而产生可见的图形。 CRT由哪些东西组成？CRT主要由电子枪、聚焦系统、加速电极、偏转系统、荧光屏组成。如下图所示：（其实其中的电极、磁场、电场、偏转系统在高中物理就学过~在此就不赘述了） 但是我们现在经常见到的都是彩色电视，也就是彩色CRT（指的是大头电视，不是液晶电视~），那么CRT是怎么显示彩色的呢？ CRT是怎么显示彩色像素点的？常用的有两种方法：射线穿透法、影孔板法。 射线穿透法：原理：屏幕表面的荧光材料有两层：红色荧光涂层（发红光）和绿色荧光涂层（发绿光），电子束轰击穿透荧光层的深浅，决定了最后所产生的颜色。如下图所示：使用射线穿透法的CRT成本低，但是只能产生有限几种颜色。主要用于画线显示器。 影孔板法： 原理：屏幕表面其实有三层，最内层是影孔板，中间层才是荧光涂层，最外层是屏幕玻璃。其中影孔板上有很多个小孔，每个小孔对应后面荧光涂层上的三个荧光点（呈三角形排列），所以每个小孔其实也是对应一个像素点（即三个荧光点）。如下图所示：在影孔板的内侧有三支电子枪，对应红、绿、蓝三种基色，电子枪、影孔板中的一个小孔和荧光点在一条直线上（如下图所示）。通过调节各电子枪发生的电子数目，就可以控制三个荧光点产生的三种色光强度。我们知道，三种基色的不同比例混合可以产生多种颜色，如此便达到了彩色的效果。（如果每支电子枪发出的电子束的强度有256个等级，则显示器能同时显示256*256*256=16M种颜色，称为真彩系统。） 【注】：三基色通常是RGB（红绿蓝），多用于硬件设备，如摄像机、扫描仪、投影仪等。还有一种三基色是CMY（蓝绿cyan、品红magenta、黄yellow），常用于彩色打印。CMY与RGB具有互补关系，即R=1-C、G=1-M、B=1-Y。 平板型显示器这里主要介绍液晶显示器。 液晶显示器LCD（Liquid Crystal Display）我们先来看看什么是液晶。 什么是液晶？液晶是一种液体和固体之间的特殊物质，它具有液体的流态性质和固体的光学性质。当液晶分子的某种排列状态，在电场作用下变为另一种排列状态时，液晶的光学性质会随之改变。 液晶分子受到电压影响时，会改变其分子排列状态，于是可以让摄入的光线产生偏转现象，从而改变光的强弱。如下图所示：液晶亮度的控制原理如下：那么到底是怎么显示彩色的呢？ 液晶LCD是怎么显示彩色像素点的从上面可以看到，液晶可以改变光的强度，这就类似影孔板法中电子束的强度，在LCD中其实也和影孔板法一样，存在三基色，通过不同的光强产生不同强度的三种色光，再组合就能得到各种各样的颜色。只是荧光涂层和三基色的实现方式不同于影孔板法罢了，原理都是一样的。影孔板法通过在阴极上调节电压来控制电子束的强度，从而控制三基色的强度，达到彩色效果，而LCD是通过液晶分子在电压下的不同排列方式来控制光强，从而控制三基色的强度，达到彩色效果。想要了解的更详细，可以看这篇文章哦！ LCD显示器和CRT显示器的比较 相同点：都是通过单个发光元素（像素）来显示图形或文字。 不同点： LCD体积小，厚度薄，重量轻，耗能少，无辐射 CRT显示亮度高，色彩鲜艳，分辨率高，但是体积较大 【注】：分辨率是CRT在水平或竖直方向单位长度上能识别的最大像素个数，单位通常为dpi（dots per inch）。在假定屏幕尺寸一定的情况下，也可用整个屏幕所能容纳的像素个数描述，如640480，1024768，1280*1024等等。分辨率越高显示的图形就越精细。 到此，我们搞清了显示器的原理。是时候来看看我们的主题了：计算机图形显示系统。 计算机图形显示系统先来看看显示系统由哪些东西组成。 显示系统由哪些东西组成？主要组成部分是：显示器、视频控制器、显示缓冲器。 视频控制器：控制显示设备（有的含图形加速处理器GPU），通过访问帧缓存来刷新屏幕 显示缓冲器：可以在内存或显示控制器中，帧缓存存放在显示缓冲器中 如下图所示：视频控制器就是从系统存储器（显示缓冲器）的帧缓存中取出一帧要显示的内容（一些绘图命令），然后由视频控制器来显示数据对应的图形。 视频控制器以不同的方式显示计算机图形，可把显示系统分为两类：随机扫描显示系统、光栅扫描显示系统。 随机扫描显示系统 什么是随机扫描？电子束可以随意移动，只扫描荧屏上要显示的部分像素。对应的显示器为画线设备。 随机扫描显示系统主要靠哪些东西来实现（逻辑部件）？ 刷新存储器（Refreshing Buffer）：帧缓存所在的地方 显示处理器（DPU：Display Processing Unit）：解释执行绘图命令，驱动电子枪绘图 CRT 随机扫描显示是怎么实现的（显示原理）？应用程序发出绘图命令，这些绘图命令被解析成为显示处理器可以接受的命令格式，存储在刷新储存器中。刷新存储器中的所有绘图命令组成一个显示文件，交由显示处理器DPU解释执行，驱动电子枪在屏幕上绘图。如下图所示： 光栅扫描显示系统 什么是光栅扫描？电子束按固定的扫面线和扫描顺序从左到右、自上而下进行扫描。【注】： 扫描线：一条水平线 帧：一次扫描生成的图像 水平回扫期：水平线间的回扫期 垂直回扫期：帧间的回扫期（从上到下的扫描期） 分辨率：电子束按固定的扫描顺序扫描N条扫描线，每条扫描线有M个像素，则M*N为显示器的分辨率。 光栅扫描过程图示 光栅扫描显示系统主要靠哪些东西来实现（逻辑部件）光栅扫描显示系统的主要逻辑部件是：帧缓冲存储器、视频控制器、显示处理器、显示器（CRT、液晶）。如下图所示：下面分别来了解一下这些部件： 帧缓冲存储器：简称帧缓存，是显存中的部分存储单元。用于存储屏幕上的颜色值，所以帧缓存中的存储单元与屏幕上的像素一一对应（总数也是相同的），帧缓存中存储单元的数值决定了对应屏幕像素的颜色，存储单元的位数自然也就决定了屏幕像素颜色有多少种。如黑白显示系统的帧缓存存储单元位数就应该是1位。对于真彩色系统应该是每种基色有8位，所以真彩色的帧缓存存储单元位数应该是24位，显示系统最多可显示2^24种颜色若分辨率为M*N、颜色个数为K，则帧缓存大小V&gt;=M*N*[log2K]（向上取整）【注：】 目前PC机的显存容量一般都在256M以上，但是对于1024*1024的真彩色系统需要的缓存大小只有：1024*1024*log2(2^24)/8=3M字节，为何显存容量远大于真彩色需要的存储容量呢？这是因为显存不止包括像素的颜色信息，还包括深度缓存、纹理内存等等。 视频控制器：负责解释执行帧缓存中的绘图命令，驱动电子枪在荧光屏上绘图，实现刷新。具体工作过程如下：刷新周期开始，依扫描次序依次取出帧缓存单元的数值，放入像素值寄存器，列对应的地址寄存器的地址加1，如此重复，直到该扫描线上的最后一个元素，转下一行，列地址置0，行地址加1。其逻辑结构如下图所示： 显示处理器（GPU）：用于代替CPU完成部分图形处理功能，如扫描转换、几何变换、裁剪、光栅操作、纹理映射等等。 光栅扫描显示系统的优缺点 优点：成本低、容易绘制填充图形、色彩丰富、刷新频率一定（与图形的复杂程度无关）、易于修改图形（其实就是修改绘图命令） 缺点：需要扫描转换，这样复杂图形计算量会比较大；会产生混淆（走样）。]]></content>
      <categories>
        <category>计算机图形学</category>
      </categories>
      <tags>
        <tag>图形显示系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图形学概述]]></title>
    <url>%2F2016%2F10%2F18%2F%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[什么是计算机图形学？ ISO定义：通过计算机将数据转换为图形，并在专门的显示设备上进行显示，而计算机图形学就是研究其中的原理、方法和技术的学科。 IEEE定义：Computer graphics is the art or science of producing graphical images with the aid of computer。 说白了，计算机图形学就是应用计算机技术进行图形的生成、处理和输出。 那么什么是图形呢？图形有哪些特征吗？ 什么是图形？凡是能在人的视觉系统中产生视觉映像的客观对象都是图形，在计算机中是指可以用计算机生成、显示、存储、处理并输出的对象。【注】：图形也可以是完全虚构的物体（如假想中的天堂）。 图形的基本要素 几何要素：如点、线、多边形、多面体等。主要用于刻画对象的轮廓、形状。 非几何要素：如颜色、纹理等。主要用于刻画物体的颜色、材质等等。 那么在计算机中图形是以何种方式显示的呢？ 计算机图形的表示方法？首先要明白，计算机肯定都是通过一个一个的像素点的颜色来显示图形的。但是对于要显示的图形，根据记录其像素点的方式不同，计算机图形的表示方法分为点阵法和参数法。 点阵法记录图形中的所有像素点（包括轮廓和其内部、外部的所有点，也就是带背景的图形），显示时按行按列依次快速显示出每个像素点，就能看到完整的一幅图形。其实以这种方式表示的图形通常称为图像（image）。 参数法只记录图形的的形状参数（方程或表达式的系数、线段的端点坐标等）、属性参数（颜色、线型等），显示时通过计算来确定哪些像素点应该位于图形上，再根据属性参数绘制出相应的点，最后便能形成完整的图形（如圆可以通过圆心坐标、半径和颜色来表示）。以这种方式表示的通常才称为图形（graphics）。 不难看出，点阵法表示的计算机图形数据量很大，不需要复杂的计算；而参数法表示的计算机图形数据量很小，显示时需要复杂的计算。更多比较，请看下图： 搞清了什么是图形和计算机图形学，那么计算机图形学究竟是研究哪些东西呢？ 计算机图形的研究内容 图形系统（硬件、软件、标准化）。 基本图形生成。比如如何显示点、线段、多边形、圆等几何图形。 图形处理。比如几何变换（图形动起来）、投影变化（如何显示三维图形）、真实感图形（关照、阴影等）。 物体造型（建模）。比如实体表示、曲线曲面、真实感等等。 下面来看一看图形学的发展历史吧！ 计算机图形学的发展史分三个方向来回顾这段历史：学科发展历程、硬件发展历程、软件以软件标准的发展历程（该部分略，可问度娘）。 学科发展历程 20世纪50年代，计算机图形学诞生。1950年，第一台图形显示器诞生，当时是作为麻省理工旋风1号计算机的附件。CRT的出现为计算机生成并显示图形提供了可能。而后MIT（麻省理工）林肯实验室，在Whirlwind上开发SAGE空中防御系统，通过光笔在屏幕上指点实现与系统交互。标志着交互式图形技术诞生。 20世纪60年代，计算机图形学这一门学科被确立。1962年，MIT林肯实验室，Ivan E.Sutherland在他的博士论文中首次提出”Computer Graphics”一词。从此，Sutherland被称为计算机图形学之父。 1962年，雷洛汽车公司的工程师Pierre Bezier提出Bezier曲线、曲面的理论。 1964年，MIT的Steven A.Coons教授提出了超限插值的新思想，通过插值四条任意的边界曲线来构造曲面。 19实际70年代，光栅图形学迅速发展。区域填充、裁剪、消隐等基本图形概念及其相应算法纷纷诞生。 在真实感图形学上，1970年，Bouknight提出了第一个光反射模型；1971年，Gourand提出”漫反射+插值”的思想，被称为Gourand明暗处理。1975年，Phong提出了著名的简单关照模型-Phong模型。 19世纪80年代，计算机图形学开始实用化。大量图形应用软件出现，但是图形硬件设备却是十分昂贵。8 .19世纪90年代，计算机图形学被广泛应用。多用于多媒体技术、人工智能、科学计算可视化、虚拟现实、三维造型技术等领域。而且硬件集成化也大幅度提高：GPU出现。 硬件发展历程 图形显示设备的发展 20世纪60年代中期，主要是画线显示器，需要刷新。具有较高的分辨率和对比度，良好的动态性能。但设备昂贵。 20世纪60年代后期，主要是存储管式显示器，许需要刷新。价格较低，但是不具有动态修改图形的功能，不适合交互式。 20世纪70年代初，主要是刷新式光栅扫描器。以点阵形式表示图形，使用专用的缓冲区存放点阵，由视频控制器负责刷新扫描。大大推动了交互式图形技术的发展。 20世纪90年代至今，主要是液晶和等离子显示器，和一些新的显示设备（如立体显示器）。 图形输入设备的发展 控制开关、穿孔纸等。 键盘。 二维定位设备。如鼠标、光笔、触摸屏、语音、操纵杆等。 三维输入设备。如空间球、数据手套、用户手势和表情等（将来）。 用户思维（将来）。]]></content>
      <categories>
        <category>计算机图形学</category>
      </categories>
      <tags>
        <tag>图形学概述</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL1：OpenGL概述及环境配置]]></title>
    <url>%2F2016%2F10%2F18%2FOpenGL1%E6%A6%82%E8%BF%B0%E5%8F%8A%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[OpenGL简介OpenGL是一个功能强大的图形库，提供了很多操作图形和图片的API（Application Programming Interface），用户可以用它很方便地开发所需要的有多种特殊视觉（如光照、透明、纹理、阴影）的三维图形。OpenGL库的实际开发者通常是各大显卡厂商。Khronos Group公开提供了所有OpenGL的规范文档，可以从这里看到OpenGL3.3规范文档。OpenGL具有很好的跨平台性，2012年8月已经更新到4.3版本。 OpenGL组成OpenGL主要由OpenGL基本函数库、OpenGL实用函数工具包、WGL库（OpenGL的Windows扩展库） OpenGL的基本函数库：主要包括三个：OpenGL核心库、OpenGL实用库、OpenGL辅助库。 OpenGL核心库（GL）这部分函数常用于常规的、核心的图形处理，是OpenGL的核心部分；包含300多个函数，函数名前缀都是”gl”。 OpenGL实用库（GLU）（Utility）这部分函数通过调用核心库的函数，为开发者提供相对简单的用法，实现一些较为复杂的操作。如绘制茶壶等简单形体。包含大约50个函数，函数名前缀都是”glu”。 OpenGL辅助库（GLAUX）（Auxiliary）这部分函数提供窗口管理、输入输出处理以及绘制一些简单的三维物体，包含约30个函数，函数名前缀都是”aux”。 OpenGL实用函数工具包（GLUT：OpenGL Utility Toolkit）：由Mark Kilgard开发。主要提供窗口系统操作功能，如创建窗口、鼠标和键盘输入、菜单、事件驱动等等。包含大约30个函数，函数名前缀都是glut。【注】：glut中的窗口管理函数不依赖于操作系统，可以在所有的OpenGL平台上运行。 WGL库：OpenGL对窗口系统的扩展 用于连接OpenGL和Windows，在Windows平台上设置OpenGL环境 并不是所有函数前缀都是”wgl” 只能在Windows上运行 OpenGL主要功能 基本几何形状绘制点、线段、多边形、Bezier曲线、简单形体等。 属性设置颜色、线型（实、虚等）… 变换几何变换：平移、旋转、缩放；投影变换：正投影、透视投影 交互键盘和鼠标 &nbsp; OpenGL的两种开发模式OpenGL的两种开发模式是：快速模式和core-profile（核心模式）。 在OpenGL3.2版本以前，都是使用快速模式，也叫fixed function pipeline，固定函数输送管道，顾名思义，快速模式是一种简单易用的绘图方式，容易使用容易理解，但是效率低下，而且大多数功能都被封装了，开发者难以获得更多的图形控制权。所以从3.2版本开始，快速模式不建议被使用了，出现了core-profile（核心模式），它是OpenGL规范的一部分，移除了所有过时的不建议使用的功能。当使用core-profile模式时，OpenGL会强制让我们使用现代函数；如果使用了过时的或不建议的函数，是会报错的。 使用core-profile，需要开发者真正懂得OpenGL，而且还要掌握图形编程，难度是提高了，但是却提供了更高的灵活性和效率，还能让我们更好的理解图形编程。由于之后版本的OpenGL都是以3.3为基础的，核心机理并没有变化，而且大多数开发情况下都需要支持较低的显卡，低显卡可能不支持最新版的OpenGL，所以我们也使用OpenGL3.3版本了。&nbsp; OpenGL特性：支持扩展OpenGL是支持扩展的。如果显卡厂商在某个时候推出了一个新技术或渲染优化， 那么图形开发者就可以通过扩展来直接使用该新技术，而不需要等待新版本的OpenGL发布。事实上，当一个扩展被证明很流行或很有用时，它就会变成未来OpenGL的一部分。 一般使用扩展的代码如下： if(GL_ARB_extension_name) //GL_ARB_扩展名 { //执行硬件支持的新特性 } else { //不支持该扩展，使用老办法 } &nbsp; OpenGL的本质OpenGL本身其实是个大状态机，也就是说它定义了一大堆OpenGL该做何操作的变量。 OpenGL的状态通常称为OpenGL环境（context）。我们通常都是设置一些选项，操作一些缓冲，来改变它们的状态（即环境），然后使用当前环境做渲染。 使用OpenGL时，会遇到多种状态改变函数，这些函数会改变环境；还会遇到多种状态使用函数，这些函数是基于当前状态来执行一些操作。&nbsp; OpenGL的库是用C写的，所以OpenGL无法表示诸如对象这些在更高级语言中才有东西。于是OpenGL开发了几种自己特有的抽象概念，对象就是其中一个。 OpenGL中的对象OpenGL的对象是一些可选项（即变量）的集合，是OpenGL状态的一部分。那么OpenGL中的对象怎么定义和使用呢？ OpenGL中定义对象的流程大致如下： //OpenGL的状态 struct OpenGL_Context { ... object* object_Window_Target; ... }; //创建对象 GLuint objectId = 0; glGenObject(1, &amp;objectId); //把对象绑定到目标上 glBindObject(GL_WINDOW_TARGET, objectId); //为当前绑定到GL_WINDOW_TARGET的对象设置选项 glSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_WIDTH, 800); glSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_HEIGHT, 600); //把目标绑定的对象恢复为默认（解绑） glBindObject(GL_WINDOW_TARGET, 0); 上面的代码是在OpenGL中会经常遇到的工作流。通过glGenObject函数创建一个对象，保存到后台内存中，并且用一个无符号整数来表示这个对象，相当于是给这个对象起了个名字（对象id，就像人的身份证号），然后把这个名字（整数）存入变量objectId中。接着用glBindObject方法把对象绑定到一个目标上（代码中是把目标定为了GL_WINDOW_TARGET）。再下一步就是设置目标的选项（这些设置会被保存到对象中），最后把目标绑定的对象id设置为0，即解绑对象。至此，便完成了对一个对象的属性设置。 【注】： 上面的代码只是在描述OpenGL的操作原理，并不是OpenGL中的实际函数，只是伪码。 当使用OpenGL时，建议使用OpenGL定义的自由类型。在写float时在前面加GL；int、char、bool等等同样处理。应为不同的操作系统可能对于各自的类型有不同的内存布局，而OpenGL的GL自有类型的内存布局是跨平台的。所以使用OpenGL的自有类型可以保证我们的应用可以跨平台。 好像还有点懵，这个对象有何意义？打个比方，上面对对象的定义流程就好像是：拿出来一张纸，先给它编个号（对应创建对象），说这是第一张纸，然后拿这张纸去找到一个橡皮泥（对应绑定目标），说我要把这个橡皮泥变成什么什么样，然后在纸上画出梦想中的橡皮泥（设置选项），橡皮泥捏好了以后，就用不上这张纸了（解绑），但是还可以根据这张纸（对象）再去捏出很多一模一样的橡皮泥（目标）啊！不用再去找张纸画画了，这就是对象的好处。&nbsp; 下面来看看，OpenGL环境应该咋配置。先看VC++6.0下的： VC6.0下的OpenGL环境配置 使用OpenGL辅助库GLAUX时的环境配置： 打开工程，工程 → 设置 → 连接 → 分类选输入 → 在对象/库模块文本框中加上opengl32.lib glu32.lib glaux.lib（注意用空格分开） → 确定。如下图所示： Windows平台下的源文件需要加上以下头文件：#include &lt;window.h> #include &lt;GL/gl.h> #include &lt;GL/glu.h> #include &lt;GL/glaux.h> 一般还需要：#include &lt;stdio.h&gt;、#include &lt;stdlib.h&gt;、#include &lt;math.h&gt; 使用OpenGL实用函数工具包GLUT时的环境配置： 文件拷贝（这三个文件百度很容易找到）：头文件glut.h拷贝到：\VC6.0安装目录\VC98\Include\GL目录下连接库glut32.lib拷贝到：\VC6.0安装目录\VC98\Lib目录下运行库glut32.dll拷贝到：C:\Windows\SysWOW64目录下（这时64位系统下的，如果是32位系统应该拷贝到：C:\Windows\System32） 打开工程，工程 → 设置 → 连接 → 分类选输入 → 在对象/库模块文本框中加上opengl32.lib glu32.lib glut32.lib（注意用空格分开） → 确定。如下图所示： 在源文件里加上头文件：#include &lt;GL/glut.h&gt; 【注】：OpenGL不需要单独下载安装，因为OpenGL是跟着驱动走的，只要装了显卡驱动，一般都会有OpenGL的。&nbsp; 但是原生的OpenGL不支持窗口管理、跨平台等功能，所以就有了很多热心人写了工具来支持这些功能，比如glut、glfw等等。 它们都是一些函数库，这些库免去了所有跨平台的问题，同时也提供了窗口、OpenGL环境等渲染所需的功能。比较流行的库主要有GLUT、SDL、SFML、GLFW。但是glut太老了，最后一个版本都是90年代的。这里我们主要用GLFW。 GLFWGLFW（OpenGL For Window）是一个轻量级的、开源的、跨平台的library，是一个跨平台的OpenGL应用框架，支持OpenGL和 OpenGL ES，用于管理窗口、读取输入、处理事件等，并且可以给我们创建一个OpenGL环境。 下面将介绍GLFW的构建过程。 构建GLFW 下载GLFW源文件GLFW可以从官网下载。当然是可以直接上面已经编译好的二进制文件，但是反正它有源码了，我们自己来编译一把，体验多多。而且使用源码编译出来的glwf库，可以完美适应自己的CPU/OS，编译好的二进制库就不一定了，所以先下载源码把（如果是下载编译好的二进制文件，尽量下32位的，64位可能会有很诡异的错误）。 但是从源码编译也有一个问题：不是所有人的IDE（ Integrated Development Environment）都是相同的，这就意味着用自己的IDE编译出来的库或其他文件可能别人并不能用，项目整合时会出现不兼容。比如有的用VS，有的用XCode，在VS上面写的项目要与和在XCode上面写的项目进行整合，但是IDE不同，很多项目文件会不兼容，比较原始的办法就是把VS上的源文件一个一个复制到XCode上，再在XCode上编译（或者相反），如果工程很大源文件很多，这样做是很要命的。而CMake可以根据源文件和一些简单的配置信息，生成对应OS下的IDE的项目文件，比如可以在用CMake把VS下的源文件直接整体编译为XCode项目，然后就可以直接和别人的XCode项目进行整合，还是很节省效率的。 CMakeCMake是一个可以根据源文件生成多个IDE下的项目/解决方案的工具（CMake可以从这里下载），我用的是Win32-x86 Installer。 安装完成后进入\bin文件夹选择cmake-gui.exe，再分别选择源码文件夹和用于生成项目的目标文件夹（需要自己新建一个文件夹），如下图：点击Configure按钮，CMake会要求选择目标IDE环境（即想要生成哪种IDE下的项目/解决方案），由于我用的是VS2015，所以选择了VS 14 2015，如下图：点击finish， 当出现configuring done后，点击generate，出现generating done以后，在新建的build文件夹内就可以看到生成的项目文件了。我的文件夹如下图所示： 编译但是这些项目文件中还没有Debug文件夹，无法拿到我们进行OpenGL编程所需要的库文件，那么打开GLFW.sln编译一下把，在VS编辑器菜单上点击生成/生成解决方案（Build/Build Solution），然后编译好的库glfw3.lib就会出现在build/src/Debug文件夹内了。接下来把这个库链接到项目上，就可以进行OpenGL编程了。 链接在链接到项目之前，得让IDE能够找到该库文件在哪里。新建一个将要写入OpenGL代码的VS项目，建好后在‘解决方案资源管理器’中右键项目名称，点击属性，在VC++目录（VC++ Directories）中点击包含目录（Include Directories），添加glfw源码的include文件夹。再点击库目录（Library Directories），添加glfw3.lib。现在VS能找到所需要的文件了。我添加的如下图（我是把包括后面glew要用到的文件一起放在文件夹内的，然后直接添加的文件夹。当然也可以向上面说的一个文件一个文件地添加）： 接下来是链接。还是在属性里点击链接器（Linker）/输入（Input），在附加依赖项（Additional Dependencies）中添加上glfw3.lib，当然还需要把OpenGL也链接上，添加opengl32.lib（只要有显卡驱动一般都会有opengl，opengl32.lib是安装VS时自带的）。如下图：&nbsp; 下面就可以在项目中使用OpenGL的函数了。其实OpenGL只是一种标准/规范，具体怎么实现要看驱动怎么来实现这种显卡支持规范（通俗点说就是提供接口函数），由于存在着很多不同版本的OpenGL驱动，不能够在编译的时候（compile-time）就确定静态链接哪个OpenGL函数，需要在运行时（run-time）指定所需要的函数地址，然后把地址存储在函数指针中以备后用（有点像先声明后定义）。在Windows中类似如下代码段： //定义函数原型 typedef void(*GL_GENBUFFERS)(GLsizei, GLuint*); //寻找函数并分配给它一个函数指针 GL_GENBUFFERS glGenBuffers = (GL_GENBUFFERS)wglGetProcAddress("glGenBuffers"); //现在可以正常使用OpenGL函数了 GLuint buffer; glGenBuffers(1, &amp;buffer); 如你所见，想使用一个OpenGL函数太麻烦了，每个函数都得先被声明。不过为了解决这个问题，一个工具GLEW应运而生。&nbsp; GLEWGLEW（OpenGL Extension Wrangler Library）是一个跨平台的C++扩展库，基于OpenGL图形接口。由于目前Windows只支持OpenGL1.1的函数，但是现在OpenGL都已反正到4了，要使用这些OpenGL的高级特性，就必须下载最新的扩展，除此之外，不同的显卡公司，也会发布一些只有自家显卡才能支持的扩展函数。如果我们想要使用这些函数，就不得不去寻找最新的glext.h（glext.h使我们可以调用常见的更高版本的OpenGL函数，但是必须在源文件中包含此头文件，并将显卡驱动更新到最新版，glext.h可以在这里找到，不保证最新，也有可能会有些函数接口找不到）。但是有了GLEW扩展库，就再也不用担心找不到这些函数的接口了，因为GLEW能自动识别你的平台所能支持的全部OpenGL高级扩展函数。也就是说，只要包含一个glew.h头文件，就能使用gl、glu、glext、wgl、glx的全部函数。并且GLEW支持目前流行的各种操作系统。当然了，我们之前得问题也迎刃而解了，可以直接使用函数，不用先声明了。下面来看看GLWF环境的搭建。&nbsp; 构建GLEW由于GLEW是一个库，所以我们还是需要把它的库文件和头文件链接到我们的项目中。GLEW可以从中这里下载。当然还是可以和前面GLFW一样从源码编译出lib库文件。这里我直接下载编译好的二进制文件Binaries了。下载好后找到\glew-2.0.0-win32\glew-2.0.0\lib\Release\Win32路径下的glew32s.lib文件，把这个文件添加到项目属性的库目录里，再把\glew-2.0.0-win32\glew-2.0.0路径下的include文件夹添加到项目属性的包含目录里（我是把这里glew和之前glfw的库文件和头文件放在了两个新建文件夹下：一个Libs文件夹、一个Includes文件夹，再把这两个文件夹添加到项目属性的相应目录里。人懒省事~。可以参考前面GLFW标题后链接标题下的第一张图。） 这里使用的是GLEW的静态库，即glew32s.lib。而且GLWF3默认也是被编译为静态库的。 如果使用GLEW的静态库，必须在包含GLEW之前定义一个预处理变量GLEW_STATIC。如下： #DEFINE GLEW_STATIC #include &lt;GL/glew.h> 如果想要使用GLEW的动态库，需要移除对GLEW_STATIC的定义，而且需要把.dll复制到二进制代码所在的文件夹里。&nbsp; 测试环境是否构建成功在自己新建的并且构建好环境的项目中，写入如下代码： // GLEW #define GLEW_STATIC #include &lt;GL/glew.h> // GLFW #include &lt;GLFW/glfw3.h> int main() { glfwInit(); glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3); glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3); glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE); glfwWindowHint(GLFW_RESIZABLE, GL_FALSE); return 0; } 如果出现了很多未定义引用错误，就是还没有构建成功了~。 【注】： 静态链接库是会在编译的时候整合到我们的二进制文件中，这样做的好处是不必保持跟踪这额外的文件，只需要发布单独的二进制文件。缺点是最后的可执行文件会变得更大，而且当一个库有一个更新的版本时需要重新编译整个应用程序。 动态链接库就是.dll或.so文件，库的代码是与我们的二进制代码分开存在的，它可以使最终的可执行文件更小，更新的时候也更容易，不足之处是必须在最终的应用程序中发布dll文件。&nbsp; 参考文献：LearnOpenGL]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>OpenGL配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程的描述与控制]]></title>
    <url>%2F2016%2F10%2F14%2F%E8%BF%9B%E7%A8%8B%E7%9A%84%E6%8F%8F%E8%BF%B0%E4%B8%8E%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[程序的并发执行程序的并发执行：宏观上，用户看到多个程序同时执行，向前不间断地推进；微观上，任意时刻一个CPU上只能有一个程序在执行。程序不加控制地并发执行的结果可能不是唯一的，举个例子： ex：counter是全局变量，初值为0，现进程p1和进程p2都对counter加1：进程p1：...;counter=counter+1;... 进程p2：...;counter=counter+1;... 但是我们知道这只是高级语言的程序语句，计算机却是逐指令进行执行的，所以还需要把上诉高级语言转换成编译后的基本指令序列：（其中r1和r2是两个通用寄存器）进程p1： r1=counter; //将counter对应内存的数据送寄存器r1 r1=r1+1; //累加1 counter:=r1; //将r1中的累加结果送往counter对应的内存中 进程p2： r2=counter; //将counter对应内存的数据送寄存器r1 r2=r2+1; //累加1 counter:=r2; //将r1中的累加结果送往counter对应的内存中 当进程p1和进程p2逐指令并发执行时，若指令执行顺序如下：r1=counter; r1=r1+1; r2=counter; r2=r2+1; counter:=r2; counter:=r1; 则执行后的结果是counter等于1，显然这不是我们想要的结果，原因就在于程序的并发执行上。若指令顺序如下：r1=counter; r1=r1+1; counter:=r1; r2=counter; r2=r2+1; counter:=r2; 则执行后的结果是counter等于2。而程序并发执行时，两个程序的指令谁先执行谁后执行是不确定的，也就造成了程序并发执行时结果的不唯一性。 进程的描述因为并发执行的程序可能是同一个程序在不同数据集合上的执行，也可能是不同的程序在不同的数据集合上的执行，它们共享系统资源，所以在并发执行中，仅仅用程序来作为描述单位是不够的，还应该加上程序的数据集合。所以，进程破壳出生了。 什么是进程 简单的定义：进程是程序在一个数据集合上的运行过程。 详细的定义：进程是由正文段、用户数据段、系统数据段共同组成的一个执行环境（正文段存放被执行的机器指令；用户数据段存放进程在执行时直接进行操作的所有数据；系统数据段存放程序的运行环境，是进程实体最重要的一部分）。 进程和程序的比较 程序是静态的，进程是动态的 。程序是一组二进制代码，而进程对应着程序执行的过程，程序执行过程中运行环境是不断变化的。 几个进程能并发地执行相同的程序代码，同一个进程也能顺序地执行几个程序（进程和程序是多对多的关系）。 进程控制块PCB操作系统中那么多进程，用什么来唯一标识呢？答案是进程控制块（PCB，Process Control Block），一种操作系统管理进程所使用的数据结构。进程控制块用于描述进程及控制进程运行所需的全部信息。每个进程都有PCB，它是操作系统感知进程存在的唯一标志。 那么进程控制块PCB中包含哪些内容呢？ 进程标识符信息PID（Process Identifier）PCB之所以能够唯一标识某个进程，就是依赖于PCB中的进程标识符，它用于唯一标识一个进程。当然出于其它一些方面的性能考虑，PCB中同时存有本进程的标识符、其父进程的标识符、子进程的标识符。 处理机状态信息所有进程共享处理机CPU，当一个进程需要被暂停执行，交出CPU使用权时，需要把当前进程CPU寄存器的值保存到内存中（即PCB中）（保存现场），以防止被覆盖，以便该进程再次获得CPU时，能从内存（PCB）中加载寄存器的值，恢复进程上次被暂停时的CPU环境，使进程能够从上次被中断处继续执行。那么需要保存的CPU状态信息有哪些呢？ 通用寄存器。用户程序可以访问的寄存器，用于暂存信息。 指令计数器。里面存放了CPU要访问的下一条指令的地址。 程序状态字PSW。里面含有状态信息，如条件码、执行方式、中断屏蔽标志灯。 用户栈指针。每个用户进程都有一个或多个与之相关的系统栈，用于存放过程和系统调用参数及调用地址。栈指针指向该栈的栈顶。 进程调度信息 进程状态信息 进程优先级 进程调度所需的其他信息 事件 进程控制信息 程序和数据的地址 进程同步和通信机制 资源清单 链接指针 进程的组织方式系统中那么多进程，它们是如何联系在一起的呢？也就是说操作系统是通过怎样的方式把它们聚在一块的？我们先来想想，需要把所有进程拿出来连在一起吗？这当然是很不划算的，因为有的进程是很大的，而且在地址空间上不一定连续，这样做会有很大的时间空间上的开销。上面讲了进程控制块PCB可以唯一标识一个进程，所以把PCB组织在一起就够了。 链接方式把系统中具有相同状态的进程的PCB用其中的链接字链接成一个队列，如下图所示： 索引方式系统根据所有进程的状态，建立几张索引表，索引表的每一个表项指向一个PCB的物理块，如下图所示： 进程的三种基本状态 就绪状态就绪状态是进程一旦获得CPU就可以投入运行的状态。把多个处于就绪状态的进程组织在一起，形成一个或多个就绪队列。 执行状态执行状态是进程获得CPU正在运行的状态。（单CPU系统中，任意时刻只会有一个进程处于执行状态） 阻塞状态阻塞状态是进程由于等待资源或由于某个事件的发生而暂停执行的状态。把多个处于阻塞状态的进程组织在一起，形成一个或多个阻塞队列。 【注】：新创建进程的状态一般被设置为就绪状态 三种基本状态之间的转换关系如下图所示： 进程的控制 进程的创建创建新进程包括在主存中为进程分配地址空间、建立操作系统用于管理进程的数据结构（如进程控制块）等操作。在Linux系统中，除了0号进程（swapper进程）外的其他进程都是由其父进程创建的。调用创建新进程的系统调用来创建进程的一般步骤为： 申请空白PCB 为新进程分配资源 初始化进程控制块 将新进程插入就绪队列 Linux2.6.11中创建进程的常用系统调用有fork()。 进程的阻塞进程阻塞的简化过程大致如下： 暂停进程的执行，将进程的状态改为阻塞状态 将进程插入相应的阻塞队列 转进程调度程序。重新进程进程调度 进程的唤醒进程唤醒的简化过程大致如下： 将进程从阻塞队列中移除 将进程状态由阻塞状态改为就绪状态 将进程插入就绪队列 进程的终止进程终止的简化工程大致如下： 从进程PCB中读进程状态 若进程正在执行状态，则终止进程的执行 若进程有子孙进程，则在大多数情况下需要终止其子孙进程 释放资源 将终止进程的PCB移出（从相应的PCB组织方式中移除） 【注】：如果一个进程终止，它的所有子进程也被终止，这称为级联终止，通常是由操作系统进行的。在Unix系统中，如果父进程终止，那么其他所有子进程会把init进程作为它们新的父进程。 线程（Thread） 要线程何用？由于进程所占的空间太大，并且独享它占有的所有资源，在进程创建、撤销、切换时，都有较大的时空开销，会降低并发程度。所以，引入了线程。让线程作为独立调度和分配的单位，线程不独立占有资源（少量基本资源还是要独占的，如程序计数器、寄存器组、栈等），而是与其他线程共享同一进程的资源，减小了系统时空开销，提高了操作系统的并发程度。 什么是线程线程只是比进程更小的执行单位，是被系统独立调度和分派的基本单位。线程和进程及其相似，包括状态、分类、调度切换等等都和进程是一样的。所以不再赘述。【注】： CPU只能感知到内核级线程的存在，而感知不到用户级线程的存在。所以： 对于用户级线程，CPU的调度单位还是进程；而对于内核级线程，CPU的调度单位是线程 当用户级线程被阻塞时，对应的整个用户级进程也会被阻塞；而内核级线程被阻塞时，对应的内核级进程不会被阻塞，OS内核可以去调度同一个内核级进程内的其他内核级线程 内核级线程进行系统调用只阻塞该线程，而用户级线程进行系统调用要阻塞线程所属的进程 内核级线程的CPU时间以线程为单位进行分配，每个线程独享一个CPU时间片；而用户级线程的CPU时间以进程为单位进行分配，同一进程里的多个线程共享一个CPU时间片 由于用户级线程的调度与切换不需要OS内核的参与，所以用户级线程切换比较快；而内核级线程在调度和切换时需要进行用户态/内核态的切换，所以内核级线程切换比较慢 线程控制块TCB采用链接方式来组织，没有PCB的索引方式 进程之间的通信必须采用OS提供的进程间通信机制，而同一进程中的各线程间可以通过直接读写全局变量来进行通信，无需操作系统的参与 由于一个进程内的多个线程共享资源，所以一个线程对资源的任何修改，都会影响到同一个进程中的其他线程的执行环境。所以，需要对各种线程的活动进行同步，保证多个线程以互斥的方式访问临界资源，使它们互不干扰。如本文开头的加法例子，如果不对共享的临界资源counter加以访问控制，任由线程随意并发执行，则可能会导致错误结果。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>进程的描述与控制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统内核（中断、时钟管理、系统调用）]]></title>
    <url>%2F2016%2F10%2F14%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%86%85%E6%A0%B8%2F</url>
    <content type="text"><![CDATA[操作系统内核是指大多数操作系统的核心部分，是把一些执行频率高的模块常驻内存，它是计算机硬件的第一次扩充。操作系统内核一般包括下述功能： 支撑功能。包括中断处理、时钟管理、原语操作（也叫原子操作，是一组在执行过程中不能被中断的操作）等。 资源管理功能。包括进程管理、存储器管理、设备管理等。 中断 中断是什么？中断时改变处理器指令执行顺序的一种事件。该事件与CPU芯片内外部硬件电路产生的电信号相对应。计算机在执行程序的过程中，若出现中断，计算机将停止现行程序的运行，转向对这些中断事件的处理，处理结束后返回被中断处，继续向下执行。 为何需要中断？引入中断机制前，当在CPU上执行的程序遇到I/O时，CPU采取反复轮询的方式检测本次I/O是否结束，在轮询的过程中CPU不能完成任何更有效的工作，这是对CPU相当大的浪费。引入中断机制后，一个正在执行的进程p1请求I/O后，CPU启动这次的I/O，然后CPU可以先去执行其他进程（而不用去轮询I/O是否结束），当I/O完成后，通过中断机制使CPU获得进程I/O结束的信息，转中断处理，处理完毕后返回到原来进程p1断点处，继续向后执行。可以看到，在p1进程的I/O过程中，CPU不用去轮询I/O是否结束，而可以转去并行执行其他的进程，这无疑很大程度上减少了CPU的浪费。 中断类型中断分为同步中断（也叫内部中断或异常）和异步中断（也叫外部中断）。 同步中断（（程序）内部中断或异常）同步中断是当指令执行时由CPU控制单元产生的。之所以称为同步中断，是因为只有在一条指令终止执行后CPU才会发出中断，如除法错误、调试、溢出、浮点出错等。 异步中断（外部中断）异步中断是由其他硬件设备依照CPU时钟信号随机产生的。外部中断又可以分为外部可屏蔽中断和外部不可屏蔽中断。 外部可屏蔽中断。这种中断是由I/O设备产生的。有两种方式可以屏蔽中断：一时在Intel80X86的CPU上，把EFLAGS寄存器的IF标志置0，表示关中断，此时CPU忽略所有可屏蔽中断；二是通过对PIC编程来禁止IRQ，即可以告诉PIC停止对给定的IRQ线发布中断。 外部不可屏蔽中断。这种中断是由紧急事件引起的，如硬件故障。 引起中断的原因有哪些呢？ 人为设置中断。在程序中认为设置中断。 程序性事故。如计算中出现除数为0等情况。 硬件故障。 I/O设备。I/O设备启动后，一旦其准备就绪或完成一次输入/输出，便向CPU发出中断请求。 外部中断。如用户通过键盘来中断现行程序。 中断响应有哪些条件吗？对于可屏蔽中断，开中断是响应中断的前提。例如，在Intel80X86 CPU上，EFLAGS寄存器的IF标志置1时表示开中断。 什么时候响应中断呢？前面我们知道，内部中断是发生在指令执行完毕之后，外部中断是发生在CPU时钟信号之后，而对于外部中断，CPU每执行完一条指令都会检测是否有外部中断信号到来。若有则转中断处理。 单重外部中断的处理过程CPU在反复执行指令的过程中，每执行完一条指令，都会去检测是否有外部中断信号到来。如果检测到有中断信号，则转中断处理过程。 保护断点。把当前要执行的下一条指令的地址保存到内存中，以便中断返回时能把这个地址恢复到程序计数器PC中，使被中断的程序从断点处开始继续执行。 关中断，转中断处理程序，在中断处理程序中保护现场。也就是把相关的硬件上下文信息（中断返回恢复被中断程序的执行时，需要写回CPU寄存器的值）保存到内存中。 根据中断向量到中断向量表中找到中断例程的入口地址。 执行中断例程，完成本次中断处理工作。 恢复现场，开中断，CPU返回断点处继续执行被中断的程序。 怎么找到中断服务子例程？ 中断向量（中断类型号）中断向量是对不同的中断源到来的信号编号，是一个无符号整数（0~255）。不可屏蔽中断和异常的中断向量是固定的，而可屏蔽中断的向量可以通过对中断控制器编程来改变。可屏蔽中断控制器的IRQ线是从0开始按顺序编号的，因此，第一条IRQ线通常表示成IRQ0。与IRQn关联的Intel缺省向量是n+32。通过向中断控制器端口发布合适的指令可以修改IRQ和向量之间的映射。 中断描述符表（Interrupt Descriptor Table,IDT，又叫中断向量表）它是一个系统表，每一个中断或异常都在表中有唯一对应的表项，其中存有与中断或异常处理子例程入口地址相关的信息。在Linux里，IDT的每个表项占8个字节（64位）。IDT表的起始地址由操作系统执行lidt汇编指令并存放在idtr CPU寄存器中。 中断子例程的入口地址相关信息在内存中的地址=idtr中的起始地址 + 8 x 中断向量的值。 时钟管理 时钟有何用时钟是计算机系统的脉搏，很多计算机的活动都是由定时器测量来驱动的。计算机中当前时间显示功能、即时通讯等与时间相关的软件都需要时钟机制的支持。比如要编译一个很大的工程文件，不可能每次编译都去重新编译所有源文件，而是只编译修改过的那些源程序。判断方法是看a.c最后生成时间是否晚于a.obj的生成时间。 计算机系统中的时钟机制计算机系统中其实有两种时钟：RTC（Real-Time Clock）时钟和OS时钟。RTC时钟也叫CMOS时钟，是一块时钟芯片，靠电池供电，为计算机提供计时标准，是最原始、最底层的时间数据。OS时钟是产生于PC机主板上的定时/计数芯片，在开机时有效，由操作系统控制。计算机开机加电后，操作系统通过BIOS获取当前RTC时钟的值，来作为系统的初始时间。操作系统初始化后启用自己的时钟硬件（可编程间隔定时器PIT，Programmable Interval Timer）。PIT按照一定的频率产生时钟中断，来告诉内核又一个时间间隔过去了。RCT时钟和OS时钟关系如下图所示： OS时钟机制OS系统时钟主要有两个作用： 保存当前日期和时间，便于用户程序可以通过系统调用获取当前时间，同时也可以由内核把当前时间作为文件和网络包的时间戳 维持定时器，用来告诉内核或用户程序某一时间间隔已经过去了 OS时钟依靠时钟硬件（可编程间隔定时器）和时钟软件（时钟中断处理程序）来实现。下面简单介绍一下它俩： 可编程间隔定时器PIT（OS时钟硬件）主要有晶振、计数器、保持寄存器三部分构成。如下图所示：晶振按固定频率产生脉冲，每产生一次脉冲计数器值减1，当计数器值减到0时，产生一次时钟中断信号，再把保持寄存器的值送往计数器，使其恢复初始值。这样，PIT就每隔一定时间产生一次时钟信号了。 时钟中断处理程序（OS时钟软件）也叫时钟驱动程序。PIT每产生一次时钟中断信号，OS内核都要执行时钟中断处理程序，来完成如下功能 维护日期、时间 递减时间片并检查是否为0，防止进程运行超时 对CPU的使用情况记账 递减报警计数器 【注】：Linux OS时钟的时间基准是1970.1.1的凌晨0点 系统调用 什么是系统调用？操作系统内核中有一些预先定义好的模块，系统调用就是让用户程序去调用这些内核模块的接口。如C语言的getpid()函数实际上是调用了在内核态运行的系统调用sysgetpid()，来获得进程标识符。可以看出，系统调用和一般函数调用还是挺像的。 系统调用和一般函数调用的区别？先来看看用户态和核心态的概念：当一个进程在用户空间执行时，该进程便处在用户态；当一个进程在具有执行系统核心代码的权利时，该进程便处于核心态。那么系统调用和一般函数调用的区别是什么呢？ 系统调用运行在核心态，一般函数运行在用户态 用户态进程执行系统调用时（调用前进程处于用户态，调用时进程处于核心态，调用后进程处于用户态），当前进程会被中断，由系统去找到相应的系统调用子程序，并且在核心态下执行，而一般函数调用是不需要中断处理的。 Linux中的一些系统调用 fork：创建一个新进程 clone：按指定条件创建子进程 execve：运行可执行文件 exit：中止进程 getpgid：获取进程组标识号 open：打开文件 creat：创建新文件 close：关键文件描述字 read：读文件 write：写文件]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>OS内核</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BIOS和微机操作系统的启动过程]]></title>
    <url>%2F2016%2F10%2F09%2FBIOS%2F</url>
    <content type="text"><![CDATA[什么是BIOS？BIOS，Basic Input Output System基本输入输出系统，是最接近硬件的软件之一，是固化在计算机主板上的ROM芯片中的一组程序，直接对计算机系统中的输入输出设备进行硬件级的控制，为其他软件程序与硬件设备之间建立连接提供了基础，包含基本的中断服务程序、系统设置程序、加电自检程序和系统启动自举程序。BIOS程序是计算机开机加电后第一个开始执行的程序，完成硬件检测及基本的设置功能，故BIOS为操作系统及其他自启动程序的开发和加载提供了接口，是计算机系统中最基础的系统软件。 BIOS的住处：BIOS芯片上面已经介绍过，BIOS程序被固化在ROM芯片中，所以保存BIOS程序的ROM加上其配套的电路就构成了BIOS芯片。BIOS芯片通常是一块32针的双列直插式长方形或正方形集成电路，表面贴有“BIOS”字样的标签，如下图所示：BIOS芯片根据其ROM存储器特点的不同，分为EPROM和EEPROM两种类型。 EPROM（Erasure Program Read Only Memory）可擦除可编程只读存储器，其芯片中央有一个透明的小窗口，通过这个小窗口可以使用紫外线光将芯片上保存的信息擦除掉（所以当不需要擦除时，就需要一块不透明的标签将已保存了信息的EPROM芯片的紫外线窗口封住）。在向EPROM写入内容时，必须先用紫外线擦除器将EPROM中的信息清除掉，即将EPROM中的每个信息存储比特单元都变成“1”状态。 EEPROM（Electricity Erasure Program Read Only Memory）电可擦除可编程只读存储器，在通常情况下，EEPROM也是只读的，当需要写入内容时，只要在指定的引脚上加一个高电压即可快速写入和擦除。 另外还有一种EEPROM就是现在主板上常见的FLASHROM（闪速存储器，闪存），其读写速度更快更可靠，而且使用单电压进行读写和编程，为便携式设备的在线操作提供了极大的便利，所以广泛应用在计算机主板上。 通常，在Intel486以及486以下档次计算机中使用的BIOS芯片基本上采用的是EPROM芯片，而586及以上档次计算机中使用的基本上都是EEPROM。 BIOS程序的组成前面已经介绍过，BIOS程序包括中断服务程序、系统设置程序、加电自检程序、系统启动自举程序。下面来看看这几种程序的详细介绍。 BIOS中断服务程序 什么是中断？中断是改变处理器执行指令顺序的一种事件，这样的事件与CPU芯片内外部硬件电路产生的电信号相对应。中断发生时，计算机停止现行程序的运行，转向对这些中断事件的处理，处理结束后再返回到现行程序的中断处，继续往下执行。 在哪里对中断事件进行处理的？CPU对中断的处理是转到中断服务程序来进行的 什么是中断服务程序？中断服务程序是系统开发者针对某种中断事件事先编写好的处理程序，并且把他们保存在内存的某个地址空间里。 那么怎么根据中断源找到相对应的中断服务程序呢？中断源在向CPU进行中断请求时，会告诉CPU一个中断类型号（在x86系统中是0~255之间的整数），每个中断类型号都会对应一个中断服务程序。那么怎么根据中断类型好去找它命中注定的中断服务程序呢？其实所有中断服务程序的入口地址（起始地址）都被保存在中断向量表（一维连续的一段内存空间）中，中断向量表的每一个表项的长度都是固定一样的。所以让中断类型号和中断向量表的表项依次一一对应不就行了嘛？根据中断类型 x 中断向量表项长度 + 中断向量表起始地址，就可以找到对应的表项了，然后再从里面取出中断服务程序的起始地址，跳转到该地址，就可以执行中断服务程序进行中断处理了。 BIOS包含哪些中断服务程序呢？显示服务程序（INT 10h）、直接磁盘服务程序（INT 13h）、键盘服务（INT 16h）等等。 这些BIOS中断服务程序可以为微型计算机软件和硬件之间提供可编程接口，是软件和硬件的中间桥梁。DOS、Windows等操作系统对软盘、硬盘、光驱与键盘、显示器等外围设备的管理就是建立在系统BIOS的基础上的。当然，程序员还可以直接调用BIOS中断服务程序。 BIOS系统设置程序如果你给自己的电脑装过操作系统，会知道当开机后狂按某个（F2、F12等等）按键时，会进入一些设置界面，这里其实就是一些BIOS系统设置。微型计算机中各部分组建的配置参数是放在一块可读写的COMSRAM芯片（简称CMON）中的，它保存着系统CPU、软/硬盘驱动器、显示器、键盘等部件的配置信息。微机关闭电源后，系统通过一块后备电池向CMOS供电以保持其中的信息。如果CMOS中关于微机部件的配置信息不正确，会导致系统性能降低和零部件不能识别，从而导致一系列的软硬件故障。在BIOS芯片中装有一个系统设置程序，用来设置CMOS中的各种参数。增加了新的部件或者要进行系统安装或升级时，一般都需要进行BIOS设置。【注】： BIOS设置和CMOS设置的区别CMOS是微机主板上一块特殊的CMOSRAM芯片，是存放系统参数的地方；而BIOS是一组程序，存储在主板上的EPROM或EEPROM芯片中。也就是说，通过BIOS中的系统设置程序其实是对CMOS参数进行设置。 POST加电自检程序为了保证计算机正常启动，微机在接通电源后，系统有一个对内部各个设备进行检查的过程，该过程是由一个通常称之为POST（Power On Self Test，加电自检）的程序来完成的。完整的POST自检过程包括了CPU、640K基本内存、1M以上的扩展内存、ROM、主板、CMOS存储器、串口、并口、显示卡、硬盘及键盘的测试。自检过程中如果发现有问题，系统将会给出提示信息或鸣笛警告。 BIOS系统启动自举程序在自己装操作系统的过程里，想想是不是有一步是让设置磁盘的优先级，如果优先级最高的是U盘，则接下来系统就会进入U盘里的操作系统映像，用U盘来装操作系统了。而这个查找优先级最高的硬盘驱动器并装载操作系统的过程，就是BIOS系统启动自举程序来完成的。BIOS系统启动自举程序的作用是在完成POST自检后，按照系统CMOS设置中的启动顺序搜寻硬盘驱动器及CDROM、网络服务器等有效的启动驱动器，读入操作系统引导程序，开始逐步完成操作系统内核的加载和初始化，完成系统的启动。 BIOS的基本功能从上诉对BIOS程序组成部分介绍，可以看出BIOS的基本功能有如下： 在微机启动过程中的自检及初始化。 提供程序服务处理。如磁盘读写、键盘读取、将文件输出到答应及等等。 提供硬件中断处理。 微机启动的过程 当按下电源开关后，电源开始向主板和其他设备供电。但是此时电压并不稳定，主板会认为电压并没有达到CMOS中所要求的电压，就会向CPU发出RESET信号（复位信号），当电压到大符合要求的稳定值时撤销复位信号，然后CPU立刻从基本内存的BIOS段读取一条跳转指令，跳转到BIOS的启动代码处，开始执行BIOS程序。 执行BIOS启动程序会进行加电自检POST。这个过程进行得很快，主要是检测关键设备（如电源、CPU芯片、BIOS芯片、基本内存等电路是否存在，供电情况是否良好等），如果发现了问题，系统喇叭会发出警报声音（更具警报声的长短和次数可以知道出现了什么问题）。 如果自检通过，系统BIOS会查找显卡BIOS，找到后会调用显卡BIOS的初始化代码，此时屏幕上会显示显卡的相关信息。 显卡检测成功后会进行其他设备的测试，通过测试后系统BIOS重新执行代码，并显示启动画面，将相关信息显示在屏幕上，然后进行内存测试，最后是短暂出现系统BIOS设置的提示信息，此时按下相应按键，可以对系统BIOS进行需要的设置，完成后系统会重新启动。 然后系统会检测系统的标准硬件（如硬盘、光驱、串行和并行接口等），检测完成后会接着检测即插即用设备，如果有的话就为该设备分配中断、DMA通道、I/O端口等资源，至此所有的设备都已经检测完了。 上面的检测都顺利完成后，BIOS会按照用户指定的设备顺序，依次从设备中找启动程序，以完成系统启动（如果首先是硬盘启动，则BIOS会检查硬盘的0面0磁道1扇区，若发现该扇区以0xAA55结束，则BIOS认为它是引导扇区。一旦发现引导扇区，BIOS会执行程序将其装入到内存地址0000：7c00处，然后跳转到该地址处执行这段引导程序代码，开始加载操作系统，BIOS将系统的控制权交给操作系统）。 简化的微机启动过程如下（结合我们平时的开机过程来理解）：按下电源开关，电源供电 → CPU通过基本内存的BIOS段，找到BIOS程序起始地址，执行BIOS程序 → BIOS进行POST加电自检 → 检测和初始化显卡，在屏幕上显示相关信息 → 内存测试 → 出现BIOS设置的提示信息 → 检测硬盘、串并行接口等标准硬件 → 检测U盘等即插即用设备并为其分配资源 → 按照设备启动顺序加载操作系统 → 将系统控制权交给操作系统。 【注】：当硬盘的多个分区中同时存在多个操作系统时，每个分区都会有自己的引导扇区，那么操作系统怎么知道应该加载哪个扇区呢？操作系统会先去执行0面0磁道0扇区的主引导扇区的代码，判断当前被激活的分区，然后加载激活分区的引导扇区，从而加载该激活分区的操作系统。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>BIOS和微机启动过程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统概述]]></title>
    <url>%2F2016%2F10%2F08%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[什么是操作系统操作系统（Operating System，OS）是一种复杂的系统软件，它提供计算机用户与计算机硬件之间的接口，并管理计算机软件和硬件资源。操作系统本身并不向用户提供功能，但是它为应用程序的运行提供平台，并使应用程序的编程变得简单、容易。 接口：两个不同组成部分的交界面。在计算机领域，接口分为硬件接口（如USB接口、串口、并口）和软件接口（如C语言中的函数调用printf()）。 操作系统必须要实现的两个功能： 与硬件部分相互作用，为包含在硬件平台上所有的低层可编程部件提供服务 为运行在计算机系统上的应用程序提供执行环境 操作系统的发展 无操作系统第一代计算机（1945-1955年）使用电子管作为主要的电子器件，用插件板上的硬连线或穿孔卡片表示程序，没有存储程序的内存，也就自然没有操作系统（因为操作系统是需要常驻内存的）。比如1946年诞生于宾夕法尼亚大学的第一台电子计算机ENIAC，它的每一个用户程序进入计算机和退出计算机系统都需要人工干预，计算机无法自动完成程序的加载和卸载，所以整个计算机系统处于“运行—因等待人工操作而暂停—运行”这样一种不能自动连续工作的状态。由于CPU长时间等待人工操作，造成CPU资源的严重浪费。 单道批处理系统第二代计算机（1955-1965年）使用的主要电子器件是晶体管，开始使用磁性存储设备，内、外存容量增加，出现了早期的单道批处理系统。单道批处理系统中有早期的操作系统（也叫监视程序）常驻内存，能够连续自动地读取磁带中的用户程序，但是内存中只能驻留一道用户作业，CPU和内存资源被用户作业独占。但是当程序执行到输入输出操作时，由于不需要CPU干预，并且内存中又只有一个程序在运行，所以CPU便空闲下来了，造成CPU的浪费。 多道程序系统为了解决上述问题，多道程序系统的最初想法是将内存分成几个部分，每一部分存放不同的作业，当一个作业等待输入输出操作时，另一个作业可以使用CPU；任何时刻，当一个作业运行完毕，操作系统会自动从外存读出另一个作业，装入空闲的内存区域运行。早期的多道程序系统不具有交互功能，称为多道批处理系统。 微机操作系统随着个人电脑的出现，微机操作系统应运而生。第一个微机操作系统是Intel的CP/M（Control Program for Microcomputer）（后由Digital Research重写，使之适用于多种微机），在微机操作系统市场风行了5年，称为最著名的8位机操作系统。20世纪80年代初，IBM进军个人电脑市场时，想要Digital Research为IBM的个人电脑编写16位操作系统，但是遭到了拒绝。可怜，这对Digital Research真的是一场肠子都悔青的商业决策。与此同时，另一位著名的商业天才风生水起，Gates从计算机制造商Seattle Computer Products手里购买了DOS（Disk Operating System），然后向IBM提供整套的DOS和BASIC。后来升级成MS-DOS（Microsoft Disk Operating System）。商业天才盖茨采取将MS-DOS与硬件捆绑销售的策略，站在蓝色巨人IBM的肩上，使MS-DOS成为微机操作系统的主流。后来受苹果Macintosh（麦金塔）的影响（很可能是抄袭~），1985年微软开始构建Windows操作系统，使之成为微机操作系统的主流（如今的微机操作系统还有Linux、Chrome OS、OS X等）。 实时操作系统随着计算机在机器人、航空航天、自动化控制等领域的应用，出现了各种实时系统。实时操作系统是支持实时计算的系统。实时计算是指计算的正确性不仅依赖于系统计算的逻辑结果，还依赖于产生这个结果的时间。应用于实时系统中的操作系统称为实时操作系统（实时系统也可以不使用操作系统）。 【注】： 单道批处理系统具有自动性、顺序性（将外存中的作业顺序装入内存运行）、单道性的特点，而多道批处理系统具有多道性、无序性（同时驻留在内存中的作业，其被调度的顺序和执行的进度无法预知）、调度性（多道程序系统必须具有作业调度和进程调度功能）。 分时系统运行多个用户通过终端同时使用计算机（通过类似时间片轮转的方法来实现），并且具有交互性，用户可以通过终端与系统进行广泛的人机对话。 操作系统的特征 并发并发是指两个或多个事件在同一时间间隔内发生。而并行是指多个事件在同一时刻发生。 共享系统中的资源可供内存中多个并发执行的进程共同使用。分为互斥共享和同时共享。 互斥共享：任意时刻一种资源只能被一个进程访问，当一个进程访问该互斥资源时，其他进程必须等待，直到资源被进程访问完毕，释放访问权。 同时共享：从宏观上看，资源可以被多个进程同时访问。例如对磁盘的访问，虽然在任意时刻只能有一个程序访问某个磁盘，但是多个程序可以在短时间内轮流访问该磁盘，就造成了在宏观上同时共享某资源的假象。 虚拟虚拟是指通过某种技术把一个物理实体变成若干逻辑上的对应物。例如虚拟CPU、虚拟内存、虚拟打印机，都是操作系统通过某种技术把少量的物理资源变成比物理资源多的逻辑资源。 异步异步是指进程以不可预知的速度向前推进。 操作系统的功能 存储器管理存储器管理的主要任务是为多道程序的运行提供良好的环境，方便用户使用存储器，提高存储器的利用率，以及能从逻辑上扩充内存。存储器管理主要有内存分配、内存保护、地址映射、内存扩充等。 内存分配：为每道程序分配内存空间，使它们“各得其所”，提高存储器的利用率，以减小不可用的内存空间，允许正在运行的程序申请附加的内存空间，以适应程序和数据动态增长的需要。主要有静态内存分配方式（实现分配好并且不再变化）和动态内存分配方式 （运行过程中根据进程的请求分配内存，内存中分区的大小和数量都是动态变化的）。 内存保护确保每道用户程序都在自己的内存空间中运行，互不干扰。可以采用界限存储器存放允许程序访问的地址区间的上限和下限值来实现内存保护。 地址映射在CPU之心改程序过程中访问内存时，把程序中的逻辑地址转换为物理地址（内存地址）。 内存扩充借助虚拟存储技术，从逻辑上扩充内存容量，使系统能够提供比物理内存大的容量。需要有请求调入功能（指令或数据不在内存时请求调入内存）和置换功能（请求调入时若内存空间不够，则要将内存中的一部分换出到外存，再调入当前需要的内若）。 进程管理主要包括进程控制、进程同步、进程通信、进程调度等。进程控制功能完成对进程的创建、撤销、唤醒、阻塞等；进程同步功能完成多个进程（以及线程）运行的互斥与协调；进程通信功能用来实现进程之间的信息交换；进程调度功能是从进程的就绪队列中选出一个进程，把处理机分配给它，并为它设置运行现场，使其投入运行。 设备管理主要完成用户的I/O请求，为用户分配I/O设备。 文件管理主要是对文件存储空间的管理、目录管理、文件读写管理和存取控制。 提供用户接口为了方便用户使用操作系统，操作系统向用户提供了用户与操作系统之间的接口。向最终用户提供命令行和图形接口，向程序员提供高级语言和操作系统之间的接口—“系统调用”。系统调用是操作系统实现的具有某种功能的程序模块。应用程序可以通过系统调用的接口，来使用操作系统实现的功能，获得操作系统内核的服务。 操作系统的体系结构简单的监控程序模型、单体结构模型、层次结构模型、客户/服务器模型与微内核结构、动态可扩展结构模型]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统概述</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网游流畅基础：帧同步游戏开发]]></title>
    <url>%2F2016%2F09%2F18%2F%E5%B8%A7%E5%90%8C%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[在现代多人游戏中，多个客户端之间的通讯，主要是同步多方状态。为了同步多方状态，主要有两个技术： 状态同步客户端发送游戏动作到服务器，服务器收到后，计算游戏行为的结果，然后以广播的方式下发游戏中各种状态，客户端收到状态后再根据状态显示内容。在回合制游戏中，大多都是这种方式 帧同步也是客户端发送游戏动作到服务器，服务器收到后并不计算游戏行为结果，只是转发所有客户端的动作（或者不需要服务器，客户端之间直接通过P2P技术发送游戏动作）。然后客户端根据收到的所有游戏动作来做游戏运算和显示。早期的IPX（Internetwork Parket Exchange Protocol，互联网数据包交换协议）网络游戏就是这种帧同步的方式，比如红色警戒、星际争霸和大量的支持网络连线双打的游戏机模拟器。 什么时候用状态同步，什么时候用帧同步？状态同步主要是依靠服务器来计算游戏状态，然后下发到客户端，而帧同步主要是依靠客户端自己来做游戏运算，服务器仅仅是做一个转发，甚至不需要服务器，客户端之间可以通过P2P方式来转发数据。 由于帧同步只是转发游戏行为，而不是游戏状态，所以要广播的数据量比状态同步要小很多，比较适合游戏行为非常频繁的动作类游戏，比如飞行射击、FPS（First Person Shooting Game，第一人称射击类游戏）、RTS（Real Time Strategy Game，即时战略游戏）这些游戏。因为这些游戏中的对象特别多，比如满屏的子弹，如果使用状态同步，那么服务器要广播的数据就很大了，但是如果用帧同步，则仅仅需要广播与玩家角色有关的动作即可，像在射击游戏中其余的满屏的子弹（这些都是有机器控制的，不是玩家控制的）都不需要广播数据了。这个时候帧同步的优势很明显。 反过来，如果游戏里有大量的玩家，那么帧同步和状态同步的差异就不明显了，因为与每一个玩家相关的动作都需要做广播。而且状态同步由于是在服务器上进行游戏运算，安全性会更高，比较容易防止外挂。 帧同步机制帧同步最重要的基础概念：相同的输入+相同的时机=相同的显示意思是每个客户端在同一时间收到的，来自网络中多个客户端的操作是一样的，就能够达到同步效果。 由于在同步中每个客户端的运算要绝对一致，所以不能依赖本地时间、本地随机数等等类似的操作，而应该是以来自网络的操作数据为主。所以，在游戏客户端引擎中的本地Update就不能再在每帧画面渲染前被调用了，因为它是依赖本地时间的。Update总不能省掉吧？因为它是游戏逻辑更新的主循环，没有它游戏就没法动了。既然Update是必须的，那么什么时候调用它才能保证同步呢？ 在一般的帧同步系统中，会有一个Relay Server负责广播所有客户端的数据，并且由于每个客户端不能依靠本地时间来驱动Update，只能依靠来自网络的数据。所以，Relay Server会每隔一定时间向所有客户端下发“网络帧”，当有玩家有输入的时候，把玩家的游戏操作数据填入到网络帧数据包中，再进行广播，如果没有玩家输入，则发送空（大部分是空的）的网络帧。当每个客户端收到网络帧的时候，就会调用一个UpdateByNet()函数来进行游戏更新。（UpdateByNet其实干的是和Update差不多的事，只是受驱动的对象变了，Update受本地CPU驱动，UpdateByNet受网络驱动。而且帧同步中Update函数依然存在，也会受CPU驱动执行，不过其中的大部分内容都挪到了UpdateByNet中，所以Update的更新不再会产生游戏逻辑的更新，UpdateByNet才会）。 显然网络帧的速度要比本地CPU帧速度慢很多，帧率会很低。那么怎么保证游戏流畅度呢？ 帧同步中如何保证游戏流畅 Delay Server每一个网络帧广播的数据应该要足够小，最好在一个 MTU（Max Transmission Unit ）以下，这样才能有效降低网络延迟。 为了让Delay Server每次广播的数据量小，一般要求每次客户端发送的数据应该小于128字节 一个减少客户端发送数据长度的方法就是：自己写序列化函数。一般的面向对象语言都带有把对象序列化和反序列化的功能，但是编程语言的默认序列化功能，为了实现一些高级功能（比如反射），会把很多游戏逻辑所不必要的数据也序列化了（比如对象类名、属性名）。所以我们可以自己针对特定的对象来编写序列化函数，来减少多余的数据，甚至能合并和裁剪一些数据项，以最小化数据长度。 另一个减少客户端发送数据长度的方法是：用整数代替浮点数。比如在游戏中所使用的位置数据，大多是浮点数，占了8个字节，其实往往我们并不需要这么高的精确度，所以可以考虑把浮点数变成整数，整数只占了4个字节，少了一倍的数据量。最简单的方法是把浮点数乘以1000或100然后取整（客户端接收到以后可以除以1000或100来还原，这样在保证整数的同时还能有一定的精确度）。 还有一个减少客户端发送数据长度的必要方法是：只有当客户端收到网络下行帧以后才发送一次上行的玩家操作，而不是每一个渲染帧（本地Update）都去发送。 玩家的网络可能会出现临时拥堵（网络抖动），也有可能中途会有玩家加进来，甚至游戏录像等等都会导致客户端收到一堆“过去时间”里的网络帧，无法即时处理。这时就要求玩家恢复正常状态后，要有处理这一堆网络数据的能力。最简单的办法就是加速播放（快进或者叫拉帧）：客户端收到网络帧处理完游戏逻辑后，在同一个渲染帧（本地Update）内，马上重复接收下一个网络帧（而不再是直到下一次Delay Server广播时才再次接收网络帧），然后又立即处理。这样往往能在一个渲染帧的时间内，加速赶上服务器广播的最新游戏进度（赶上其他正常玩家的当前游戏状态）。但是也有副作用，如果客户端积累的包太多（比如游戏已经开始10分钟，新玩家中途加入），客户端会因为在一个渲染帧内疯狂下载积累的帧同步包和快进运算，导致本地客户端长时间卡住。所以有时候会限制一个渲染帧内快进的次数，保证用户还是能看到活动的画面（虽然动的比较快但也总比一直静止好啊！）。如果帧同步包实在是太多，要快进的进度很多，那么就要采用“快照”技术了。 客户端在快进时，每个渲染帧会接收很多网络帧，因为每收到一个网络帧都会发送一次玩家操作数据，这回导致Delay Server广播的数据量很大，造成网络延迟。所以当某个客户端在快进时，应该禁止输入玩家输入，那么每次收到网络帧后由于没有玩家输入就不会再进行数据发送了。 为了提高实时性，一般使用UDP，而不是TCP，但是使用UDP又会带来丢包、乱序。所以，一般会采用冗余的方式，每个网络帧数据包其实还包含了过去2帧的数据，也就是说每次发3帧数据来对抗丢包，3个包里只要有一个包没丢就不会影响游戏。 Delay Server上还会保存大量的客户端上传的数据，如果客户端发现丢包或者乱序，就会发起一次“下载”请求，从 Delay Server上重新下载丢失或乱序的帧数据包（这可能会使用TCP）。 通过牺牲某些不重要的特性来提高游戏流畅度 牺牲一致性来交换流畅度。虽然帧同步的目标就是所有客户端都看到一致的显示，但是游戏内容很多，有一部分内容是可以容忍不一致的，飞机大战中，满屏的子弹是由机器控制的，加上子弹本身存在的时间也很短，所以这些子弹在不同的客户端上是可以不一致的；又比如几个玩家一起打电脑控制的怪物，玩家关心的是怪物被打死，而不会太在意其他玩家的出招是不是在自己电脑上滞后了几秒。这种情况下，就可以把可以容忍不一致的那部分游戏逻辑，从网络帧的UpdateByNet拿出到本地渲染帧的Update里。这样就算网络有些卡，但还是有很多东西是不会卡住的（与玩家有关的逻辑更新还是应该受网络帧驱动，不然就失去了同步的效果）。 牺牲实时性来交换流畅度。一般我们是希望玩家有输入后，从客户端把操作数据发出去，然后在收到下一个网络帧时就能立即得到响应。但是网络是不稳定的，什么时候能收到下一个网络帧是不确定的，如果网络快点，客户端响应得就快，网络慢点，客户端响应得就慢，这会造成同样的操作出现一会快一会慢的效果，像在跑酷游戏中，如果主角一会向前跑得蜗牛似的，一会又向前跑得很快，这是很诡异的。解决办法就是：收到网络帧数据包后，并不立即响应和处理，而是放入客户端的网络帧缓冲区内，客户端每隔一定时间从缓冲区中取出一个网络帧进行运算。当网络速度快时，会有比较多的网络帧被存放到缓冲区中，网络速度慢时，可能一段时间内都没有网络帧进入缓冲区，但是客户端依旧可以从缓冲区中取出网络帧（这些网络帧是在网络快时被缓存下来的），因为客户端从缓冲区取网络帧的频率是固定的，所以对数据的运算是匀速的，对游戏逻辑的更新也就匀速了。虽然在网络快时没有得到立即响应，牺牲了实时性，但是同时却换来了游戏的流畅性，平滑了对那些一会快一会慢的网络帧数据包的响应（其实原理类似于传输语音业务，可参考这篇文章）。 这种做法会让玩家感觉到一个固定的延迟：输入操作后，隔一定时间才会有反应。但起码这种延迟是可以固定的，是玩家可以预测的，方便玩家操作。（这个操作的感觉就好像玩家有了一定的”惯性”一样，按下跑并不会立刻跑，松开跑不会立刻停，但这个惯性的时间是固定的） 牺牲公平性来交换流畅度。这个特性和一致性的根源一致，玩家不希望对方因为网络好，电脑运行速度快就比自己先看到游戏的运行结果，比如在格斗对打游戏和RTS游戏里这是很不公平的。为了让网络、硬件不同的玩家能够公平游戏，经常会使用一种叫”锁步”的策略：每个客户端都定时（每N个渲染帧）发送一个网络帧到服务器，即使玩家没有任何操作也像心跳一样发送空数据帧，每个客户端要收到其他所有客户端的心跳帧才能开始一次逻辑运算和更新。这就是让所有客户端相互等待，如果有玩家卡了，其它客户端都能知道，然后让玩家停止输入来等待对方玩家恢复网络。 这种做法其实是牺牲流畅度的，一旦有玩家掉线了，其他所有玩家都会受到影响。为了减少这种对流畅度的影响，锁步的时候可以少锁一点，对方的”心跳帧”缺了若干帧（比如几秒）自己这里都还是能正常更新，能不公平地玩一会，如果这段时间内还是没有补齐所缺的”心跳帧”，才宣布锁住游戏等待对方玩家恢复网络。这就是通过牺牲公平性来叫交换流畅度。甚至在一些非PVP（玩家对战）的帧同步游戏中都不太需要这个公平性，因为不是和对方玩家实时对战的，并不关注对方是不是比自己先看到结果。 移动网络帧同步中自定义的UDP 为何要使用UDP而不是TCP呢？ TCP的慢启动算法不适合移动网络，移动网络信号时好时坏，使用慢启动会使数据包的发送速率经常在很低的段位，导致数据不能及时快速地到达对端 拥塞避免算法不适合移动网络主要原因是其考虑到网络的公平性及收敛性，并且AIMD 算法会使实时性大受影响，延迟明显提升 还有TCP协议用于重传的RTO的指数变化及拥塞算法的实现Nagle的缓存等，都是TCP并不太适合高实时性要求的游戏玩法的原因 实验表明，在弱网络环境下，UDP的RTT几乎不受影响，而TCP的RTT波动比较大，特别是受丢包率影响比较明显 基于UDP的FSP协议栈由于UDP是不可靠的，所以需要DIY自己的UDP。于是基于UDP实现一个自定义的协议栈，称为FSP（FrameSyncProtocol）。FSP的基本原理其实就是仿照TCP的ACK/SEQ重传机制，并且使用冗余重传，来实现传输的可靠性。使用冗余重传的好处是简化了麻烦的时序问题，并且收到的每个包都是顺序的。在网络拥塞时带宽利用率优于TCP，但流量会略微增加一些（好像也无法调节网络拥塞，因为它去除了TCP的拥塞控制机制，可能对于时好时坏的移动网络是比较适合的，因为网络不大会一直很差）。FSP图示如下： 客户端发Action1，服务器未收到 客户端新增Action2，发送给服务器的包同时包含Action1和Action2，并且seq=2 服务器确认并发送给客户端ACK=2的包 客户端由于某些原因（可能是网络延迟）未收到服务器ACK=2的确认包，新增Action3后，客户端则把Action1、Action2、Action3一起发送给服务器，并且seq=3 客户端收到了ACK=2的确认包，则把队列中的Action1、Action2删除，新增Action4后，把队列中的Action3、Action4一起发送给服务器，并且seq=4 实际上线测试中，FSP在弱网络环境下表现也是不错的 更多详细介绍，请看这篇文章]]></content>
      <categories>
        <category>游戏开发</category>
      </categories>
      <tags>
        <tag>帧同步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法之查找]]></title>
    <url>%2F2016%2F09%2F17%2F%E6%9F%A5%E6%89%BE%2F</url>
    <content type="text"><![CDATA[先来看几个概念 查找分为静态查找和动态查找。静态查找是只做查找操作，而动态查找是在查找过程中同时进行插入或删除。 查找算法主要分为： 顺序表查找顺序表查找就是按序从头找到尾，找到为止。时间复杂度为O(n) 有序表查找 折半查找核心思想：每次查找线性有序表(假定从小到大有序)的中间位置的记录，如果给定值小于中间记录，则在左半区查找；如果给定值大于中间记录，则在右半区查找。要求查找表是有序的顺序存储的线性表。代码如下： 插值查找核心思想：插值查找是折半查找的改良版，每次不再是查找正中间位置的元素，而是根据元素内容在最小值到最大值之间的比例，来查找区间里同比例的那个位置上的元素。插值计算公式如下：mid=low+(key-a[low])/(a[high]-a[low])*(high-low)。同折半查找一样，要求查找表示有序的顺序存储的线性表，而且需要表内元素值分布比较均匀，这样查找效率才会比较高。代码如下： 斐波那契查找(黄金分割法查找)斐波那契数列有如下定义：F(n)=F(n-1)+F(n-2)，该数列越往后相邻的两个数值的比例越接近于黄金比例0.618。核心思想：斐波那契查找也是折半查找的改良版，每次不再是查找正中间的位置，而是先把查找序列补全成为刚好比自身长度大的斐波那契数的长度(在序列后面补序列的最后一个元素值)，再去查找序列中位置等于前一个斐波那契数上的元素。如下图：代码如下： 斐波那契查找最大的优点就是它只有加减法，没有除法，这在海量数据中运算时，还是有不小的性能提升。 线性索引查找就像房间里面的n多东西，一样一样去找是非费劲的，也很难对他们去排序，即使排了序还要花大把时间去维护这个序列。如果我们一个小本子，里面记录着每一样东西它在房间里的位置，那找起来就相当方便了。这就是索引。每个索引项至少要包含记录的关键字和记录存储的位置。上面的例子里，每件物品相当于一个记录，它有各种属性，名字就相当于它的关键字，能唯一确定它，在房间里的位置就相当于记录的存储位置。线性索引表就是索引项组成的线性结构，基于线性索引表的查找就是线性索引查找。有三种重要的线性索引：稠密索引、分块索引、倒排索引。 稠密索引稠密索引是指每一条记录都对应一个索引项。为了让索引表也可以排序，我们可以用数字来替换关键字，比如用数字去替换名字。在下图中表现为关键码：但是稠密索引有个很致命的缺点，当记录量很大时，比如上亿，就需要和记录量一样多的索引项，这需要反复地去访问磁盘，查找性能反而会下降。 分块索引将大量的记录分成若干块，快内无序，块间有序，再让每块对应一个索引项，这就是分块索引(快内再有序的话代价太大)。在块数和快内记录数相等时，分块索引的平均查找长度最短，即性能达到最好。 倒排索引在前面的例子中，如果我想知道哪些东西是红色的，是需要一个物体一个物体地去查看它的所有属性，看看有没有红色这一项吗？或者说我想知道在n多篇文章里，哪几篇出现了hello这个单词，哪几篇出现了world这个单词，是需要一篇文章一篇文章去找吗？这样太费时了！如果我们有一张表，左侧是红色，右侧红色对应的物体，或者左侧是单词，右侧是单词出现的文章，根据这张表是不是能快很多？由于这是根据记录的属性去查找记录，所以称为倒排索引。 二叉排序树想要查找效率高，就应当让数据有序，但是如果采用线性顺序存储，又降低了插入和删除记录的效率。有没有什么办法能让查找、插入、删除的效率都高呢？二叉排序树可以做到。二叉排序树也叫做二叉搜索树。 二叉排序树：左子树上所有结点值小于根结点，右子树上所有结点值大于根结点。 二叉排序树的插入和创建现在有一堆记录{62，88，58，47，35，73，51，99，37，93}，把第一个数据作为根节点，后面每插入一个数据，先从根节点开始，小于则向左走，一直到某个结点的左儿子为空时插入，大于则向右走，一直到某个结点的右儿子为空时插入（在每个结点处都要判断是向左还是向右走）。最终构造出如下图的树：先把62作为根结点，接下来是88，比62大往右走，发现62结点的右儿子为空，则插入到这个位置；接下来是58，比62小往左走，发现62结点的左儿子为空，则插入；再接下来是47，比62小往左走，发现62结点的左儿子不为空，继续向左走，比58小往左走，发现58的左儿子为空，则插入；……对这棵排序二叉树作中序遍历后，就能得到有序序列：{35，37，47，51，58，62，73，88，93，99}。代码见后面。 二叉排序树的查找从根结点开始，小于则向左找，大于则向右找。一样的用递归实现，很简单。代码见后面。 二叉排序树的删除二叉排序树的删除分为4种情况： 要删除结点为叶子结点，直接删除即可。 要删除结点的右子树为空，则只需要把左子树接上来即可，得到的依然是一棵排序二叉树。如下图： 要删除结点的左子树为空，与上一个类似，只需要把右子树接上来即可。 要删除结点的左右子树都不为空，如下图：这就不能简单地把左子树或右子树接上就可以了，这样做可能就不再是一棵排序二叉树了。仔细观察，其实有37结点和48结点可以代替47结点，而它俩又恰好是47结点中序排列的前驱和后继，其中前驱肯定没有右子树，后继肯定没有左子树（由中序决定的）。比如把37结点的数据移到47结点的位置，再由35结点的右子树去接管37结点的左子树。注意，如果上图中35结点(待删除结点的左儿子)没有右子树，则待删除结点47的直接前驱就应该是35结点，这时候就需要47的左子树去接管35的左子树了。所以这里应该分两种情况讨论，一种是待删除结点的前驱结点不是它的左儿子，另一种是待删除结点的前驱结点就是它的左儿子。代码如下：可以看出，查找某个元素的次数，等于该元素在二叉排序树中的层数。也就是说，二叉排序树的查找性能取决于二叉排序树的形状，深度太大，性能会很低。所以我们希望二叉排序树是平衡的，即它的深度与完全二叉树相同，均为[logn]+1（以2为底，向下取整）。那么查找的时间复杂度将变为O(logn)。 平衡二叉树 平衡二叉树：一种每个结点的左右子树高度差不会超过1的二叉排序树。 平衡因子BF：结点的左子树深度减右子树深度的值。对于平衡二叉树的BF。 最小不平衡子树：其根节点距离插入结点最近，且平衡因子绝对值大于1应该只有三种取值：1，0，-1。非平衡二叉树的BF就多了去了。 平衡二叉树的创建：平衡二叉树只是在创建排序二叉树的基础上，每添加一个结点都去递归检查插入结点后树是不是长高了，然后去改变自己的平衡因子，如果打破了平衡（平衡因子绝对值大于1）则作相应的旋转处理（BF为2则把对应的最小不平衡子树右旋，BF为-2则把对应的最小不平衡子树左旋），重新达到平衡状态，并修改平衡因子。插入节点时由于非平衡所带来的旋转处理分为以下4种： 左左（给结点的左子树插入一个左孩子）：分为以下两种：这俩其实是一样的，都是把BF为2的分支旋转成BF为1的结点的右子树，再把BF为1的结点的原先的右子树改为BF为2的结点的左子树。 右右分为以下两种：这俩其实也是一样的，都是把BF为-2的分支旋转成BF为-1的结点的左子树，再把BF为-1的结点的原先的左子树改为BF为-2的结点的右子树。 左右分为以下三种：这三其实也是一样的，先把不平衡分支下BF符号相反的结点（下图中BF为-1的结点2）进行左旋，结果旋转成了左左类型，后续处理和左左一致。 右左 多路查找树我们前面讲的树结构都只能一个结点存储一个元素，在元素非常多的时候，就会使得树的度非常大或者树的深度非常大，这样会造成频繁地访问外存（因为所访问的树结点很可能并不是顺序存储的），导致性能很低。所以，我们需要打破一个结点只存储一个元素的限制，于是就有了多路查找树。 多路查找树：每个结点可以存储多个元素，且孩子不止于两个 2-3树2-3树同时具有以下特点： 每个结点具有两个孩子（称为2结点）或者三个孩子（称为3结点） 每个2结点包含一个元素和两个孩子（或没有孩子），其左子树的元素小于该2结点的元素，其右子树的元素大于该2结点的元素 每个3结点包含两个元素和三个孩子（或没有孩子），其左子树的元素小于3结点中的较小元素，其中子树的元素介于3结点的两个元素之间，其右子树的元素大于3结点中的较大元素 2-3树的所有叶子都在同一层上 2-3-4树2-3-4树是2-3树的扩展，增加了一个四结点，所以相比2-3树增加了以下特点： 每个结点可以是2结点或者3结点或者4结点 每个4结点包含三个元素和4个孩子（或没有孩子），其左子树的元素小于4结点中的最小元素；第二子树的元素大于4结点的最小元素，小于4结点的第二元素；第三子树的元素大于4结点的第二元素，小于4结点的最大元素；右子树的元素大于4结点的最大元素 B树B树是一种平衡的多路查找树，2-3树和2-3-4树都是B树的特例。结点最大的孩子数目称为B树的阶。B树具有如下特点（其阶数为m）： 如果根结点不是叶结点，则至少有两棵子树 每个非根的分支结点都有超过(m/2-1)（向下取整）个元素和m/2个孩子（孩子比元素个数多1） 每个叶子结点都有超过(m/2-1)个元素 所有叶子结点位于同一层 每个结点的各个子树所包含的元素的值都介于结点中孩子对应的相邻元素值之间（结点中孩子和元素相间存放，最左孩子的左边元素看作无穷小，最右孩子的右边看作无穷大） B+树虽然使用B树访问多个关键字（元素）时，由于一个结点可以存储多个关键字，会减少访问外存的次数，但是如果是访问多个结点，则需要从根结点开始去遍历树，遍历过程中的很多结点可能并不在一个内存页面上，也就是说访问B树的多个结点时，还是要频繁地访问外存。而B+树则是应文件系统所需而产生的一种B树的变形树，严格来说，B+树已经不能算作树了。m阶B+树和m阶B树的区别： 有n棵子树的结点中包含n个关键字 所有分支结点可以看成是索引，分子结点中仅含有其子树中的最大（或最小）关键字 所有叶子结点按关键字大小从小到大链接在一起 所有的叶子结点加在一起一定包含了树中的全部关键字，以及指向这些关键字记录的指针 即使在分支结点中已经找到了要查找的关键字，但它也只是用来索引的，不能提供实际记录的访问，因为只有叶子结点中才存储着关键字对应记录的实际指针，还是需要到达包含此关键字的叶子结点才行。 那么使用B+树为什么能减少外存访问次数呢？因为B+树中的所有叶子结点是按大小链接在一起的，当需要访问多个结点时，可以从B+树最左端的叶子结点出发，不经过分支结点，而是沿着指向向下一个叶子结点的指针就可以遍历所有的关键字，这样就省去了从根结点开始遍历所需要访问的诸多分支结点，访问的结点少了，访问外存的次数当然就少了。 由于所有叶子结点包含了所有关键字，且是按关键字从小到大链接在一起的，所以B+树特别适合带有范围的查找。 散列表查找之前的查找都是先有关键字，然后去表中挨个查找，再根据顺序存储位置的计算方法找到关键字记录对应的内存地址。那么能不能直接根据关键字，不用去表中一个一个地比较就能知道对应记录的内存地址呢？？？可以发现，关键字和内存地址是一对映射关系，如果知道它们之间是怎么映射的，不就可以直接通过关键字找到内存地址吗？也就是如下形式： 存储位置=f(关键字)所以在存储的时候，我们就可以按照关系f来存储，查找的时候也按照关系f来查找。 这就是散列技术：在记录的存储位置和它的关键字之间确定一个对应关系f，使得每一个关键字key对应一个存储位置f(key)。对应关系f称为散列函数或哈希函数。使用散列技术将记录存储在一块连续的存储空间中，这块连续存储空间称为散列表或哈希表。（散列技术既是存储方法，也是对应的查找方法）。 但是散列技术也有很多缺点： 同样的关键字对应很多记录时，不适合用散列技术。因为函数本身可以多个x对应一个y，但不能一个x对应多个y。 散列表不适合范围查找，比如查找一个公司18~50岁的员工，在散列技术中是没法进行这种范围查找的。 散列查找也不能获得记录的排序，而且像最大值、最小值等都无法通过散列查找知道。 散列技术还可能出现冲突，因为在散列函数中有可能会有多个x对应一个y的情况，即多个关键字通过散列函数算出来的是同一个存储地址（这多个关键字称为同义词），但是多个关键字对应的记录明显是多个不同的记录，总不能把这多个记录都存储到一个地址中把，这会产生数据覆盖的，造成后续查找错误，找不到关键字对应的正确记录。 散列技术的冲突其实是由散列函数造成的，如果构造出来的散列函数只能一个x对应一个y，那当然是不会产生冲突了。同时散列函数还不能太复杂，不然计算散列函数就得花费大量时间，反而查找性能不好。所以在散列技术中如何构造散列函数f是一个关键点。 散列函数的构造方法 直接定址法：取关键字的某个线性函数值作为散列地址，即：f(key)=a x key+b（a、b为常数）。直接定址法的优点是简单、均匀，也不会产生冲突，但是需要事先知道关键字的分布情况，因为关键字如果分布比较稀疏，就会造成散列地址很分散，可能在不同的内存页面上，导致频繁换页，性能降低。所以直接定址法只适合查找表小且连续的情况，实际中并不常用。 数字分析法：数字分析法是抽取关键字的一部分来计算散列地址，这在散列函数中常常用到。数字分析法适合处理关键字位数比较大的情况，而且如果事先知道关键字的分布且关键字中的若干位分布较均匀，就可以考虑使用数字分析法。 平方取中法比如关键字是1234，它的平方是1522756，再抽取中间三位227来作为散列地址。这就是平方取中法。平方取中法比较适合不知道关键字分布，而且关键字位数又不是很大的情况。 折叠法折叠法是将关键字从左到右分割成位数相等的几部分（最后一部分位数不够就不够了，不管它），然后将这几部分叠加求和，并且根据散列表表长，取后几位作为散列地址。比如关键字是9876543210，散列表表长为3位，将关键字分为4组：987|654|321|0，然后将它们叠加求和987+654+321+0=1962，再拿出后3位962作为散列地址。折叠法适合不知道关键字分布，而且关键字位数比较多的情况。 除留余数法此方法为最常用的散列函数构造方法。除留余数法就是把关键字除以某个数，取余数作为散列地址，即：f(key)=key % p很显然，除留余数法是会产生冲突的，它的关键就在于选择合适的p。 经验表明，p应该选为小于或等于散列表长度（最好接近表长）的最小质数或不包含20以下的质因子的合数。 随机数法随机数法就是取关键字的随机函数值作为它的散列地址，即f(key)=random(key)。随机数法适合关键字长度不等的情况。 处理散列冲突的方法虽然可以通过构造好的散列函数来减少冲突的发生，但是冲突总还是有的，几乎不可避免。那么应该有一些处理散列冲突的方法。 开放地址法就像你要去买一套房子，发现它已经被人买走了，怎么办？找别的房子呗！这就是开放地址法：发生冲突后，去寻找下一个空的地址。只要散列表足够大，空的散列地址总是能找到的。那么以何种方式去找下一个空的地址呢？ 开放定址法之线性探测法发生冲突后，一个一个往后顺序查找空的地址，即： fi(key)=(f(key)+di) % p （di=1，2，3…..p-1）但是使用线性探测法，很可能会出现本来不是同义词却要争夺一个地址的情况，这种现象称为堆积。 开放定址法之二次探测法发生冲突后，以平方跳跃的方式往前或者往后查找空的地址，即使用平方是为了不让关键字算出来的散列地址都聚集在某一块区域，减少堆积现象。 开放地址法之随机探测法发生冲突后，随机地去查找空的地址，即：fi(key)=(f(key)+di) % p （di是一个随机数列） 再散列函数法当发生冲突时，换个散列函数来计算散列地址。这种方法不会产生堆积，但是也相应地增加了计算时间。 链地址法发生冲突后，把同义词的记录链接到上一个同义词的后面，构成一个单链表，称之为同义词子表，而散列表中只存储所有同义词子表的头指针（有些类似于之前介绍过的树中的孩子表示法）链地址法适合处理可能会造成很多冲突的散列函数，因为它提供了绝对不会出现找不到地址的保障。但是同时，也带来了查找时需要遍历单链表的性能消耗。 公共溢出区法发生冲突后，把冲突的关键字放到一个公共的溢出区（顺序存储表）里去。查找时，先根据关键字和散列函数计算出来的地址去查找，如果关键字不匹配，则到再溢出区里去顺序查找关键字。公共溢出区法适合冲突数据很少的情况，因为在溢出区里顺序查找关键字也是比较费时的。冲突数据很少时，公共溢出区法对查找性能来说是非常高的。 影响散列查找性能的因素 散列函数是否均匀，即散列函数下发生冲突的可能性是否小 处理冲突的方法。比如线性探测法处理冲突有可能会产生堆积现象，显然性能就没有二次探测法好。 散列表的装填因子。装填因子=填入表中的记录个数/散列表长度。显然，装填因子越大，散列表中的空闲地址就越少，产生冲突的可能性就越大。所以通常把散列表的空间设置得记录集合大。无论记录集合有多大，都总可以选择一个合适的装填因子以便将平均查找长度限定在一个范围之内，这个时候查找的时间复杂度就是O(1)了。不过这是以牺牲空间为代价的，典型的用空间换时间。]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>查找</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[递归与尾递归]]></title>
    <url>%2F2016%2F09%2F16%2F%E5%B0%BE%E9%80%92%E5%BD%92%2F</url>
    <content type="text"><![CDATA[递归：在函数或者方法里调用自身，且有明确的递归结束条件。 下面来看一个基本递归（一般意义下的递归）问题：计算n!计算公式为：n!=nx(n-1)x(n-2)……2x1递归公式为：代码如下： static int Recursion(int n) { if (n &lt; 0) return 0; else if (n == 0 || n == 1) //0的阶乘也等于1 return 1; else return n * Recursion(n - 1); } 在上面的每一次递归中，都需要在栈中开辟一块新的空间，用来保存当前方法的参数、局部变量、返回地址等等，便于后面递归返回时能够回溯到正确的位置和状态。如果递归深度太大，栈中就会保存大量的递归之前的数据，可能会造成栈溢出。 下面再来看一下尾递归问题还是：计算n!代码如下： //调用时currentValue传入1 static int Recursion(int n, int currentValue) { if (n &lt; 0) return 0; else if (n == 0 || n == 1) return currentValue; else return Recursion(n - 1, n * currentValue); } 比较上诉两份代码，可以看到第一份代码的递归调用是在倒数第二步进行的（先递归调用再做乘法），而第二份代码的递归调用是在最后一步进行的。所以，顾名思义，尾递归：对函数自身的递归调用在函数体的最后一步 还有更有意思的，由于尾递归是在最后一步调用的自身，所以在调用返回后应该就直接退出调用函数了（因为它已经是函数体最后一步了），也就是说返回到函数体的哪个位置（返回地址）不需要了，递归到最后一层时直接退出，不再需要回溯了。而且调用函数的参数、局部变量等等也不会再用到，那么就没有必要在尾递归调用的时候在栈中开辟新的空间去存储调用之前的状态信息了。很多编译器会自动识别并这样优化尾递归（部分高级语言不支持）。这样，尾递归就带来了性能上的很大提升。 在第一份基本递归的代码中，由于递归调用是在倒数第二步进行的，再递归返回后还需要与方法的参数n相乘，这样就不得不在栈中开辟一块新的空间，来存储调用之前的参数n、返回地址等等。如果不开辟新的空间，下次进入递归的函数内部时，由于递归函数本身就有参数、局部变量等等，就有可能把递归调用之前的n给覆写了，导致递归返回时，跟它相乘的n不是正确的n，导致结果错误。 可以看到在尾递归中，不仅需要把递归调用放在最后一步，还需要设置一个参数用来保存或计算调用之前的计算结果，如第二份尾递归代码中的currentValue。其实由于尾递归没了回溯，所以它的过程还是很类似迭代的。 【注】：可以看出，这种优化其实不止于尾递归，对于所有尾调用（在函数体最后一步调用别的函数）其实都是有这种优化的。尾递归是尾调用的一种。]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>尾递归</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法之图之拓扑排序]]></title>
    <url>%2F2016%2F09%2F09%2F%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[先来看几个概念： AOV网：在表示一个工程的有向图中，用顶点表示活动，用弧表示活动之间的优先关系，这样的用有向图顶点表示活动的网，称为AOV(Activity On Vertex)网 AOV网中不能存在回路。因为某个活动要以自己完工作为先决条件，是不可能的，也就是某个活动不可能优先于自己 拓扑序列：在有向图的所有顶点组成的序列中，任意弧尾顶点都排在弧头顶点之前的序列 拓扑排序：对一个有向图构造拓扑序列的过程。一个AOV网的拓扑序列不是唯一的。 拓扑排序算法 由于是要找一个任意弧尾顶点都在弧头顶点之前的序列，所以我们可以从入度为0的顶点出发，那么怎么找到下一个顶点呢？看定义，任意弧尾顶点在弧头顶点之前，也就是说需要保证我们找到的下一个顶点不会称为之前顶点的弧头(经过1段或n段有向弧称为弧头)。怎么保证？我们切断所有从之前顶点出去的弧(以之前顶点作为弧尾的有向弧)不就ok了。所以：核心思想：从AOV网中选择一个入度为0的顶点，输出并删去它以及从它出去的弧(该顶点时弧尾)，重复上述步骤，直到输出全部顶点或AOV网中不存在入度为0的顶点为止。 由于需要删除顶点，所以用邻接表要比邻接矩阵方便。因为对数组的删除操作效率并不高，有很多元素需要移位。还有我们需要查找入度为0的点，所以需要给邻接表中顶点结点增加一个数据成员InDegree，标识顶点的入度数。为了避免每次都去遍历所有顶点查找入度为0的顶点，我们需要一个栈，用来存储一开始入度就为0的顶点和删除有向弧过程中入度变为0的顶点。综上，需要用到的数据结构：邻接表+栈。其中邻接表的顶点类结构如下： 代码如下： 未完待续]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>拓扑排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法之改进排序]]></title>
    <url>%2F2016%2F09%2F03%2F%E6%94%B9%E8%BF%9B%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[排序算法主要分为7类：冒泡排序、简单选择排序、直接插入排序(这三种属于简单算法)、希尔排序、堆排序、归并排序、快速排序(这四种属于改进算法) 希尔排序希尔排序是直接插入排序的升级版。对于直接插入排序，原序列中待排序的元素还是比较多。每次插入时需要很多次后移操作(因为序列较长时一般后移距离也长)，有没有什么办法能够减少后移的距离呢？很容易想到的是，把原序列分组，在每一组内进行直接插入排序，由于每一组序列长度较小，再插入时移动的次数也就自然少了。但是有一个问题，对{9，1，2，5，7，4，8，6，3，5}分成五组：{9，1}，{2，5}，{7，4}，{8，6}，{3，5}，即使每一分组都排好序后再合并：{1，9，2，5，4，7，6，8，3，5}，得到的这个序列依旧是杂乱无章的，如下图：并没有大体上让小的元素往前走，让大的元素往后走，对下一次的直接排序几乎没有多大帮助。原因在于分组时，元素间隔太小，交换位置时，只能和附近的元素交换，如果把元素间隔设大一点，就能够和较远的元素交换位置，这就增大了小元素大幅度往前走，大元素大幅度往后走的几率。但是通常仅有一次排序是不够的，需要缩小间隔再直接插入排序多次（第一次间隔gap=n/2，后面几次的间隔减半gap=gap/2，直到gap==1。直接插入排序相当于gap=1时的希尔排序）。如下图所示：希尔排序的核心：按间隔分组直接插入排序，再缩小间隔分组直接插入排序，直到间隔等于1代码如下： static void ShellSort(int[] array) { int gap = array.Length / 2; //多次分组直接插入排序，直到gap=1 for (; gap >= 1; gap /= 2) { for (int i = 0; i &lt; array.Length - gap; i++) { if (array[i + gap] &lt; array[i]) { int temp = array[i + gap]; int j; for (j = i; j >= 0 &amp;&amp; array[j] > temp; j -= gap) { array[j + gap] = array[j]; } array[j + gap] = temp; } } } } 【注】： 由于希尔排序比直接插入排序减少了移动距离(移动次序)，所以希尔排序的效率比直接插入排序高，也就自然比简单选择排序和冒泡排序性能好了。进过分析希尔排序的平均时间复杂度是O(nlogn)。 由于希尔排序是将元素跳跃式分组，插入元素时也是跳跃式插入，如上图中第一轮排序里两个5在排序前后的次序发生了变化，所以希尔排序是不稳定排序。 大量研究表明，当间隔序列为时，可以获得不错的效果。但是最后一个增量值必须等于1。 堆排序堆排序是对简单选择排序的一种改进。来看几个定义： 堆是一棵完全二叉树，满足一下特性：所有结点比它的子结点大（大顶堆）或者所有结点比它的子结点小（小顶堆）。 堆可以用层序遍历的次序存入到数组中 把待排序的序列建成一个大顶堆的方法：先把待排序的序列按照层序构建成一棵完全二叉树，再从下往上、从右到左，将每个非叶结点与其左右子结点的较大值互换，直到比它的左右儿子都大为止。 比如有一个待排序序列：{50，10，90，30，70，40，80，60，20}，先按层序构建成完全二叉树，如下图：接下来从下往上，从右到左的第一个非叶结点是30，将它与左右儿子的较大者60互换，结果如下图：接着从下往上，从右到左的第二个非叶结点是10，将它与左右儿子的较大者70互换，结果如下图：再接下来从下往上，从右到左的第三个非叶结点是90，因为它本身就比它的左右儿子都大，所以不用互换了。再接下来从下往上，从右到左的第四个非叶结点是50，将它与左右儿子的较大者90互换，因为要一直换到比左右儿子都大为止，所以把50、90互换之后，50还要和它的左右儿子的较大者80互换，结果如下图：到此，整个大顶堆就构建完成了。那么如何利用这个大顶堆来排序呢？ 利用大顶堆来排序的方法：把根结点元素与还未排序的最后一个元素交换位置（层序下的最后一个未排序元素），再把交换后的根结点与其左右孩子的较大者交换，直到比它的左右孩子都大。重复，直到所有结点都排序完成。 对上面的大顶堆排序的过程如下：先把根结点90和待排序的最后一个元素20交换位置，结果如下图：再把20和它的左右儿子的较大者交换位置，直到比它的左右儿子都大，结果如下图：这样最大的元素90就被放到了数组的最后一个位置，是不是有点像选出了最大的元素然后把它放到最后的位置？？？所以从这里可以看出堆排序是简单选择排序的改进版。接下来把根结点80和待排序的最后一个元素30交换位置，结果如下图：再把30和它的左右儿子的较大者交换位置，直到比它的左右儿子都大，结果如下图：后面的变化完全类似，不再赘述，如下图：至此，便完成了堆排序的过程。经过分析，堆排序的时间复杂度为O(nlogn)（堆排序对原始序列的排序状态并不敏感，所以堆排序的最好、最坏和平均时间复杂度都为O(nlogn)），空间复杂度为O(1)。但是由于它的交换是跳跃式的（不是和相邻的元素交换），所以堆排序也是一种不稳定排序。【注】： 由于构建堆的时候需要很多次比较，所以它并不适合待排序序列个数较少的情况，因为得不偿失嘛！ 代码如下： #include using namespace std; void HeapSort(int array[], int length); int main() { int array[] = { 65535,1,6,9,7,2,5,0,3,1 }; int length = sizeof(array) / sizeof(int); HeapSort(array, length-1); for (int i = 1; i < length; i++) { cout < array[i] < ' '; } int key; cin >> key; return 0; } int GreaterRoot(int array[], int i, int length); void HeapSort(int array[], int length) { //数组从1开始存数 //构建大顶堆 for (int i = length / 2; i >= 1; i--) { int j = GreaterRoot(array, i, length); while (j != 0) { //一直向下调整到比它的子结点都大 j = GreaterRoot(array, j, length); } } //对大顶堆排序 for (int i = length; i >= 2; i--) { //第一个位置和右下角最后一个未排序位置互换 int temp; temp = array[1]; array[1] = array[i]; array[i] = temp; //将调到第一个位置的元素和它的子结点一直向下比较，直到重新调整为大顶堆 int j = GreaterRoot(array, 1, i - 1); while (j != 0) { j = GreaterRoot(array, j, i - 1); } } } //如果该结点已经比子结点都大，则返回0，否则返回跟它交换的那个子结点的编号 int GreaterRoot(int array[], int i, int length) { if (i * 2 > length) //叶节点 return 0; if (array[i] > array[2 * i] && (2 * i + 1 > length || array[i] > array[2 * i + 1])) { //只有左儿子，但是比左二子大，或者有右儿子但是比左右儿子都大 return 0; } if (2 * i + 1 > length || array[2 * i] > array[2 * i + 1]) { //和子结点的较大者交换 int temp; temp = array[i]; array[i] = array[2 * i]; array[2 * i] = temp; return 2 * i; } else { int temp; temp = array[i]; array[i] = array[2 * i + 1]; array[2 * i + 1] = temp; return 2 * i + 1; } } Length_InsertSort){ while (low &lt; high) { //递归待排序序列长度大于7时用快速排序 pivot = Partition(array, low, high);//把array[low..high]一分为二，小的在左边，大的在右边，返回基准数所在的位置 QuickSort(array, low, pivot - 1); low = pivot + 1; } } else { //递归待排序序列长度小于等于7时用快速排序 InsertSort(array); } } 将low=pivot+1后，再循环来一次pivot = Partition(array, low, high);，其实就是pivot = Partition(array, pivot+1, high);，与QuickSort(array, pivot + 1, high);是同样的效果，因为QuickSort本来做的就是Partition操作。但是使用循环减少了一个递归调用，从而减少了堆栈带来的开销，提高了性能。 7种排序算法的时间复杂度和空间复杂度的比较]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>改进排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法之简单排序]]></title>
    <url>%2F2016%2F09%2F03%2F%E7%AE%80%E5%8D%95%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[排序：将一组记录序列变成，在一组关键字的非递减(或非递增)排列下的映射记录序列。比如下面这4个人的总分成绩为：令狐冲 753，郭靖 573，杨过 682，张无忌 753按照总分成绩这组关键字的非递减排列{573，682，753，753}，那么排序后的记录应该是：郭靖 573，杨过 682，令狐冲 753，张无忌 753所以排序的依据是关键字之间的大小关系。 排序的稳定性：当关键字相等时，如果排序前后对应记录的先后次序没有发生变化，则是稳定排序，如果变化了则是不稳定排序。如上面的例子有两个相等的关键字753，排序前令狐冲记录在张无忌记录前面，若排序后令狐冲记录还是在张无忌记录前面，则是稳定排序；若排序后令狐冲记录跑到了张无忌记录后面，则是不稳定排序。如下图所示： 排序算法主要分为7类：冒泡排序、简单选择排序、直接插入排序(这三种属于简单算法)、希尔排序、堆排序、归并排序、快速排序(这四种属于改进算法) 冒泡排序冒泡排序是一种交换排序，核心思想是：两两比较，符合大小关系则交换，将最小的元素浮到最上面(非递减排序) 冒泡排序初级版如下图所示：先让数组中第一个元素依次和后面的元素作比较，如果小于则交换位置，交换位置后依然是让第一个元素继续和后面的元素作比较，直到比到数组中最后一个元素为止。这样第一轮完了以后最小的元素(数字1)就浮到了最上面。然后让数组中的第二个元素依次和后面的元素作比较，如果小于则交换位置。这样第二轮完了以后最小的元素(数字2)就浮到了次上面。以此类推，9个元素8轮比较后，就完成了整个排序。代码如下：static void BubbleSort(int[] array){ //i既表示比较多少轮，也表示数组下标，所以得从0开始 for (int i = 0; i &lt; array.Length - 1; i++){ //j表示数组下标 for (int j = i + 1; j &lt; array.Length; j++){ if (array[i] > array[j]){ int temp = array[i]; array[i] = array[j]; array[j] = temp; } } } } 正宗的冒泡排序上面的初级版其实效率是很低的，一个数字浮上去了却对其它数字没有任何帮助，比如在第二轮里2虽然浮上去了，却把3沉下来了。我们希望能够找到一种算法能够让2浮上去的同时，不会把3沉那么多下来。仔细观察会发现，初级版冒泡是把当前元素和与之比较的元素作交换，这两个元素有可能位置相差很远，就很有可能会让数值较小的元素一下大幅度沉底，比如上面第二轮的最后一次交换，让仅仅比2小的3一下子就沉底了。那么能不能缩短每次交换的元素的距离呢？也就是缩短相比较的两个元素的距离。这就是正宗的冒泡排序：每次只比较相邻的两个元素的大小。不过它是从数组后面往前面比的，因为要冒泡把最小(或最大)的元素浮上去嘛。如下图所示：先让数组最后一个元素和倒数第二个元素比较，如果小于则交换位置，再让倒数第二个元素和倒数第三个元素作比较，以此类推。因为每次比较的结果都是较小的元素在上面，所以一轮完成后就能把最小的元素浮到最上面去。以此类推，9个元素8轮比较后，就完成了排序。可以看到在把1浮到最上面的同时，也把2浮上去了很多，这相比初级版的冒泡会减少很多交换次数。代码如下：static void BubbleSort(int[] array){ //i既表示比较多少轮，也表示数组下标，所以得从0开始 for (int i = 0; i &lt; array.Length - 1; i++){ for (int j = array.Length - 1; j > i; j--){ if (array[j] &lt; array[j - 1]){ //注意这里和冒泡初级版的差别 int temp = array[j]; array[j] = array[j - 1]; array[j - 1] = temp; } } } } 冒泡排序升级版正宗的冒泡排序也只是比初级版的冒泡减少了交换次数而已，那么有没有可能减少比较次数呢？如下面的情况：第一轮交换完，最小元素浮到最上面以后，下面的序列就已经有序了，那么其实后面的比较都不用了。但是在正宗的冒泡算法里，后面的比较还是要继续的。为了减少这种无用的比较，我们可以设置一个bool变量，标识这一轮比较有没有数据交换，如果没有，则说明后面的元素已经有序了，不用再比较了。代码如下：static void BubbleSort(int[] array){ //标识后面的元素是否已经有序 bool ordered = false; //i既表示比较多少轮，也表示数组下标，所以得从0开始 for (int i = 0; !ordered &amp;&amp; i &lt; array.Length - 1; i++) { ordered = true; for (int j = array.Length - 1; j > i; j--) { if (array[j] &lt; array[j - 1]) { int temp = array[j]; array[j] = array[j - 1]; array[j - 1] = temp; ordered = false; } } } } 简单选择排序冒泡排序还是存在着很多次的位置交换，有没有可能直接找到某个元素应该所处的位置，然后只交换一次就可以了呢？选择排序就是这样的。简单选择排序的核心思想：在每一轮排序中找出最小的元素，把它放到该轮次对应的位置上去。如下图所示：在第一轮排序中，找到最小的元素是1，将它与数组中第一个元素交换位置在第二轮排序中，在剩下的元素中找到的最小元素是2，将它与数组中第二个元素交换位置以此类推…代码如下： static void SimpleSelectSort(int[] array){ //i既表示比较多少轮，也表示数组下标，所以得从0开始 for (int i = 0; i &lt; array.Length - 1; i++) { int minIndex = i; for (int j = i + 1; j &lt; array.Length; j++) { if (array[j] &lt; array[minIndex]) { minIndex = j; } } if (minIndex != i) { int temp = array[minIndex]; array[minIndex] = array[i]; array[i] = temp; } } } 由于简单选择排序每一轮最多只有一次交换数据，不像冒泡排序那样频繁地交换位置，所以简单选择排序的性能要略优于冒泡排序。 直接插入排序直接插入排序的核心：一开始把数组的第一个元素看作是一个有序序列，接着在每一轮排序中把轮次对应的元素插入到该有序序列(数组的前i个元素就是该有序序列)中去。如下图所示(箭头表示接下来这一轮排序中将要后移的元素)：有一组待排序的序列如下：把第一个元素9看作是一个有序序列：{9}在第一轮排序中，要将元素1插入到有序序列{9}(数组前1个元素)中，先将有序序列中大于1的所有元素右移一位，左边会多出一个空位(如下图中的残缺方块)，再把1插入到空位中去。结果如下图：在第二轮排序中，要将元素5插入到有序序列{1，9}(数组前两个元素)中，先将有序序列中大于5的所有元素右移一位，会出现一个空位(如下图中的残缺方块)，再把5插入到空位中去。结果如下图：在第三轮排序中，要将元素8插入到有序序列{1，5，9}(数组前三个元素)中，先将有序序列中大于8的所有元素右移一位，出现空位，再把8插入到空位中去。结果如下图：在第四轮排序中，要将元素3插入到有序序列{1，5，8，9}中，需要先将有序序列中所有大于3的元素右移一位，出现空位，再把3插入到空位中去。结果如下图：一次类推，9个元素8轮插入后，将完成整个排序。【如果要插入元素的左边没有比它大的元素，则让这个要插入的元素什么也不做，保留在原地】代码如下： static void StraightInsertSort(int[] array) { for (int i = 0; i &lt; array.Length - 1; i++) { //如果要插入元素小于左边有序序列最大值，则让有序序列中所有比它大的元素右移一位 if (array[i + 1] &lt; array[i]) { int temp = array[i + 1];//保存要插入元素的值，因为在右移过程中会覆盖这个元素 int j; for (j = i; j >= 0 &amp;&amp; array[j] > temp; j--) { array[j + 1] = array[j]; } //把要插入元素插入到移出来的空位中去 array[j + 1] = temp; } } } 因为插入排序是向有序序列中插入新元素的，所以比较次数会比简单选择排序少，且每一轮排序都只是把大于的元素往后移再插入一个元素而已，所以直接插入排序要比简单选择排序和冒泡排序的性能好一些。]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>简单排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法之关键路径]]></title>
    <url>%2F2016%2F09%2F01%2F%E5%85%B3%E9%94%AE%E8%B7%AF%E5%BE%84%2F</url>
    <content type="text"><![CDATA[先来看几个概念和式子：关键路径：从源点到汇点具有最大长度的路径关键活动：关键路径上的活动事件：带权图中的顶点活动：带权图中的边事件(顶点)Vi的最早发生时间VE：源点到顶点的最长距离事件(顶点)Vi的最晚发生时间VL：工期-结点到汇点的最长距离活动的最早开始时间AE：对应有向边的起点的最早发生时间活动的最晚开始时间AL：对应有向边的终点的最晚发生时间-该有向边的权值关键活动：AE=AL的活动(边) 求关键路径的步骤： 从源点开始，向后求出每一个结点的最长路径（也就是AE），直到汇点为止（到某个顶点有多个路径值时取最大值）。 从汇点开始反推，向前求出每一个结点的【工期-汇点到结点的最长路径】，即AL，直到源点为止（到某个结点有多个路径值是取最小值）。 取出上面两步中AE=AL的点，由它们构成的路径就是关键路径。 【注】： 求源点到结点的最长路径或者汇点到结点的最长路径，都可以根据已经求出的点作为跳板来计算，这一点和《最短路径》有点像 图的关键路径不唯一，有多条关键路径时，需要同时提高这些关键路径上的活动的速度，才能缩短工期。 举例如下，求下面这幅图的关键路径：先从源点开始，算出每个结点的最长路径AE；再从汇点开始，算出每个路径的AL。结果如下图所示：取出AE和AL相等的结点V0、V2、V3、V4、V7、V8、V9。所以关键路径如下图： 未完待续]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>关键路径</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法之图之最短路径]]></title>
    <url>%2F2016%2F09%2F01%2F%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%2F</url>
    <content type="text"><![CDATA[最短路径：两顶点之间权值之和最小的路径寻找带权图(网图)中两点之间最短路径的算法主要有两种：迪杰斯特拉(Dijkstra)算法、弗洛伊德(Floyd)算法 迪杰斯特拉(Dijkstra)算法迪杰斯特拉算法的核心思想：在每个顶点处，都会去存储它到周围点的路径长度。每次找出未知结点中到源点路径最短的结点，看其周围的结点是否会通过它得到比以前更短的路径长度，若是，则更新对应结点的最短路径长度和其前驱结点。如下图所示：要求源点V0到终点V8的最短路径，根据迪杰斯特拉算法需要先求得到中间所有顶点的最短路径：1. 先将V0加入已知顶点序列，V0到V0的最短距离自然是0，前驱结点就设为它自己吧：0，它周围点V1的当前最短路径就变为1，前驱结点为0；V2的当前最短路径变为5，前驱结点为0.如下图所示（空的地方路径都是无穷大，不可达）：2. 然后找出未知结点中当前路径长度最短的，为V1，把它加入已知结点序列，以V1为跳板的话，V2的路径长度就变为了4（V1的最短路径加上V1到V2的长度），比之前存储的5要短，所以把V2的当前最短路径变为4，前驱结点变为1；V3的当前最短路径变为8，前驱结点变为1；V4的当前最短路径变为6，前驱结点为1.如下图所示：3. 然后找出未知结点中当前路径长度最短的，为V2，把它加入已知顶点序列，以V2为跳板的话，V4的路径长度变为5，比之前的6要短，所以把V4的当前最短路径变为5，前驱结点变为2；V5的当前最短路径变为11，前驱结点变为2.如下图所示：4. 然后继续找出未知结点中当前路径长度最短的，为V4，把它加入已知顶点序列，以V4为跳板的话，V3的路径长度变为7，比之前的8要短，所以把V4的当前最短路径变为7，前驱结点变为4；同样V5比之前也短了，当前最短路径变为8，前驱结点变为4；V6、V7的当前最短路径分别变为11和14，前驱结点变为4。如下图所示：5. 然后继续找出未知结点中当前路径长度最短的，为V3，把它加入已知顶点序列，以V3为跳板的话，V6的路径长度变为9，比之前的11要短，所以把V6的当前最短路径变为9，前驱结点变为3。如下图所示：6. 然后继续找出未知结点中当前路径长度最短的，为V5，把它加入已知顶点序列，以V5位跳板的话，V7的路径长度变为13，比之前的14要短，所以把V7的当前路径长度变为13，前驱结点变为5。如下图所示：7. 然后找出最短的V6，把它加入已知顶点序列，以V6为跳板，V7的路径长度变为11，比之前的13要短，所以把V7的当前最短路径变为11，前驱结点变为6；V8的当前最短路径变为16，前驱结点变为6。如下图所示：8. 然后找出最短的V7，把它加入已知顶点序列，以V7位跳板，V8的路径长度变为15，比之前的16要短，所以把V8的当前最短路径变为15，前驱结点变为7。如下图所示：9. 然后找出最短的V8，把它加入已知顶点序列，现在图中的所有顶点都在已知顶点序列中了，终止循环。V8的最短路径就是一个一个地回溯前驱结点：V8的前驱结点是6，V6的前驱结点是3，V3的前驱结点是4，V4的前驱结点是1，V1的前驱结点是0。所以最短路径是：V0 → V1 → V4 → V3 → V6 → V8。迪杰斯特拉算法求最短路径的代码如下：迪杰斯特拉算法求某两点之间的最短路径的时间复杂度为O(n^2)，求所有顶点到所有顶点之间最短路径的时间复杂度为O(n^3)。*弗洛伊德(Floyd)算法 未完待续]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>最短路径</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法之图之最小生成树]]></title>
    <url>%2F2016%2F09%2F01%2F%E6%9C%80%E5%B0%8F%E7%94%9F%E6%88%90%E6%A0%91%2F</url>
    <content type="text"><![CDATA[看下面这个实际问题：假设你是电信的工程师，需要为下面的9个村庄架设网线，村庄位置如下图所示。边上的数字表示村庄之间的距离。要求以最小的成本使这9个村庄的网线互通，应该怎么办？最小成本，自然是需要连线的公里数最小。因为只需要9个村庄网线互通，不要求直接可达，所以设计路线至少应该是一颗生成树，9个结点，只铺设8条线路即可。但是图的生成树有很多个，我们需要代价最小的那棵生成树，即最小生成树。要根据图找出这棵最小生成树，有两种算法：普里姆(Prim)算法、克鲁斯卡尔(Kruskal)算法。 普里姆(Prim)算法算法规则： 设置一个已知顶点序列和一个生成树边序列。 先随机找一个顶点，把这个顶点加入已知顶点序列中 找出已知顶点和图中剩余顶点(未知顶点)之间权值最小的边，把这个边加入到生成树边序列中，并且把这条边上的那个未知顶点加入到已知顶点序列中 重复步骤3，直到已知顶点序列已经包含了图中所有的顶点为止 Prim算法核心：从已知顶点到未知顶点中找出最小边（权值最小）按Prim算法找出的最小生成树如下图所示：代码如下： 普里姆(Prim)算法的时间复杂度为O(n^2)。 克鲁斯卡尔(Kruskal)算法算法规则： 设置最小生成树的一个顶点序列和一个边序列。先确定图中的所有顶点，全部存放到最小生成树的顶点序列中，边序列还是空的 找出原图中除去最小生成树边序列以外的权值最小的边，如果这条边的两个顶点在现有最小生成树的不同连通子图上(也就是加入这条边后不会在现有生成树中形成回路)，则加入到最小生成树的边序列中 重复第2步，直到现有最小生成树的所有边都在同一连通子图上(只有一个连通分量) Kruskal算法核心：从剩下的边中找出不会构成回路的最小边（权值最小）按Kruskal算法找出的最小生成树如下图所示：代码如下： 克鲁斯卡尔(Kruskal)算法的时间复杂度为O(eloge)。其中e是图的边数 普里姆(Prim)算法和克鲁斯卡尔(Kruskal)算法的比较： 普里姆算法是从结点入手的，找出已知结点和未知结点之间权值最小的边；克鲁斯卡尔算法是从边入手的，其最小生成树中的所有结点已经事先确定好，再去找不会构成回路的权值最小的边 普里姆算法在边数非常多的情况下，比如稠密图，效率会比克鲁斯卡尔算法高；而在边数比较少时，例如稀疏图，克鲁斯卡尔算法的效率比普里姆算法高 未完待续]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>最小生成树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法之图]]></title>
    <url>%2F2016%2F09%2F01%2F%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[先来看几个图的概念和特性 图：由顶点的有穷非空集合和顶点之间边的集合组成 完全图：图中任意两个顶点之间都存在可直接到达对方的边。分为无向完全图和有向完全图，其中无向完全图有n(n-1)/2条边，有向完全图有n(n-1)条边 稀疏图：边数很少的图，反之为稠密图 简单路径：路径的顶点序列中不存在重复的顶点 连通图：任意两点之间都有路径可达(不需要直接可达)的无向图 强连通图：任意两点之间都有路径可达的有向图 连通分量：非连通无向图中的极大连通子图(顶点数最大)叫做连通分量 强连通分量：非强连通有向图的极大强连通子图叫做强连通分量 连通图的生成树：连通图的极小连通子图。有n个顶点时，只有n-1条边，随便加哪两个顶点之间的边都将构成环，而生成树里是没有环的。 网：带权图称为网 图的存储结构由于图的结构比较复杂，任意两点之间都可能存在联系，难以用元素在内存中的物理位置来表示元素之间的关系，也就是图不可能用简单的顺序存储结构来表示。前辈们给我们提供了图的5种存储结构： 图的邻接矩阵存储方式：将图的点和边分开存储，用一个一维数组加一个二维数组来表示图。一维数组存储图中的顶点信息，二维数组(邻接矩阵)存储图中边或弧的信息。当然，边数组不仅可以存储0,1这两个数字，如果是带权图(网)，边数组中还能存储对应边的权值。不过这时需要指定一个比较大的数来标识图中不存在的边，如代码中的Infinity。如下图所示：我们可以通过给顶点数组和边数组输入数据，来创建邻接矩阵图。当然，由于是数组，需要先输入要创建的图的顶点数numVertexs和边数numEdges。代码如下： class AdjacencyMatrixGrpah { int numVertexs; int numEdges; object[] Vertexs; int[,] EdgesMatrix; //Infinity标识图中不存在的边 const int Infinity = 66535; //建立邻接矩阵图 public void CreateGraph() { numVertexs = Convert.ToInt32(Console.ReadLine()); numEdges = Convert.ToInt32(Console.ReadLine()); Vertexs = new object[numVertexs]; EdgesMatrix = new int[numVertexs,numVertexs]; //建立顶点数组 for (int i = 0; i &lt; numVertexs; i++) { Vertexs[i] = Console.ReadLine(); } //初始化边数组(邻接矩阵) for (int i = 0; i &lt; numVertexs; i++) { for (int j = 0; j &lt; numVertexs; j++) { EdgesMatrix[i,j] = Infinity; } } //将图中的带权边存储到邻接矩阵中 for (int k = 0; k &lt; numEdges; k++) { int i = Convert.ToInt32(Console.ReadLine()); int j = Convert.ToInt32(Console.ReadLine()); int weight = Convert.ToInt32(Console.ReadLine()); EdgesMatrix[i, j] = weight; } } } 【注】： 上面代码是针对有向图的，如果是无向图，只需要把EdgesMatrix[i, j] = weight;改为EdgesMatrix[i, j] = EdgesMatrix[j, i] = weight;，因为无向图的邻接矩阵是一个对称矩阵。 在邻接矩阵主对角线上的元素，即顶点到自身的边，我也是设置为Infinity的，并非像上图中那样主对角线上的元素都为0 图的邻接表存储方式：可以看到在图的邻接矩阵存储方式中，还有很多没有用到的空间，尤其是在稀疏图中，将会浪费很多存储空间。所以我们考虑用链表替换邻接矩阵中的每一行，减少空间浪费。但是图中每个结点的出度不一样，不方便把每个结点的邻接结点引用都存储的自身结点中，其实可以用类似树中的孩子表示法，把结点的所有邻接结点都用链表连起来。这就是图的邻接表存储方式，如下图所示：需要的数据结构有：顶点类+邻接结点类+图(类)顶点类由两个数据成员组成：顶点数据、第一个邻接结点的引用邻接结点类由三个数据成员：邻接结点在数组中的下标、权值、下一个邻接结点的引用图(类)的数据成员主要是：顶点类数组代码如下： public class VertexNode { public object Data; public AdjacencyNode FirstAdjacencyNode; public VertexNode() { Data = null; FirstAdjacencyNode = null; } public VertexNode(object data) { Data = data; FirstAdjacencyNode = null; } } //邻接结点类 public class AdjacencyNode { public int NodeIndex; public int Weight; public AdjacencyNode NextAdjacencyNode; const int Infinity = 65535; public AdjacencyNode() { NodeIndex = -1; Weight = Infinity; NextAdjacencyNode = null; } public AdjacencyNode(int index,int weight) { NodeIndex = index; Weight = weight; NextAdjacencyNode = null; } } //邻接表图类 class AdjacencyListGraph { private VertexNode[] Vertexs; int numVertexs; int numEdges; //建立邻接表图 public void CreateGraph() { numVertexs = Convert.ToInt32(Console.ReadLine()); numEdges = Convert.ToInt32(Console.ReadLine()); Vertexs = new VertexNode[numVertexs]; //建立顶点数组 for (int i = 0; i &lt; numVertexs; i++) { object data = Console.ReadLine(); Vertexs[i] = new VertexNode(data); } //建立顶点的邻接结点链表(边表) for (int k = 0; k &lt; numEdges; k++) { int i = Convert.ToInt32(Console.ReadLine()); int j = Convert.ToInt32(Console.ReadLine()); int weight = Convert.ToInt32(Console.ReadLine()); AdjacencyNode newNode = new AdjacencyNode(j, weight); //头插法 newNode.NextAdjacencyNode = Vertexs[i].FirstAdjacencyNode; Vertexs[i].FirstAdjacencyNode = newNode; //无向图还要同时对另一个顶点对称操作，有向图就不需要下面的代码了 AdjacencyNode newNode1 = new AdjacencyNode(i, weight); //头插法 newNode1.NextAdjacencyNode = Vertexs[j].FirstAdjacencyNode; Vertexs[j].FirstAdjacencyNode = newNode1; } } } 图的十字链表存储方式 图的邻接多重表存储方式 图的边集数组存储方式 图的遍历图的遍历：从图中某一顶点出发访遍图中其余顶点，且要求每个顶点仅被访问一次。分为深度优先遍历DFS(depth first search)和广度优先遍历BFS(breadth first search)。 深度优先遍历DFS先来看下面这个图任意选择一个顶点，比如A点，现在开始想象在走这个迷宫，给自己定一个原则：没有碰到重复顶点时，就始终向右手边走，碰到了重复顶点则回退到上一个顶点处，再选择除开重复顶点外的最右手边的路(最右边没被访问过的邻接结点)，如果在某个顶点处所有的路都走过了(所有的邻接结点都被访问过了)，则回退到上一个顶点处。重复上述操作，一直到回退到起点A，这时就能保证连通图中的所有结点都被访问到了，且只被访问了一次(发现是重复结点的那一步不算)。上图的访问过程如下：在A出一直沿着右手边走到F处，再向右走发现A被访问过了，回退到F，再访问F处除了A的最右手边结点G，在G点去访问B，发现B已经访问过了，回退到G，再去访问D，发现D已经访问过了，又回退到G，再访问H，在H点去访问D、E，发现D、E都已经访问过了，按原路回退到上一个访问过的结点G，也没有未被访问过的邻接点，再回退到F，同样没有未被访问过的结点，再回退到E，再回退到D，发现I是没有被访问过的，则去访问I，在I处没有未被访问过的邻接点，回退到D，再回退到C，回退到B，回退到A。此时回到了起点，则访问结束。不难发现，这个访问过程其实就是一棵二叉树的前序遍历过程，如下图：所以，对图的深度优先遍历DFS，其实就是类似对树的前序遍历。注意，上述过程是针对一个连通图来说的，如果不是连通图，则需要把图中每一个顶点作为起点，都来一次深度优先遍历DFS，这样就能保证非连通图也能访问到所有结点了。对邻接矩阵图的深度优先遍历DFS的代码如下(还未上机验证过)：//标识每一个节点是否被访问过 bool[] Visited; public void DFSTraverse() { Visited = new bool[numVertexs]; for (int i = 0; i &lt; numVertexs; i++) { Visited[i] = false; } DFS(0); } //深度优先遍历DFS public void DFS(int i) { Visited[i] = true; Console.WriteLine(Vertexs[i]); for (int j = 0; j &lt; numVertexs; j++) { if (EdgesMatrix[i, j] == 1 &amp;&amp; Visited[j] == false) { DFS(j); } } } 对邻接表图的深度优先遍历DFS的代码如下(还未上机验证过)：//标识每一个节点是否被访问过 bool[] Visited; public void DFSTraverse() { Visited = new bool[numVertexs]; for (int i = 0; i &lt; numVertexs; i++) { Visited[i] = false; } DFS(0); } //深度优先遍历DFS public void DFS(int i) { Visited[i] = true; Console.WriteLine(Vertexs[i].Data); AdjacencyNode current = Vertexs[i].FirstAdjacencyNode; while (current != null) { if (Visited[current.NodeIndex] == false) { DFS(current.NodeIndex); } current = current.NextAdjacencyNode; } } 广度优先遍历BFS深度优先遍历类似于树的前序遍历，其实广度优先遍历BFS类似于树的层序遍历。需要先把图调整称为层次分明一点的图。如下图所示：由于是层序遍历，所以是需要借助队列的，如下图所示： 先让图中的任意一个结点入队列 让队头的结点出队列，同时让与此结点相连的其他结点入队列 重复第2步，直到队列为空。广度优先遍历BFS的代码如下： 未完待续]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法之二叉树]]></title>
    <url>%2F2016%2F09%2F01%2F%E4%BA%8C%E5%8F%89%E6%A0%91%2F</url>
    <content type="text"><![CDATA[先来看几个二叉树的特点和概念： 二叉树： 二叉树的左子树和右子树是有顺序的，是有序树。 任意一颗二叉树的：叶子数=2度结点数+1 满二叉树：每个分支结点都有左儿子和右儿子，且所有叶子结点位于同一层。如下图： 完全二叉树：按层序编号后，对应结点编号和满二叉树完全相同(完全二叉树的结点数&lt;=满二叉树的结点数)。如下图： 所以，判断某二叉树是否是完全二叉树的方法：看着树的示意图，按照完全二叉树的结构逐层按顺序编号，如果编号出现空挡，则不是完全二叉树。 同样结点的二叉树，完全二叉树的深度最小 具有n个结点的完全二叉树的深度为： 对具有n个结点的完全二叉树【前提条件是2i和2i+1均小于n】：左孩子跟双亲满足关系：2i&lt;=&gt;i右孩子跟双亲满足关系：2i+1&lt;=&gt;i 顺序二叉树任何一颗二叉树的顺序存储都是按其对应的完全二叉树的编号来的，当出现大量空挡(比如右倾斜树)时，会浪费很多存储空间，所以顺序存储一般只用于完全二叉树。 链表二叉树 链表二叉树的数据结构：结点类+树(类)结点类由三个数据成员组成：结点数据、左儿子、右儿子树(类)主要由一个数据成员组成：根结点 建立二叉树要建立一颗二叉树，这棵二叉树应该是已经确定好的，而且需要事先知道该二叉树的前序序列(或中序序列、后序序列)。并且为了确认每一个结点是否有左右孩子，需要将原二叉树进行扩展，也就是将每个二叉树结点内的空指针用一个虚结点代替(假定虚结点数据为#)，得到一颗扩展二叉树。由扩展二叉树得到的前序序列称为完全前序序列。如下图所示：上图的完全前序序列为：AB#D##C##，输入已知的完全前序序列，便能通过CreateBinaryTree()函数来建立该二叉树。代码见后面。 遍历二叉树二叉树的遍历是从根节点开始的。按照根结点访问次序的不同，分为三种遍历方式：前序遍历、中序遍历、后序遍历，另外还有一种层序遍历。 前序遍历：先根再左再右遍历规则：若结点为空，则返回，否则先访问根结点，再访问左子树，再访问右子树。如下图所示：遍历的顺序(前序序列)为：ABDGHCEIF 中序遍历：先左再根再右遍历规则：若结点为空，则返回，否则先访问左子树，再访问根结点，再访问右子树。如下图所示：遍历的顺序(中序序列)为：GDHBAEICF 后序遍历：先左再右再根遍历规则：若结点为空，则返回，否则先访问根结点，再访问左子树，再访问右子树。如下图所示：遍历的顺序(后序序列)为：GHDBIEFCA 层序遍历：按层从左到右访问结点如下图所示：遍历的顺序(层序序列)为：ABCDEFGHI 上面得到的各种遍历序列可以用来创建二叉树，当然也可以根据各种遍历方法来遍历已经创建好的二叉树，前序、中序、后序遍历的代码见后面。 public class BinaryTreeNode { public object Data; public BinaryTreeNode LeftChild; public BinaryTreeNode RightChild; public BinaryTreeNode() { Data = null; LeftChild = null; RightChild = null; } public BinaryTreeNode(object data) { Data = data; LeftChild = null; RightChild = null; } } class BinaryTree { public BinaryTreeNode root; //按前序序列建立二叉树(中序、后序建立的代码类似) public void CreateBinaryTree(ref BinaryTreeNode root) { object data; data=Console.ReadLine(); if (data.Equals("#")) { root = null; return; } root = new BinaryTreeNode(data); CreateBinaryTree(ref root.LeftChild); CreateBinaryTree(ref root.RightChild); } //前序遍历二叉树(中序、后序遍历的代码类似） public void PreOrderTraverse(BinaryTreeNode root) { if (root == null) return; Console.Write(root.Data+" "); PreOrderTraverse(root.LeftChild); PreOrderTraverse(root.RightChild); } //中序遍历二叉树 public void InOrderTraverse(BinaryTreeNode root) { if (root == null) return; InOrderTraverse(root.LeftChild); Console.Write(root.Data + " "); InOrderTraverse(root.RightChild); } //后序遍历二叉树 public void PostOrderTraverse(BinaryTreeNode root) { if (root == null) return; PostOrderTraverse(root.LeftChild); PostOrderTraverse(root.RightChild); Console.Write(root.Data + " "); } } 二叉树前序、中序、后序序列的推导 小技巧：推导一棵树的前序、中序、后序序列时，可以想着对应的递归代码来推导，不容易出错。 已知前序序列和中序序列，推导后序序列：把握两个关键点：前序、后序序列用于确定树或子树的根结点是谁，而中序序列用于确定哪些结点位于根节点左边，哪些结点位于根节点右边。如：已知一颗二叉树前序序列为ABCDEF，中序序列为CBAEDF，求后序序列： 根据前序序列ABCDEF可知，结点A为树的根结点(最前面的是根结点)，再由中序序列CBAEDF可知结点CB位于A的左边，结点EDF位于A的右边。如下图所示： 由前序序列中的BC可知，在BC子树中，B是根结点(最前面的是根节点)。又由中序序列的CB可知C应该位于B的左边。如下图所示： 由前序序列的DEF可知，在DEF子树中，D是根结点(最前面的是根结点)。又由中序序列的EDF可知E位于D的左边，F位于D的右边。如下图： 已知后序序列和中序序列，推导前序序列：唯一的不同之处在于：如上面的第1、2、3步，在前序序列(先根再左再右)中，最前面的是根节点，而在后序序列(先左再右再根)中最后的才是根结点。 已知前序序列和后序序列，是无法唯一确定一颗二叉树的。原因很简单，因为没有中序序列，无法确定哪些结点位于根结点左边，哪些结点位于根结点右边。 【注】：不画出二叉树也可以很快推导对应序列。关键点在于：由前序或后序来确定根结点，由中序来确定哪些结点位于根结点左边，哪些结点位于根结点右边。如下图所示： 线索二叉树 在扩展二叉树里面，我们就已经看到一颗二叉树里其实还留有很多空引用(指针)，主要来源于叶子结点和单分支结点(1度结点)。 在链表二叉树里面，我们只能直接知道结点的左右儿子是谁，而如果要知道某个结点在对应序列中的前驱和后继是谁，就必须得重新遍历一次。 其实可以考虑把那些空引用用来存储结点的前驱和后继。更巧的是，一颗二叉树中的空引用数目和所有结点的前驱后继总数刚好相等。 我们把这种指向前驱和后继的引用称为线索，加上线索的二叉树便成了线索二叉树。所以线索化的实质就是将链表二叉树中的空引用利用起来，去指向结点的前驱和后继。如下图所示：将该二叉树线索化后：仔细观察会发现线索化后的二叉树其实就是一个双向链表，如下图：既然是双向链表，那么可以给它加上一个头结点，方便我们既可以从第一个结点沿着后继进行遍历，也可以从最后一个结点沿着前驱进行遍历。 还有一个问题，原来的空引用变成了前驱和后继，那么怎么和原来那些指向左右儿子的非空引用区别开来呢？这时我们需要两个标志位，来分别标识两个引用到底是指向左右儿子还是作为前驱后继：ltag为0时表示指向结点的左儿子，为1时表示指向结点的前驱；rtag为0时表示指向结点的右儿子，为1时表示指向结点的后继。如下图所示：线索二叉树的数据结构：和二叉树的数据结构类似，只是结点类增加了两个数据成员：ltag、rtag。 可以在前序遍历的过程中就实现线索化。由于线索二叉树其实是一个双向链表，所以可以按照链表的遍历方式来遍历线索二叉树了，省去了递归的大量开销。代码中的CluePreOrderTraverse()函数其实是模拟了二叉树的前序遍历，先一直向左，再向右，利用RightChild访问到下一个序列结点。可参考线索二叉树标题下的第一幅图（有后继的那幅图）。部分代码如下： class ClueBinaryTreeNode { public object Data; public ClueBinaryTreeNode LeftChild; public ClueBinaryTreeNode RightChild; public int LeftTag; public int RightTag; ... } class ClueBinaryTree { public ClueBinaryTreeNode first; //全局变量，指向刚刚访问过的结点 ClueBinaryTreeNode pre; public ClueBinaryTree() { first = new ClueBinaryTreeNode(); } //前序遍历过程中实现线索化 void PreOrderTraverse(ClueBinaryTreeNode root) { if (root == null) return; //设置当前结点的前驱 if (root.LeftChild == null) { root.LeftTag = 1; root.LeftChild = pre; } //设置前驱结点的后继为当前结点 if (pre.RightChild == null) { pre.RightTag = 1; pre.RightChild = root; } pre = root; PreOrderTraverse(root.LeftChild); PreOrderTraverse(root.RightChild); } //用双向链表的方式来遍历线索二叉树 void CluePreOrderTraverse() { ClueBinaryTreeNode current; current = first.LeftChild; while (current != first) { while (current.LeftTag == 0) { current = current.LeftChild; } Console.WriteLine(current.Data); while (current.RightTag == 1 &amp;&amp; current.RightChild != first) { current = current.RightChild; Console.WriteLine(current.Data); } current = current.RightChild; } } ... } 树、森林与二叉树的转换 树转换为二叉树 兄弟加线：在所有兄弟之间加一条连线 非长子去线：对树中每个结点，只保留它与第一个孩子结点的连线，删除它与其他孩子结点之间的连线 层次调整：以树和子树的根结点为轴心，将整棵树顺时针旋转一定的角度，使之结构层次分明。【注意第一个孩子是二叉树结点的左孩子，兄弟转换过来的孩子是结点的右孩子】如下图所示： 森林转换为二叉树：每棵树的根结点依次作为右兄弟 把每个树转换为二叉树 把后一棵二叉树的根结点作为右孩子连到前一棵二叉树的根结点上。再调整层成层次分明的二叉树 如下图所示： 二叉树转换为树 加线：二叉树及其所有子树的根结点与它的长子的右孩子加线 去线：删除原二叉树中所有结点与其右孩子结点的连线 层次调整，使其结构层次分明 如下图所示： 二叉树转换为森林(森林到二叉树的逆转换) 首先要判断一棵二叉树能否转换成森林，需要看二叉树的根结点是否有右孩子，如果有则删掉与右孩子的连线。一直进行下去，直到分离的所有二叉树根结点与右孩子的连线都删除为止 将每棵分离的二叉树转换为树 如下图所示： 二叉树的应用之哈夫曼树树的带权路径长度WPL：树中所有叶子结点的权值乘以路径长度的和。带权路径长度WPL最小的二叉树称为哈夫曼树。哈夫曼树又称带权最优二叉树。 求解哈夫曼树的方法： 把所有带权值得叶子节点排成一个序列 取出权值最小的两个加起来，作为新结点，加入到序列中(取出的两个结点报废)，并在对应哈夫曼树的结构图作为取出的两个结点的双亲结点 重复第二步，直到序列中不再有结点为止 假设六个字母的频率为A 27，B 8，C 15，D 15，E 30，F 5，则由它们构成的哈夫曼树如下图所示：规定哈夫曼树的左分支代表0，右分支代表1，则从叶子结点到根结点的01序列就是对应字符的哈夫曼编码。]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C#常用容器]]></title>
    <url>%2F2016%2F08%2F30%2FC%23%E5%B8%B8%E7%94%A8%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[C#常用容器如下： T[]：静态数组，连续内存，可快速地随机访问和遍历 List：可变大小，固定类型，连续内存，可快速地随机访问和遍历 ArrayList：可变大小，泛型容器，但是性能开销大 LinkedList/LinkedListNode：双向链表，可快速地随机插入删除 Dictionary：散列字典，快速查找，但是性能开销大 HashSet：单项散列表，快速查找，但是性能开销大(优于Dictionary) Queue：队列，快速入队出队 Stack：栈]]></content>
      <categories>
        <category>C#语法</category>
      </categories>
      <tags>
        <tag>C#容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法之树]]></title>
    <url>%2F2016%2F08%2F30%2F%E6%A0%91%2F</url>
    <content type="text"><![CDATA[树：任意一颗树或其子树都只有一个根节点，且子树之间互不相交。节点的度：结点拥有的子树数目，或者说结点的直接子节点的数目。树的度：树中所有结点的度的最大值。 树的存储结构 双亲表示法为了让每一个结点都能很快地找到它的双亲结点，我们可以给每一个结点附加一个双亲结点引用，指向该结点的双亲结点。伪码如下： public class ParentNode { public object Data; public ParentNode Parent; public ParentNode() { } } class ParentTree { private ParentNode root; public ParentTree() { } ... } 但是如果某结点想要找到它的子节点是谁，用上面的存储结构就得把整个树重新遍历一次。可以考虑给每个结点再增加一个长子(最左孩子)结点引用。如果结点还想要知道自己的兄弟是谁，可以考虑再给每个结点增加一个右兄弟结点引用。当然，如何设计要看具体情况，适度够用就好，要避免过度设计。【注】：树的双亲表示法用数组也很好实现，只需要把Parent引用改为双亲节点在数组中的位置(数组下标)即可。 孩子表示法孩子表示法是从结点的n个孩子来看问题的。首先想到的表示方法应该是：把每个结点的所有孩子引用都在结点中存储起来，如下图：但是树的每个结点的孩子个数可能不一样，那结点到底该准备多少个孩子引用呢？一种方法是：让孩子引用个数等于树的度，但是这样会浪费很多引用的存储空间，因为很可能某些结点并没有那么多孩子。第二种方法是：让每个结点孩子引用的个数等于该结点的度，可是仔细考虑，虽然这种方法节省了存储空间，但是由于每个结点的引用个数不同，也就是每个结点的存储结构不一样，这会给遍历、查找、删除等等操作带来很大的运算开销，时间复杂度会很高。其实问题的根源出在：为何一定要把所有孩子引用都存储到双亲结点中呢？上面的方法相当于在结点中开辟了一个数组，用来存储孩子引用，但是每个结点的这个数组大小是不一样的，相当于是需要一个动态变化的数组。而这恰巧是数组的弊端，一般数组的大小初始化后都是固定不变的，而解决数组这个弊端的方法就是用链表：把数组中的元素(结点的所有孩子)用链表连起来，这样就不用考虑结点到底该用多少个存储单元来放置孩子引用了。图示如下：不过总不能让这些结点及其链表都独立存在吧，需要用一个数组把这些节点存储起来就ok，每个节点跟着一个孩子链表，如下图：上图就是孩子表示法。 树的孩子表示法的数据结构：表头结点类+孩子结点类+树(类)。 表头结点类由两个数据成员组成：结点数据+孩子结点引用(长子) 孩子结点类也由两个数据成员组成：结点的数组下标+孩子结点引用(指向该孩子结点的右兄弟) 树(类)主要由一个数据成员组成：表头结点数组 伪码如下： public class ArrayNode { public object Data; public ChildNode FirstChild; public ArrayNode() { } } public class ChildNode { public int index; public ChildNode RightBrother; public ChildNode() { } } class ChildTree { ArrayNode[] Headers; public ChildTree() { } ... } 如果结点还想知道它的双亲是谁，可以在表头结点中再加一个数据成员：双亲结点的数组下标，标识该结点的双亲结点是谁。这种表示结构叫孩子双亲表示法 孩子兄弟表示法：孩子兄弟表示法是从结点的孩子和兄弟来看问题的。在孩子表示法中，是把一个结点的所有孩子都存储在一个链表中，也就是一个孩子和这个孩子的兄弟都在一个链表中。因为每一个孩子其实也是一个结点，而且它的右兄弟是唯一的，所以其实也可以把右兄弟引用搬到结点中去，作为结点的数据成员。这样就省去了给每个结点建立一个子链表的操作。图示如下：这棵树用孩子兄弟表示法如下：其实仔细看，上面的表示结构其实是一颗二叉树。所以，孩子兄弟表示法的最大好处在于它能够把一个复杂的树变成一颗二叉树。 树的孩子兄弟表示法的数据结构：结点类+树(类) 结点类由三个数据成员组成：结点数据+孩子结点引用(指向结点的第一个孩子)+右兄弟结点引用 树(类)主要由一个数据成员组成：树根结点 伪码如下： public class ChildBrotherNode { public object Data; ChildBrotherNode FirstChild; ChildBrotherNode RightBrother; public ChildBrotherNode() { } } class ChildBrotherTree { ChildBrotherNode root; public ChildBrotherTree() { } ... } 二叉树请看另一篇博文《数据结构与算法之二叉树》]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法之队列]]></title>
    <url>%2F2016%2F08%2F28%2F%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[队列：只允许在一端进行插入操作，在另一端进行删除操作的线性表。允许插入的一端称为队尾，允许删除的一端称为队头。 顺序队列 最简单的顺序队列：由数组构成，入队时在数组元素尾部插入新元素，出队时移去数组下标为0的元素，同时其他数组元素向前移动一个位置。就像一群人在买票，前面的人离开，后面的人就会全部向前一步，补上空位。图示如下：入队列：出队列：C#的容器已经实现了这个在尾部插入数据、在头部删除数据并且自动补位的功能，用C#容器实现的队列代码如下(由于C#自带实现队头队尾的插入删除，所以不需要队头队尾节点的引用)： class SequenceQueue { private ArrayList Data; public SequenceQueue() { Data = new ArrayList(); } //入队列 public void EnQueue(object data) { Data.Add(data); } //出队列 public void DeQueue(ref object data) { data = Data[0]; Data.RemoveAt(0); } //查找队列第i个元素 public object Find(int i) { return Data[i]; } //清除队列 public void Clear() { Data.Clear(); } //队列元素个数 public int Count() { return Data.Count; } } 循环队列 但是上面的队列实现方式有个性能缺陷：出队列时所有元素都要移位。所以我们可以设置一个队头和队尾的引用(指针)，出队列时直接把队头引用处的结点移除，入队列时直接把元素添加到队尾引用所在的节点，而其他元素不用动，只是在入队列和出队列时修改队头引用或者队尾引用即可。所以，队头引用front指向队头元素，队尾引用rear指向队尾元素的下一个位置(方便下次入队时直接添加到该位置)。但是，这种方式存在下图的尴尬(针对固定容量的队列，非ArrayList这种大小可变的容器)：若再在rear位置入队插入新元素，则会溢出，但是明显数组前面还有空位，是可以插入新元素的。就像坐公交，前面有空位置肯定是要去座的。为了让新元素能够按次序插入到前面的空位里去，应该把队列的首尾连起来，形成循环队列，这样新元素插入到前面的空位就水到渠成了。还有一个问题，如下：如上图所示，队列空和队列满的条件都是front==rear，为了区分他俩，我们人为设定：数组中只剩下一个空闲单元时，就认为队列已经满了。即敲定队列空的条件为：front==rear，队列满的条件为(rear+1)%QueueSize==front。如下图所示：综上，循环队列数据结构：数据成员：数组、队头引用front、队尾引用rear，方法成员：入队、出队等。代码如下： class RoundQueue { private Object[] Data; private int front; private int rear; private int QueueSize; public RoundQueue() { QueueSize = 3; front = 0; rear = 0; Data = new object[QueueSize]; } //入队列 public void EnQueue(object data) { //如果队列满，则不能再入队列 if ((rear + 1) % QueueSize == front) return; Data[rear] = data; rear = (rear + 1) % QueueSize; } //出队列 public void DeQueue(ref object data) { //如果队列空，则不能再出队列 if (rear == front) return; data = Data[front]; front = (front + 1) % QueueSize; } //队列中元素个数 public int Count() { return (rear - front + QueueSize) % QueueSize; } } 优先队列 优先队列不再是每次移除队头的结点元素，而是每次出队优先级最高的结点。严格来说，它已经不算是一个队列。对于优先队列，需要给每一个结点都加上一个表示优先级的数据成员，可以把结点单独写成一个类，如下： class PriorQueueNode{ public object Data; public int Priority; } 优先队列可以继承普通的顺序队列或者循环队列，但是需要重载出队列函数，伪码如下： public override object DeQueue(){ //找出优先队列里优先级最大的结点 for(;;){ } //移除优先级最大的结点 Remove(); } 链队列 因为顺序队列的存储空间有限且大小是固定的，插入时会有溢出，所以我们需要链队列。由于链队列需要在表头(队头)删除结点，删除结点需要知道该结点的前一个结点是谁，为了统一第一个结点和中间结点，需要给链队列加上一个头结点。链队列的队头引用front其实就是指向头结点，是固定不动的，队尾引用rear是一直指向表中的最后一个结点(最后一个结点有Next成员，所以rear不需要指向最后一个结点的下一个位置)。代码如下： public class Node{ public object Data; public Node Next; public Node() { Data = null; Next = null; } public Node(Object data) { Data = data; Next = null; } } class LinkQueue { protected Node header; protected Node front; protected Node rear; public LinkQueue() { header = new Node(); front = header; rear = header; } //入队列 public void EnQueue(object data) { Node newNode = new Node(data); rear.Next = newNode; rear = newNode; } //出队列，队头引用front是不动的，一直指向头结点 public void DeQueue(ref object data) { //队列空，则不再出队列 if (front == rear) return; //队头结点(头结点)的下一个结点就是队尾结点(表中只有一个元素了),则出队列后让队尾引用重新指向头结点 if (front.Next == rear) rear = header; data = front.Next.Data; front.Next = front.Next.Next; } } 【注】： 可以确定队列容量的情况下，建议使用循环队列，如果队列长度不能确定或者需要动态变化时，则需要用链队列]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[链表中什么时候需要用到头结点]]></title>
    <url>%2F2016%2F08%2F28%2F%E5%A4%B4%E7%BB%93%E7%82%B9%2F</url>
    <content type="text"><![CDATA[链表中什么时候需要用到头结点： 需要统一对第一个结点和中间结点的操作 ，这时需要加上头结点 链接的方向(引用/指针指向的方向)是从表头指向表尾时，这时需要加上头结点，因为需要对开始节点初始化内存以后，才能使用Node.Next。不可能在插入结点的函数里去指定第一个插入的结点是表头结点，因为这样会增加复杂度，每次都要判断插入的结点会不会是表里的第一个节点 存在对链表的第一个结点的删除操作时，这时需要加上头结点。就像队列，出队列时需要删除表中第一个结点，如果链接方向是从表头指向表尾，虽然node=node.next就可以从容器中删除第一个结点，但是从第二条看，初始化时还是需要头结点的。 因为在栈里只存在对表尾结点的插入删除，不涉及中间结点，也不涉及对第一个结点的删除(栈中只有一个结点时，该结点也可以被看作是表尾结点来处理)，所以从原理上栈是可以不要头结点的，所有栈采用了从表尾指向表头的链接方式。而队列中存在对第一个结点的删除操作，所以是需要头结点作为辅助的。 链接方向从表头指向表尾(比如队列)：链接方向从表尾指向表头(比如栈)【头结点：链表头部不存放数据的一个结点，是有真实内存的，不同于结点引用、头指针等等，头结点存在的意义在于降低程序/时间复杂度】]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>头结点</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法之栈]]></title>
    <url>%2F2016%2F08%2F26%2F%E6%A0%88%2F</url>
    <content type="text"><![CDATA[栈：只允许在表尾(栈顶)进行插入和删除操作的的线性表。 顺序栈 顺序栈是由数组+栈顶引用(指针)构成的。由于是数组，所以下标较小的那一端作为固定的栈底。程序员习惯数字从0开始，所以当栈中存在一个元素时，栈顶引用top等于0，所以栈空时top=-1。 class SequenceStack { private ArrayList Data; private int Top; public SequenceStack() { Data = new ArrayList(); Top = -1; } //进栈 public void Push(object data) { Top++; Data.Add(data); } //出栈 public void Pop(ref object data) { if (Top == -1) { return; } data = Data[Top]; Top--; } //栈中元素数量 public int Count() { return Data.Count; } //清空栈 public void Clear() { Data.Clear(); Top = -1; } } 【注】： 上述代码用的是C#语言，如果用C++就不能再用ArrayList了，应该指定数组容量：Data[MaxSize]，且push操作还要在函数内加上数组是否越界的判断 实际问题中尽量使用List代替ArrayList，因为ArrayList性能开销大，可参考博客《C#常用容器》 两顺序栈共享空间 因为实际情况中，有可能出现一个栈已经满了，而另一个栈还有很多存储空间的情形。这时可以把两个栈合并成一个栈：它有两个栈底，一个栈底为数组的始端(下标最小处)，一个栈底为数组的末端(下标最大处)。这样由于两个栈底在数组的两端，所以对这两个栈进栈时，就会向数组的中间靠拢。 栈满就是两个栈见面之时，即Top1+1==Top2为栈满 Push和Pop操作时都要传入一个stackNumber参数，表示是对栈1还是栈2操作 适用情况：两个栈数据类型相同，且一个栈增长时另一个栈在缩短。 class ShareStack { Object[] Data; int Top1; int Top2; int MaxSize = 50; public ShareStack() { Data = new object[MaxSize]; Top1 = -1; Top2 = MaxSize; } public void Push(Object data,int stackNumber) { //栈满就不能再push新元素了 if (Top1 + 1 == Top2) { return; } if (stackNumber == 1){ Top1++; Data[Top1] = data; } else if (stackNumber == 2) { Top2--; Data[Top2] = data; } } public void Pop(ref object data,int stackNumber) { if (stackNumber == 1){ //栈1空则栈1不能再pop if (Top1 == -1) return; data = Data[Top1]; Top1--; } else if (stackNumber == 2) { //栈2空则栈2不能再pop if (Top2 == MaxSize) return; data = Data[Top2]; Top2++; } } } 链栈 链栈其实就是对单链表的改造，由于链栈只在栈顶(表尾)插入删除，不会对链表中间结点有插入删除操作，所以链栈不再需要头结点。但是需要一个栈顶节点的引用(指针) public class Node { public Object Data; public Node Next; public Node() { Data = null; Next = null; } public Node(Object data) { Data = data; Next = null; } } class LinkStack { protected Node Top; public LinkStack(){ Top = null; } //进栈 public void Push(object data) { Node newNode = new Node(data); newNode.Next = Top; Top = newNode; } //出栈 public void Pop(ref object data) { //栈空则不再出栈 if (Top == null) return; data = Top.Data; Top = Top.Next; } } 栈的应用——递归之斐波那契数列 形如：0，1，1，2，3，5，8，13……，它除了第一项是0和第二项是1以外，其余每项都是其前两项的和，这个数列被称为斐波那契数列。用数学函数定义如下：不用递归输出斐波那契数列前40项，代码如下： static void Main(string[] args) { int[] a = new int[40]; a[0] = 0; a[1] = 1; Console.WriteLine(a[0]); Console.WriteLine(a[1]); for (int i = 2; i &lt; 40; i++) { a[i] = a[i - 1] + a[i - 2]; Console.WriteLine(a[i]); } Console.ReadKey(); } 用递归输出斐波那契数列前40项，代码如下： static void Main(string[] args) { for (int i = 0; i &lt; 40; i++) { Console.WriteLine(FBNQ(i)); } Console.ReadKey(); } static int FBNQ(int i) { if (i == 0) return 0; if (i == 1) return 1; return FBNQ(i - 1) + FBNQ(i - 2); } 而编译器是用栈来实现递归的。在向下递归阶段，对于每一层递归，函数的局部变量、参数值以及返回地址都被压入栈中，在向上回溯阶段，位于栈顶的局部变量、参数值和返回地址被弹出，用于返回调用层次中执行代码的其余部分，也就是恢复了被调用时的状态。【注】： 每个递归定义必须至少有一个递归终止的条件，即不再是调用自身而是返回一个具体的值退出 大量的递归调用会建立函数的副本，会消耗大量的时间和内存。而像第一种代码这种迭代是不需要反复调用函数和占用额外内存的 栈的应用——四则运算表达式求值 为了方便计算机运算，需要把人们习惯的中缀表达式利用栈转化为计算机更容易处理的后缀表达式，计算机在后缀表达式的基础上再利用栈计算出最后的结果。所以分为两步：中缀转后缀表达式(逆波兰式)、后缀表达式计算结果 中缀转后缀表达式“9+(3-1)x3+10/2”，这是中缀表达式，而”9 3 1-3*+10 2/+”，这是它的后缀表达式。中缀转后缀表达式的方法：从左到右遍历中缀表达式的每个数字和符号，遇到数字则输出，作为后缀表达式的一部分，遇到符号，则判读当前符号与栈顶符号的优先级，若大于则进栈，否则使栈顶符号出栈，直到当前符号优先级大于栈顶符号优先级，再把当前符号进栈。重复上述操作一直到遍历完且栈空为止(即输出了最终的后缀表达式)核心思想：遍历的当前符号的优先级大于栈顶符号优先级则进栈，否则出栈图示如下： 后缀表达式计算结果从左到右遍历后缀表达式的每个数字和符号，遇到数字则进栈，遇到符号则让栈顶的两个数字出栈并进行运算，再将运算结果进栈。重复上述操作一直到栈空核心思想：数字进栈，遇到符号则让数字出栈运算，运算结果再进栈图示如下： 【注】： 中缀转后缀表达式是符号进栈，而后缀表达式计算结果是数字进栈]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>栈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法之链表]]></title>
    <url>%2F2016%2F08%2F24%2F%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[由于数组的删除、插入是很费时的，所以我们需要链表。 链表的数据结构：节点类+链表类 节点类：表示链表中的节点，由两个数据成员组成：节点数据Data，指向表内下一节点的引用Link public class Node { public Object Data; public Node Next; public Node() { Data = null; Next = null; } public Node(Object theData) { Data = theData; Next = null; } } 链表类：表示链表中节点之间的链接。数据成员只有一个头节点(如果要用到尾插法，则还需要一个尾节点)，类方法包括：构造函数、链表创建(分为头插法和尾插法)、查找、插入、删除、遍历 class LinkedList { protected Node header; protected Node tailer; public LinkedList() { header = new Node(); tailer = header; } //头插法创建单链表(非整表创建) public void InsertHead(Object theData) { Node newNode = new Node(theData); newNode.Next = header.Next; header.Next = newNode; } //尾插法创建单链表(非整表创建) public void InsertTail(Object theData) { Node newNode = new Node(theData); tailer.Next = newNode; tailer = newNode; } //查找 public Node Find(Object theData) { Node current = header.Next; while (current != null &amp;&amp; !current.Data.Equals(theData)) { current = current.Next; } return current; } //插入(在指定内容(theData)的节点后插入新节点) public void Insert(Object theData,Object newData) { Node current = header.Next; while (current != null &amp;&amp; !current.Data.Equals(theData)) { current = current.Next; } //以上的代码和Find方法一致 if (current != null) { Node newNode = new Node(newData); newNode.Next = current.Next; current.Next = newNode; } } //删除(删除指定内容的节点) public void Remove(Object theData) { Node current = header.Next; Node previous = header.Next; while (current != null &amp;&amp; !current.Data.Equals(theData)) { previous = current; current = current.Next; } //以上代码和Find方法类似 if (current != null) { previous.Next = current.Next; } } //遍历 public void ShowList() { Node current = header.Next; while (current != null) { Console.WriteLine(current.Data); current = current.Next; } } } 注： 其中的头插法和尾插法都只是向链表中插入了一个节点，如果需要插入多个节点，多次调用即可。这是非整表创建的一种方式，如果需要整表创建，可在LinkedList类中加入如下代码： //头插法整表创建 public void CreateListHead(int n) { for (int i = 0; i &lt; n; i++) { Object data; data=Console.ReadLine(); InsertHead(data); } } //尾插法整表创建 public void CreateListTail(int n) { for (int i = 0; i &lt; n; i++) { object data; data = Console.ReadLine(); InsertTail(data); } } 在代码中节点的数据类型是Object，而在实际问题中最好换成相应的数据类型，否则像list.InsertTail(1);等等传入数值时，将会发生多次装箱拆箱过程，浪费资源 循环链表循环链表只是把单链表作些许改动： 尾节点不再是指向null，而是指向头节点header 判断循环结束的条件不再是current是否为null，而是current不等于头节点header 为了让查找头节点和尾节点的时间复杂度都为O(1)，需要保留一个尾节点的引用(如上述代码中的tailer)，如下图： 使用尾节点引用还可以方便地将两个链表链接成一个表：将上面两个循环链表合并成一个链表，如下：合并的代码如下：headerA = rearA-&gt;next; //保存A表的头节点,即图中1 rearA-&gt;next = rearB-&gt;next-&gt;next; //将A表的尾节点的Link指向B表的第一个节点(非B表头节点),即图中2 rearB-&gt;next = headerA; //将B表的尾节点的Link指向A表的头节点,即图中3 双向链表双向链表在单链表上做出的改动： 节点类增加一个数据成员prior，指向该结点的前驱结点。代码如下： public class Node { public Object Data; public Node next; public Node prior; //双向链表新增的数据成员 public Node() { Data = null; next = null; prior = null; } public Node(Object theData) { Data = theData; next = null; prior = null; } } 插入结点时要不仅要考虑next，还要考虑prior对应代码如下：(顺序很重要) s-&gt;prior = p; s-&gt;next = p-&gt;next; p-&gt;next-&gt;prior = s; p-&gt;next = s; 删除结点时也要考虑到prior对应代码如下： p-&gt;prior-&gt;next = p-&gt;next; p-&gt;next-&gt;prior = p-&gt;prior; 链表中头结点存在的意义： 如果没有头结点，那么对链表的第一个节点和中间节点的插入删除操作就是不一样的，需要把第一个结点分开来处理，而有了头结点以后，原来的第一个结点和中间结点都变成了中间结点，不用再分开处理。加入头结点后对链表中的所有结点操作就变得一致了。]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C#语法之测试程序时间花费]]></title>
    <url>%2F2016%2F08%2F24%2F%E6%B5%8B%E8%AF%95%E7%A8%8B%E5%BA%8F%E6%97%B6%E9%97%B4%2F</url>
    <content type="text"><![CDATA[不多说，直接上代码 using System; using System.Diagnostics; namespace timeTest { class Program { static void Main(string[] args){ int[] nums = new int[100000]; TimeSpan duration; BuildArray(nums); duration = Process.GetCurrentProcess().TotalProcessorTime; Console.WriteLine(&quot;Time: &quot;+duration.TotalSeconds); Console.ReadKey(); } static void BuildArray(int[] arr){ for (int i = 0; i &lt;= 99999; i++) { arr[i] = i; } } } } 测试的是程序当前进程的处理器时间，不会包括控制台输出等进程所花费的时间 使用Process类需要using System.Diagnostics; TimeSpan类：表示一个时间间隔]]></content>
      <categories>
        <category>C#语法</category>
      </categories>
      <tags>
        <tag>timeTest</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[给博客添加多说评论]]></title>
    <url>%2F2016%2F08%2F23%2F%E8%AE%BE%E7%BD%AE%E5%A4%9A%E8%AF%B4%E8%AF%84%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[Hexo+Github博客添加多说评论 在多说官网 点击我要安装，创建自己的多说域名，其中http://xxx.duoshuo.com 中的xxx就是自己的duoshuo_shortname 打开 主题路径\_config.yml，修改(\增加)duoshuo_shortname为duoshuo_shortname: xxx(xxx参考第一步，注意:后面有一个空格) 打开主题路径\layout\_partial\comment.ejs(不同主题路径可能不一样)，将之间的代码替换为如下：&lt;h2 class=&quot;title&quot;&gt;&lt;%= __(&#39;comment&#39;) %&gt;&lt;/h2&gt; &lt;% if(theme.duoshuo_shortname) { %&gt; &lt;!-- 多说评论框 start --&gt; &lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;&lt;%- page.path %&gt;&quot; data-title=&quot;&lt;%- page.title %&gt;&quot; data-url=&quot;&lt;%- page.permalink %&gt;&quot;&gt;&lt;/div&gt; &lt;!-- 多说评论框 end --&gt; &lt;!-- 多说公共JS代码 start (一个网页只需插入一次) --&gt; &lt;script type=&quot;text/javascript&quot;&gt; var duoshuoQuery = {short_name:&quot;duoshuo_shortname&quot;}; &lt;!-- 替换这里的duoshuo_shortname为第一步的xxx --&gt; (function() { var ds = document.createElement(&#39;script&#39;); ds.type = &#39;text/javascript&#39;;ds.async = true; ds.src = (document.location.protocol == &#39;https:&#39; ? &#39;https:&#39; : &#39;http:&#39;) + &#39;//static.duoshuo.com/embed.unstable.js&#39;; ds.charset = &#39;UTF-8&#39;; (document.getElementsByTagName(&#39;head&#39;)[0] || document.getElementsByTagName(&#39;body&#39;)[0]).appendChild(ds); })(); &lt;/script&gt; &lt;!-- 多说公共JS代码 end --&gt; &lt;% } else if(config.disqus_shortname) { %&gt; &lt;div id=&quot;disqus_thread&quot;&gt; &lt;noscript&gt;Please enable JavaScript to view the &lt;a href=&quot;//disqus.com/?ref_noscript&quot;&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt; &lt;/div&gt; &lt;% } %&gt; 重新部署到github即可。打开博客文章便能看到多说评论框了。 【注：博主用的主题是transparent，在github主题官网就能找到，其它主题可能配置方法不太一样，但大多数都大同小异】]]></content>
      <categories>
        <category>博客配置</category>
      </categories>
      <tags>
        <tag>多说</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MarkDown的简单语法规则]]></title>
    <url>%2F2016%2F08%2F22%2FMarkDown%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[&lt;font size=&quot;5&quot; color=&quot;orange&quot;&gt;标题&lt;/font&gt;### 标题2###### 标题3有序列表(嵌套时需要在序号前加空格)：1. a2. 阿斯顿 &nbsp;a. 阿斯顿 &nbsp;b. 阿达3. 阿达4. 阿斯顿 无序列表：- 撒旦- 阿斯顿- 阿达 链接[百度](http://baidu.com)图片![](http://cfwjm.img48.wal8.com/img48/559974_20161023165829/147721517339.jpg)引用> 黄河远上白云间> 一片孤城万仞山 分割线****斜体***粗体** 表格(表格前要空一行，多一个|就会多一个单元格，其中冒号表示对齐方式) ad | asd| ad :- | :-: | -: h | j | k 1 | 2 | 3 代码框(行)`void fun(){ destroy();}` 代码框(段落),如下格式(或每一行代码前面加4个空格，且代码段前有空行)```csharpvoid fun(){ destroy();}``` ## 公式$$J\_\alpha(x)=\sum _{m=0}^\infty \frac{(-1)^ m}{m! \, \Gamma (m + \alpha + 1)}{\left({\frac{x}{2}}\right)}^{2 m + \alpha }$$ ***&lt;table&gt;&lt;tr&gt;&lt;td bgcolor=&quot;YellowGreen&quot;&gt;文本框背景色&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; ##所展示的效果如下 标题 标题2标题3有序列表： a 阿斯顿a. 阿斯顿b. 阿达 阿达 阿斯顿 无序列表： 撒旦 阿斯顿 阿达 链接百度图片引用 黄河远上白云间一片孤城万仞山 分割线 斜体粗体 表格(表格前要空一行，多一个|就会多一个单元格) ad asd ad h j k 1 2 3 代码框(行)void fun(){ destroy(); }代码框(段落),如下格式(或每一行代码前面加4个空格，且代码段前有空行) void fun(){ estroy(); } 公式$$J_\alpha(x)=\sum _{m=0}^\infty \frac{(-1)^ m}{m! \, \Gamma (m + \alpha + 1)}{\left({\frac{x}{2}}\right)}^{2 m + \alpha }$$ 文本框背景色]]></content>
      <categories>
        <category>博客配置</category>
      </categories>
      <tags>
        <tag>MarkDown</tag>
      </tags>
  </entry>
</search>
