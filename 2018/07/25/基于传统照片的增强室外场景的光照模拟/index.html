<!DOCTYPE HTML>
<html>

<head>
	<link rel="bookmark"  type="image/x-icon"  href="/img/logo_miccall.png"/>
	 <link rel="shortcut icon" href="/img/logo_miccall.png">
	
			
    <title>
    Elays'Blog
    </title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="/css/mic_main.css" />
    <link rel="stylesheet" href="/css/dropdownMenu.css" />
    
    	<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
	
    <noscript>
        <link rel="stylesheet" href="/css/noscript.css" />
    </noscript>
			    <script src="/js/jquery.min.js"></script>
    <script src="/js/jquery.scrollex.min.js"></script>
    <script src="/js/jquery.scrolly.min.js"></script>
    <script src="/js/skel.min.js"></script>
    <script src="/js/util.js"></script>
    <script src="/js/main.js"></script>
	
<link rel="stylesheet" href="/css/prism-dark.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>
    
		
<!-- Layouts -->


<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<!--<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">-->
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML" async>
</script>

<!--  代码渲染  -->
<link rel="stylesheet" href="/css/prism_undefined.css" />
<link rel="stylesheet" href="/css/typo.css" />
<!-- 文章页 -->
<body class="is-loading">
    <!-- Wrapper 外包 s-->
    <div id="wrapper" class="fade-in">
        <!-- Intro 头部显示 s -->
        <!-- Intro 头部显示 e -->
        <!-- Header 头部logo start -->
        <header id="header">
    <a href="/" class="logo">MICCALL</a>
</header>
        <!-- Nav 导航条 start -->
        <nav id="nav" class="special" >
            <ul class="menu links" >
			<!-- Homepage  主页  --> 
			<li >
	            <a href="/" rel="nofollow">主页</a>
	        </li>
			<!-- categories_name  分类   --> 
	        
	        <li class="active">
	            <a href="#s1">分类</a>
	                    <ul class="submenu">
	                        <li>
	                        <a class="category-link" href="/categories/Boost/">Boost</a></li><li><a class="category-link" href="/categories/C-语法/">C#语法</a></li><li><a class="category-link" href="/categories/C/">C++</a></li><li><a class="category-link" href="/categories/C语言/">C语言</a></li><li><a class="category-link" href="/categories/OpenGL/">OpenGL</a></li><li><a class="category-link" href="/categories/c/">c++</a></li><li><a class="category-link" href="/categories/全局光照/">全局光照</a></li><li><a class="category-link" href="/categories/博客配置/">博客配置</a></li><li><a class="category-link" href="/categories/并行计算/">并行计算</a></li><li><a class="category-link" href="/categories/操作系统/">操作系统</a></li><li><a class="category-link" href="/categories/数据结构/">数据结构</a></li><li><a class="category-link" href="/categories/毕设/">毕设</a></li><li><a class="category-link" href="/categories/游戏开发/">游戏开发</a></li><li><a class="category-link" href="/categories/游戏设计模式/">游戏设计模式</a></li><li><a class="category-link" href="/categories/计算机图形学/">计算机图形学</a></li><li><a class="category-link" href="/categories/计算机系统/">计算机系统</a></li><li><a class="category-link" href="/categories/设计模式/">设计模式</a></li><li><a class="category-link" href="/categories/调试错误集锦/">调试错误集锦</a>
	                    </ul>
	        </li>
	        
	        <!-- archives  归档   --> 
	        
	        
		        <!-- Pages 自定义   -->
		        
		        <li>
		            <a href="/gallery/" title="图库">
		                图库
		            </a>
		        </li>
		        
		        <li>
		            <a href="/tag/" title="搜索">
		                搜索
		            </a>
		        </li>
		        


            </ul>
            <!-- icons 图标   -->
			<ul class="icons">
		            
		                <li><a href="https://github.com/miccall" class="icon fa-github"><span class="label">GitHub</span></a></li>
		            
		            
		            
		            
			</ul>
</nav>

        <div id="main" >
            <div class ="post_page_title_img" style="height: 25rem;background-image: url(http://oqcvzqam1.bkt.clouddn.com/%E5%9F%BA%E4%BA%8E%E4%BC%A0%E7%BB%9F%E7%85%A7%E7%89%87%E7%9A%84%E5%A2%9E%E5%BC%BA%E6%88%B7%E5%A4%96%E5%9C%BA%E6%99%AF%E7%9A%84%E5%85%89%E7%85%A7%E6%A8%A1%E6%8B%9F_BG.png);background-position: center; background-repeat:no-repeat; background-size:cover;-moz-background-size:cover;overflow:hidden;" >
                <a href="#" style="padding: 4rem 4rem 2rem 4rem ;"><h2 >基于传统照片的增强室外场景的光照模拟</h2></a>
            </div>
            <!-- Post -->
            <div class="typo" style="padding: 3rem;">
				<div id="toc" class="toc-article">
					<strong class="toc-title">文章目录</strong>
					<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#摘要"><span class="toc-number">1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-简介"><span class="toc-number">2.</span> <span class="toc-text">1. 简介</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-室外光照模拟"><span class="toc-number">3.</span> <span class="toc-text">2. 室外光照模拟</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-室外光照模型"><span class="toc-number">3.0.1.</span> <span class="toc-text">2.1 室外光照模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-初始化数据采集"><span class="toc-number">3.0.2.</span> <span class="toc-text">2.2 初始化数据采集</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#几何近似"><span class="toc-number">3.0.2.1.</span> <span class="toc-text">几何近似.</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#合成环境贴图"><span class="toc-number">3.0.2.2.</span> <span class="toc-text">合成环境贴图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#太阳方位估算"><span class="toc-number">3.0.2.3.</span> <span class="toc-text">太阳方位估算</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#太阳遮蔽系数近似"><span class="toc-number">3.0.2.4.</span> <span class="toc-text">太阳遮蔽系数近似</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-光照近似"><span class="toc-number">3.0.3.</span> <span class="toc-text">2.3 光照近似</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-1-恢复材质反射率"><span class="toc-number">3.0.3.1.</span> <span class="toc-text">2.3.1 恢复材质反射率</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#漫反射材质的情况"><span class="toc-number">3.0.3.1.1.</span> <span class="toc-text">漫反射材质的情况</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#镜面材质的情况"><span class="toc-number">3.0.3.1.2.</span> <span class="toc-text">镜面材质的情况</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#光照参数估计"><span class="toc-number">3.0.3.2.</span> <span class="toc-text">光照参数估计</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-阴影模型"><span class="toc-number">4.</span> <span class="toc-text">3. 阴影模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-在真实阴影里的虚拟物体"><span class="toc-number">4.1.</span> <span class="toc-text">3.1 在真实阴影里的虚拟物体</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-总结和未来工作"><span class="toc-number">5.</span> <span class="toc-text">5. 总结和未来工作</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考文献"><span class="toc-number">6.</span> <span class="toc-text">参考文献</span></a></li></ol>
				</div>
                <p><img src="http://oqcvzqam1.bkt.clouddn.com/%E5%9F%BA%E4%BA%8E%E4%BC%A0%E7%BB%9F%E7%85%A7%E7%89%87%E7%9A%84%E5%A2%9E%E5%BC%BA%E6%88%B7%E5%A4%96%E5%9C%BA%E6%99%AF%E7%9A%84%E5%85%89%E7%85%A7%E6%A8%A1%E6%8B%9F_1.png" alt=""></p>
<p><center>图1：本文系统根据传统照片模拟室外场景的照明。我们根据图像恢复环境贴图，并使用六个光照参数为其照明进行建模。真实世界和虚拟物体之间的阴影投射可以被合成，确保增强的场景图像的一致性。该图显示了两个不同的场景，左边的是输入图像，右边的是我们合成后的结果。</center></p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>我们提出了一种新的方法来模拟基于传统照片的增强室外场景的光照。不像前人只把表明辐射度和光照相关的先验知识来作为光照估计的基础，本文方法集成了这两者。通过使用球函数，我们推导出一个只有6个光照参数的线性模型。室外场景的光照最终通过求解日光和天光颜色约束下的线性最小二乘问题来计算。然后建立一个高质量的环境贴图，引导出真实的渲染结果。我们还研究了在不知道投射阴影的物体的几何形状下，怎样在真实的和虚拟的物体之间投射阴影的问题。一种有效的方式是，通过纹理映射将真实世界地面上复杂的阴影（比如树的阴影）投射到虚拟物体的表面。最后，我们提出了一个真实场景和虚拟物体进行图像合成的统一方案，以确保光照一致性和阴影一致性。实验结果证明了我们方法的有效性和灵活性。</p>
<h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h1><p>当把一个合成的物体插入到图像或者视频里时，真实场景的光照模拟是很有必要的。对于基于传统照片的室外光照模拟，有两个问题需要解决：1）恢复场景的光照分布； 2）在真实的和虚拟的物体之间投射阴影。然而，照片中的每一个像素都是物体和入射关系之间交互影响的综合结果，这让基于传统照片去做光照模拟变得很困难。</p>
<p>已经有几张方法可以根据图像或者视频去估计自然场景的光照分布[JL06]。有些尝试用于光照相关的先验知识去估计场景的光照。[Deb98]拍摄了一个镜面球来记录场景的光照，[SSI99]捕获HDR全方位图像来实现这个目标。 Lalonde等人的方法[LEN09]使用Perez天空模型[PMI93]作为先验信息来估计室外光照，它生成一张包含真实光照环境中的高频分量的环境贴图。但是，这种方法需要生成时间圈图像序列，而且是基于经验模型来估计光源强度。[LQX ∗ 09]采用了一种简单的室外场景的光照模型，它认为太阳是一个平行光源，天空是一个均匀的区域光源，所以可以通过与光照有关的统计参数，或者从样本图像中学习得到的基础图像来估计光照。 [LG12]采用相同的假设，它们根据光照的空间和时间一致性作为先验知识，来恢复移动相机拍摄下的视频的光照。然后，室外场景的简单光源假设阻止了这些方法实现高度逼真的渲染结果。</p>
<p>或者，有些根据表面辐射度来恢复场景光照，他们推导出一个针对场景中与渲染方程有关的物体外观的优化问题。但是，其中的大多数方法都需要知道场景的3D几何信息。Sato等人根据阴影来估计兰伯特场景的光照[SSI03]。[ZY01]选择了几个关键点去计算光源的方向和强度。[YWAC06,HFC ∗ 09]使用多张图像来恢复真实场景的反射模型和光照环境。一般来说，基于场景几何的方法为真实场景的光照估计提供完美的理论基础，但是已知场景几何的要求限制了它们的应用。而且，这些方法所恢复的光照强度仅包含真实环境的低频光照分量，这可能会导致不能成功渲染出具有强烈的镜面反射的虚拟物体。显然，以上讨论的所有方法都不适用于基于传统照片的光照模拟。最近， Karsch等人 [KHFH11]提供了一种基于交互的方法来估计传统照片的光照，他们假设场景在一个盒子里，盒子的尺寸和光源的位置是交互指定的，然后他们的方法根据基于渲染方程的兰伯特模型，自动重建场景的材质和光源的强度。但是，材质和光照条件的恢复需要解决计算密集型的大规模非线性优化问题；极其远的光源的强度需要由用户指定；此外，该方法假设所有光源（太阳除外）都分布在一个平面上。难怪，Karsch的方法更适合室内场景。</p>
<p>如果我们想要在真实场景和虚拟物体之间模拟阴影投射，有两个问题需要解决：1）怎样投射真实的阴影到虚拟物体上；2）怎样避免虚拟和真实阴影之间的重叠。 [KTM ∗ 10,NGM ∗ 11]提出了几种渲染方法，可以将虚拟物体的阴影快速投射到真实场景中，但是，真实阴影在虚拟物体上的交互。 [GM00]使用使用阴影贴图来获得正确的合成结果。为了达到类似的效果，[JAL05, MJA06]使用了体积阴影。然而，要求以场景的3D模型作为基本信息，这是很难从传统照片中恢复出来的。Karsch的方法 [KHFH11] 使用光轴模拟极远的光源，他们将与阴影区域相对应的光轴强度设置为0，因此能够在虚拟物体表面产生阴影效果。然而，自然场景中的阴影总是奇形怪状的，这使得光轴的创建变得很困难；另外，光轴会带来额外的渲染成本。</p>
<p>在本文中，我们提出了一种将合成对象逼真地插入到室外场景的传统照片中的方法，该方法既考虑了准确的环境光照，也考虑了虚拟物体和真实场景之间的交互的阴影投射。本文方法不需要光照捕捉设备，也不需要多张图片。不像之前的方法仅仅使用表面辐射度或者与光照相关的先验知识作为光照估计的基础，本文方法使用从传统照片中提取出的天光分布和光照条件作为先验信息，并且把它们集成到渲染方程中。通过采用球函数，我们建立了一个只有6个光照参数的线性模型，这个简单的模型为我们提供了一个简单而有效的方法来合成真实场景的高质量环境贴图。我们首先使用几个简单的交互来估计场景的粗略集合信息；然后线性（漫反射）或迭代（镜面反射）地求解采样点的材质。最终通过求解日光和天光的颜色作为约束的线性最小二乘问题来计算这些光照参数。我们还提出了一种有效的方法，通过纹理映射将真实场景的阴影重新投射到虚拟物体的表面。为了避免虚拟阴影和真实阴影之间的重叠，我们提出了统一的方案来生成增强室外场景的合成图像。不像前人的工作，本文方法不需要知道投射阴影的物体的几何信息，也不需要使用复杂的渲染技术。</p>
<p>这篇文章的主要贡献包括：1）我们使用与光照相关的先验知识和表面辐射度作为光照估计的基础，从而提供了一种简单有效的方式从传统照片来合成真实场景的高质量环境贴图；2）我们提出了一种基于图像的方法，将真实场景的阴影投射到合成物体上，而且不需要知道投射阴影的物体的几何信息，同时还避免了虚拟和真实阴影之间的重叠。这些贡献为基于单个图像的室外光照模拟提供了一种强大而有效的方法，在许多领域具有良好的应用潜力。</p>
<h1 id="2-室外光照模拟"><a href="#2-室外光照模拟" class="headerlink" title="2. 室外光照模拟"></a>2. 室外光照模拟</h1><p>这部分将要介绍本文的光照模拟算法。我们首先提出了室外场景的光照模型。基于这个模型，提出了一种新的方法去求解场景的材质和光照参数。这个方法需要几个交互来部分重建场景，涉及到环境贴图技术和线性约束最小二乘法。</p>
<h3 id="2-1-室外光照模型"><a href="#2-1-室外光照模型" class="headerlink" title="2.1 室外光照模型"></a>2.1 室外光照模型</h3><p>室外场景中的物体会受到来自太阳和周围环境的光照，比如天空和周围的物体，场景中点p的光照辐射度可以表示为：<br>$$I_p(\lambda)=I_p^{sun}(\lambda)+I_p^{env}(\lambda) \tag{1}$$<br>其中$\lambda$表示R、G、B通道。</p>
<p>因为太阳可以被模拟为一个平行光源，所以：<br>$$I_p^{sun}(\lambda)=s_p^{sun}L^{sun}(\lambda)[\rho_p(\lambda)(\boldsymbol{n_p}\cdot \boldsymbol{l})+k_p(\lambda)(\boldsymbol{n_p}\cdot \boldsymbol{h_p})^{\alpha_p}] \tag{2}$$<br>其中$L^{sun}$是日光的入射强度，$\boldsymbol{l}$是入射方向，$\boldsymbol{n_p}$是点$p$的表明法线向量，$\boldsymbol{h_p}$是点$p$处光线入射方向$\boldsymbol{l}$和观察方向的角平分线，$\rho_p$是漫反射系数，$k_p$和$\alpha_p$是点$p$处的镜面属性，$s_p^{sun} \in [0,1]$是日光遮蔽系数。</p>
<p>环境光可以看作分布在球上的区域光源，我们忽略掉环境光镜面成分。本文实验显示，这种近似能够适当地保持模拟结果的准确性，同时节省大量计算量。我们用环境贴图来记录点$p$处的环境光，用$L_p^{env}$来表示环境光的分布。然后我们有：<br>$$I_p^{env}(\lambda)=\rho_p(\lambda)\int_{\Omega(\boldsymbol{n_p})}L_p^{env}(\boldsymbol{\omega},\lambda)(\boldsymbol{n_p}\cdot \boldsymbol{\omega})d\boldsymbol{\omega} \tag{3}$$<br>其中$\Omega(\boldsymbol{n_p})$是点$p$所在表面的上半球，$\boldsymbol{\omega}$是单位向量。我们使用球函数$Y_{lm}$（其中$l\ge0$而且$-l\le m \le l$）来近似计算这个积分。$I_p^{env}$可以用$Y_{lm}$的线性组合来表示[RH01]：<br>$$I_p^{env}(\lambda)=\rho_p(\lambda)\sum_{l,m}\hat{A}_lL_{lm,p}^{env}(\lambda)Y_{lm}(\boldsymbol{n_p}) \tag{4}$$<br>其中$\hat{A}_l$与$A=(\boldsymbol{n_p} \cdot \boldsymbol{\omega})$的组合系数相关，是一个常数；$L_{lm,p}^{env}(\lambda)$可以按照下式来计算：<br>$$L_{lm,p}^{env}(\lambda)=\int_{\theta=0}^{\pi}\int_{\phi=0}^{2\pi}L_p^{env}(\lambda,\theta,\phi)Y_{lm}(\theta,\phi)sin\theta ~d\theta d\phi \tag{5}$$<br>这个积分可以看作函数$L_p^{env}$和$Y_{lm}$的内积。另一方面，单位球表面$\Omega_p$可以被划分为$\Omega_p^{sky}$和$\Omega_p^{obj}$，它俩分别对应天空和周围物体。所以：<br>$$<br>\begin{align}<br>L_{lm,p}^{env}(\lambda)&amp;=L_{lm,p}^{sky}(\lambda)+L_{lm,p}^{obj}(\lambda) \\<br>&amp;=\sum_{(\theta,\phi)\in \Omega_p^{sky}}L_p^{env}(\lambda,\theta,\phi)Y_{lm}(\theta,\phi)sin\theta\Delta\theta\Delta\phi \\<br>&amp;+\sum_{(\theta,\phi)\in \Omega_p^{obj}}L_p^{env}(\lambda,\theta,\phi)Y_{lm}(\theta,\phi)sin\theta\Delta\theta\Delta\phi<br>\end{align} \tag{6}<br>$$<br>天空是一个不均匀的区域光源，它的光照分布很难从图像中计算出来。幸运地，Perez等人[PMI93]研究了天光分布并且提出了一个天空模型。该模型将天空元素$q$的绝对亮度$L_q$表示为关于实际天顶亮度$L_z^{sky}$、太阳的天顶角$\theta_s$、$q$的天顶角$\theta_q$和$q$相对于太阳的角度$\gamma_q$的函数：<br>$$L_q=L_z^{sky}\frac{f(\theta_q,\gamma_q)}{f(0,\theta_s)} \tag{7}$$<br>其中$f(\theta_q,\gamma_q)$是计算$q$的相对亮度的函数。对于一个光线入射方向$(\theta,\phi)$，记：<br>$$F(\theta,\phi)=\frac{f(\theta_q,\gamma(\theta,\phi))}{f(0,\theta_s)}$$<br>其中$\gamma(\theta,\phi)$是一个用来近似点$q$相对于太阳的角度的函数，综上：<br>$$L_{lm,p}^{sky}(\lambda)=L_z^{sky}(\lambda)\sum_{(\theta,\phi)\in \Omega_p^{sky}}F(\theta,\phi)Y_{lm}(\theta,\phi)sin\theta ~\Delta\theta \Delta\phi \tag{8}$$<br>令$R_{lm,p}^{sky}$表示公式8中的加和结果，再根据公式6有：<br>$$L_{lm,p}^{sky}=L_z^{sky}(\lambda)R_{lm,p}^{sky}+L_{lm,p}^{obj}(\lambda) \tag{9}$$<br>将它带回公式4有：<br>$$I_p^{env}(\lambda)=\rho_p(\lambda)[L_z^{sky}(\lambda)\sum_{l,m}\hat{A_l}R_{lm,p}^{sky}Y_{lm}(\boldsymbol{n_p})+\sum_{l,m}\hat{A_l}L_{lm,p}^{obj}Y_{lm}(\boldsymbol{n_p})] \tag{10}$$<br>令$P_p^{sky}=\sum_{l,m}\hat{A_l}R_{lm,p}^{sky}Y_{lm}(\boldsymbol{n_p})$、$E_p^{obj}(\lambda)=\sum_{l,m}\hat{A_l}L_{lm,p}^{obj}Y_{lm}(\boldsymbol{n_p})$，所以我们最终的室外场景光照模型是：<br>$$I_p(\lambda)=s_p^{sun}L^{sun}(\lambda)[\rho_p(\lambda)(\boldsymbol{n_p\cdot l})+k_p(\lambda)(\boldsymbol{n_p\cdot h_p})^{\alpha_p}]+\rho_p(\lambda)P_p^{sky}L_z^{sky}(\lambda)+\rho_p(\lambda)E_p^{obj}(\lambda) \tag{11}$$<br>表1列出了公式11中的部分变量：</p>
<p>表1：公式11中的部分变量</p>
<table>
<thead>
<tr>
<th style="text-align:center">变量</th>
<th style="text-align:center">定义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$P_p^{sky}$</td>
<td style="text-align:center">$\sum_{l,m}\hat{A_l}R_{lm,p}^{sky}Y_{lm}(\boldsymbol{n_p})$</td>
</tr>
<tr>
<td style="text-align:center">$E_p^{obj}$</td>
<td style="text-align:center">$\sum_{l,m}\hat{A_l}L_{lm,p}^{obj}Y_{lm}(\boldsymbol{n_p})$</td>
</tr>
<tr>
<td style="text-align:center">$R_{lm,p}^{sky}$</td>
<td style="text-align:center">公式8中的加和部分，$L_{lm,p}^{sky}=L_z^{sky}R_{lm,p}^{sky}$</td>
</tr>
<tr>
<td style="text-align:center">$L^{sun},L_z^{sky}$</td>
<td style="text-align:center">光照参数（公式2，公式7）</td>
</tr>
<tr>
<td style="text-align:center">$\hat{A_l},L_{lm,p}^{env}$</td>
<td style="text-align:center">$I_p^{env}$的组合系数（公式4）</td>
</tr>
<tr>
<td style="text-align:center">$L_{lm,p}^{sky},L_{lm,p}^{obj}$</td>
<td style="text-align:center">$L_{lm,p}^{env}=L_{lm,p}^{sky}+L_{lm,p}^{obj}$（公式6）</td>
</tr>
</tbody>
</table>
<h3 id="2-2-初始化数据采集"><a href="#2-2-初始化数据采集" class="headerlink" title="2.2 初始化数据采集"></a>2.2 初始化数据采集</h3><p>这节介绍我们采集数据的过程，这些数据用来计算室外光照模型的参数。</p>
<h4 id="几何近似"><a href="#几何近似" class="headerlink" title="几何近似."></a>几何近似.</h4><p>为了部分恢复场景的的粗略几何信息，需要校准相机。我们自动或者交互地估计场景的灭点，然后可以求出相机参数。为了简化几何重建，我们设置地面的方程为$z=0$。然后用户在地面上画几条线，每一条都对应着一个垂直平面和地面的交线。这些平面就表示了场景的粗略几何形状。有了这些几何信息和相机参数，就可以计算出公式11中的$(\boldsymbol{n_p\cdot h_p})$。</p>
<h4 id="合成环境贴图"><a href="#合成环境贴图" class="headerlink" title="合成环境贴图"></a>合成环境贴图</h4><p>为了近似光照模型中的$E_p^{obj}(\lambda)$，我们应该合成一张没有天空区域的环境贴图。用天空遮罩来近似地移除天空区域 [HEH07]。然后用 Lalonde方法来生成点$p$处期望的环境贴图。通过公式6，环境贴图会被用来计算$L_{lm,p}^{obj}(\lambda)$，然后$E_p^{obj}(\lambda)$就可以被计算出来了（公式10）。</p>
<h4 id="太阳方位估算"><a href="#太阳方位估算" class="headerlink" title="太阳方位估算"></a>太阳方位估算</h4><p>太阳是一个平行光源。Perez天空模型指出，天空的光照分布取决于太阳的位置。Landonde等人[LEN11]提出了一种基于单张室外图像的自动化方法去估算太阳的位置，我们也采用了这种方法。然而，这个方法需要天空、地面阴影和场景里的多个垂直平面。对于没有包含这三个部分的图像，用户需要手动地标明太阳的位置，这个也很简单。用户只需要画两条线来表示一个垂直物体和它的阴影。完成这步以后，$P_p^{sky}$和$(\boldsymbol{n_p\cdot l})$都可以计算出来了。</p>
<h4 id="太阳遮蔽系数近似"><a href="#太阳遮蔽系数近似" class="headerlink" title="太阳遮蔽系数近似"></a>太阳遮蔽系数近似</h4><p>令$C^{sun}$表示只被日光照射并且没有阴影的场景图像。使用公式1和公式2中的符号，我们有：<br>$$<br>\begin{align}<br>I_p(\lambda)&amp;=s_p^{sun}C_p^{sun}(\lambda)I_p^{env}(\lambda)\\<br>&amp;=s_p^{sun}(C_p^{sun}(\lambda)+I_p^{env}(\lambda))+(1-s_p^{sun})I_p^{env}(\lambda)<br>\end{align} \tag{12}<br>$$<br>显然，$I$是由$(C^{sun}+I^{env})$（移除阴影的图像）作为前景，$I^{env}$（阴影图像）作为背景所构成的。所以，太阳遮蔽系数可以通过消光算法得到。我们使用Levin方法 [LLW08]来获取阴影遮罩图像，这个方法需要用户通过几次涂鸦来指出前景（无阴影区域）和背景（阴影区域）。或者，我们可以使用自适应的阴影遮罩算法来估算遮蔽系数，但是自适应方法看上去没有Levin方法稳定。</p>
<h3 id="2-3-光照近似"><a href="#2-3-光照近似" class="headerlink" title="2.3 光照近似"></a>2.3 光照近似</h3><p>现在公式11中的未知数是$L^{sun}(\lambda)$、$L_z^{sky}(\lambda)$、$\rho_p(\lambda)$、$k_p(\lambda)$和$\alpha_p$。这节将介绍怎样去估算它们。我们首先提出了一种估算场景反射率的算法，然后就可以使用恢复出来的材质求解光照参数。</p>
<h4 id="2-3-1-恢复材质反射率"><a href="#2-3-1-恢复材质反射率" class="headerlink" title="2.3.1 恢复材质反射率"></a>2.3.1 恢复材质反射率</h4><p>我们通过假设一个完美的漫反射情况来开始算法介绍，然后再考虑镜面表明的情况。</p>
<h5 id="漫反射材质的情况"><a href="#漫反射材质的情况" class="headerlink" title="漫反射材质的情况"></a>漫反射材质的情况</h5><p>如果我们忽略镜面成分，光照模型可以写成下面这样：<br>$$I_p(\lambda)=\rho_p(\lambda)[P_p^{sun}L^{sun}(\lambda)+P_p^{sky}L_z^{sky}(\lambda)+E_p^{obj}(\lambda)] \tag{13}$$<br>其中，$P_p^{sun}=s_p^{sun}(\boldsymbol{n_p\cdot l})$。等式13两边同时除以$\rho_p(\lambda)$有：<br>$$P_p^{sun}L^{sun}(\lambda)+P_p^{sky}L_z^{sky}(\lambda)-I_p(\lambda)\frac{1}{\rho_p(\lambda)}=-E_p^{obj}(\lambda) \tag{14}$$<br>注意这是一个关于未知数$L^{sun}(\lambda)$、$L_z^{sky}(\lambda)$和$1/\rho_p(\lambda)$的线性方程，如果我们在场景里选择$n$个采样点，就可以建立起一个线性方程组。然而，在约束条件下，$3n$个方程有$3n+6$个未知数。幸好，在场景里面不同的点可能共享相同的材质，这会极大地减少未知数的数量。和Bousseau方法[BPD09]类似，我们让用户通过画刷选择具有相同材质的点。为简单起见，我们还假设画刷覆盖的所有点共享相同的环境贴图。</p>
<p>还有一些额外限制可以用来提高近似精度。我们首先探索由于日光的光谱分布引起的颜色约束。对于日光我们有$L^{sun}(R)&gt;L^{sun}(G)&gt;L^{sun}(B)$，而且对于天光有$L_z^{sky}(R)&lt; L_z^{sky}(G)&lt; L_z^{sky}(B)$；$\rho_p(\lambda)$是点$p$的漫反射系数，所以一定是$1/\rho_p(\lambda)\ge 1$。实际上，设置$\rho_p(\lambda)\ge 5$会让近似的天空获得更好的视觉效果。</p>
<p>这个线性方程组可以通过线性约束最小二乘法来求解。场景中更多点的漫反射系数可以公式13和近似的$L^{sun}(\lambda)$和$L_z^{sky}(\lambda)$来求解。不过，没有必要使用整张图像来计算光照，所以我们只恢复画刷所在包围盒里的那些点的漫反射系数。图2表示了我们所做的交互和恢复的材质。<br><img src="http://oqcvzqam1.bkt.clouddn.com/%E5%9F%BA%E4%BA%8E%E4%BC%A0%E7%BB%9F%E7%85%A7%E7%89%87%E7%9A%84%E5%A2%9E%E5%BC%BA%E6%88%B7%E5%A4%96%E5%9C%BA%E6%99%AF%E7%9A%84%E5%85%89%E7%85%A7%E6%A8%A1%E6%8B%9F_2.png" alt=""></p>
<p><center>图2：图中蓝色的画笔是用户画的，表明相同画笔覆盖的那些点由同一种材质组成。地面上的点恢复的反射率显示在右图里。</center></p>
<h5 id="镜面材质的情况"><a href="#镜面材质的情况" class="headerlink" title="镜面材质的情况"></a>镜面材质的情况</h5><p>本文方法也考虑到了镜面反射率较低的材质。和Boivin等人 [BG01]的方法类似，我们首先忽略这些表面的镜面反射成分，从而获得近似的材质参数$\rho^0$和光照参数$L^0$，以它们作为初始值，然后最终材质可以通过程序细化方法得到。有两种程序：1）更新材质参数；2）更新光照参数。这两个程序交替执行，直到收敛。</p>
<ul>
<li><strong>更新材质参数</strong><br>镜面表面的材质参数包括$\rho_p(\lambda)$、$k_p(\lambda)$和$\alpha_p$。我们在这里做一个近似，对场景中的这些镜面表面设置$\alpha_p$为一个常数，并且假设$k_p(\lambda)$在空间上变化缓慢。我们还对固有图像进行了假设，即漫反射分量由具有潜在清晰边界的分段常数碎片组成。使用这些初始化的材质和光照参数，可以用一个目标函数来求解$\rho_p(\lambda)$、$k_p(\lambda)$和$\alpha_p$。<br>$$arg~min_{\rho,k,\alpha}\sum_{p\in Q}\sum_{\lambda \in C}|I_p(\lambda)-I_p^*(\lambda)|^2+\mu_1\omega_p|\nabla\rho_p(\lambda)|^2+\mu_2(\rho_p(\lambda)-\rho_p^0(\lambda))^2+\mu_3|\nabla k_p(\lambda)| \tag{15}$$<br>其中，$C={R,G,B}$，$Q$是被选中的点集，$\mu_1,\mu_2,\mu_3$是权重，在本文实验里它们被设置为$\mu_1=5.0,\mu_2=3.0,\mu_3=5.0$。第一项确保合成的图像$I^*$符合原始图像；第三项确保估算的$\rho_p(\lambda)$保持在其初始值附近；第二项和最后一项用于保证$\rho$和$k$的平滑，$\omega_p$是一个用来惩罚具有最大梯度幅度像素的加权函数。</li>
<li><strong>更新光照参数</strong><br>得到材质参数以后，我们可以把公式11重写为：<br>$$M_p^{sun}(\lambda)L^{sun}(\lambda)+M_p^{sky}(\lambda)L_z^{sky}(\lambda)=B_p(\lambda) \tag{16}$$<br>其中：<br>$$<br>\begin{align}<br>&amp; B_p(\lambda)=I_p(\lambda)-\rho_p(\lambda)E_p^{obj}(\lambda) \\<br>&amp; M_p^{sky}(\lambda)=\rho_p(\lambda)P_p^{sky} \\<br>&amp; M_p^{sun}(\lambda)=s_p^{sun}[\rho_p(\lambda)(\boldsymbol{n_p\cdot l})+k_p(\lambda)(\boldsymbol{n_p\cdot h_p})^{\alpha_p}]<br>\end{align}<br>$$<br>我们从Q中均匀地采样并把它们嵌入到线性方程组中。再使用颜色约束，就可以通过求解线性约束最小二乘问题来得到光照参数。图3是在考虑和不考虑材质的镜面属性的情况下，使用恢复出来的光照得到的合成结果。<br><div style="text-align:center;"><br><img src="http://oqcvzqam1.bkt.clouddn.com/%E5%9F%BA%E4%BA%8E%E4%BC%A0%E7%BB%9F%E7%85%A7%E7%89%87%E7%9A%84%E5%A2%9E%E5%BC%BA%E6%88%B7%E5%A4%96%E5%9C%BA%E6%99%AF%E7%9A%84%E5%85%89%E7%85%A7%E6%A8%A1%E6%8B%9F_3_1.png" width="50%" height="50%"><br>图3：圆环体是插入图像中的虚拟物体，并使用恢复的光照进行渲染。可以发现，（a）中圆环体的阴影和树的阴影在地面上的重叠区域看起来不如（b）那么逼真。<br></div><h4 id="光照参数估计"><a href="#光照参数估计" class="headerlink" title="光照参数估计"></a>光照参数估计</h4>我们使用同样的方法来更新2.3.1节（公式16）中描述的光照参数，再加上近似的表面反射率来解决光照问题。当$L^{sun}$表示平行光的强度时，$L_z^{sky}(\lambda)$用来生成一张完整的HDR环境贴图来模拟环境光。这两个光源用于模拟室外光照。图4是用本文方法合成的不同场景的环境贴图。<br><div style="text-align:center;"><br><img src="http://oqcvzqam1.bkt.clouddn.com/%E5%9F%BA%E4%BA%8E%E4%BC%A0%E7%BB%9F%E7%85%A7%E7%89%87%E7%9A%84%E5%A2%9E%E5%BC%BA%E6%88%B7%E5%A4%96%E5%9C%BA%E6%99%AF%E7%9A%84%E5%85%89%E7%85%A7%E6%A8%A1%E6%8B%9F_4.png" width="50%" height="50%"><br>图4：用本文方法生成的最终的环境贴图，只展示对应于特定曝光时间的HDR图，天空的外观取决于$L_z^{sky}(\lambda)$和Perez天空模型，而周围的物体用Lalonde方法生成 [LE10]。<br></div><h1 id="3-阴影模型"><a href="#3-阴影模型" class="headerlink" title="3. 阴影模型"></a>3. 阴影模型</h1>太阳是室外场景的主要光源，当入射到场景的部分或全部光线被遮挡时，就会产生阴影。合成物体将投射阴影到真实环境里，而且合成物体可能会受到来自真实物体的阴影投射。这节尝试去模拟这种现象。我们首先提出了一种新的方法来处理真实和虚拟的阴影，然后举例说明一种往视频里插入虚拟物体及其阴影的方法。</li>
</ul>
<h2 id="3-1-在真实阴影里的虚拟物体"><a href="#3-1-在真实阴影里的虚拟物体" class="headerlink" title="3.1 在真实阴影里的虚拟物体"></a>3.1 在真实阴影里的虚拟物体</h2><p>如果遮挡物体的几何形状已知，虚拟物体的阴影就可以被合成出来。不幸的是，这些信息从传统照片中获取不到。我们提出了一种新的方法来将真实阴影投射到虚拟物体表面。会用到在2.2节中计算的场景粗略几何信息和阴影遮罩图像（一种标量图像，其中在阴影里的像素对应的值是0，不在阴影里的值在(0,1]之间）。为了方便，我们把阴影遮罩图像表示为$M_S^{img}$。</p>
<p>我们只考虑地面上的真实阴影，这个方法也可以扩展至那些阴影表面几何形状已知的复杂表面。假如我们插入一个虚拟物体到场景里，我们从虚拟物体的一个顶点$v$沿着日光方向发出一条射线$r$，计算它和地平面的交点，把交点记为$i$。如果$i$在阴影里，倘若$v$和$i$之间没有其他物体，那么$v$一定会在阴影里。这意味着$v$是否在阴影里仅仅取决于$i$的状态，$i$的状态可以通过$M_S^{img}$中对应的像素$p_i$来检测。</p>
<p>接下来的问题是怎样合成遮蔽的虚拟物体上的阴影。注意$v$和$i$之间的关系可以被定义为一张纹理贴图。有了这张贴图，我们可以把阴影遮罩图像自动投影到虚拟物体的表面。因为阴影区域仅仅被环境光照亮，所以这个区域可以用一张阴影遮罩图像$M_S^{obj}$来表示。然后我们渲染虚拟物体两次，来获得虚拟物体的完整渲染结果，一次考虑日光光照，另一次考虑环境光，将这两个成分分别表示为$I_{obj}^{sun}$和$I_{obj}^{env}$。最终图像$I_{obj}$可以表示为：<br>$$I_{obj}=M_S^{obj}\odot I_{obj}^{sun}+I_{obj}^{env} \tag{17}$$<br>其中$\odot$是Hadamard乘积。</p>
<p>注意，如果地面上的阴影是$v$和$i$之间的某个物体$O$所投射的，那么上述将失败，这也是我们方法的局限。为了避免这种情况，用户需要手动指出这些阴影区域，并从$M_S^{img}$中删除它们。最终的阴影图像称为阴影纹理。图5(a)和(b)展示了有我们方法估计的阴影纹理和阴影遮罩，虚拟物体的渲染结果如图5(c)所示。</p>
<div style="text-align:center;"><br><img src="http://oqcvzqam1.bkt.clouddn.com/%E5%9F%BA%E4%BA%8E%E4%BC%A0%E7%BB%9F%E7%85%A7%E7%89%87%E7%9A%84%E5%A2%9E%E5%BC%BA%E6%88%B7%E5%A4%96%E5%9C%BA%E6%99%AF%E7%9A%84%E5%85%89%E7%85%A7%E6%A8%A1%E6%8B%9F_5.png" width="70%" height="70%"><br>图5：我们尝试将一个斯坦福佛陀整合到场景里。本文的阴影遮罩是在不知道遮挡对象的几何形状的情况下生成的。渲染结果表明地面上的阴影很自然地投射到虚拟物体上。<br></div><br>## 3.2 虚拟阴影处理<br>或者，虚拟物体也可以投射阴影到环境里，但是它只对$M_S^{img}$中值不为0的像素有效。由于我们已经得到了阴影遮罩图像$M_S^{img}$，所以可以避免虚拟和真实阴影之间的重叠错误。本文方法组成4个图像：前两个是原始场景分别在日光和环境光照射下的图像，表示为$I_{scene}^{sun}$和$I_{scene}^{env}$。后两个是包含虚拟物体的增强场景，分别在日光和环境光照射下的图像，表示为$I_{v-scene}^{sun}$和$I_{v-scene}^{env}$。使用阴影遮罩图像$M_S^{img}$，我们可以生成原始图像的增强阴影遮罩，它在像素$p$的值可以通过下式计算：<br>$$I_S(p)=\frac{I_{v-scene}^{sun}(p)M_S^{img}(p)+I_{v-scene}^{env}(p)}{I_{scene}^{sun}(p)M_S^{img}(p)+I_{scene}^{env}(p)} \tag{18}$$<br>对于一个像素$p$，如果$M_S^{img}(p_s)=0$，无论虚拟物体是否投射阴影到$p_s$上，$I_S(p_s)$的值都是$I_{v-scene}^{env}(p_s)/I_{scene}^{env}(p_s)$。如果$M_S^{img}(p)\ne0$，$I_{v-scene}^{sun}$才会对像素$p$有效（图6）。<br><div style="text-align:center;"><br><img src="http://oqcvzqam1.bkt.clouddn.com/%E5%9F%BA%E4%BA%8E%E4%BC%A0%E7%BB%9F%E7%85%A7%E7%89%87%E7%9A%84%E5%A2%9E%E5%BC%BA%E6%88%B7%E5%A4%96%E5%9C%BA%E6%99%AF%E7%9A%84%E5%85%89%E7%85%A7%E6%A8%A1%E6%8B%9F_6.png" width="50%" height="50%"><br>图6：本文方法避免了真实阴影和虚拟阴影之间的重叠问题。(a)输入图像，(b)合成结果，阴影细节显示在图片底部，合成汽车的阴影在没有被真实阴影覆盖的地面上起作用了。<br></div><br>## 3.3 插入合成物体<br>在本文方法获得室外光照参数、检测地面阴影区域和重建部分场景几何信息以后，用户就可以自如地将合成物体插入到场景里了。将室外场景的传统照片表示为$I$，最终的合成图像$I_{final}$可以由下式生成：<br>$$I_{final}=M\odot I_{obj}+(1-M)\odot I_S\odot I$$<br>其中，$M$是虚拟物体的遮罩（一种标量图像，在虚拟物体投影区域之外的像素值为0，投影区域之内的像素值在(0,1]之间）。<br><br># 4. 实验<br>我们在具有Core2 Duo E7400 2.80GHz CPU和3GB RAM的PC上实现了所提出的方法。我们选择了几张室外场景图像，并用本文方法恢复了他们的照明环境。<br><br>我们使用估计的光照渲染了一些虚拟物体，并将它们整合到在晴天（图7）或阴天（图8）捕获的室外图像中。恢复的光照包含环境信息，从而能够生成高质量的渲染结果。我们生成了两个虚拟对象的动画序列来检查移动物体上的阴影投射。 图9展示出了合成视频序列中的一些视频帧。<br><div style="text-align:center;"><br><img src="http://oqcvzqam1.bkt.clouddn.com/%E5%9F%BA%E4%BA%8E%E4%BC%A0%E7%BB%9F%E7%85%A7%E7%89%87%E7%9A%84%E5%A2%9E%E5%BC%BA%E6%88%B7%E5%A4%96%E5%9C%BA%E6%99%AF%E7%9A%84%E5%85%89%E7%85%A7%E6%A8%A1%E6%8B%9F_7.png" width="50%" height="50%"><br>图7：将具有复杂材质的虚拟物体插入到晴天捕获的图像中<br></div>

<div style="text-align:center;"><br><img src="http://oqcvzqam1.bkt.clouddn.com/%E5%9F%BA%E4%BA%8E%E4%BC%A0%E7%BB%9F%E7%85%A7%E7%89%87%E7%9A%84%E5%A2%9E%E5%BC%BA%E6%88%B7%E5%A4%96%E5%9C%BA%E6%99%AF%E7%9A%84%E5%85%89%E7%85%A7%E6%A8%A1%E6%8B%9F_8.png" width="50%" height="50%"><br>图8：将虚拟物体插入到阴天捕获的图像中<br></div>

<div style="text-align:center;"><br><img src="http://oqcvzqam1.bkt.clouddn.com/%E5%9F%BA%E4%BA%8E%E4%BC%A0%E7%BB%9F%E7%85%A7%E7%89%87%E7%9A%84%E5%A2%9E%E5%BC%BA%E6%88%B7%E5%A4%96%E5%9C%BA%E6%99%AF%E7%9A%84%E5%85%89%E7%85%A7%E6%A8%A1%E6%8B%9F_9.png" width="50%" height="50%"><br>图9：我们将动画嵌入到两个背景图像中。 第一排显示滚动篮球，第二排显示跳跃式足球。<br></div><br>我们把用本文方法恢复出来的光照下渲染虚拟物体的结果，和 [KHFH11]方法假设均匀的半球光源、使用光探头得到的渲染结果进行了对比（图10）。可以看到，均匀光源不能精确模拟真实场景的光照分布，合成物体的底部非常暗，因为均匀的光源半球没有考虑到地面反射的光线。光探头试图记录场景的真实光照。我们使用名为HDR SHOP的软件来合成与光探头相对应的场景的环境地图。由于太阳及其周围区域太亮而不能被相机捕获，因此，太阳被记录为HDR环境贴图中的区域光源，导致虚拟物体表面上的不真实阴影和明亮区域。另一方面，[KHFH11]的方法手动设置太阳光的强度，因此，很难保持虚拟阴影区域的颜色与周围环境一致。我们的方法恢复了定向光源和环境贴图，从而实现了更好的渲染效果。此外，我们使用环境贴图作为光源，加速虚拟物体的渲染。 即使对于复杂的模型，渲染过程也只需几分钟。[KHFH11]的方法需要渲染整个场景来计算全局光照，通常需要几个小时。<br><br><div style="text-align:center;"><br><img src="http://oqcvzqam1.bkt.clouddn.com/%E5%9F%BA%E4%BA%8E%E4%BC%A0%E7%BB%9F%E7%85%A7%E7%89%87%E7%9A%84%E5%A2%9E%E5%BC%BA%E6%88%B7%E5%A4%96%E5%9C%BA%E6%99%AF%E7%9A%84%E5%85%89%E7%85%A7%E6%A8%A1%E6%8B%9F_10.png" width="50%" height="50%"><br>图10：本文的合成结果与其他方法的比较。从左到右，合成图像由均匀光源，光探针，[KHFH11]和本文方法产生。我们在第一个场景中插入一条龙和一个篮球，而在第二个场景中插入一个路障和一个足球。<br></div>


<p>我们还在虚拟物体和真实场景的阴影交互上，将本文方法和[KHFH11]的方法做了比较（图11）。我们将斯坦福佛陀和一个球插入第一行所示的图像中。由于[KHFH11]的方法不能准确地恢复日光的强度，导致佛像的外观与实际情况不同。第二行中的虚拟物体是圆环体，显然，我们的方法在软阴影处理中产生了更好的效果。</p>
<p><div style="text-align:center;"><br><img src="http://oqcvzqam1.bkt.clouddn.com/%E5%9F%BA%E4%BA%8E%E4%BC%A0%E7%BB%9F%E7%85%A7%E7%89%87%E7%9A%84%E5%A2%9E%E5%BC%BA%E6%88%B7%E5%A4%96%E5%9C%BA%E6%99%AF%E7%9A%84%E5%85%89%E7%85%A7%E6%A8%A1%E6%8B%9F_11.png" width="50%" height="50%"><br>图11：本文阴影模型结果与[KHFH11]方法的比较。<br></div><br>本文的合成结果也与实际情况进行了比较。我们采用了几个真实的石膏模型作为参考对象，并拍摄了包含这些模型的不同室外场景的照片作为真实结果。然后，我们拍摄了没有这些模型的相同场景的照片，作为背景图像。将这些石膏模型作为虚拟物体插入到背景图像中。将增强场景的渲染结果与真实结果进行了比较。我们首先假设石膏模型有均匀的兰伯特反射率并交互地调整它们的反射系数，直到它们能够成功匹配一个选定的测试图像。图12显示了我们的两个比较结果。 我们的演示视频中可以找到更多测试场景。</p>
<p><div style="text-align:center;"><br><img src="http://oqcvzqam1.bkt.clouddn.com/%E5%9F%BA%E4%BA%8E%E4%BC%A0%E7%BB%9F%E7%85%A7%E7%89%87%E7%9A%84%E5%A2%9E%E5%BC%BA%E6%88%B7%E5%A4%96%E5%9C%BA%E6%99%AF%E7%9A%84%E5%85%89%E7%85%A7%E6%A8%A1%E6%8B%9F_12.png" width="50%" height="50%"><br>图12：用户调查的结果。 对于每个场景，蓝色条表示难以识别真实结果的用户百分比; 而绿线代表认为我们的结果更加真实的用户百分比。水平红线表示50％的线。还演示了为每个场景做出决定的平均时间成本。图表下方的图像显示了我们在用户研究中使用的两个场景。<br></div><br>我们恢复的照明可能与实际照明条件不同这并不奇怪，但是，这不应该阻止我们获得逼真的合成结果。 我们进行了一项用户研究，以衡量用户如何区分基本结果和合成结果。招募了40名研究生作为这项任务的测试者，其中大多数都有图形背景。 我们的测试采用了十个不同的场景，所有这些场景都是以随机排列的顺序呈现的。对于每个场景，演示了真实结果和合成结果，并且图像放置（左侧或右侧）也是随机的。用户被告知每对图像有两种情况：(1) 一个是真实照片，另一个是合成结果; (2) 两者都是真实照片。因此，用户有三种选择：左图像是真实照片，右图像是真实照片，两者都是真实照片。用户研究的结果如图12所示。发现超过一半的用户很难识别大多数场景中的真正结果，一部分用户甚至认为合成结果更加真实。对于场景6,65％的用户可以识别真实照片，他们的证据是阴影球与真实图片相比过于平滑。 大多数用户承认，如果不与真实结果进行比较，很难找出合成图像的异常。</p>
<p>请注意，我们的算法仅在图像的某些区域恢复材质，我们从所选像素集（我们的测试中每个都对应5个像素）均匀地采样像素，以计算光照参数。表2中显示了选择不同尺寸像素集的时间开销。关于镜面反射材质的时间成本是指细化程序的一次迭代，在我们的大多数示例中迭代执行五到十次。对于阴影投射，其效率主要取决于创建纹理贴图的时间，贴图运行起来是很快的。对于包含50000个顶点的模型，其时间开销仅为半秒，对于包含263144个顶点的模型，则为2.8秒。</p>
<p>表2：光照计算的时间开销</p>
<table>
<thead>
<tr>
<th style="text-align:center">数量</th>
<th style="text-align:center">漫反射(秒)</th>
<th style="text-align:center">镜面反射(秒)</th>
<th style="text-align:center">光照（毫秒）</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"> 70×70</td>
<td style="text-align:center">2.86</td>
<td style="text-align:center">2.30</td>
<td style="text-align:center">468</td>
</tr>
<tr>
<td style="text-align:center">110×110</td>
<td style="text-align:center">3.75</td>
<td style="text-align:center">4.83</td>
<td style="text-align:center">812</td>
</tr>
<tr>
<td style="text-align:center">230×230</td>
<td style="text-align:center">5.63</td>
<td style="text-align:center">20.43</td>
<td style="text-align:center">2158</td>
</tr>
</tbody>
</table>
<p>尽管在我们的方法中近似镜面材质很耗时，但是用于恢复漫反射材质和照明参数的计算是很高效的。由于室外场景中的许多物体几乎都是漫反射的，因此，对于大多数室外图像，我们的方法运行得相当快。 目前，我们采用均匀采样，自适应采样策略将减少所需采样数量，使我们的方法也可以适用于在线视频光照恢复。</p>
<h1 id="5-总结和未来工作"><a href="#5-总结和未来工作" class="headerlink" title="5. 总结和未来工作"></a>5. 总结和未来工作</h1><p>我们提出了一种基于传统照片模拟室外场景光照的新方法。 我们采用与光照相关的先验信息，并将它们合并到渲染方程中，以得出室外光照模型。采用球函数将从图像中提取的复杂光照信息减少为一组参数，使得光照恢复更加容易。 我们的方法通过求解线性问题来估计漫反射表面的反射率，而在镜面材质的情况下执行迭代方法。然后可以通过在某些约束下求解线性最小二乘问题来恢复光照。利用这些光照参数，我们可以构建高质量的场景环境贴图，以支持逼真的渲染。 我们还探讨了在将虚拟物体插入真实图像时可能出现的阴影投射问题。提出了一种基于纹理映射的新方法，将真实阴影投射到合成物体上。最后，我们采用统一的方案来生成虚拟和真实物体之间正确阴影投射的合成图像。 实验结果证明了本文方法的有效性和灵活性。</p>
<p>但是，本文工作也有一些局限。 如果可用信息不足以确定消失点，则摄像机校准和几何恢复可能会失败。 本文方法无法处理具有复杂纹理的场景，因为很难选择具有相似材质的点。 此外，我们的方法还不适用于具有强镜面反射的表面。 我们的阴影建模方法还需要进一步增强以处理某些特定情况。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li>[BG01] B OIVIN S., G AGALOWICZ A.: Image-based rendering of diffuse, specular and glossy surfaces from a single image. In Proc. ACM Siggraph (August 2001), Los Angeles, California,USA, pp. 107–116. 5</li>
<li>[BPD09] B OUSSEAU A., P ARIS S., D URAND F.: User-assisted intrinsic images. ACM Transactions on Graphics 28, 5 (December 2009), 130. 4</li>
<li>[Deb98] D EBEVEC P.: Rendering synthetic objects into real scenes: bridging traditional and image-based graphics with global illumination and high dynamic range photography. In Proc. SIGGRAPH’98 (July 1998), Oralando, florida, USA, pp. 189–198. 2</li>
<li>[GM00] G IBSON S., M URTA A.: Interactive rendering with real-world illumination. In Proceedings of the Eurographics Work-shop on Rendering Techniques (2000), pp. 365–376. 2</li>
<li>[HEH07] H OIEM D., E FROS A. A., H EBERT M.: Recovering surface layout from a single image. International Journal of Computer Vision 75, 1 (October 2007), 151–172. 4</li>
<li>[HFC ? 09] H ABER T., F UCHS , C HRISTIAN , B EKAER P., S EIDEL H.-P. P., G OESELE M., L ENSCH H. P. A.: Relighting objects from image collections. In Proceeding CVPR09 (june 2009), Miami Beach, Florida, USA, pp. 627–634. 2</li>
<li>[HHF09] H EDAU V., H OIEM D., F ORSYTH D.: Recovering the spatial layout of cluttered rooms. In Proc. ICCV (September 2009), Champaign, USA, pp. 1849–1856. 4 [JAL05] J ACOBS K., A NGUS C., L OSCOS C.: Automatic generation of consistent shadows for augmented reality. In Proceedings of Graphics Interface 2005 (May 2005), Waterloo, Ontario,Canada, pp. 113–120. 2</li>
<li>[JL06] J ACOBS K., L OSCOS C.: Classification of illumination methods for mixed reality. Computer Graphics Forum 25, 1(2006), 29–51. 2</li>
<li>[KHFH11] K ARSCH K., H EDAU V., F ORSYTH D., H OIEM D.:Rendering synthetic objects into legacy photographs. In Proc.ACM Siggraph Aisa (December 2011), Hong Kong, China,pp. 157:1–157:12. 2, 7, 8, 9</li>
<li>[KTM ? 10] K NECHT M., T RAXLER C., M ATTAUSCH O., P UR -GATHOFER W., W IMMER M.: Differential instant radiosity for mixed reality. In Proceedings of ISMAR (October 2010), Miami Beach, Florida, USA, pp. 99–107. 2</li>
<li>[LE10] L ALONDE J.-F., E FROS A. A.: Synthesizing Environment Maps from a Single Image. Tech. Rep. CMU-RI-TR 10-24, Robotics Institute, Carnegie Mellon University, July 2010. 4, 6</li>
<li>[LEN09] L ALONDE J.-F., E FROS A. A., N ARASIMHAN S. G.:Webcam clip art: appearance and illuminant transfer from timelaps squences. ACM Transactions on Graphics 28, 5 (December 2009), 131:1–131:10. 2</li>
<li>[LEN11] L ALONDE J.-F., E FROS A. A., N ARASIMHAN S. G.:Estimating the natural illumination conditions from a single outdoor image. International Journal of Computer Vision 98, 2 (2011), 123–145. 4</li>
<li>[LG12] L IU Y., G RANIER X.: Online tracking of outdoor lighting variations for augmented reality with moving cameras. IEEE Trans. Vis. Comput. Graph 18, 4 (April 2012), 573–580. 2</li>
<li>[LLW08] L EVIN A., L ISCHINSKI D., W EISS Y.: A closed-form solution to natural image matting. IEEE Transactions on Pattern Analysis and Machine Intelligence 30, 2 (2008), 228–242. 4</li>
<li>[LQX ? 09] L IU Y., Q IN X., X U S., E IHACHIRO N., P ENG Q.:Light source estimation of outdoor scenes for mixed reality. Vis.Comput. 25, 5-7 (April 2009), 637–646. 2</li>
<li>[MJA06] M ADSEN C. B., J ENSEN T., A NDERSEN M. S.: Real-time image-based lighting for outdoor augmented reality under dynamically changing illumination conditions. In Proceedings: International Conference on Graphics Theory and Applications (February 2006), Setubal, Portugal, pp. 364–371. 2</li>
<li>[NGM ? 11] N OWROUZEZAHRAI D., G EIGER S., M ITCHELL K.,S UMNER R., J AROSZ W., G ROSS M.: Light factorization for mixed-frequency shadows in augmented reality. In Proceedings of ISMAR (Oct. 2011). 2</li>
<li>[PMI93] PEREZ R., M R. S. J., INEICHEN P.: An all-weather model for sky luminance distribution. Solar Energy 50, 3 (March 1993), 235–245. 2, 3 </li>
<li>[RH01] R AMAMOORTHI R., H ANRAHAN P.: On the relationship between radiance and irradiance: determining the illumination from images of a convex lambertian object. Journal of the Optical Society of America A 18, 10 (October 2001), 2448–2459.3</li>
<li>[SSI99] S ATO I., S ATO Y., I KEUCHI K.: Acquiring a radiance distribution to superimpose virtual objects onto a real scene.IEEE TVCG 5, 1 (March 1999), 542–547. 2</li>
<li>[SSI03] S ATO I., S ATO Y., I KEUCHI K.: Illumination from shadows. IEEE Trans. Pattern Analysis and Machine Intelligence 25,3 (March 2003), 290–300. 2</li>
<li>[YWAC06] Y U T., W ANG H., A HUJA N., C HEN W.-C.: Sparse lumigraph relighting by illumination and reflectance estimation from multi-view images. In Proceeding Siggraph2006 (july 2006), Boston, Massachusetts, USA, pp. 175–175. 2</li>
<li>[ZY01] Z HANG Y., Y ANG Y.-H.: Multiple illuminant direction detection with application to image synthesis. IEEE Transactions on Pattern Analysis and Machine Intelligence 23, 8 (August 2001), 915–920. 2</li>
</ul>

            </div>

            <!-- Post Comments -->
            
    <!-- 使用 DISQUS_CLICK -->
<div id="disqus-comment">
    <div id="disqus_thread"></div>

<!-- add animation -->
<style>
	.disqus_click_btn {
            line-height: 30px;
            margin: 0;
            min-width: 50px;
            padding: 0 14px;
            display: inline-block;
            font-family: "Roboto", "Helvetica", "Arial", sans-serif;
            font-size: 14px;
            font-weight: 400;
            text-transform: uppercase;
            letter-spacing: 0;
            overflow: hidden;
            will-change: box-shadow;
            transition: box-shadow .2s cubic-bezier(.4, 0, 1, 1), background-color .2s cubic-bezier(.4, 0, .2, 1), color .2s cubic-bezier(.4, 0, .2, 1);
            outline: 0;
            cursor: pointer;
            text-decoration: none;
            text-align: center;
            vertical-align: middle;
            border: 0;
            background: rgba(158, 158, 158, .2);
            box-shadow: 0 2px 2px 0 rgba(0, 0, 0, .14), 0 3px 1px -2px rgba(0, 0, 0, .2), 0 1px 5px 0 rgba(0, 0, 0, .12);
            color: #fff;
            background-color: #7EC0EE;
            text-shadow: 0
        }
</style>
	
<div class="btn_click_load" id="disqus_bt"> 
    <button class="disqus_click_btn">点击查看评论</button>
</div>

<!--
<script type="text/javascript">
$('.btn_click_load').click(function() {
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'http-miccall-tech'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    document.getElementById('disqus_bt').style.display = "none";
});
</script>
-->
<script type="text/javascript">
    var disqus_config = function () {
        this.page.url = 'http://yoursite.com/2018/07/25/基于传统照片的增强室外场景的光照模拟/';  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'http://yoursite.com/2018/07/25/基于传统照片的增强室外场景的光照模拟/'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
</script>

<script type="text/javascript">
    $('.btn_click_load').click(function() {  //click to load comments
        (function() { // DON'T EDIT BELOW THIS LINE
            var d = document;
            var s = d.createElement('script');
            s.src = '//http-miccall-tech.disqus.com/embed.js';
            s.setAttribute('data-timestamp', + new Date());
            (d.head || d.body).appendChild(s);
        })();
        $('.btn_click_load').css('display','none');
    });
</script>
</div>
<style>
    #disqus-comment{
        background-color: #eee;
        padding: 2pc;
    }
</style>


        </div>
        <!-- Copyright 版权 start -->
                <div id="copyright">
            <ul>
                <li>&copy;Powered By <a href="https://hexo.io/zh-cn/" style="border-bottom: none;">hexo</a></li>
                <li>Design: <a href="http://miccall.tech " style="border-bottom: none;">miccall</a></li>
            </ul>
            
            	<span id="busuanzi_container_site_pv">2018总访问量<span id="busuanzi_value_site_pv"></span>次</span>
			
        </div>
    </div>
</body>



 	
</html>
